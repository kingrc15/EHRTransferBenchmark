Experiment dir: ./exp/Test_phen_midwest
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.43720813110470774
Train: epoch: 1, loss = 0.42286929436028003
Train: epoch: 1, loss = 0.4165690532575051
Train: epoch: 1, loss = 0.41363827956840393
Train: epoch: 1, loss = 0.4122613756507635
Train: epoch: 1, loss = 0.40934488823016485
Train: epoch: 1, loss = 0.40588282171104634
Train: epoch: 1, loss = 0.4038380798790604
Train: epoch: 1, loss = 0.40131995341016186
Train: epoch: 1, loss = 0.39994045078754425
Train: epoch: 1, loss = 0.398606833612377
Train: epoch: 1, loss = 0.39693253505975007
Train: epoch: 1, loss = 0.39552768908441066
Train: epoch: 1, loss = 0.39468520249107053
Train: epoch: 1, loss = 0.3934007190565268
Train: epoch: 1, loss = 0.39199424924328924
Train: epoch: 1, loss = 0.39082945511621586
Train: epoch: 1, loss = 0.3900686506802837
Train:  Epoch 1, Loss=0.39000713045678587, AUC-ROC Macro=0.6648850789305584, AUC-ROC Micro=0.7531162294364089
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.37287883708874386, AUC-ROC Macro=0.7139068919781292, AUC-ROC Micro=0.7811817027227945
Eval task: 2
Eval:  Epoch 1, Loss=0.3277071639895439, AUC-ROC Macro=0.49957626692491536, AUC-ROC Micro=0.5768842165938284
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.3713096348196268
Train: epoch: 2, loss = 0.37318408831954003
Train: epoch: 2, loss = 0.3717640706648429
Train: epoch: 2, loss = 0.37171283379197123
Train: epoch: 2, loss = 0.37070205365121367
Train: epoch: 2, loss = 0.3716230617463589
Train: epoch: 2, loss = 0.37177372623767174
Train: epoch: 2, loss = 0.37157552072778344
Train: epoch: 2, loss = 0.3703841173234913
Train: epoch: 2, loss = 0.3696931273043156
Train: epoch: 2, loss = 0.37025652903047473
Train: epoch: 2, loss = 0.3703700879154106
Train: epoch: 2, loss = 0.37016641858678595
Train: epoch: 2, loss = 0.3697655077225396
Train: epoch: 2, loss = 0.3688638986249765
Train: epoch: 2, loss = 0.36856057433411477
Train: epoch: 2, loss = 0.36835618619533145
Train: epoch: 2, loss = 0.3682852057574524
Train:  Epoch 2, Loss=0.3682565179890038, AUC-ROC Macro=0.7247993211606523, AUC-ROC Micro=0.7914133074301939
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.36245669921239215, AUC-ROC Macro=0.7366201150926233, AUC-ROC Micro=0.7975934301214481
Eval task: 2
Eval:  Epoch 2, Loss=0.32061585038900375, AUC-ROC Macro=0.5014884729969142, AUC-ROC Micro=0.5802753934400772
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3624606541544199
Train: epoch: 3, loss = 0.36215561602264645
Train: epoch: 3, loss = 0.3613881328205268
Train: epoch: 3, loss = 0.36118219001218677
Train: epoch: 3, loss = 0.36179202343523503
Train: epoch: 3, loss = 0.3623935245970885
Train: epoch: 3, loss = 0.3613134554134948
Train: epoch: 3, loss = 0.3612850951962173
Train: epoch: 3, loss = 0.36233298654357593
Train: epoch: 3, loss = 0.3620425707027316
Train: epoch: 3, loss = 0.3617678380418908
Train: epoch: 3, loss = 0.360995990211765
Train: epoch: 3, loss = 0.3608976201369212
Train: epoch: 3, loss = 0.36072987782103677
Train: epoch: 3, loss = 0.3603761053184668
Train: epoch: 3, loss = 0.36017480060458185
Train: epoch: 3, loss = 0.360093722426716
Train: epoch: 3, loss = 0.36015694126072856
Train:  Epoch 3, Loss=0.36030053625351344, AUC-ROC Macro=0.7431935404783051, AUC-ROC Micro=0.8037051886127822
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.35811392093698186, AUC-ROC Macro=0.7487190068336025, AUC-ROC Micro=0.8045401432139527
Eval task: 2
Eval:  Epoch 3, Loss=0.3352043926715851, AUC-ROC Macro=0.4872656620149485, AUC-ROC Micro=0.5873368275975581
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.3580208870768547
Train: epoch: 4, loss = 0.3493217082694173
Train: epoch: 4, loss = 0.35194820165634155
Train: epoch: 4, loss = 0.3541668378189206
Train: epoch: 4, loss = 0.35366992822289467
Train: epoch: 4, loss = 0.3537240443502863
Train: epoch: 4, loss = 0.35369483592254775
Train: epoch: 4, loss = 0.3537810968607664
Train: epoch: 4, loss = 0.35481050882074566
Train: epoch: 4, loss = 0.3549366255775094
Train: epoch: 4, loss = 0.35506800961088053
Train: epoch: 4, loss = 0.3543042302628358
Train: epoch: 4, loss = 0.35431569709227634
Train: epoch: 4, loss = 0.3541863429439919
Train: epoch: 4, loss = 0.3541653123497963
Train: epoch: 4, loss = 0.3542890017107129
Train: epoch: 4, loss = 0.3549446816260324
Train: epoch: 4, loss = 0.3549204086057014
Train:  Epoch 4, Loss=0.35483246047680195, AUC-ROC Macro=0.7555415716774553, AUC-ROC Micro=0.8118950067809657
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.35501068209608394, AUC-ROC Macro=0.754065439631105, AUC-ROC Micro=0.8086370818248012
Eval task: 2
Eval:  Epoch 4, Loss=0.352983757853508, AUC-ROC Macro=0.48591263582809807, AUC-ROC Micro=0.5782554114902323
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.34333639800548554
Train: epoch: 5, loss = 0.34878557957708833
Train: epoch: 5, loss = 0.3512052034586668
Train: epoch: 5, loss = 0.3523872830346227
Train: epoch: 5, loss = 0.3522432605922222
Train: epoch: 5, loss = 0.35144475548217696
Train: epoch: 5, loss = 0.35147033384868076
Train: epoch: 5, loss = 0.3515173786599189
Train: epoch: 5, loss = 0.35194485968185796
Train: epoch: 5, loss = 0.351781973361969
Train: epoch: 5, loss = 0.35159458960321816
Train: epoch: 5, loss = 0.35102624745418626
Train: epoch: 5, loss = 0.3504834651488524
Train: epoch: 5, loss = 0.35029312613819324
Train: epoch: 5, loss = 0.3503601722021898
Train: epoch: 5, loss = 0.35051439475733787
Train: epoch: 5, loss = 0.35041889897602446
Train: epoch: 5, loss = 0.35030498427649337
Train:  Epoch 5, Loss=0.35047169637680053, AUC-ROC Macro=0.7642978809711936, AUC-ROC Micro=0.8179628324789141
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3520413401226203, AUC-ROC Macro=0.7604482015286765, AUC-ROC Micro=0.8136132569256966
Eval task: 2
Eval:  Epoch 5, Loss=0.35694068670272827, AUC-ROC Macro=0.48034275615946115, AUC-ROC Micro=0.5645103832359538
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.34619743697345257
Train: epoch: 6, loss = 0.3504070169851184
Train: epoch: 6, loss = 0.3509768244624138
Train: epoch: 6, loss = 0.34957435516640545
Train: epoch: 6, loss = 0.34981016448140145
Train: epoch: 6, loss = 0.34894912092636027
Train: epoch: 6, loss = 0.3492159260490111
Train: epoch: 6, loss = 0.3480002163909376
Train: epoch: 6, loss = 0.3483794540249639
Train: epoch: 6, loss = 0.3479654894843697
Train: epoch: 6, loss = 0.34794834222305904
Train: epoch: 6, loss = 0.34797970882306495
Train: epoch: 6, loss = 0.3472482091303055
Train: epoch: 6, loss = 0.347300577717168
Train: epoch: 6, loss = 0.3473004030982653
Train: epoch: 6, loss = 0.34702323861420153
Train: epoch: 6, loss = 0.3471637070485774
Train: epoch: 6, loss = 0.3469111936291059
Train:  Epoch 6, Loss=0.34669128208486444, AUC-ROC Macro=0.7720248826689587, AUC-ROC Micro=0.8232320477140437
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3525878116488457, AUC-ROC Macro=0.7605868430381338, AUC-ROC Micro=0.813588649561589
Eval task: 2
Eval:  Epoch 6, Loss=0.3611607514321804, AUC-ROC Macro=0.4849655748286084, AUC-ROC Micro=0.5901506230113863
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3540022087593873, AUC-ROC Macro=0.7624432424719452, AUC-ROC Micro=0.8145851331360001
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.36045778915286064, AUC-ROC Macro=0.49484573403480164, AUC-ROC Micro=0.5874992150883931
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.30687564581632615
Train: epoch: 1, loss = 0.300167262069881
Train: epoch: 1, loss = 0.29518330765267214
Train: epoch: 1, loss = 0.2933084551617503
Train: epoch: 1, loss = 0.29063988155126574
Train: epoch: 1, loss = 0.28862301071484886
Train:  Epoch 1, Loss=0.2871909232931344, AUC-ROC Macro=0.5861771058342151, AUC-ROC Micro=0.7451833173265243
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.34420351063211757, AUC-ROC Macro=0.753980454287217, AUC-ROC Micro=0.8067053287681764
Eval task: 2
Eval:  Epoch 1, Loss=0.28185831382870674, AUC-ROC Macro=0.6707918246806254, AUC-ROC Micro=0.7898588875572581
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.27372880682349204
Train: epoch: 2, loss = 0.27433886505663396
Train: epoch: 2, loss = 0.27396882136662803
Train: epoch: 2, loss = 0.27275792757049205
Train: epoch: 2, loss = 0.2726599045097828
Train: epoch: 2, loss = 0.2716331697379549
Train:  Epoch 2, Loss=0.2709454823628057, AUC-ROC Macro=0.6784704874684357, AUC-ROC Micro=0.7991341610490357
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3501066267490387, AUC-ROC Macro=0.7502272613382247, AUC-ROC Micro=0.8054037589965768
Eval task: 2
Eval:  Epoch 2, Loss=0.24907837621867657, AUC-ROC Macro=0.6882495143646608, AUC-ROC Micro=0.8017353204908865
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.2682356993854046
Train: epoch: 3, loss = 0.2670145719125867
Train: epoch: 3, loss = 0.26704885890086494
Train: epoch: 3, loss = 0.26650829089805483
Train: epoch: 3, loss = 0.2652415848970413
Train: epoch: 3, loss = 0.26460383510837954
Train:  Epoch 3, Loss=0.26453783477342385, AUC-ROC Macro=0.7142062965861872, AUC-ROC Micro=0.813273572664287
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.33793913448850316, AUC-ROC Macro=0.7474543952353901, AUC-ROC Micro=0.8022810421767052
Eval task: 2
Eval:  Epoch 3, Loss=0.27673300728201866, AUC-ROC Macro=0.7128407870031307, AUC-ROC Micro=0.8145579939756254
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.25785177692770955
Train: epoch: 4, loss = 0.25919511567801234
Train: epoch: 4, loss = 0.2582006907214721
Train: epoch: 4, loss = 0.2570329915545881
Train: epoch: 4, loss = 0.25615130968391897
Train: epoch: 4, loss = 0.2562074881295363
Train:  Epoch 4, Loss=0.25619112711926406, AUC-ROC Macro=0.726559177059286, AUC-ROC Micro=0.8215704590980117
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.33191507930556935, AUC-ROC Macro=0.7398877134569487, AUC-ROC Micro=0.7960541926648212
Eval task: 2
Eval:  Epoch 4, Loss=0.26880077831447124, AUC-ROC Macro=0.7102078393577649, AUC-ROC Micro=0.8159864951692908
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.24923279538750648
Train: epoch: 5, loss = 0.2502426271885633
Train: epoch: 5, loss = 0.25177629518012207
Train: epoch: 5, loss = 0.25198425283655523
Train: epoch: 5, loss = 0.2515619869083166
Train: epoch: 5, loss = 0.2513209790736437
Train:  Epoch 5, Loss=0.2506946058151164, AUC-ROC Macro=0.740364633280417, AUC-ROC Micro=0.8278681609907869
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3300245963037014, AUC-ROC Macro=0.7367815004224242, AUC-ROC Micro=0.7936326826519212
Eval task: 2
Eval:  Epoch 5, Loss=0.25161356292665005, AUC-ROC Macro=0.7146778614900231, AUC-ROC Micro=0.8165891328789466
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.2394400265067816
Train: epoch: 6, loss = 0.2404191641509533
Train: epoch: 6, loss = 0.242855600665013
Train: epoch: 6, loss = 0.24267271533608437
Train: epoch: 6, loss = 0.24314141279459
Train: epoch: 6, loss = 0.2434583211193482
Train:  Epoch 6, Loss=0.24378239199039914, AUC-ROC Macro=0.7470794920373365, AUC-ROC Micro=0.8327148450684718
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.33936432376503944, AUC-ROC Macro=0.7306941408323196, AUC-ROC Micro=0.7885930621646265
Eval task: 2
Eval:  Epoch 6, Loss=0.24787401780486107, AUC-ROC Macro=0.7137295868582691, AUC-ROC Micro=0.8155579104089532
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3923266902565956, AUC-ROC Macro=0.7301353432635618, AUC-ROC Micro=0.7875394064677543
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.21625696867704391, AUC-ROC Macro=0.7046312764130042, AUC-ROC Micro=0.8121591115639292
{'0': {'precision': 0.47761194029850745, 'recall': 0.41590214067278286, 'f1-score': 0.4446260727421332, 'support': 1308}, '1': {'precision': 0.518796992481203, 'recall': 0.5149253731343284, 'f1-score': 0.5168539325842697, 'support': 402}, '2': {'precision': 0.3977272727272727, 'recall': 0.10638297872340426, 'f1-score': 0.16786570743405274, 'support': 658}, '3': {'precision': 0.44958968347010553, 'recall': 0.385427135678392, 'f1-score': 0.41504329004329005, 'support': 1990}, '4': {'precision': 0.3487972508591065, 'recall': 0.2518610421836228, 'f1-score': 0.292507204610951, 'support': 806}, '5': {'precision': 0.3170731707317073, 'recall': 0.08354755784061697, 'f1-score': 0.13224821973550357, 'support': 778}, '6': {'precision': 0.4810810810810811, 'recall': 0.20506912442396313, 'f1-score': 0.2875605815831987, 'support': 1302}, '7': {'precision': 0.24545454545454545, 'recall': 0.06367924528301887, 'f1-score': 0.10112359550561797, 'support': 424}, '8': {'precision': 0.4917541229385307, 'recall': 0.39902676399026765, 'f1-score': 0.44056413700470115, 'support': 1644}, '9': {'precision': 0.6190176322418136, 'recall': 0.48399803052683404, 'f1-score': 0.5432439900525007, 'support': 2031}, '10': {'precision': 0.523696682464455, 'recall': 0.3856893542757417, 'f1-score': 0.4442211055276382, 'support': 573}, '11': {'precision': 0.42027027027027025, 'recall': 0.26445578231292516, 'f1-score': 0.3246346555323591, 'support': 1176}, '12': {'precision': 0.5291970802919708, 'recall': 0.327683615819209, 'f1-score': 0.40474528960223305, 'support': 1770}, '13': {'precision': 0.5224447513812155, 'recall': 0.5828197226502311, 'f1-score': 0.5509832483612527, 'support': 2596}, '14': {'precision': 0.42504211117349805, 'recall': 0.46527350952673635, 'f1-score': 0.44424882629107987, 'support': 1627}, '15': {'precision': 0.12903225806451613, 'recall': 0.008264462809917356, 'f1-score': 0.015533980582524271, 'support': 484}, '16': {'precision': 0.3339622641509434, 'recall': 0.22264150943396227, 'f1-score': 0.26716981132075474, 'support': 795}, '17': {'precision': 0.35384615384615387, 'recall': 0.08455882352941177, 'f1-score': 0.1364985163204748, 'support': 544}, '18': {'precision': 0.23076923076923078, 'recall': 0.008547008547008548, 'f1-score': 0.016483516483516484, 'support': 351}, '19': {'precision': 0.3958333333333333, 'recall': 0.07251908396946564, 'f1-score': 0.12258064516129032, 'support': 262}, '20': {'precision': 0.2222222222222222, 'recall': 0.021314387211367674, 'f1-score': 0.03889789303079417, 'support': 563}, '21': {'precision': 0.4304, 'recall': 0.3213859020310633, 'f1-score': 0.3679890560875513, 'support': 837}, '22': {'precision': 0.6304128902316214, 'recall': 0.576427255985267, 'f1-score': 0.6022126022126022, 'support': 1086}, '23': {'precision': 0.505982905982906, 'recall': 0.3437862950058072, 'f1-score': 0.4094052558782849, 'support': 861}, '24': {'precision': 0.4296028880866426, 'recall': 0.23564356435643563, 'f1-score': 0.30434782608695654, 'support': 505}, 'micro avg': {'precision': 0.4852622814321399, 'recall': 0.34453947109131755, 'f1-score': 0.4029685627362405, 'support': 25373}, 'macro avg': {'precision': 0.41718474938211414, 'recall': 0.27323318679687125, 'f1-score': 0.3116635583910212, 'support': 25373}, 'weighted avg': {'precision': 0.45797207592094935, 'recall': 0.34453947109131755, 'f1-score': 0.3798256421960615, 'support': 25373}, 'samples avg': {'precision': 0.41079538544138156, 'recall': 0.3172299500395778, 'f1-score': 0.326888678323748, 'support': 25373}}
{'0': {'precision': 0.6240875912408759, 'recall': 0.4090909090909091, 'f1-score': 0.49421965317919075, 'support': 418}, '1': {'precision': 0.45121951219512196, 'recall': 0.1712962962962963, 'f1-score': 0.2483221476510067, 'support': 216}, '2': {'precision': 0.3333333333333333, 'recall': 0.010416666666666666, 'f1-score': 0.0202020202020202, 'support': 288}, '3': {'precision': 0.3333333333333333, 'recall': 0.011904761904761904, 'f1-score': 0.022988505747126436, 'support': 252}, '4': {'precision': 0.40476190476190477, 'recall': 0.059027777777777776, 'f1-score': 0.10303030303030303, 'support': 288}, '5': {'precision': 0.3, 'recall': 0.011152416356877323, 'f1-score': 0.021505376344086023, 'support': 269}, '6': {'precision': 0.36, 'recall': 0.03180212014134275, 'f1-score': 0.05844155844155844, 'support': 283}, '7': {'precision': 0.8166666666666667, 'recall': 0.3843137254901961, 'f1-score': 0.5226666666666667, 'support': 255}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 177}, '9': {'precision': 0.5142857142857142, 'recall': 0.07627118644067797, 'f1-score': 0.13284132841328414, 'support': 236}, '10': {'precision': 0.5, 'recall': 0.01092896174863388, 'f1-score': 0.0213903743315508, 'support': 183}, '11': {'precision': 0.7619047619047619, 'recall': 0.07655502392344497, 'f1-score': 0.1391304347826087, 'support': 209}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 160}, '13': {'precision': 0.2, 'recall': 0.02702702702702703, 'f1-score': 0.047619047619047616, 'support': 111}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26}, '15': {'precision': 0.6770833333333334, 'recall': 0.7222222222222222, 'f1-score': 0.6989247311827957, 'support': 90}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 69}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 60}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 55}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 25}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8}, 'micro avg': {'precision': 0.5862977602108037, 'recall': 0.11707445409102868, 'f1-score': 0.19517543859649125, 'support': 3801}, 'macro avg': {'precision': 0.25106704604220176, 'recall': 0.08008036380347336, 'f1-score': 0.1012512859036498, 'support': 3801}, 'weighted avg': {'precision': 0.3948909445287516, 'recall': 0.11707445409102868, 'f1-score': 0.1551279957132766, 'support': 3801}, 'samples avg': {'precision': 0.19690406436011904, 'recall': 0.1369349888392857, 'f1-score': 0.15176792337436867, 'support': 3801}}