
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_west_baseline
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
west_val.csv
test_listfile.csv
west_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1666556066274643
Train: epoch: 1, loss = 2.1350606739521027
Train: epoch: 1, loss = 2.116994587580363
Train: epoch: 1, loss = 2.1050467589497566
Train: epoch: 1, loss = 2.0979729771614073
Train: epoch: 1, loss = 2.0879837413628897
Train: epoch: 1, loss = 2.082463233726365
Train: epoch: 1, loss = 2.078492138162255
Train: epoch: 1, loss = 2.073556406100591
Train: epoch: 1, loss = 2.0716876817941667
Train: epoch: 1, loss = 2.0674016028100795
Train: epoch: 1, loss = 2.0666044746836025
Train: epoch: 1, loss = 2.0641423887931385
Train: epoch: 1, loss = 2.0613841582196097
Train: epoch: 1, loss = 2.060030186533928
Train: epoch: 1, loss = 2.058659867607057
Train: epoch: 1, loss = 2.056235421229811
Train: epoch: 1, loss = 2.054507964849472
Train: epoch: 1, loss = 2.054092989563942
Train: epoch: 1, loss = 2.052492332905531
Train: epoch: 1, loss = 2.051984880765279
Train: epoch: 1, loss = 2.0515621188824826
Train: epoch: 1, loss = 2.050607521819032
Train: epoch: 1, loss = 2.0502439507593713
Train: epoch: 1, loss = 2.0493292824029923
Train: epoch: 1, loss = 2.0484155175548335
Train: epoch: 1, loss = 2.048088956983001
Train: epoch: 1, loss = 2.047430594776358
Train: epoch: 1, loss = 2.046688236327007
Train: epoch: 1, loss = 2.0461218759616218
Train: epoch: 1, loss = 2.04611375001169
Train: epoch: 1, loss = 2.046057140547782
Train: epoch: 1, loss = 2.0458099509369245
Train: epoch: 1, loss = 2.0456080834479895
Train: epoch: 1, loss = 2.0454247525589806
Train: epoch: 1, loss = 2.0455799913075237
Train: epoch: 1, loss = 2.0453309873310297
Train: epoch: 1, loss = 2.0448090075505405
Train: epoch: 1, loss = 2.044824863962638
Train: epoch: 1, loss = 2.044247243329883
Train: epoch: 1, loss = 2.043733031502584
Train: epoch: 1, loss = 2.04375613038029
Train: epoch: 1, loss = 2.043334774555162
Train:  Epoch 1, Loss=2.0430685285704477, Cohen Kappa=0.38861912060521175, MAD=0.7178356582461506
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0295830636188903, Cohen Kappa=0.43231273394964265, MAD=0.7168253144276486
Eval task: 2
Eval:  Epoch 1, Loss=1.8763480022035797, Cohen Kappa=0.0007995047950000167, MAD=0.7385352993064096
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.053822807196913, Cohen Kappa=0.34836302311644973, MAD=0.721377780164626
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.890902798751305, Cohen Kappa=-0.0004335542993190167, MAD=0.7395991876190865
west_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.884680990576744
Train: epoch: 1, loss = 1.8756842270493508
Train: epoch: 1, loss = 1.8800138733784357
Train: epoch: 1, loss = 1.8792766711115838
Train: epoch: 1, loss = 1.8788477807044983
Train: epoch: 1, loss = 1.8794396363695463
Train: epoch: 1, loss = 1.8793666737420218
Train: epoch: 1, loss = 1.8800759505480529
Train: epoch: 1, loss = 1.8802843642234803
Train: epoch: 1, loss = 1.8801096993088722
Train: epoch: 1, loss = 1.8784418018297715
Train: epoch: 1, loss = 1.8783090292910736
Train: epoch: 1, loss = 1.8785765366370861
Train: epoch: 1, loss = 1.8776137525268963
Train: epoch: 1, loss = 1.876801664908727
Train: epoch: 1, loss = 1.8772833675146103
Train: epoch: 1, loss = 1.8763315977068509
Train: epoch: 1, loss = 1.875960425502724
Train: epoch: 1, loss = 1.8755042348409954
Train: epoch: 1, loss = 1.875384635746479
Train: epoch: 1, loss = 1.8753509593577613
Train:  Epoch 1, Loss=1.8752169990812029, Cohen Kappa=0.007406936016062349, MAD=0.724806894309576
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.114727661527436, Cohen Kappa=0.20970418374412447, MAD=0.7371001601312095
Eval task: 2
Eval:  Epoch 1, Loss=1.8637677677746476, Cohen Kappa=0.07108671415191481, MAD=0.7151347044192732
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.087272317245089, Cohen Kappa=0.12613341324493754, MAD=0.7276950649694944
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8775503758726448, Cohen Kappa=0.13549216401835573, MAD=0.714498596275482
{'0': {'precision': 0.1220472440944882, 'recall': 0.007607361963190184, 'f1-score': 0.014322014322014322, 'support': 4075}, '1': {'precision': 0.2032806092560047, 'recall': 0.9689354275741711, 'f1-score': 0.33605713939834153, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.3871657754010695, 'recall': 0.29769736842105265, 'f1-score': 0.3365876336587634, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.2134294181034483, 'macro avg': {'precision': 0.07124936287515624, 'recall': 0.1274240157958414, 'f1-score': 0.06869667873791192, 'support': 14848}, 'weighted avg': {'precision': 0.10442719882079696, 'recall': 0.2134294181034483, 'f1-score': 0.09634001045713315, 'support': 14848}}
{'0': {'precision': 0.3333333333333333, 'recall': 0.0004035512510088781, 'f1-score': 0.0008061265618702137, 'support': 2478}, '1': {'precision': 0.35436223081170626, 'recall': 0.9892100192678227, 'f1-score': 0.5218009960361825, 'support': 2595}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1084}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 501}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 215}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 121}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 103}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, '8': {'precision': 0.38922155688622756, 'recall': 0.42483660130718953, 'f1-score': 0.40624999999999994, 'support': 153}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102}, 'accuracy': 0.35466056034482757, 'macro avg': {'precision': 0.10769171210312671, 'recall': 0.1414450171826021, 'f1-score': 0.09288571225980527, 'support': 7424}, 'weighted avg': {'precision': 0.2431466712230564, 'recall': 0.35466056034482757, 'f1-score': 0.19103278776053448, 'support': 7424}}