Experiment dir: ./exp/Test_phen_midwest
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.4375943212211132
Train: epoch: 1, loss = 0.42018101930618285
Train: epoch: 1, loss = 0.4163834257423878
Train: epoch: 1, loss = 0.4131576193124056
Train: epoch: 1, loss = 0.4115872210562229
Train: epoch: 1, loss = 0.4108306274066369
Train: epoch: 1, loss = 0.40904094302228516
Train: epoch: 1, loss = 0.4074270359240472
Train: epoch: 1, loss = 0.4062466054492527
Train: epoch: 1, loss = 0.40412384550273417
Train: epoch: 1, loss = 0.4020516527444124
Train: epoch: 1, loss = 0.4004754762475689
Train: epoch: 1, loss = 0.39878311780782844
Train: epoch: 1, loss = 0.39703773568251305
Train: epoch: 1, loss = 0.395751729413867
Train: epoch: 1, loss = 0.3948182403948158
Train: epoch: 1, loss = 0.3936178651013795
Train: epoch: 1, loss = 0.39253655331830184
Train:  Epoch 1, Loss=0.39217950237103, AUC-ROC Macro=0.6576886289958292, AUC-ROC Micro=0.7488134610320144
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3692575792471568, AUC-ROC Macro=0.7212830836008507, AUC-ROC Micro=0.7850166222522574
Eval task: 2
Eval:  Epoch 1, Loss=0.3179839178919792, AUC-ROC Macro=0.4971760126825177, AUC-ROC Micro=0.5717141699389675
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.3739136618375778
Train: epoch: 2, loss = 0.3717358702793717
Train: epoch: 2, loss = 0.37218481113513313
Train: epoch: 2, loss = 0.37344441859051586
Train: epoch: 2, loss = 0.3729268968105316
Train: epoch: 2, loss = 0.37191454123705625
Train: epoch: 2, loss = 0.3714346248762948
Train: epoch: 2, loss = 0.37057196789421143
Train: epoch: 2, loss = 0.3703151465704044
Train: epoch: 2, loss = 0.3701326172798872
Train: epoch: 2, loss = 0.3699348295547745
Train: epoch: 2, loss = 0.3699849226884544
Train: epoch: 2, loss = 0.3690616854853355
Train: epoch: 2, loss = 0.36941062564296384
Train: epoch: 2, loss = 0.369218187669913
Train: epoch: 2, loss = 0.368731984263286
Train: epoch: 2, loss = 0.3684291405537549
Train: epoch: 2, loss = 0.3684266607380576
Train:  Epoch 2, Loss=0.3684843597717774, AUC-ROC Macro=0.7242577161519093, AUC-ROC Micro=0.7911251630554398
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3616837014754613, AUC-ROC Macro=0.7378293733100574, AUC-ROC Micro=0.7979831041534551
Eval task: 2
Eval:  Epoch 2, Loss=0.3217446692287922, AUC-ROC Macro=0.48524721178264807, AUC-ROC Micro=0.5628627957242258
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.36410585820674896
Train: epoch: 3, loss = 0.3598217284679413
Train: epoch: 3, loss = 0.35820114945371945
Train: epoch: 3, loss = 0.35935894494876264
Train: epoch: 3, loss = 0.35942705246806145
Train: epoch: 3, loss = 0.3607651894042889
Train: epoch: 3, loss = 0.360320655011705
Train: epoch: 3, loss = 0.3606895581074059
Train: epoch: 3, loss = 0.3605660496900479
Train: epoch: 3, loss = 0.3609393870532513
Train: epoch: 3, loss = 0.3607121720029549
Train: epoch: 3, loss = 0.3609266630932689
Train: epoch: 3, loss = 0.360681150538417
Train: epoch: 3, loss = 0.3607361130363175
Train: epoch: 3, loss = 0.3603601367423932
Train: epoch: 3, loss = 0.360617968486622
Train: epoch: 3, loss = 0.3603982345321599
Train: epoch: 3, loss = 0.36057666282273
Train:  Epoch 3, Loss=0.36059263189837465, AUC-ROC Macro=0.7427520271816915, AUC-ROC Micro=0.8034022375924628
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3592678556839625, AUC-ROC Macro=0.7466481795954623, AUC-ROC Micro=0.8043461170211985
Eval task: 2
Eval:  Epoch 3, Loss=0.33965273201465607, AUC-ROC Macro=0.4887530465358433, AUC-ROC Micro=0.5458050696805026
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.3574460715055466
Train: epoch: 4, loss = 0.3542271212115884
Train: epoch: 4, loss = 0.35583775758743286
Train: epoch: 4, loss = 0.3571428447589278
Train: epoch: 4, loss = 0.35676992473006247
Train: epoch: 4, loss = 0.357489749652644
Train: epoch: 4, loss = 0.35700255817600657
Train: epoch: 4, loss = 0.35680584370158613
Train: epoch: 4, loss = 0.35572545033362174
Train: epoch: 4, loss = 0.35558133366703987
Train: epoch: 4, loss = 0.35506734894080594
Train: epoch: 4, loss = 0.3551069885243972
Train: epoch: 4, loss = 0.3548505811794446
Train: epoch: 4, loss = 0.3548775762213128
Train: epoch: 4, loss = 0.35491162528594333
Train: epoch: 4, loss = 0.35490265258122233
Train: epoch: 4, loss = 0.35476443406851854
Train: epoch: 4, loss = 0.35466566702144015
Train:  Epoch 4, Loss=0.35477498929113405, AUC-ROC Macro=0.7554463176727085, AUC-ROC Micro=0.8120204787251493
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3531101557115714, AUC-ROC Macro=0.7576811115365949, AUC-ROC Micro=0.8114752502102522
Eval task: 2
Eval:  Epoch 4, Loss=0.34125396609306335, AUC-ROC Macro=0.48071868170528015, AUC-ROC Micro=0.5544385322877506
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.34678354792296884
Train: epoch: 5, loss = 0.34938982196152213
Train: epoch: 5, loss = 0.34836319071551164
Train: epoch: 5, loss = 0.34890331419184806
Train: epoch: 5, loss = 0.3495073307752609
Train: epoch: 5, loss = 0.3490869843835632
Train: epoch: 5, loss = 0.3481914137516703
Train: epoch: 5, loss = 0.34875439203344283
Train: epoch: 5, loss = 0.34856983019245996
Train: epoch: 5, loss = 0.34889856453984974
Train: epoch: 5, loss = 0.34958162381567737
Train: epoch: 5, loss = 0.3493735130317509
Train: epoch: 5, loss = 0.3495854327369195
Train: epoch: 5, loss = 0.3494666705972382
Train: epoch: 5, loss = 0.34940605622529985
Train: epoch: 5, loss = 0.34963819299824533
Train: epoch: 5, loss = 0.3498024129560765
Train: epoch: 5, loss = 0.3499669348117378
Train:  Epoch 5, Loss=0.3501325417176271, AUC-ROC Macro=0.7652619934531978, AUC-ROC Micro=0.8186203298405518
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3507618283232053, AUC-ROC Macro=0.7609197291382214, AUC-ROC Micro=0.8143075858218132
Eval task: 2
Eval:  Epoch 5, Loss=0.33863383531570435, AUC-ROC Macro=0.48117047857698636, AUC-ROC Micro=0.5603225959957954
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.34242110796272757
Train: epoch: 6, loss = 0.3430920577049255
Train: epoch: 6, loss = 0.34435149061183135
Train: epoch: 6, loss = 0.3456011379882693
Train: epoch: 6, loss = 0.3457106483578682
Train: epoch: 6, loss = 0.3456611762692531
Train: epoch: 6, loss = 0.3447953818525587
Train: epoch: 6, loss = 0.3459713872335851
Train: epoch: 6, loss = 0.34548211356004077
Train: epoch: 6, loss = 0.3449108248874545
Train: epoch: 6, loss = 0.34526485073295504
Train: epoch: 6, loss = 0.3453305149264634
Train: epoch: 6, loss = 0.34534143826709346
Train: epoch: 6, loss = 0.3456259906079088
Train: epoch: 6, loss = 0.34633954892059166
Train: epoch: 6, loss = 0.346730948695913
Train: epoch: 6, loss = 0.3465127717046177
Train: epoch: 6, loss = 0.34677144268320664
Train:  Epoch 6, Loss=0.3469411643325773, AUC-ROC Macro=0.7716076877245881, AUC-ROC Micro=0.8230494929951055
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3507616842786471, AUC-ROC Macro=0.7629166251108284, AUC-ROC Micro=0.8153130307109617
Eval task: 2
Eval:  Epoch 6, Loss=0.34165792167186737, AUC-ROC Macro=0.4832277836948002, AUC-ROC Micro=0.55086242802863
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.353451494127512, AUC-ROC Macro=0.7632143475378629, AUC-ROC Micro=0.8144497533901814
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.3406325988471508, AUC-ROC Macro=0.47940066364974443, AUC-ROC Micro=0.5512787574808605
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.28394205451011656
Train: epoch: 1, loss = 0.27607451420277357
Train: epoch: 1, loss = 0.2709359040856361
Train: epoch: 1, loss = 0.26781215067952874
Train: epoch: 1, loss = 0.26546146158874034
Train: epoch: 1, loss = 0.258953745054702
Train:  Epoch 1, Loss=0.2557182172807902, AUC-ROC Macro=0.5968778128715031, AUC-ROC Micro=0.754788914904305
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3810989720125993, AUC-ROC Macro=0.729868704780957, AUC-ROC Micro=0.7804920582382828
Eval task: 2
Eval:  Epoch 1, Loss=0.2601432241499424, AUC-ROC Macro=0.6793171900689227, AUC-ROC Micro=0.7976225804745124
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.2478117948770523
Train: epoch: 2, loss = 0.24822104677557946
Train: epoch: 2, loss = 0.24870026886463165
Train: epoch: 2, loss = 0.25011282943189145
Train: epoch: 2, loss = 0.2493598067909479
Train: epoch: 2, loss = 0.24503404640903076
Train:  Epoch 2, Loss=0.2416258597204555, AUC-ROC Macro=0.6899468954001087, AUC-ROC Micro=0.8053410244602294
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3742506218453248, AUC-ROC Macro=0.7380824707418914, AUC-ROC Micro=0.7920243753483581
Eval task: 2
Eval:  Epoch 2, Loss=0.25556969456374645, AUC-ROC Macro=0.7003438933908906, AUC-ROC Micro=0.8075150223525885
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.23710820432752372
Train: epoch: 3, loss = 0.24355371579527854
Train: epoch: 3, loss = 0.2446336341649294
Train: epoch: 3, loss = 0.24537989297881724
Train: epoch: 3, loss = 0.24539970001578332
Train: epoch: 3, loss = 0.23967223546157282
Train:  Epoch 3, Loss=0.23624121161454992, AUC-ROC Macro=0.7208456525836298, AUC-ROC Micro=0.8193744334295077
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3642552395661672, AUC-ROC Macro=0.7439806568332394, AUC-ROC Micro=0.7984238480201482
Eval task: 2
Eval:  Epoch 3, Loss=0.25000554136931896, AUC-ROC Macro=0.7122190919711477, AUC-ROC Micro=0.8157641140677749
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.23859380535781383
Train: epoch: 4, loss = 0.23867768969386816
Train: epoch: 4, loss = 0.24022114199896655
Train: epoch: 4, loss = 0.2407280709967017
Train: epoch: 4, loss = 0.2409806597083807
Train: epoch: 4, loss = 0.2363118036960562
Train:  Epoch 4, Loss=0.23307051505717932, AUC-ROC Macro=0.7438725874834341, AUC-ROC Micro=0.8280350780076747
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3668002635240555, AUC-ROC Macro=0.7413924544887196, AUC-ROC Micro=0.7963298236733733
Eval task: 2
Eval:  Epoch 4, Loss=0.252590024843812, AUC-ROC Macro=0.722022337571527, AUC-ROC Micro=0.8193196301257075
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.23417732428759336
Train: epoch: 5, loss = 0.2372520582936704
Train: epoch: 5, loss = 0.23706274813661973
Train: epoch: 5, loss = 0.23723333631642163
Train: epoch: 5, loss = 0.23699038369953632
Train: epoch: 5, loss = 0.2318130877117316
Train:  Epoch 5, Loss=0.22927625772662366, AUC-ROC Macro=0.7595703553208419, AUC-ROC Micro=0.8360113967623295
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.36146456003189087, AUC-ROC Macro=0.7443265143114801, AUC-ROC Micro=0.7993183972491431
Eval task: 2
Eval:  Epoch 5, Loss=0.2476002238690853, AUC-ROC Macro=0.7268342223641215, AUC-ROC Micro=0.823785255993962
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.23288317058235408
Train: epoch: 6, loss = 0.23317757591605187
Train: epoch: 6, loss = 0.2347186256200075
Train: epoch: 6, loss = 0.234496092768386
Train: epoch: 6, loss = 0.23407186095416546
Train: epoch: 6, loss = 0.2288030151401957
Train:  Epoch 6, Loss=0.226268211222221, AUC-ROC Macro=0.7705366528224666, AUC-ROC Micro=0.8421727039425886
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.36318861568967503, AUC-ROC Macro=0.7451700812185287, AUC-ROC Micro=0.7990122741018681
Eval task: 2
Eval:  Epoch 6, Loss=0.25178875029087067, AUC-ROC Macro=0.7291069712485647, AUC-ROC Micro=0.8228938800202872
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.36883480350176495, AUC-ROC Macro=0.7428041309823574, AUC-ROC Micro=0.7982604550748023
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.21337636187672615, AUC-ROC Macro=0.7273036408284846, AUC-ROC Micro=0.8186838230290905
{'0': {'precision': 0.5347593582887701, 'recall': 0.3058103975535168, 'f1-score': 0.3891050583657587, 'support': 1308}, '1': {'precision': 0.6062717770034843, 'recall': 0.43283582089552236, 'f1-score': 0.5050798258345427, 'support': 402}, '2': {'precision': 0.38095238095238093, 'recall': 0.0121580547112462, 'f1-score': 0.023564064801178203, 'support': 658}, '3': {'precision': 0.5314401622718052, 'recall': 0.2633165829145729, 'f1-score': 0.35215053763440857, 'support': 1990}, '4': {'precision': 0.56, 'recall': 0.052109181141439205, 'f1-score': 0.09534619750283767, 'support': 806}, '5': {'precision': 0.3333333333333333, 'recall': 0.02956298200514139, 'f1-score': 0.05430932703659976, 'support': 778}, '6': {'precision': 0.5253807106598984, 'recall': 0.15898617511520738, 'f1-score': 0.24410377358490568, 'support': 1302}, '7': {'precision': 0.42857142857142855, 'recall': 0.007075471698113208, 'f1-score': 0.013921113689095127, 'support': 424}, '8': {'precision': 0.5544933078393881, 'recall': 0.35279805352798055, 'f1-score': 0.4312267657992565, 'support': 1644}, '9': {'precision': 0.6843525179856115, 'recall': 0.3746922698178237, 'f1-score': 0.484250715876551, 'support': 2031}, '10': {'precision': 0.6470588235294118, 'recall': 0.2879581151832461, 'f1-score': 0.39855072463768115, 'support': 573}, '11': {'precision': 0.5061728395061729, 'recall': 0.13945578231292516, 'f1-score': 0.21866666666666662, 'support': 1176}, '12': {'precision': 0.6006051437216339, 'recall': 0.22429378531073446, 'f1-score': 0.32661456190867955, 'support': 1770}, '13': {'precision': 0.5828729281767956, 'recall': 0.325115562403698, 'f1-score': 0.41740850642927796, 'support': 2596}, '14': {'precision': 0.5492753623188406, 'recall': 0.2329440688383528, 'f1-score': 0.32714717306862323, 'support': 1627}, '15': {'precision': 0.2972972972972973, 'recall': 0.022727272727272728, 'f1-score': 0.04222648752399233, 'support': 484}, '16': {'precision': 0.3761467889908257, 'recall': 0.05157232704402516, 'f1-score': 0.09070796460176993, 'support': 795}, '17': {'precision': 0.4523809523809524, 'recall': 0.034926470588235295, 'f1-score': 0.06484641638225255, 'support': 544}, '18': {'precision': 0.3333333333333333, 'recall': 0.002849002849002849, 'f1-score': 0.005649717514124295, 'support': 351}, '19': {'precision': 0.46153846153846156, 'recall': 0.0916030534351145, 'f1-score': 0.15286624203821655, 'support': 262}, '20': {'precision': 0.28125, 'recall': 0.015985790408525755, 'f1-score': 0.030252100840336135, 'support': 563}, '21': {'precision': 0.5127118644067796, 'recall': 0.14456391875746716, 'f1-score': 0.22553588070829447, 'support': 837}, '22': {'precision': 0.6767676767676768, 'recall': 0.49355432780847147, 'f1-score': 0.5708200212992546, 'support': 1086}, '23': {'precision': 0.6137931034482759, 'recall': 0.2067363530778165, 'f1-score': 0.30929626411815814, 'support': 861}, '24': {'precision': 0.58, 'recall': 0.17227722772277226, 'f1-score': 0.26564885496183205, 'support': 505}, 'micro avg': {'precision': 0.5775390229069531, 'recall': 0.22456942419106923, 'f1-score': 0.32339169669967927, 'support': 25373}, 'macro avg': {'precision': 0.5044303820929023, 'recall': 0.17743632191392894, 'f1-score': 0.24157179851297172, 'support': 25373}, 'weighted avg': {'precision': 0.5374240176684617, 'recall': 0.22456942419106923, 'f1-score': 0.3010711204703004, 'support': 25373}, 'samples avg': {'precision': 0.32486868216238335, 'recall': 0.19601203986687668, 'f1-score': 0.22269092881926103, 'support': 25373}}
{'0': {'precision': 0.56875, 'recall': 0.4354066985645933, 'f1-score': 0.49322493224932246, 'support': 418}, '1': {'precision': 0.4077669902912621, 'recall': 0.19444444444444445, 'f1-score': 0.26332288401253917, 'support': 216}, '2': {'precision': 0.25, 'recall': 0.003472222222222222, 'f1-score': 0.00684931506849315, 'support': 288}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 252}, '4': {'precision': 0.4626865671641791, 'recall': 0.1076388888888889, 'f1-score': 0.1746478873239437, 'support': 288}, '5': {'precision': 0.4, 'recall': 0.022304832713754646, 'f1-score': 0.04225352112676056, 'support': 269}, '6': {'precision': 0.32, 'recall': 0.028268551236749116, 'f1-score': 0.05194805194805195, 'support': 283}, '7': {'precision': 0.7795275590551181, 'recall': 0.38823529411764707, 'f1-score': 0.518324607329843, 'support': 255}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 177}, '9': {'precision': 0.6666666666666666, 'recall': 0.05084745762711865, 'f1-score': 0.09448818897637797, 'support': 236}, '10': {'precision': 0.6363636363636364, 'recall': 0.03825136612021858, 'f1-score': 0.07216494845360824, 'support': 183}, '11': {'precision': 0.7, 'recall': 0.06698564593301436, 'f1-score': 0.1222707423580786, 'support': 209}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 160}, '13': {'precision': 0.1111111111111111, 'recall': 0.009009009009009009, 'f1-score': 0.016666666666666666, 'support': 111}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26}, '15': {'precision': 0.6831683168316832, 'recall': 0.7666666666666667, 'f1-score': 0.7225130890052356, 'support': 90}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 69}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 60}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 55}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 25}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8}, 'micro avg': {'precision': 0.5742092457420924, 'recall': 0.12417784793475402, 'f1-score': 0.20419640925805754, 'support': 3801}, 'macro avg': {'precision': 0.23944163389934625, 'recall': 0.08446124310177307, 'f1-score': 0.10314699338075684, 'support': 3801}, 'weighted avg': {'precision': 0.37408965783775716, 'recall': 0.12417784793475402, 'f1-score': 0.15824609076511428, 'support': 3801}, 'samples avg': {'precision': 0.21297200520833331, 'recall': 0.14662969680059523, 'f1-score': 0.16312003968253969, 'support': 3801}}