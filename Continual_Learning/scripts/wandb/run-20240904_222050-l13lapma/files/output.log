
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_midwest
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.440906233638525
Train: epoch: 1, loss = 0.42305195063352585
Train: epoch: 1, loss = 0.41799326916535695
Train: epoch: 1, loss = 0.4150137982144952
Train: epoch: 1, loss = 0.4126855475902557
Train: epoch: 1, loss = 0.40990754375855126
Train: epoch: 1, loss = 0.4078965918932642
Train: epoch: 1, loss = 0.4057424607872963
Train: epoch: 1, loss = 0.40424342423677445
Train: epoch: 1, loss = 0.40214616714417933
Train: epoch: 1, loss = 0.39947620697996833
Train: epoch: 1, loss = 0.3975921469864746
Train: epoch: 1, loss = 0.39614387657779915
Train: epoch: 1, loss = 0.3948729269791927
Train: epoch: 1, loss = 0.3938321175475915
Train: epoch: 1, loss = 0.39237903443630784
Train: epoch: 1, loss = 0.39159808560329323
Train: epoch: 1, loss = 0.3902790776350432
Train:  Epoch 1, Loss=0.39004229572491766, AUC-ROC Macro=0.6654172350414665, AUC-ROC Micro=0.7531973589911289
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.37161651502052945, AUC-ROC Macro=0.7202041156254282, AUC-ROC Micro=0.7848246990619692
Eval task: 2
Eval:  Epoch 1, Loss=0.31250960007309914, AUC-ROC Macro=0.5009645762607386, AUC-ROC Micro=0.5711974651043695
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.37019871942698956
Train: epoch: 2, loss = 0.3712349978461862
Train: epoch: 2, loss = 0.37024839729070663
Train: epoch: 2, loss = 0.3703611765988171
Train: epoch: 2, loss = 0.3702997704297304
Train: epoch: 2, loss = 0.37039690268536407
Train: epoch: 2, loss = 0.36992991490023475
Train: epoch: 2, loss = 0.37028626701794565
Train: epoch: 2, loss = 0.3705240707016654
Train: epoch: 2, loss = 0.36960173622518777
Train: epoch: 2, loss = 0.36811812544410877
Train: epoch: 2, loss = 0.36738483250141146
Train: epoch: 2, loss = 0.367444384682637
Train: epoch: 2, loss = 0.36702779791184836
Train: epoch: 2, loss = 0.36700738467276095
Train: epoch: 2, loss = 0.36701036162208767
Train: epoch: 2, loss = 0.367176218576291
Train: epoch: 2, loss = 0.3672549006591241
Train:  Epoch 2, Loss=0.36710747011298805, AUC-ROC Macro=0.7275875648400675, AUC-ROC Micro=0.7932668174704646
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.35914797087510425, AUC-ROC Macro=0.7435681123464257, AUC-ROC Micro=0.8020222356535595
Eval task: 2
Eval:  Epoch 2, Loss=0.31262974068522453, AUC-ROC Macro=0.49158735633595185, AUC-ROC Micro=0.5695889115466939
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3657473187893629
Train: epoch: 3, loss = 0.36526666037738326
Train: epoch: 3, loss = 0.364732200105985
Train: epoch: 3, loss = 0.36259970689192417
Train: epoch: 3, loss = 0.36314363341033457
Train: epoch: 3, loss = 0.3629819666966796
Train: epoch: 3, loss = 0.36219598941504955
Train: epoch: 3, loss = 0.36173941949382427
Train: epoch: 3, loss = 0.3608683610790306
Train: epoch: 3, loss = 0.3605252242386341
Train: epoch: 3, loss = 0.3605119542371143
Train: epoch: 3, loss = 0.36047499207779765
Train: epoch: 3, loss = 0.3605685817163724
Train: epoch: 3, loss = 0.36011416705591337
Train: epoch: 3, loss = 0.36016353729367256
Train: epoch: 3, loss = 0.35994194432161747
Train: epoch: 3, loss = 0.3595431657617583
Train: epoch: 3, loss = 0.3597633958856265
Train:  Epoch 3, Loss=0.3596757831573486, AUC-ROC Macro=0.7447369271555737, AUC-ROC Micro=0.8048646921815102
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3575316295027733, AUC-ROC Macro=0.7493258625289377, AUC-ROC Micro=0.8046121985234241
Eval task: 2
Eval:  Epoch 3, Loss=0.3262103907763958, AUC-ROC Macro=0.48777951959555166, AUC-ROC Micro=0.5556824472939952
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.35642896898090837
Train: epoch: 4, loss = 0.3574098240211606
Train: epoch: 4, loss = 0.3560820669184128
Train: epoch: 4, loss = 0.35429334187880157
Train: epoch: 4, loss = 0.35406088243424894
Train: epoch: 4, loss = 0.354145485299329
Train: epoch: 4, loss = 0.35443505552198207
Train: epoch: 4, loss = 0.3548035630956292
Train: epoch: 4, loss = 0.3539923278159565
Train: epoch: 4, loss = 0.3543658574819565
Train: epoch: 4, loss = 0.35481661458584396
Train: epoch: 4, loss = 0.3554666156694293
Train: epoch: 4, loss = 0.35544209472835064
Train: epoch: 4, loss = 0.3553091363981366
Train: epoch: 4, loss = 0.35502158526082833
Train: epoch: 4, loss = 0.35513727776240556
Train: epoch: 4, loss = 0.35492480359094986
Train: epoch: 4, loss = 0.35488443309234247
Train:  Epoch 4, Loss=0.3548512455112914, AUC-ROC Macro=0.7552688326581454, AUC-ROC Micro=0.811955902426724
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.35285942008097965, AUC-ROC Macro=0.7559028793775849, AUC-ROC Micro=0.8112632361128798
Eval task: 2
Eval:  Epoch 4, Loss=0.32365432754158974, AUC-ROC Macro=0.48147998047298723, AUC-ROC Micro=0.5429233340418329
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.34923505775630476
Train: epoch: 5, loss = 0.35082116443663836
Train: epoch: 5, loss = 0.34933050952851774
Train: epoch: 5, loss = 0.3503775099478662
Train: epoch: 5, loss = 0.35160715512931345
Train: epoch: 5, loss = 0.35224878072738647
Train: epoch: 5, loss = 0.35257212712296415
Train: epoch: 5, loss = 0.35223489250056444
Train: epoch: 5, loss = 0.35182778680490123
Train: epoch: 5, loss = 0.3515677988901734
Train: epoch: 5, loss = 0.3514023317328908
Train: epoch: 5, loss = 0.35114227056503294
Train: epoch: 5, loss = 0.35042863328296403
Train: epoch: 5, loss = 0.3506301165957536
Train: epoch: 5, loss = 0.35049677593509354
Train: epoch: 5, loss = 0.3506482617277652
Train: epoch: 5, loss = 0.3503653423707275
Train: epoch: 5, loss = 0.3504642879217863
Train:  Epoch 5, Loss=0.35063145602055085, AUC-ROC Macro=0.7641824493379394, AUC-ROC Micro=0.8179706052904573
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.35135279844204587, AUC-ROC Macro=0.7601683907288035, AUC-ROC Micro=0.8137996559314733
Eval task: 2
Eval:  Epoch 5, Loss=0.3380623981356621, AUC-ROC Macro=0.4849117424372467, AUC-ROC Micro=0.5631735066697465
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3540774567425251
Train: epoch: 6, loss = 0.34984334737062456
Train: epoch: 6, loss = 0.3479184855520725
Train: epoch: 6, loss = 0.3487284142524004
Train: epoch: 6, loss = 0.348495040088892
Train: epoch: 6, loss = 0.3479604938129584
Train: epoch: 6, loss = 0.34808023090873447
Train: epoch: 6, loss = 0.3474320257361978
Train: epoch: 6, loss = 0.3471203494237529
Train: epoch: 6, loss = 0.3476958923190832
Train: epoch: 6, loss = 0.3474236160719937
Train: epoch: 6, loss = 0.3478226044463615
Train: epoch: 6, loss = 0.3479647024663595
Train: epoch: 6, loss = 0.3480563744104334
Train: epoch: 6, loss = 0.3478637303064267
Train: epoch: 6, loss = 0.3478376390738413
Train: epoch: 6, loss = 0.3477570196460275
Train: epoch: 6, loss = 0.3475244295348724
Train:  Epoch 6, Loss=0.34733390835411526, AUC-ROC Macro=0.7707877216821422, AUC-ROC Micro=0.8224651596902927
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3519011264046033, AUC-ROC Macro=0.7634719184168586, AUC-ROC Micro=0.8151804642530314
Eval task: 2
Eval:  Epoch 6, Loss=0.34117086604237556, AUC-ROC Macro=0.477572255717801, AUC-ROC Micro=0.551267143788976
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3555866877237956, AUC-ROC Macro=0.7621553496267842, AUC-ROC Micro=0.8127559052937058
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.3404967673122883, AUC-ROC Macro=0.4891212699129, AUC-ROC Micro=0.551263055085839
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.25654163405299185
Train: epoch: 1, loss = 0.24625211101025343
Train: epoch: 1, loss = 0.2417211300879717
Train: epoch: 1, loss = 0.23866775535047055
Train: epoch: 1, loss = 0.235089626647532
Train: epoch: 1, loss = 0.23348484243576725
Train:  Epoch 1, Loss=0.23211287885413923, AUC-ROC Macro=0.6092130112505426, AUC-ROC Micro=0.7613519219973266
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.4543593650062879, AUC-ROC Macro=0.6828686116925354, AUC-ROC Micro=0.6900738108818977
Eval task: 2
Eval:  Epoch 1, Loss=0.22094671800732613, AUC-ROC Macro=0.6860972926419554, AUC-ROC Micro=0.7950916106148391
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.21682348143309355
Train: epoch: 2, loss = 0.21816375533118845
Train: epoch: 2, loss = 0.2184717230622967
Train: epoch: 2, loss = 0.21759881214238702
Train: epoch: 2, loss = 0.21732640199363232
Train: epoch: 2, loss = 0.21651111339529355
Train:  Epoch 2, Loss=0.21630036224602048, AUC-ROC Macro=0.7033438625818111, AUC-ROC Micro=0.8077589517564605
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.48051955675085384, AUC-ROC Macro=0.6471685659395505, AUC-ROC Micro=0.6598519647885275
Eval task: 2
Eval:  Epoch 2, Loss=0.21602309122681618, AUC-ROC Macro=0.714278524395736, AUC-ROC Micro=0.808208876337933
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.21059253830462693
Train: epoch: 3, loss = 0.20964171336963772
Train: epoch: 3, loss = 0.20997990902513267
Train: epoch: 3, loss = 0.2103624028339982
Train: epoch: 3, loss = 0.21046827872097493
Train: epoch: 3, loss = 0.21034124709665775
Train:  Epoch 3, Loss=0.20987835058924326, AUC-ROC Macro=0.73832985199152, AUC-ROC Micro=0.8237606221203568
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.49855923155943555, AUC-ROC Macro=0.6289100364904436, AUC-ROC Micro=0.6531541776156871
Eval task: 2
Eval:  Epoch 3, Loss=0.2104473952203989, AUC-ROC Macro=0.7308154947894717, AUC-ROC Micro=0.8233599072815492
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.2095722360908985
Train: epoch: 4, loss = 0.20722155194729566
Train: epoch: 4, loss = 0.206229370671014
Train: epoch: 4, loss = 0.20631519637070597
Train: epoch: 4, loss = 0.20680023051053287
Train: epoch: 4, loss = 0.20593361732239523
Train:  Epoch 4, Loss=0.20559312567594074, AUC-ROC Macro=0.757256503326683, AUC-ROC Micro=0.8340121495066987
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.5122227544585863, AUC-ROC Macro=0.6184948579329714, AUC-ROC Micro=0.632352956146653
Eval task: 2
Eval:  Epoch 4, Loss=0.2099890261888504, AUC-ROC Macro=0.7335984646107622, AUC-ROC Micro=0.8232767153978191
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.20089421063661575
Train: epoch: 5, loss = 0.20267980759963394
Train: epoch: 5, loss = 0.20218088787049054
Train: epoch: 5, loss = 0.20178506994619966
Train: epoch: 5, loss = 0.20207981946319342
Train: epoch: 5, loss = 0.2014752380301555
Train:  Epoch 5, Loss=0.20188579816446434, AUC-ROC Macro=0.7725516078529513, AUC-ROC Micro=0.8419934325427223
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.5170388979216417, AUC-ROC Macro=0.6174632534402288, AUC-ROC Micro=0.6325588512333072
Eval task: 2
Eval:  Epoch 5, Loss=0.2101612389087677, AUC-ROC Macro=0.733170025538717, AUC-ROC Micro=0.8251733583317711
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.195481031909585
Train: epoch: 6, loss = 0.19798114931210875
Train: epoch: 6, loss = 0.19901261077572902
Train: epoch: 6, loss = 0.1987448695767671
Train: epoch: 6, loss = 0.19874980250000954
Train: epoch: 6, loss = 0.19868804027015965
Train:  Epoch 6, Loss=0.19881019528980298, AUC-ROC Macro=0.7875673446619753, AUC-ROC Micro=0.8487226392703398
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.5259736428658167, AUC-ROC Macro=0.5960847513758918, AUC-ROC Micro=0.6245216046977143
Eval task: 2
Eval:  Epoch 6, Loss=0.20896513760089874, AUC-ROC Macro=0.7331518922711712, AUC-ROC Micro=0.8262603963353751
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.528312548995018, AUC-ROC Macro=0.598519449013557, AUC-ROC Micro=0.6275940874756738
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.21083118580281734, AUC-ROC Macro=0.7261948472604051, AUC-ROC Micro=0.8229511528574648
{'0': {'precision': 0.2936936936936937, 'recall': 0.3738532110091743, 'f1-score': 0.3289606458123108, 'support': 1308}, '1': {'precision': 0.34615384615384615, 'recall': 0.04477611940298507, 'f1-score': 0.07929515418502202, 'support': 402}, '2': {'precision': 0.1, 'recall': 0.00303951367781155, 'f1-score': 0.0058997050147492625, 'support': 658}, '3': {'precision': 0.5773195876288659, 'recall': 0.02814070351758794, 'f1-score': 0.053665548634403454, 'support': 1990}, '4': {'precision': 0.22629969418960244, 'recall': 0.09181141439205956, 'f1-score': 0.13062665489849956, 'support': 806}, '5': {'precision': 0.21084337349397592, 'recall': 0.13496143958868895, 'f1-score': 0.164576802507837, 'support': 778}, '6': {'precision': 0.3892857142857143, 'recall': 0.0837173579109063, 'f1-score': 0.13780025284450065, 'support': 1302}, '7': {'precision': 0.0695364238410596, 'recall': 0.049528301886792456, 'f1-score': 0.05785123966942148, 'support': 424}, '8': {'precision': 0.5537190082644629, 'recall': 0.04075425790754258, 'f1-score': 0.07592067988668555, 'support': 1644}, '9': {'precision': 0.5882352941176471, 'recall': 0.009847365829640572, 'f1-score': 0.019370460048426155, 'support': 2031}, '10': {'precision': 0.11475409836065574, 'recall': 0.012216404886561954, 'f1-score': 0.022082018927444793, 'support': 573}, '11': {'precision': 0.3684210526315789, 'recall': 0.005952380952380952, 'f1-score': 0.011715481171548118, 'support': 1176}, '12': {'precision': 0.5128205128205128, 'recall': 0.03389830508474576, 'f1-score': 0.06359300476947535, 'support': 1770}, '13': {'precision': 0.4327956989247312, 'recall': 0.06201848998459168, 'f1-score': 0.10849056603773585, 'support': 2596}, '14': {'precision': 0.5555555555555556, 'recall': 0.003073140749846343, 'f1-score': 0.006112469437652812, 'support': 1627}, '15': {'precision': 0.102803738317757, 'recall': 0.022727272727272728, 'f1-score': 0.03722504230118443, 'support': 484}, '16': {'precision': 0.2, 'recall': 0.0012578616352201257, 'f1-score': 0.0024999999999999996, 'support': 795}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.37142857142857144, 'recall': 0.04961832061068702, 'f1-score': 0.08754208754208753, 'support': 262}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 563}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 837}, '22': {'precision': 0.7272727272727273, 'recall': 0.014732965009208104, 'f1-score': 0.028880866425992784, 'support': 1086}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 861}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 505}, 'micro avg': {'precision': 0.2994214079074253, 'recall': 0.04894967091002247, 'f1-score': 0.08414349107415062, 'support': 25373}, 'macro avg': {'precision': 0.2696375436392383, 'recall': 0.04263699307054816, 'f1-score': 0.0568843472045991, 'support': 25373}, 'weighted avg': {'precision': 0.36478870510990247, 'recall': 0.04894967091002247, 'f1-score': 0.06617825658000102, 'support': 25373}, 'samples avg': {'precision': 0.09950028676835317, 'recall': 0.032332551702238053, 'f1-score': 0.044576653714826796, 'support': 25373}}
{'0': {'precision': 0.6278195488721805, 'recall': 0.39952153110047844, 'f1-score': 0.48830409356725146, 'support': 418}, '1': {'precision': 0.6923076923076923, 'recall': 0.08333333333333333, 'f1-score': 0.14876033057851237, 'support': 216}, '2': {'precision': 0.25, 'recall': 0.006944444444444444, 'f1-score': 0.013513513513513514, 'support': 288}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 252}, '4': {'precision': 0.46774193548387094, 'recall': 0.10069444444444445, 'f1-score': 0.16571428571428573, 'support': 288}, '5': {'precision': 0.43333333333333335, 'recall': 0.048327137546468404, 'f1-score': 0.08695652173913045, 'support': 269}, '6': {'precision': 0.4166666666666667, 'recall': 0.0176678445229682, 'f1-score': 0.03389830508474576, 'support': 283}, '7': {'precision': 0.8016528925619835, 'recall': 0.3803921568627451, 'f1-score': 0.5159574468085106, 'support': 255}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 177}, '9': {'precision': 0.576271186440678, 'recall': 0.1440677966101695, 'f1-score': 0.2305084745762712, 'support': 236}, '10': {'precision': 0.5, 'recall': 0.0273224043715847, 'f1-score': 0.05181347150259067, 'support': 183}, '11': {'precision': 0.6666666666666666, 'recall': 0.09569377990430622, 'f1-score': 0.1673640167364017, 'support': 209}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 160}, '13': {'precision': 0.3333333333333333, 'recall': 0.018018018018018018, 'f1-score': 0.03418803418803419, 'support': 111}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26}, '15': {'precision': 0.7415730337078652, 'recall': 0.7333333333333333, 'f1-score': 0.7374301675977653, 'support': 90}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 69}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 60}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 55}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 25}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8}, 'micro avg': {'precision': 0.6334716459197787, 'recall': 0.12049460668245199, 'f1-score': 0.20247568523430595, 'support': 3801}, 'macro avg': {'precision': 0.2602946515749708, 'recall': 0.08221264897969177, 'f1-score': 0.10697634646428052, 'support': 3801}, 'weighted avg': {'precision': 0.4020406308050692, 'recall': 0.12049460668245199, 'f1-score': 0.16349359483772902, 'support': 3801}, 'samples avg': {'precision': 0.20325520833333333, 'recall': 0.14473121279761902, 'f1-score': 0.15921766493055556, 'support': 3801}}