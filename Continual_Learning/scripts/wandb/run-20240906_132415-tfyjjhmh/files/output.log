
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south_baseline
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.155694256424904
Train: epoch: 1, loss = 2.125290948152542
Train: epoch: 1, loss = 2.1111489895979565
Train: epoch: 1, loss = 2.099119692146778
Train: epoch: 1, loss = 2.090183811187744
Train: epoch: 1, loss = 2.089325038592021
Train: epoch: 1, loss = 2.0856020948716574
Train: epoch: 1, loss = 2.0813282567262648
Train: epoch: 1, loss = 2.077173196805848
Train: epoch: 1, loss = 2.0745612097382544
Train: epoch: 1, loss = 2.0733357814767146
Train: epoch: 1, loss = 2.070042338768641
Train: epoch: 1, loss = 2.0669490201656635
Train: epoch: 1, loss = 2.064585515516145
Train: epoch: 1, loss = 2.0633137070735295
Train: epoch: 1, loss = 2.061999978609383
Train: epoch: 1, loss = 2.060703217983246
Train: epoch: 1, loss = 2.060136104358567
Train: epoch: 1, loss = 2.0587805576073497
Train: epoch: 1, loss = 2.057024750113487
Train: epoch: 1, loss = 2.0559431343703043
Train: epoch: 1, loss = 2.0553608401526104
Train: epoch: 1, loss = 2.055455706404603
Train: epoch: 1, loss = 2.0546340161561965
Train: epoch: 1, loss = 2.054828046321869
Train: epoch: 1, loss = 2.0541641441446084
Train: epoch: 1, loss = 2.053898207280371
Train: epoch: 1, loss = 2.0538385362284526
Train: epoch: 1, loss = 2.0527877078796255
Train: epoch: 1, loss = 2.052479447722435
Train: epoch: 1, loss = 2.05193155461742
Train: epoch: 1, loss = 2.050747240036726
Train: epoch: 1, loss = 2.0503113267096604
Train: epoch: 1, loss = 2.0498716380841593
Train: epoch: 1, loss = 2.049425728883062
Train: epoch: 1, loss = 2.0490422696040738
Train: epoch: 1, loss = 2.0484440994262694
Train: epoch: 1, loss = 2.0483635590735236
Train: epoch: 1, loss = 2.0480888713628818
Train: epoch: 1, loss = 2.04788012778759
Train: epoch: 1, loss = 2.0476443322838804
Train: epoch: 1, loss = 2.0474749235879806
Train: epoch: 1, loss = 2.0476232849304066
Train:  Epoch 1, Loss=2.0473221958977836, Cohen Kappa=0.3700336492587064, MAD=0.7196371344992312
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.035783052444458, Cohen Kappa=0.4206424937725538, MAD=0.7026312275675529
Eval task: 2
Eval:  Epoch 1, Loss=1.9175425480152, Cohen Kappa=0.0011124698216735673, MAD=0.7217994664509284
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0566425878426124, Cohen Kappa=0.33070191296587836, MAD=0.7030282713181735
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9076444054472035, Cohen Kappa=0.0017875458856124737, MAD=0.7218768772718074
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9234169441461564
Train: epoch: 1, loss = 1.912625306546688
Train: epoch: 1, loss = 1.9144851076602936
Train: epoch: 1, loss = 1.9166630274057388
Train: epoch: 1, loss = 1.9129131661653518
Train: epoch: 1, loss = 1.9111809195081393
Train: epoch: 1, loss = 1.9120533489329474
Train: epoch: 1, loss = 1.913326767012477
Train: epoch: 1, loss = 1.9145214775535795
Train: epoch: 1, loss = 1.9151512432694435
Train: epoch: 1, loss = 1.9152684127742594
Train: epoch: 1, loss = 1.915860230376323
Train: epoch: 1, loss = 1.9155453593914324
Train: epoch: 1, loss = 1.9155949946386472
Train: epoch: 1, loss = 1.915659548719724
Train: epoch: 1, loss = 1.9154612016305328
Train: epoch: 1, loss = 1.915925347103792
Train: epoch: 1, loss = 1.9155516390336884
Train: epoch: 1, loss = 1.9157921808958054
Train: epoch: 1, loss = 1.915157517105341
Train: epoch: 1, loss = 1.9139933323576337
Train: epoch: 1, loss = 1.9133449235016649
Train: epoch: 1, loss = 1.9129480400551921
Train: epoch: 1, loss = 1.912866325676441
Train: epoch: 1, loss = 1.9129900330305099
Train: epoch: 1, loss = 1.912662977048984
Train: epoch: 1, loss = 1.912515613017259
Train: epoch: 1, loss = 1.9124284597592693
Train: epoch: 1, loss = 1.9121020796586727
Train: epoch: 1, loss = 1.9115909257531165
Train: epoch: 1, loss = 1.9115083179550787
Train: epoch: 1, loss = 1.911323276795447
Train: epoch: 1, loss = 1.9114288463917646
Train: epoch: 1, loss = 1.91105356719564
Train: epoch: 1, loss = 1.9109268849066325
Train: epoch: 1, loss = 1.9107952306502396
Train: epoch: 1, loss = 1.9106592883451565
Train: epoch: 1, loss = 1.9103236945993023
Train: epoch: 1, loss = 1.909817251991003
Train: epoch: 1, loss = 1.9097237668037415
Train: epoch: 1, loss = 1.9093201886880689
Train: epoch: 1, loss = 1.9092571898159527
Train: epoch: 1, loss = 1.9089215094960013
Train:  Epoch 1, Loss=1.9087318205560957, Cohen Kappa=0.06442608345152545, MAD=0.6932000748483576
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.1725736157647493, Cohen Kappa=0.051607327262481184, MAD=0.6921752319235739
Eval task: 2
Eval:  Epoch 1, Loss=1.906557755223636, Cohen Kappa=0.18361145811546853, MAD=0.707446744619479
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.112021799745231, Cohen Kappa=0.07573138432301851, MAD=0.708402911596471
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8969481217450108, Cohen Kappa=0.13022753544947252, MAD=0.7084988272671189
{'0': {'precision': 0.41072127298813094, 'recall': 0.772760736196319, 'f1-score': 0.5363651848066768, 'support': 4075}, '1': {'precision': 0.14185843285755897, 'recall': 0.3399650959860384, 'f1-score': 0.2001849758503751, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.2776804956896552, 'macro avg': {'precision': 0.055257970584568994, 'recall': 0.11127258321823574, 'f1-score': 0.0736550160657052, 'support': 14848}, 'weighted avg': {'precision': 0.14009385759452722, 'recall': 0.2776804956896552, 'f1-score': 0.18583095931428695, 'support': 14848}}
{'0': {'precision': 0.34910032715376227, 'recall': 0.5765420981539847, 'f1-score': 0.434878587196468, 'support': 4442}, '1': {'precision': 0.3305925715905869, 'recall': 0.45316750874465606, 'f1-score': 0.3822950819672132, 'support': 5146}, '2': {'precision': 0.4, 'recall': 0.0007874015748031496, 'f1-score': 0.0015717092337917485, 'support': 2540}, '3': {'precision': 0.08196721311475409, 'recall': 0.003843197540353574, 'f1-score': 0.007342143906020558, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.20134228187919462, 'recall': 0.17045454545454544, 'f1-score': 0.18461538461538457, 'support': 176}, '9': {'precision': 0.1522633744855967, 'recall': 0.33035714285714285, 'f1-score': 0.20845070422535208, 'support': 112}, 'accuracy': 0.3345231681034483, 'macro avg': {'precision': 0.15152657682238946, 'recall': 0.15351518943254855, 'f1-score': 0.121915361114423, 'support': 14848}, 'weighted avg': {'precision': 0.29815881670511796, 'recall': 0.3345231681034483, 'f1-score': 0.26726860407941144, 'support': 14848}}