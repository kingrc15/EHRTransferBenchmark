
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1559116411209107
Train: epoch: 1, loss = 2.1342377737164497
Train: epoch: 1, loss = 2.1217200507720313
Train: epoch: 1, loss = 2.109366451948881
Train: epoch: 1, loss = 2.100342377662659
Train: epoch: 1, loss = 2.0917771833141643
Train: epoch: 1, loss = 2.0865387538501197
Train: epoch: 1, loss = 2.0816559687256815
Train: epoch: 1, loss = 2.0797575689686667
Train: epoch: 1, loss = 2.0767947407364846
Train: epoch: 1, loss = 2.074029473228888
Train: epoch: 1, loss = 2.070710815687974
Train: epoch: 1, loss = 2.0698384080483363
Train: epoch: 1, loss = 2.068768238042082
Train: epoch: 1, loss = 2.067619763771693
Train: epoch: 1, loss = 2.0658398616313933
Train: epoch: 1, loss = 2.0644407831921296
Train: epoch: 1, loss = 2.0644836103253894
Train: epoch: 1, loss = 2.063797188934527
Train: epoch: 1, loss = 2.062758513301611
Train: epoch: 1, loss = 2.061002141379175
Train: epoch: 1, loss = 2.0595537041263148
Train: epoch: 1, loss = 2.0586905747392903
Train: epoch: 1, loss = 2.0577154924968877
Train: epoch: 1, loss = 2.0566842065572737
Train: epoch: 1, loss = 2.056476741845791
Train: epoch: 1, loss = 2.055540153869876
Train: epoch: 1, loss = 2.0553287790928567
Train: epoch: 1, loss = 2.0533989803955475
Train: epoch: 1, loss = 2.0526783828139306
Train: epoch: 1, loss = 2.051917393957415
Train: epoch: 1, loss = 2.05157395651564
Train: epoch: 1, loss = 2.0514577826947877
Train: epoch: 1, loss = 2.0508087435890645
Train: epoch: 1, loss = 2.0495660036291397
Train: epoch: 1, loss = 2.049336696449253
Train: epoch: 1, loss = 2.04901060639201
Train: epoch: 1, loss = 2.0485583846663173
Train: epoch: 1, loss = 2.048378218916746
Train: epoch: 1, loss = 2.0477307647168637
Train: epoch: 1, loss = 2.047614665976385
Train: epoch: 1, loss = 2.0467356098549705
Train: epoch: 1, loss = 2.046703013805456
Train:  Epoch 1, Loss=2.0460256755965096, Cohen Kappa=0.37690808406638676, MAD=0.7160835146039691
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.028051736025975, Cohen Kappa=0.4347013841018518, MAD=0.7335427107908211
Eval task: 2
Eval:  Epoch 1, Loss=1.9778138337464168, Cohen Kappa=0.007746763267194701, MAD=0.749797748134494
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.053434026652369, Cohen Kappa=0.3283126140317161, MAD=0.7299197120526958
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9438441334099605, Cohen Kappa=0.004638324481528233, MAD=0.7484979353429936
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.978000558614731
Train: epoch: 1, loss = 1.9590695795416833
Train: epoch: 1, loss = 1.9545984584093095
Train: epoch: 1, loss = 1.950674905627966
Train: epoch: 1, loss = 1.9489593242406844
Train: epoch: 1, loss = 1.9498742868502934
Train: epoch: 1, loss = 1.9499900713988714
Train: epoch: 1, loss = 1.94918112821877
Train: epoch: 1, loss = 1.948684312502543
Train: epoch: 1, loss = 1.9497046762704848
Train: epoch: 1, loss = 1.9489421305331316
Train: epoch: 1, loss = 1.9497410088280838
Train: epoch: 1, loss = 1.9487059577611776
Train: epoch: 1, loss = 1.949396036395005
Train: epoch: 1, loss = 1.949471439043681
Train: epoch: 1, loss = 1.949625292532146
Train: epoch: 1, loss = 1.9492836251679588
Train: epoch: 1, loss = 1.9487646263506677
Train: epoch: 1, loss = 1.948220792350016
Train: epoch: 1, loss = 1.948258215367794
Train: epoch: 1, loss = 1.9484316156875519
Train: epoch: 1, loss = 1.9478503411195496
Train: epoch: 1, loss = 1.9475089876029803
Train: epoch: 1, loss = 1.9473127099623282
Train: epoch: 1, loss = 1.9480787766695022
Train: epoch: 1, loss = 1.9484044453960199
Train: epoch: 1, loss = 1.9484464175833596
Train: epoch: 1, loss = 1.9483784478051323
Train: epoch: 1, loss = 1.9484576439240884
Train: epoch: 1, loss = 1.9494126686851183
Train: epoch: 1, loss = 1.949576153063005
Train: epoch: 1, loss = 1.9493618506379427
Train: epoch: 1, loss = 1.949319209564816
Train: epoch: 1, loss = 1.9492196230152075
Train: epoch: 1, loss = 1.949520626255444
Train: epoch: 1, loss = 1.9493329129285282
Train: epoch: 1, loss = 1.9489551816920976
Train: epoch: 1, loss = 1.9489019975693602
Train: epoch: 1, loss = 1.9489665906245892
Train: epoch: 1, loss = 1.949234428986907
Train: epoch: 1, loss = 1.949037952466709
Train: epoch: 1, loss = 1.9487562951303663
Train: epoch: 1, loss = 1.9486683462664138
Train:  Epoch 1, Loss=1.9485572431836808, Cohen Kappa=0.10455107523481666, MAD=0.6859442185669563
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.072534672145186, Cohen Kappa=0.4000682200347807, MAD=0.715329593664293
Eval task: 2
Eval:  Epoch 1, Loss=1.9549472064807498, Cohen Kappa=0.1343907987178934, MAD=0.6721667892498135
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.058514919774286, Cohen Kappa=0.30725650892048684, MAD=0.7140119904367543
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9274058917473103, Cohen Kappa=0.15289168562306255, MAD=0.6765434797519116
{'0': {'precision': 0.41381766381766383, 'recall': 0.7128834355828221, 'f1-score': 0.5236593059936909, 'support': 4075}, '1': {'precision': 0.2348426707597851, 'recall': 0.3204188481675393, 'f1-score': 0.2710363153232949, 'support': 2865}, '2': {'precision': 0.16569200779727095, 'recall': 0.046754675467546754, 'f1-score': 0.07293007293007293, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.19495008807985909, 'recall': 0.5460526315789473, 'f1-score': 0.28732150584162697, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.30792025862068967, 'macro avg': {'precision': 0.1009302430454579, 'recall': 0.16261095907968554, 'f1-score': 0.11549472000886855, 'support': 14848}, 'weighted avg': {'precision': 0.1951386455458184, 'recall': 0.30792025862068967, 'f1-score': 0.22847525181949227, 'support': 14848}}
{'0': {'precision': 0.40771230502599654, 'recall': 0.44481210115811864, 'f1-score': 0.42545495648242343, 'support': 4231}, '1': {'precision': 0.33171270718232043, 'recall': 0.5967004571655734, 'f1-score': 0.42639017115261696, 'support': 5031}, '2': {'precision': 0.1978021978021978, 'recall': 0.052152317880794705, 'f1-score': 0.08254176220111367, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.12293577981651377, 'recall': 0.21895424836601307, 'f1-score': 0.15746180963572268, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.34193157327586204, 'macro avg': {'precision': 0.10601629898270286, 'recall': 0.13126191245705, 'f1-score': 0.10918486994718768, 'support': 14848}, 'weighted avg': {'precision': 0.2632937668987883, 'recall': 0.34193157327586204, 'f1-score': 0.28238638760589785, 'support': 14848}}