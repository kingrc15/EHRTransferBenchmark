
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1670944464206694
Train: epoch: 1, loss = 2.130377212166786
Train: epoch: 1, loss = 2.1093781401713687
Train: epoch: 1, loss = 2.1059935112297534
Train: epoch: 1, loss = 2.0943648257255556
Train: epoch: 1, loss = 2.0854011542598405
Train: epoch: 1, loss = 2.0834651651552747
Train: epoch: 1, loss = 2.081237996891141
Train: epoch: 1, loss = 2.0770546367433336
Train: epoch: 1, loss = 2.0749168483018874
Train: epoch: 1, loss = 2.075773727514527
Train: epoch: 1, loss = 2.0723077056805295
Train: epoch: 1, loss = 2.069356437417177
Train: epoch: 1, loss = 2.0675263859970228
Train: epoch: 1, loss = 2.069104147553444
Train: epoch: 1, loss = 2.069410730190575
Train: epoch: 1, loss = 2.0666393100514133
Train: epoch: 1, loss = 2.065802098148399
Train: epoch: 1, loss = 2.063801284965716
Train: epoch: 1, loss = 2.0628311513364315
Train: epoch: 1, loss = 2.061790893049467
Train: epoch: 1, loss = 2.06046329327605
Train: epoch: 1, loss = 2.0595477352453315
Train: epoch: 1, loss = 2.0586459946632387
Train: epoch: 1, loss = 2.0580492708683016
Train: epoch: 1, loss = 2.056857375044089
Train: epoch: 1, loss = 2.0565037558034613
Train: epoch: 1, loss = 2.055696553800787
Train: epoch: 1, loss = 2.054971561575758
Train: epoch: 1, loss = 2.053706876715024
Train: epoch: 1, loss = 2.053117927505124
Train: epoch: 1, loss = 2.052691387590021
Train: epoch: 1, loss = 2.0521556347969807
Train: epoch: 1, loss = 2.0522161221854827
Train: epoch: 1, loss = 2.0513347605126246
Train: epoch: 1, loss = 2.0508316430615054
Train: epoch: 1, loss = 2.050070590505729
Train: epoch: 1, loss = 2.0500587719678878
Train: epoch: 1, loss = 2.0492052874656825
Train: epoch: 1, loss = 2.0491918454170226
Train: epoch: 1, loss = 2.0488129140400306
Train: epoch: 1, loss = 2.0488256430909746
Train: epoch: 1, loss = 2.0484994286437366
Train:  Epoch 1, Loss=2.0480721546309333, Cohen Kappa=0.36779220155925507, MAD=0.7200884643366094
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.028522029005248, Cohen Kappa=0.43114662860505637, MAD=0.7193444128665377
Eval task: 2
Eval:  Epoch 1, Loss=1.974224162512812, Cohen Kappa=0.007748497041715874, MAD=0.7295165538456106
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.053804475685646, Cohen Kappa=0.33781070152250425, MAD=0.7080370664075544
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9390235502144386, Cohen Kappa=0.0028374069499532695, MAD=0.7267841845564275
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9648796206712722
Train: epoch: 1, loss = 1.9685880768299102
Train: epoch: 1, loss = 1.9731489062309264
Train: epoch: 1, loss = 1.9747405235469342
Train: epoch: 1, loss = 1.9752985795736313
Train: epoch: 1, loss = 1.9712866046031317
Train: epoch: 1, loss = 1.9710943906647818
Train: epoch: 1, loss = 1.9727389858663082
Train: epoch: 1, loss = 1.972886198427942
Train: epoch: 1, loss = 1.9731606808304787
Train: epoch: 1, loss = 1.972641595005989
Train: epoch: 1, loss = 1.9727964301904042
Train: epoch: 1, loss = 1.9722670198862369
Train: epoch: 1, loss = 1.9718739783763886
Train: epoch: 1, loss = 1.9711749184528986
Train: epoch: 1, loss = 1.9706871681660414
Train: epoch: 1, loss = 1.970369421839714
Train: epoch: 1, loss = 1.9702657678061062
Train: epoch: 1, loss = 1.9700316123272243
Train: epoch: 1, loss = 1.970297515332699
Train: epoch: 1, loss = 1.9700356461604436
Train: epoch: 1, loss = 1.9697800594297323
Train: epoch: 1, loss = 1.9698179029900096
Train: epoch: 1, loss = 1.9695831761757532
Train: epoch: 1, loss = 1.969469143295288
Train: epoch: 1, loss = 1.9691644306824758
Train: epoch: 1, loss = 1.9693463170307655
Train: epoch: 1, loss = 1.9689534511523588
Train: epoch: 1, loss = 1.9687445737986728
Train: epoch: 1, loss = 1.9688820271690686
Train: epoch: 1, loss = 1.9687008142471314
Train: epoch: 1, loss = 1.969003063607961
Train: epoch: 1, loss = 1.9687217606558944
Train: epoch: 1, loss = 1.9687741412835962
Train: epoch: 1, loss = 1.9682731393575668
Train: epoch: 1, loss = 1.9675049171182843
Train: epoch: 1, loss = 1.967276872396469
Train: epoch: 1, loss = 1.9668575218163038
Train: epoch: 1, loss = 1.9666063696451677
Train: epoch: 1, loss = 1.9661254356056452
Train: epoch: 1, loss = 1.965641612526847
Train: epoch: 1, loss = 1.9654139392716543
Train: epoch: 1, loss = 1.9651668851320134
Train:  Epoch 1, Loss=1.9648791829109191, Cohen Kappa=0.09798627484343347, MAD=0.6904592498643181
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0366848070045998, Cohen Kappa=0.38440065679670776, MAD=0.7380106652442994
Eval task: 2
Eval:  Epoch 1, Loss=1.9686254982290596, Cohen Kappa=0.06850006499527272, MAD=0.68192037721582
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.053544815244346, Cohen Kappa=0.3042044786812901, MAD=0.733085889596285
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9211848871461277, Cohen Kappa=0.07346647257536087, MAD=0.6853874101073776
{'0': {'precision': 0.3954858794752057, 'recall': 0.8728834355828221, 'f1-score': 0.5443415716581224, 'support': 4075}, '1': {'precision': 0.1933534743202417, 'recall': 0.1787085514834206, 'f1-score': 0.1857427897696354, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.2273449920508744, 'recall': 0.3527960526315789, 'f1-score': 0.2765066065098292, 'support': 1216}, '9': {'precision': 0.133434420015163, 'recall': 0.16402609506057783, 'f1-score': 0.14715719063545152, 'support': 1073}, 'accuracy': 0.3147898706896552, 'macro avg': {'precision': 0.09496187658614849, 'recall': 0.15684141347583996, 'f1-score': 0.11537481585730384, 'support': 14848}, 'weighted avg': {'precision': 0.17411027113409813, 'recall': 0.3147898706896552, 'f1-score': 0.21851270853075472, 'support': 14848}}
{'0': {'precision': 0.4001611928269192, 'recall': 0.46939257858662253, 'f1-score': 0.4320208831846856, 'support': 4231}, '1': {'precision': 0.31678802174135984, 'recall': 0.6139932419002186, 'f1-score': 0.41794073873630094, 'support': 5031}, '2': {'precision': 0.1875, 'recall': 0.0037251655629139072, 'f1-score': 0.007305194805194805, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.03488372093023256, 'recall': 0.00980392156862745, 'f1-score': 0.015306122448979591, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.34260506465517243, 'macro avg': {'precision': 0.09393329354985115, 'recall': 0.10969149076183823, 'f1-score': 0.08725729391751609, 'support': 14848}, 'weighted avg': {'precision': 0.2525940842427349, 'recall': 0.34260506465517243, 'f1-score': 0.26622260489328353, 'support': 14848}}