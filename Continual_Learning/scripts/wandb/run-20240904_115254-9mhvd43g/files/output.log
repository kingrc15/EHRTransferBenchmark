
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
midwest_val.csv
test_listfile.csv
midwest_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.176261582374573
Train: epoch: 1, loss = 2.1388686630129814
Train: epoch: 1, loss = 2.113575953046481
Train: epoch: 1, loss = 2.1004050704836845
Train: epoch: 1, loss = 2.0959059376716613
Train: epoch: 1, loss = 2.0877209668358168
Train: epoch: 1, loss = 2.085577320286206
Train: epoch: 1, loss = 2.081362077817321
Train: epoch: 1, loss = 2.0764389959308835
Train: epoch: 1, loss = 2.0713245616555214
Train: epoch: 1, loss = 2.0681405672701922
Train: epoch: 1, loss = 2.064960135916869
Train: epoch: 1, loss = 2.0623986365703435
Train: epoch: 1, loss = 2.06069772030626
Train: epoch: 1, loss = 2.060150117794673
Train: epoch: 1, loss = 2.059634528271854
Train: epoch: 1, loss = 2.0591476025651483
Train: epoch: 1, loss = 2.0569810536172657
Train: epoch: 1, loss = 2.056323069773222
Train: epoch: 1, loss = 2.0551055546998978
Train: epoch: 1, loss = 2.054105144029572
Train: epoch: 1, loss = 2.0534208167141133
Train: epoch: 1, loss = 2.052770906453547
Train: epoch: 1, loss = 2.0520359182606143
Train: epoch: 1, loss = 2.0511550463676453
Train: epoch: 1, loss = 2.050261718263993
Train: epoch: 1, loss = 2.0508530583425806
Train: epoch: 1, loss = 2.0507268976100854
Train: epoch: 1, loss = 2.0502951822404203
Train: epoch: 1, loss = 2.050192382693291
Train: epoch: 1, loss = 2.0496106845717277
Train: epoch: 1, loss = 2.0489737405069173
Train: epoch: 1, loss = 2.049125934207078
Train: epoch: 1, loss = 2.0482677633446804
Train: epoch: 1, loss = 2.0478391600506645
Train: epoch: 1, loss = 2.0476314645508924
Train: epoch: 1, loss = 2.047175011699264
Train: epoch: 1, loss = 2.0466725182846974
Train: epoch: 1, loss = 2.046745013946142
Train: epoch: 1, loss = 2.0468161369860174
Train: epoch: 1, loss = 2.046162938635524
Train: epoch: 1, loss = 2.0459757793943085
Train: epoch: 1, loss = 2.045936649150627
Train:  Epoch 1, Loss=2.045460775062016, Cohen Kappa=0.38439240961136356, MAD=0.7182889624493324
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.03054252780717, Cohen Kappa=0.42644816802304875, MAD=0.727555739164544
Eval task: 2
Eval:  Epoch 1, Loss=1.9757167429759586, Cohen Kappa=0.009207160787950697, MAD=0.747520123362848
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.05515763882933, Cohen Kappa=0.3312995004209305, MAD=0.7238759869995632
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9406246357950672, Cohen Kappa=0.0032792463574409236, MAD=0.7466694632664337
midwest_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9903076356649398
Train: epoch: 1, loss = 2.000549354851246
Train: epoch: 1, loss = 2.0015223745505013
Train: epoch: 1, loss = 2.0044762921333312
Train: epoch: 1, loss = 2.0026727809906006
Train: epoch: 1, loss = 1.999051778614521
Train: epoch: 1, loss = 1.999523133124624
Train: epoch: 1, loss = 1.998342344686389
Train: epoch: 1, loss = 1.9980874163574642
Train: epoch: 1, loss = 1.99627674305439
Train: epoch: 1, loss = 1.9959345010735772
Train: epoch: 1, loss = 1.9955599967141946
Train: epoch: 1, loss = 1.9953127875236365
Train: epoch: 1, loss = 1.995780638541494
Train: epoch: 1, loss = 1.9938576724529267
Train: epoch: 1, loss = 1.9939827056601644
Train: epoch: 1, loss = 1.993511899359086
Train: epoch: 1, loss = 1.9928486852513418
Train: epoch: 1, loss = 1.9928030890540074
Train: epoch: 1, loss = 1.9927474248409272
Train: epoch: 1, loss = 1.9920803606226332
Train: epoch: 1, loss = 1.991717839457772
Train: epoch: 1, loss = 1.9916568985970124
Train: epoch: 1, loss = 1.9912673559536536
Train: epoch: 1, loss = 1.9911657761096955
Train: epoch: 1, loss = 1.9907948527198571
Train: epoch: 1, loss = 1.9905997695525488
Train: epoch: 1, loss = 1.9906426759277072
Train: epoch: 1, loss = 1.9903490187998476
Train: epoch: 1, loss = 1.9898913058638572
Train: epoch: 1, loss = 1.9898491761376782
Train: epoch: 1, loss = 1.9897701494954527
Train: epoch: 1, loss = 1.9898937358820077
Train: epoch: 1, loss = 1.9898147269908127
Train: epoch: 1, loss = 1.9895720185892922
Train: epoch: 1, loss = 1.9892297247383332
Train: epoch: 1, loss = 1.9890823997033609
Train: epoch: 1, loss = 1.9892895074267136
Train: epoch: 1, loss = 1.9889374915300276
Train: epoch: 1, loss = 1.9888743194490676
Train: epoch: 1, loss = 1.9887974321696817
Train: epoch: 1, loss = 1.9884608670501482
Train: epoch: 1, loss = 1.9879696297368339
------------- 1, Loss=1.9878111743927003, Cohen Kappa=0.06919384549792718, MAD=0.692386590540521
------------- 1, Loss=1.9878111743927003, Cohen Kappa=0.06919384549792718, MAD=0.692386590540521
Eval task: 1
Eval:  Epoch 1, Loss=2.0439702601268372, Cohen Kappa=0.4294518539429064, MAD=0.7255148696606084
Eval task: 2
Eval:  Epoch 1, Loss=1.984371407278653, Cohen Kappa=0.10359049868615311, MAD=0.695836677620463
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0522540807724, Cohen Kappa=0.352690276165041, MAD=0.7214114830225742
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9254756384882434, Cohen Kappa=0.09077845811073393, MAD=0.6992747210388043
{'0': {'precision': 0.438953488372093, 'recall': 0.5928834355828221, 'f1-score': 0.5044367888088527, 'support': 4075}, '1': {'precision': 0.25492145555776496, 'recall': 0.4474694589877836, 'f1-score': 0.3248036483405118, 'support': 2865}, '2': {'precision': 0.7142857142857143, 'recall': 0.00825082508250825, 'f1-score': 0.01631321370309951, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.14407260351673284, 'recall': 0.41776315789473684, 'f1-score': 0.21425558835934205, 'support': 1216}, '9': {'precision': 0.1328125, 'recall': 0.09506057781919851, 'f1-score': 0.11080934274850623, 'support': 1073}, 'accuracy': 0.29115032327586204, 'macro avg': {'precision': 0.1685045761732305, 'recall': 0.1561427455367049, 'f1-score': 0.11706185819603121, 'support': 14848}, 'weighted avg': {'precision': 0.27851272644376696, 'recall': 0.29115032327586204, 'f1-score': 0.2286660162727629, 'support': 14848}}
{'0': {'precision': 0.33503359044538444, 'recall': 0.6364925549515481, 'f1-score': 0.43899258293259436, 'support': 4231}, '1': {'precision': 0.3235670829330772, 'recall': 0.4017094017094017, 'f1-score': 0.3584286601046378, 'support': 5031}, '2': {'precision': 0.2151394422310757, 'recall': 0.022350993377483443, 'f1-score': 0.04049493813273341, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.11182108626198083, 'recall': 0.11437908496732026, 'f1-score': 0.11308562197092083, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3234779094827586, 'macro avg': {'precision': 0.09855612018715182, 'recall': 0.11749320350057538, 'f1-score': 0.09510018031408865, 'support': 14848}, 'weighted avg': {'precision': 0.24241562905692204, 'recall': 0.3234779094827586, 'f1-score': 0.255460141313714, 'support': 14848}}