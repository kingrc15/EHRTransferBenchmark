
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
midwest_val.csv
test_listfile.csv
midwest_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.183832251429558
Train: epoch: 1, loss = 2.1356991320848464
Train: epoch: 1, loss = 2.1153659675518672
Train: epoch: 1, loss = 2.1006232373416425
Train: epoch: 1, loss = 2.0873074383735655
Train: epoch: 1, loss = 2.0837763755520187
Train: epoch: 1, loss = 2.078523995791163
Train: epoch: 1, loss = 2.0730711785703897
Train: epoch: 1, loss = 2.0693277700742088
Train: epoch: 1, loss = 2.0685646525025367
Train: epoch: 1, loss = 2.0669493158297105
Train: epoch: 1, loss = 2.064514234413703
Train: epoch: 1, loss = 2.0621450117459665
Train: epoch: 1, loss = 2.060807486133916
Train: epoch: 1, loss = 2.059379465699196
Train: epoch: 1, loss = 2.057026793062687
Train: epoch: 1, loss = 2.0558586976458044
Train: epoch: 1, loss = 2.054289615088039
Train: epoch: 1, loss = 2.054171462090392
Train: epoch: 1, loss = 2.053838858038187
Train: epoch: 1, loss = 2.0530386290947598
Train: epoch: 1, loss = 2.0521758672053165
Train: epoch: 1, loss = 2.0514947756477024
Train: epoch: 1, loss = 2.0507490426301955
Train: epoch: 1, loss = 2.0507051357507704
Train: epoch: 1, loss = 2.049949442033584
Train: epoch: 1, loss = 2.049433337494179
Train: epoch: 1, loss = 2.048114160533462
Train: epoch: 1, loss = 2.048274141858364
Train: epoch: 1, loss = 2.047072136859099
Train: epoch: 1, loss = 2.046707891994907
Train: epoch: 1, loss = 2.046283665392548
Train: epoch: 1, loss = 2.045952184760209
Train: epoch: 1, loss = 2.0456765337200724
Train: epoch: 1, loss = 2.0449865438256944
Train: epoch: 1, loss = 2.0450455921557213
Train: epoch: 1, loss = 2.0449003656007148
Train: epoch: 1, loss = 2.0447680616378783
Train: epoch: 1, loss = 2.044308952704454
Train: epoch: 1, loss = 2.0441206284165383
Train: epoch: 1, loss = 2.044218778537541
Train: epoch: 1, loss = 2.043999574581782
Train: epoch: 1, loss = 2.043718461602233
Train:  Epoch 1, Loss=2.0433473625183107, Cohen Kappa=0.38690126004844694, MAD=0.7209142141593459
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0382380547194647, Cohen Kappa=0.41235698048834024, MAD=0.7167429700102921
Eval task: 2
Eval:  Epoch 1, Loss=1.976071546817648, Cohen Kappa=0.004536997146688093, MAD=0.746026563826738
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0579757114936568, Cohen Kappa=0.3214269407235607, MAD=0.7174353184892153
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9408413274534817, Cohen Kappa=0.0016699122766317132, MAD=0.744489877343687
midwest_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.964942917227745
Train: epoch: 1, loss = 1.9738962841033936
Train: epoch: 1, loss = 1.972929257750511
Train: epoch: 1, loss = 1.978276023566723
Train: epoch: 1, loss = 1.9776959493160249
Train: epoch: 1, loss = 1.9781447024146717
Train: epoch: 1, loss = 1.978331796186311
Train: epoch: 1, loss = 1.9767316241562367
Train: epoch: 1, loss = 1.9768220129940244
Train: epoch: 1, loss = 1.9749864387512206
Train: epoch: 1, loss = 1.97508868932724
Train: epoch: 1, loss = 1.9745813219745953
Train: epoch: 1, loss = 1.9756546837549944
Train: epoch: 1, loss = 1.9751289115633284
Train: epoch: 1, loss = 1.9737395931084951
Train: epoch: 1, loss = 1.973245833106339
Train: epoch: 1, loss = 1.9721083249064053
Train: epoch: 1, loss = 1.9720858996113142
Train: epoch: 1, loss = 1.971598683187836
Train: epoch: 1, loss = 1.9716143215596675
Train: epoch: 1, loss = 1.9713977091369175
Train: epoch: 1, loss = 1.9715756529569626
Train: epoch: 1, loss = 1.9715088865549668
Train: epoch: 1, loss = 1.9712755728016298
Train: epoch: 1, loss = 1.9713152781963348
Train: epoch: 1, loss = 1.9708916773704381
Train: epoch: 1, loss = 1.9711377931303449
Train: epoch: 1, loss = 1.9710466869175434
Train: epoch: 1, loss = 1.97135827465304
Train: epoch: 1, loss = 1.9713304594953855
Train: epoch: 1, loss = 1.971295945413651
Train: epoch: 1, loss = 1.9713883758895099
Train: epoch: 1, loss = 1.9711534415411227
Train: epoch: 1, loss = 1.9707467715179219
Train: epoch: 1, loss = 1.9704052040406637
Train: epoch: 1, loss = 1.9696771863102913
Train: epoch: 1, loss = 1.9688392104168195
Train: epoch: 1, loss = 1.9678577189696462
Train: epoch: 1, loss = 1.9673109594828044
Train: epoch: 1, loss = 1.9672850471138954
Train: epoch: 1, loss = 1.9669179118261104
Train: epoch: 1, loss = 1.9659983350975172
Train: epoch: 1, loss = 1.96571432091469
Train:  Epoch 1, Loss=1.9652782002312796, Cohen Kappa=0.06866280941779646, MAD=0.6900679601784928
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0478758565310775, Cohen Kappa=0.39157781916730294, MAD=0.7581972669584017
Eval task: 2
Eval:  Epoch 1, Loss=1.9661378819366981, Cohen Kappa=0.08627644298841342, MAD=0.7067901531135456
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0608147197756272, Cohen Kappa=0.2963263313293989, MAD=0.7563643810366163
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9245028927408416, Cohen Kappa=0.09470291071138992, MAD=0.7093287899222319
{'0': {'precision': 0.388231315522489, 'recall': 0.8451533742331289, 'f1-score': 0.5320562335856635, 'support': 4075}, '1': {'precision': 0.18936495791889824, 'recall': 0.17277486910994763, 'f1-score': 0.1806899069173207, 'support': 2865}, '2': {'precision': 1.0, 'recall': 0.00055005500550055, 'f1-score': 0.0010995052226498074, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.22808093194359289, 'recall': 0.3059210526315789, 'f1-score': 0.26132771338250793, 'support': 1216}, '9': {'precision': 0.16002310803004044, 'recall': 0.2581547064305685, 'f1-score': 0.19757489300998574, 'support': 1073}, 'accuracy': 0.30906519396551724, 'macro avg': {'precision': 0.19657003134150206, 'recall': 0.15825540574107247, 'f1-score': 0.11727482521181276, 'support': 14848}, 'weighted avg': {'precision': 0.29577211902959516, 'recall': 0.30906519396551724, 'f1-score': 0.21670103686337042, 'support': 14848}}
{'0': {'precision': 0.38104152484683457, 'recall': 0.5291893169463484, 'f1-score': 0.4430592658553478, 'support': 4231}, '1': {'precision': 0.31746031746031744, 'recall': 0.5525740409461339, 'f1-score': 0.4032492022048158, 'support': 5031}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.18536585365853658, 'recall': 0.12418300653594772, 'f1-score': 0.1487279843444227, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3405845905172414, 'macro avg': {'precision': 0.08838676959656885, 'recall': 0.120594636442843, 'f1-score': 0.09950364524045863, 'support': 14848}, 'weighted avg': {'precision': 0.2199657529626432, 'recall': 0.3405845905172414, 'f1-score': 0.2659510542386717, 'support': 14848}}