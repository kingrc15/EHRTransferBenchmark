
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1406993305683137
Train: epoch: 1, loss = 2.120936059653759
Train: epoch: 1, loss = 2.0972714551289875
Train: epoch: 1, loss = 2.089968298226595
Train: epoch: 1, loss = 2.083347786307335
Train: epoch: 1, loss = 2.082350156505903
Train: epoch: 1, loss = 2.0754975779567446
Train: epoch: 1, loss = 2.0705790328234435
Train: epoch: 1, loss = 2.0697740963432523
Train: epoch: 1, loss = 2.0675060985684395
Train: epoch: 1, loss = 2.0664790777184745
Train: epoch: 1, loss = 2.0645183309912682
Train: epoch: 1, loss = 2.063051993388396
Train: epoch: 1, loss = 2.061205328745501
Train: epoch: 1, loss = 2.059650884707769
Train: epoch: 1, loss = 2.059468096271157
Train: epoch: 1, loss = 2.0580330989641302
Train: epoch: 1, loss = 2.0574217242333623
Train: epoch: 1, loss = 2.0568906717551383
Train: epoch: 1, loss = 2.056259941458702
Train: epoch: 1, loss = 2.0564981579780577
Train: epoch: 1, loss = 2.055674589547244
Train: epoch: 1, loss = 2.0544006923748097
Train: epoch: 1, loss = 2.0534422081212202
Train: epoch: 1, loss = 2.0526147050857544
Train: epoch: 1, loss = 2.0523404739453244
Train: epoch: 1, loss = 2.051516019679882
Train: epoch: 1, loss = 2.050840006789991
Train: epoch: 1, loss = 2.0506987950103035
Train: epoch: 1, loss = 2.0500830628871918
Train: epoch: 1, loss = 2.050107599592978
Train: epoch: 1, loss = 2.0496545120701195
Train: epoch: 1, loss = 2.048630526607687
Train: epoch: 1, loss = 2.048074971472516
Train: epoch: 1, loss = 2.047621580685888
Train: epoch: 1, loss = 2.0472463804317846
Train: epoch: 1, loss = 2.0466578026719997
Train: epoch: 1, loss = 2.0463147282757257
Train: epoch: 1, loss = 2.0456908430961462
Train: epoch: 1, loss = 2.045339750081301
Train: epoch: 1, loss = 2.0452872105342585
Train: epoch: 1, loss = 2.0448119665753275
Train: epoch: 1, loss = 2.044186205850091
Train:  Epoch 1, Loss=2.043683700915745, Cohen Kappa=0.38489390240584775, MAD=0.7204011865777252
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0298808566455184, Cohen Kappa=0.4281284380505569, MAD=0.7459281034814413
Eval task: 2
Eval:  Epoch 1, Loss=1.979644594521358, Cohen Kappa=0.0019956542535158883, MAD=0.7421096260013404
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.05236633070584, Cohen Kappa=0.34054289305620433, MAD=0.745252304328556
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9433719228053916, Cohen Kappa=0.0031190267550157413, MAD=0.7402874974292107
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.982575935125351
Train: epoch: 1, loss = 1.9778967997431756
Train: epoch: 1, loss = 1.9771965376536051
Train: epoch: 1, loss = 1.9758053101599216
Train: epoch: 1, loss = 1.974078997850418
Train: epoch: 1, loss = 1.9719609405597052
Train: epoch: 1, loss = 1.9737838938406536
Train: epoch: 1, loss = 1.9726117134094239
Train: epoch: 1, loss = 1.9724130664931403
Train: epoch: 1, loss = 1.9714583888053894
Train: epoch: 1, loss = 1.9712620376998728
Train: epoch: 1, loss = 1.971468142569065
Train: epoch: 1, loss = 1.9713040046049999
Train: epoch: 1, loss = 1.9716402216468538
Train: epoch: 1, loss = 1.9721002581914266
Train: epoch: 1, loss = 1.9721229922026395
Train: epoch: 1, loss = 1.9719276942926294
Train: epoch: 1, loss = 1.971640073855718
Train: epoch: 1, loss = 1.9710540371505838
Train: epoch: 1, loss = 1.9709386495649814
Train: epoch: 1, loss = 1.9705452230998448
Train: epoch: 1, loss = 1.9701455188068477
Train: epoch: 1, loss = 1.9699823865683181
Train: epoch: 1, loss = 1.9701035067687431
Train: epoch: 1, loss = 1.9697376267910003
Train: epoch: 1, loss = 1.969813277858954
Train: epoch: 1, loss = 1.9693742838170794
Train: epoch: 1, loss = 1.9699134949701174
Train: epoch: 1, loss = 1.9698231608703218
Train: epoch: 1, loss = 1.970043595870336
Train: epoch: 1, loss = 1.9708470331276617
Train: epoch: 1, loss = 1.9707036955468356
Train: epoch: 1, loss = 1.9703668729102972
Train: epoch: 1, loss = 1.9706338802856558
Train: epoch: 1, loss = 1.9705181567498615
Train: epoch: 1, loss = 1.9697412625451882
Train: epoch: 1, loss = 1.969308795397346
Train: epoch: 1, loss = 1.9687626424274947
Train: epoch: 1, loss = 1.9678203804523517
Train: epoch: 1, loss = 1.9672493324279785
Train: epoch: 1, loss = 1.9668405095833104
Train: epoch: 1, loss = 1.9660861353930972
Train: epoch: 1, loss = 1.965965502428454
Train:  Epoch 1, Loss=1.9654918182373047, Cohen Kappa=0.06876832130740129, MAD=0.6882049541452486
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.045324979157283, Cohen Kappa=0.381826506419524, MAD=0.7270031369424232
Eval task: 2
Eval:  Epoch 1, Loss=1.9764893466028675, Cohen Kappa=0.06996493741218668, MAD=0.670702826045341
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.05776584148407, Cohen Kappa=0.3128423567991031, MAD=0.723354823752673
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9218279842672676, Cohen Kappa=0.09223023344409664, MAD=0.6726861916188296
{'0': {'precision': 0.3857158458010265, 'recall': 0.8667484662576687, 'f1-score': 0.533857315598549, 'support': 4075}, '1': {'precision': 0.21349644830307812, 'recall': 0.18883071553228623, 'f1-score': 0.20040748286719762, 'support': 2865}, '2': {'precision': 0.125, 'recall': 0.00055005500550055, 'f1-score': 0.001095290251916758, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.21625912988250237, 'recall': 0.5600328947368421, 'f1-score': 0.3120274914089347, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.32024515086206895, 'macro avg': {'precision': 0.09404714239866072, 'recall': 0.16161621315322977, 'f1-score': 0.10473875801265982, 'support': 14848}, 'weighted avg': {'precision': 0.1800700766409365, 'recall': 0.32024515086206895, 'f1-score': 0.21087369791957555, 'support': 14848}}
{'0': {'precision': 0.41128318584070794, 'recall': 0.4393760340345072, 'f1-score': 0.42486572963089925, 'support': 4231}, '1': {'precision': 0.32357305371451184, 'recall': 0.6501689524945339, 'f1-score': 0.43210039630118896, 'support': 5031}, '2': {'precision': 0.125, 'recall': 0.0012417218543046358, 'f1-score': 0.002459016393442623, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.08205128205128205, 'recall': 0.05228758169934641, 'f1-score': 0.06387225548902196, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3467807112068966, 'macro avg': {'precision': 0.09419075216065019, 'recall': 0.11430742900826922, 'f1-score': 0.09232973978145528, 'support': 14848}, 'weighted avg': {'precision': 0.24886468782579718, 'recall': 0.3467807112068966, 'f1-score': 0.2691938233867063, 'support': 14848}}