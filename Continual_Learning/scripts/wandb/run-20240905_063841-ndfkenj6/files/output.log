
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
south_val.csv
test_listfile.csv
south_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.18199492931366
Train: epoch: 1, loss = 2.1374342519044878
Train: epoch: 1, loss = 2.1159017284711203
Train: epoch: 1, loss = 2.0990831169486044
Train: epoch: 1, loss = 2.0892224632501604
Train: epoch: 1, loss = 2.08743271668752
Train: epoch: 1, loss = 2.081070400646755
Train: epoch: 1, loss = 2.0762655057758095
Train: epoch: 1, loss = 2.0726676611767876
Train: epoch: 1, loss = 2.070610209941864
Train: epoch: 1, loss = 2.068442999503829
Train: epoch: 1, loss = 2.0660487589240075
Train: epoch: 1, loss = 2.0642578539940026
Train: epoch: 1, loss = 2.0633293115666933
Train: epoch: 1, loss = 2.062379626552264
Train: epoch: 1, loss = 2.061330681964755
Train: epoch: 1, loss = 2.059548058334519
Train: epoch: 1, loss = 2.0579676584071582
Train: epoch: 1, loss = 2.0564549210510754
Train: epoch: 1, loss = 2.055435263842344
Train: epoch: 1, loss = 2.054227953609966
Train: epoch: 1, loss = 2.0540466083450752
Train: epoch: 1, loss = 2.053217296237531
Train: epoch: 1, loss = 2.05220562150081
Train: epoch: 1, loss = 2.051339667057991
Train: epoch: 1, loss = 2.0510438060989746
Train: epoch: 1, loss = 2.0506260775636744
Train: epoch: 1, loss = 2.050171148478985
Train: epoch: 1, loss = 2.049292991387433
Train: epoch: 1, loss = 2.048634643296401
Train: epoch: 1, loss = 2.04853840620287
Train: epoch: 1, loss = 2.048549396060407
Train: epoch: 1, loss = 2.0480972944967673
Train: epoch: 1, loss = 2.04766083938234
Train: epoch: 1, loss = 2.0472786912236893
Train: epoch: 1, loss = 2.047067833625608
Train: epoch: 1, loss = 2.0468024023803504
Train: epoch: 1, loss = 2.0460919659231838
Train: epoch: 1, loss = 2.0457665253908206
Train: epoch: 1, loss = 2.0456601540744304
Train: epoch: 1, loss = 2.045780308377452
Train: epoch: 1, loss = 2.0454979135450864
Train: epoch: 1, loss = 2.0449893291051997
Train:  Epoch 1, Loss=2.0449264450890676, Cohen Kappa=0.3858358084820238, MAD=0.7167304015799227
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.033271131844356, Cohen Kappa=0.4196569992826168, MAD=0.7313591920771192
Eval task: 2
Eval:  Epoch 1, Loss=1.92159955665983, Cohen Kappa=0.000903487598854058, MAD=0.7452410691601002
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.055876427683337, Cohen Kappa=0.3195595958018238, MAD=0.7357189355525827
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.913818330600344, Cohen Kappa=0.0016499814266158763, MAD=0.7454891838261719
south_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9108198136091232
Train: epoch: 1, loss = 1.9102174612879752
Train: epoch: 1, loss = 1.9086011344194411
Train: epoch: 1, loss = 1.911921875923872
Train: epoch: 1, loss = 1.9111504105329513
Train: epoch: 1, loss = 1.9126793201764425
Train: epoch: 1, loss = 1.9122072959797722
Train: epoch: 1, loss = 1.9115617498755455
Train: epoch: 1, loss = 1.9107842097679775
Train: epoch: 1, loss = 1.9091867482662201
Train: epoch: 1, loss = 1.9100408952886407
Train: epoch: 1, loss = 1.910190718472004
Train: epoch: 1, loss = 1.9092748321936681
Train: epoch: 1, loss = 1.9104909304210118
Train: epoch: 1, loss = 1.9115625267028808
Train: epoch: 1, loss = 1.9108163120225072
Train: epoch: 1, loss = 1.9108296548268375
Train: epoch: 1, loss = 1.9111405690842205
Train: epoch: 1, loss = 1.9099337961485512
Train: epoch: 1, loss = 1.909752486795187
Train: epoch: 1, loss = 1.9099737813075384
Train: epoch: 1, loss = 1.9098040757125074
Train: epoch: 1, loss = 1.9093707073512285
Train: epoch: 1, loss = 1.909505589455366
Train: epoch: 1, loss = 1.9094815284490585
Train: epoch: 1, loss = 1.9094359429524494
Train: epoch: 1, loss = 1.9088873024781545
Train: epoch: 1, loss = 1.9087039228848048
Train: epoch: 1, loss = 1.9090336491732762
Train: epoch: 1, loss = 1.9091070838769277
Train: epoch: 1, loss = 1.9093334998623017
Train: epoch: 1, loss = 1.9090212273225189
Train: epoch: 1, loss = 1.908821294795383
Train: epoch: 1, loss = 1.908703872859478
Train: epoch: 1, loss = 1.9087967920643942
Train: epoch: 1, loss = 1.9088300956454543
Train: epoch: 1, loss = 1.9086170468781445
Train: epoch: 1, loss = 1.908470501742865
Train: epoch: 1, loss = 1.9084215554824242
Train: epoch: 1, loss = 1.9083278709501028
Train: epoch: 1, loss = 1.9085367389132337
Train: epoch: 1, loss = 1.9088663793035916
Train: epoch: 1, loss = 1.9093363030566726
Train:  Epoch 1, Loss=1.909042232131958, Cohen Kappa=0.06868774094618424, MAD=0.692240243778943
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.055686880802286, Cohen Kappa=0.401912860010989, MAD=0.7278208123894505
Eval task: 2
Eval:  Epoch 1, Loss=1.9078559896041607, Cohen Kappa=0.18017248079664405, MAD=0.6999402185180199
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0822680880283486, Cohen Kappa=0.32062198993667534, MAD=0.7351901386082857
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.900015804274329, Cohen Kappa=0.06791806707011161, MAD=0.7005785019137802
{'0': {'precision': 0.22608695652173913, 'recall': 0.006380368098159509, 'f1-score': 0.012410501193317422, 'support': 4075}, '1': {'precision': 0.24172632015769271, 'recall': 0.8132635253054101, 'f1-score': 0.372680742162508, 'support': 2865}, '2': {'precision': 0.24489795918367346, 'recall': 0.013201320132013201, 'f1-score': 0.025052192066805846, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.0960960960960961, 'recall': 0.02631578947368421, 'f1-score': 0.041316978695932864, 'support': 1216}, '9': {'precision': 0.145985401459854, 'recall': 0.6337371854613234, 'f1-score': 0.23730588030012212, 'support': 1073}, 'accuracy': 0.20824353448275862, 'macro avg': {'precision': 0.09547927334190556, 'recall': 0.14928981884705905, 'f1-score': 0.06887662944186863, 'support': 14848}, 'weighted avg': {'precision': 0.1570965741846088, 'recall': 0.20824353448275862, 'f1-score': 0.098916935580017, 'support': 14848}}
{'0': {'precision': 0.3481029810298103, 'recall': 0.5783430886987844, 'f1-score': 0.43461343258331925, 'support': 4442}, '1': {'precision': 0.31432525951557094, 'recall': 0.4413136416634279, 'f1-score': 0.36714897744725566, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.20930232558139536, 'recall': 0.006917755572636433, 'f1-score': 0.013392857142857142, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.14814814814814814, 'recall': 0.06818181818181818, 'f1-score': 0.0933852140077821, 'support': 176}, '9': {'precision': 0.02586206896551724, 'recall': 0.026785714285714284, 'f1-score': 0.02631578947368421, 'support': 112}, 'accuracy': 0.3275862068965517, 'macro avg': {'precision': 0.10457407832404422, 'recall': 0.11215420184023812, 'f1-score': 0.09348562706548982, 'support': 14848}, 'weighted avg': {'precision': 0.2333690853031488, 'recall': 0.3275862068965517, 'f1-score': 0.259746011497034, 'support': 14848}}