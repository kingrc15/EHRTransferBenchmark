
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_west
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
west_val.csv
test_listfile.csv
west_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.175035703778267
Train: epoch: 1, loss = 2.1400328615307807
Train: epoch: 1, loss = 2.110698147813479
Train: epoch: 1, loss = 2.0958097751438616
Train: epoch: 1, loss = 2.085898545026779
Train: epoch: 1, loss = 2.079857671658198
Train: epoch: 1, loss = 2.0745853988613403
Train: epoch: 1, loss = 2.072115247398615
Train: epoch: 1, loss = 2.0683989583121405
Train: epoch: 1, loss = 2.0649823345541956
Train: epoch: 1, loss = 2.0629934029145676
Train: epoch: 1, loss = 2.0611483586827912
Train: epoch: 1, loss = 2.0605740706737223
Train: epoch: 1, loss = 2.0598110548513278
Train: epoch: 1, loss = 2.058815531373024
Train: epoch: 1, loss = 2.0570635127648713
Train: epoch: 1, loss = 2.056249727641835
Train: epoch: 1, loss = 2.0554892572429444
Train: epoch: 1, loss = 2.054710854229174
Train: epoch: 1, loss = 2.053569994688034
Train: epoch: 1, loss = 2.0520932472036
Train: epoch: 1, loss = 2.051860951699994
Train: epoch: 1, loss = 2.051236575116282
Train: epoch: 1, loss = 2.0504556823521853
Train: epoch: 1, loss = 2.0502968228101732
Train: epoch: 1, loss = 2.0503075560239643
Train: epoch: 1, loss = 2.050506934876795
Train: epoch: 1, loss = 2.050436912051269
Train: epoch: 1, loss = 2.049843936932498
Train: epoch: 1, loss = 2.0493549942374227
Train: epoch: 1, loss = 2.048883675836748
Train: epoch: 1, loss = 2.0482106260582804
Train: epoch: 1, loss = 2.0479338250918824
Train: epoch: 1, loss = 2.04702077311628
Train: epoch: 1, loss = 2.046717840399061
Train: epoch: 1, loss = 2.046664521429274
Train: epoch: 1, loss = 2.0459813978220964
Train: epoch: 1, loss = 2.0459934264107753
Train: epoch: 1, loss = 2.044943464321968
Train: epoch: 1, loss = 2.0443881169408558
Train: epoch: 1, loss = 2.0439595065756544
Train: epoch: 1, loss = 2.0433962477530754
Train: epoch: 1, loss = 2.0434147580972937
Train:  Epoch 1, Loss=2.0434847137314933, Cohen Kappa=0.3870617084464766, MAD=0.7179402188016575
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0394574300996187, Cohen Kappa=0.4123090011706547, MAD=0.7299715789036381
Eval task: 2
Eval:  Epoch 1, Loss=1.8861730098724365, Cohen Kappa=0.003709194979637065, MAD=0.7581710903177818
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.061416278625357, Cohen Kappa=0.3126601680182255, MAD=0.7355985919536051
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9008117215386753, Cohen Kappa=-0.0015081280417115206, MAD=0.7598239977406085
west_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.965856249332428
Train: epoch: 1, loss = 1.959708041846752
Train: epoch: 1, loss = 1.95581640958786
Train: epoch: 1, loss = 1.9605806198716165
Train: epoch: 1, loss = 1.956963982462883
Train: epoch: 1, loss = 1.9546748542785644
Train: epoch: 1, loss = 1.9536076760292054
Train: epoch: 1, loss = 1.9537456024438142
Train: epoch: 1, loss = 1.9540267586045794
Train: epoch: 1, loss = 1.9527601267099381
Train: epoch: 1, loss = 1.9536314609375867
Train: epoch: 1, loss = 1.9539115166167418
Train: epoch: 1, loss = 1.9535910249214905
Train: epoch: 1, loss = 1.9538056419576917
Train: epoch: 1, loss = 1.9538660625219344
Train: epoch: 1, loss = 1.953480386659503
Train: epoch: 1, loss = 1.9536496952000786
Train: epoch: 1, loss = 1.951364731490612
Train: epoch: 1, loss = 1.947383187601441
Train: epoch: 1, loss = 1.9442812350094318
Train: epoch: 1, loss = 1.940688578713508
Train:  Epoch 1, Loss=1.9391334760665893, Cohen Kappa=0.004090445974788026, MAD=0.7281415462838621
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0434935031266046, Cohen Kappa=0.4066250396021258, MAD=0.7137739450954178
Eval task: 2
Eval:  Epoch 1, Loss=1.9839525099458366, Cohen Kappa=-0.002931985560197914, MAD=0.7116149057818358
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0657287034495124, Cohen Kappa=0.33353704273010576, MAD=0.7086087742752037
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8834991537291428, Cohen Kappa=-0.0179777808107906, MAD=0.712210469839424
{'0': {'precision': 0.4197769197769198, 'recall': 0.48024539877300615, 'f1-score': 0.44797985578573885, 'support': 4075}, '1': {'precision': 0.25521000320615583, 'recall': 0.555671902268761, 'f1-score': 0.3497747995166429, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.18440436880873762, 'recall': 0.5970394736842105, 'f1-score': 0.28177760527847856, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.28791756465517243, 'macro avg': {'precision': 0.08593912917918131, 'recall': 0.16329567747259777, 'f1-score': 0.10795322605808604, 'support': 14848}, 'weighted avg': {'precision': 0.17955302530630451, 'recall': 0.28791756465517243, 'f1-score': 0.2135145663362539, 'support': 14848}}
{'0': {'precision': 0.3172328379334749, 'recall': 0.7235673930589185, 'f1-score': 0.44108241082410826, 'support': 2478}, '1': {'precision': 0.38656884875846503, 'recall': 0.26396917148362237, 'f1-score': 0.31371651019006186, 'support': 2595}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1084}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 501}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 215}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 121}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 103}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 153}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102}, 'accuracy': 0.3337823275862069, 'macro avg': {'precision': 0.07038016866919398, 'recall': 0.09875365645425409, 'f1-score': 0.075479892101417, 'support': 7424}, 'weighted avg': {'precision': 0.24100877356241482, 'recall': 0.3337823275862069, 'f1-score': 0.256882618260419, 'support': 7424}}