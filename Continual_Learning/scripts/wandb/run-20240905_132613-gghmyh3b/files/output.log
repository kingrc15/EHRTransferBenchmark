
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_west
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
west_val.csv
test_listfile.csv
west_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.165625551342964
Train: epoch: 1, loss = 2.1233315759897233
Train: epoch: 1, loss = 2.1027336992820103
Train: epoch: 1, loss = 2.090621674358845
Train: epoch: 1, loss = 2.0839027330875397
Train: epoch: 1, loss = 2.077728456556797
Train: epoch: 1, loss = 2.0737665333918165
Train: epoch: 1, loss = 2.070127850845456
Train: epoch: 1, loss = 2.0660051684247125
Train: epoch: 1, loss = 2.063048047244549
Train: epoch: 1, loss = 2.061930290677331
Train: epoch: 1, loss = 2.061060257007678
Train: epoch: 1, loss = 2.0617807637728176
Train: epoch: 1, loss = 2.0620547579016004
Train: epoch: 1, loss = 2.0610919326941173
Train: epoch: 1, loss = 2.060234571620822
Train: epoch: 1, loss = 2.0583617047351948
Train: epoch: 1, loss = 2.0572224166989326
Train: epoch: 1, loss = 2.055768221365778
Train: epoch: 1, loss = 2.05496798607707
Train: epoch: 1, loss = 2.054259291489919
Train: epoch: 1, loss = 2.0533067731965673
Train: epoch: 1, loss = 2.052720542265021
Train: epoch: 1, loss = 2.0525537346303464
Train: epoch: 1, loss = 2.052229603815079
Train: epoch: 1, loss = 2.052186932128209
Train: epoch: 1, loss = 2.052529420852661
Train: epoch: 1, loss = 2.051788321925061
Train: epoch: 1, loss = 2.051503390176543
Train: epoch: 1, loss = 2.0516458295583724
Train: epoch: 1, loss = 2.0502207200565645
Train: epoch: 1, loss = 2.049878379739821
Train: epoch: 1, loss = 2.049396763498133
Train: epoch: 1, loss = 2.048866359363584
Train: epoch: 1, loss = 2.0484735252857207
Train: epoch: 1, loss = 2.048063281741407
Train: epoch: 1, loss = 2.0475721453492706
Train: epoch: 1, loss = 2.046981537357757
Train: epoch: 1, loss = 2.047321931475248
Train: epoch: 1, loss = 2.0469905694425106
Train: epoch: 1, loss = 2.0464978017312725
Train: epoch: 1, loss = 2.0459899318502064
Train: epoch: 1, loss = 2.0455322583331617
Train:  Epoch 1, Loss=2.0453206754956925, Cohen Kappa=0.38487735524912203, MAD=0.7188768767176
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.032250478349883, Cohen Kappa=0.41944620667863564, MAD=0.7342158745947339
Eval task: 2
Eval:  Epoch 1, Loss=1.8757605100500172, Cohen Kappa=0.0009811488017437142, MAD=0.740941259910037
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0548503686641824, Cohen Kappa=0.314509780464596, MAD=0.7324484858519111
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8898383954475666, Cohen Kappa=0.0011135506176576104, MAD=0.7419758232091426
west_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.8627125257253647
Train: epoch: 1, loss = 1.874818159043789
Train: epoch: 1, loss = 1.874727618296941
Train: epoch: 1, loss = 1.884012213498354
Train: epoch: 1, loss = 1.8842739936113357
Train: epoch: 1, loss = 1.8846347209811212
Train: epoch: 1, loss = 1.8837867325544357
Train: epoch: 1, loss = 1.8828939849883317
Train: epoch: 1, loss = 1.8835585036542681
Train: epoch: 1, loss = 1.882286502122879
Train: epoch: 1, loss = 1.8810179546746342
Train: epoch: 1, loss = 1.8807407052318255
Train: epoch: 1, loss = 1.8797424658445212
Train: epoch: 1, loss = 1.8794691158192498
Train: epoch: 1, loss = 1.8790520691076915
Train: epoch: 1, loss = 1.8788669791817665
Train: epoch: 1, loss = 1.878660039621241
Train: epoch: 1, loss = 1.8778999005092516
Train: epoch: 1, loss = 1.8769740376660697
Train: epoch: 1, loss = 1.8771613213121892
Train: epoch: 1, loss = 1.8763286137013209
Train:  Epoch 1, Loss=1.8765236821855817, Cohen Kappa=0.0012113160850446558, MAD=0.7231450909245218
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0533335332212777, Cohen Kappa=0.3622621804655747, MAD=0.7371548330804886
Eval task: 2
Eval:  Epoch 1, Loss=1.8728226793223415, Cohen Kappa=0.0039543499371382795, MAD=0.7276981606283526
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.078124761581421, Cohen Kappa=0.23222413242757511, MAD=0.731339556213629
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8850684124847938, Cohen Kappa=0.006003211649911355, MAD=0.7271381813703355
{'0': {'precision': 0.3869212962962963, 'recall': 0.8203680981595092, 'f1-score': 0.5258356272119544, 'support': 4075}, '1': {'precision': 0.1954215522054718, 'recall': 0.2443280977312391, 'f1-score': 0.21715526601520088, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.21944035346097202, 'recall': 0.1225328947368421, 'f1-score': 0.15725593667546175, 'support': 1216}, '9': {'precision': 0.10580380071905496, 'recall': 0.19198508853681268, 'f1-score': 0.13642384105960265, 'support': 1073}, 'accuracy': 0.29620150862068967, 'macro avg': {'precision': 0.0907587002681795, 'recall': 0.13792141791644028, 'f1-score': 0.10366706709622198, 'support': 14848}, 'weighted avg': {'precision': 0.16951468059376162, 'recall': 0.29620150862068967, 'f1-score': 0.20895312624438173, 'support': 14848}}
{'0': {'precision': 0.33858267716535434, 'recall': 0.9196933010492333, 'f1-score': 0.4949505918123575, 'support': 2478}, '1': {'precision': 0.38095238095238093, 'recall': 0.10173410404624278, 'f1-score': 0.16058394160583941, 'support': 2595}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1084}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 501}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 215}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 121}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 103}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 153}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102}, 'accuracy': 0.3425377155172414, 'macro avg': {'precision': 0.07195350581177354, 'recall': 0.10214274050954761, 'f1-score': 0.0655534533418197, 'support': 7424}, 'weighted avg': {'precision': 0.24617178105969514, 'recall': 0.3425377155172414, 'f1-score': 0.22133659684512058, 'support': 7424}}