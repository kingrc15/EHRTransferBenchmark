
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_decomp_midwest_baseline
['/data/datasets/mimic3-benchmarks/data/decompensation', '/data/datasets/eICU2MIMIC/decompensation_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.12720445476006717
Train: epoch: 1, loss = 0.10643107240321115
Train: epoch: 1, loss = 0.10046762555837631
Train: epoch: 1, loss = 0.09633883043657988
Train: epoch: 1, loss = 0.09551381588121877
Train: epoch: 1, loss = 0.09359440250943105
Train: epoch: 1, loss = 0.0925535561540164
Train: epoch: 1, loss = 0.09385227142323856
Train: epoch: 1, loss = 0.0902735560903481
Train: epoch: 1, loss = 0.08932630679081194
Train: epoch: 1, loss = 0.08777981290011666
Train: epoch: 1, loss = 0.0877731313520538
Train: epoch: 1, loss = 0.08865458589656135
Train: epoch: 1, loss = 0.08808466665080882
Train: epoch: 1, loss = 0.08914936285838485
Train: epoch: 1, loss = 0.08832170633642818
Train: epoch: 1, loss = 0.08726591172439786
Train: epoch: 1, loss = 0.08770337545219162
Train: epoch: 1, loss = 0.08720742118480541
Train: epoch: 1, loss = 0.08624283920813468
Train: epoch: 1, loss = 0.08524875253436177
Train: epoch: 1, loss = 0.08450377225132384
Train: epoch: 1, loss = 0.08436046130972935
Train: epoch: 1, loss = 0.08383766643564741
Train: epoch: 1, loss = 0.08346072706284467
Train: epoch: 1, loss = 0.08329305573418073
Train: epoch: 1, loss = 0.08301078742932684
Train: epoch: 1, loss = 0.08258131306691212
Train: epoch: 1, loss = 0.08255252745586592
Train: epoch: 1, loss = 0.08307202166720526
Train: epoch: 1, loss = 0.0823940600426079
Train: epoch: 1, loss = 0.082469429476605
Train: epoch: 1, loss = 0.08226251975183417
Train: epoch: 1, loss = 0.08239060715743107
Train: epoch: 1, loss = 0.08260182041167614
Train: epoch: 1, loss = 0.08264861607295138
Train: epoch: 1, loss = 0.08267784420987655
Train: epoch: 1, loss = 0.08295734440088333
Train: epoch: 1, loss = 0.08257022508048417
Train: epoch: 1, loss = 0.08212089532070968
Train: epoch: 1, loss = 0.08211995062443836
Train: epoch: 1, loss = 0.08214613416833648
Train: epoch: 1, loss = 0.08247593015229308
Train:  Epoch 1, Loss=0.08259981538879552, AUC-ROC=0.8258622547681287, AUC-PR=0.1643768916658499
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.08679801026551888, AUC-ROC=0.8567490227743411, AUC-PR=0.22104999731205222
Eval task: 2
Eval:  Epoch 1, Loss=0.12952966859628415, AUC-ROC=0.6332595730881512, AUC-PR=0.04973537731434896
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.0882303387825859, AUC-ROC=0.8700736959336683, AUC-PR=0.2189832514209657
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.1195025927676209, AUC-ROC=0.6130469678953626, AUC-PR=0.04441214717762207
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.11945526500523557
Train: epoch: 1, loss = 0.1129911009411444
Train: epoch: 1, loss = 0.1077421370880135
Train: epoch: 1, loss = 0.11428401145691168
Train: epoch: 1, loss = 0.11802470186224673
Train: epoch: 1, loss = 0.11723469441261841
Train: epoch: 1, loss = 0.11805347679490556
Train: epoch: 1, loss = 0.11857587454585883
Train: epoch: 1, loss = 0.11704504676868156
Train: epoch: 1, loss = 0.11725366635929095
Train: epoch: 1, loss = 0.11599876521859022
Train: epoch: 1, loss = 0.1134012500771496
Train: epoch: 1, loss = 0.11331229823789236
Train: epoch: 1, loss = 0.11323299439894202
Train: epoch: 1, loss = 0.11250450670257366
Train: epoch: 1, loss = 0.11254503822816332
Train: epoch: 1, loss = 0.11214786440781181
Train: epoch: 1, loss = 0.11214435878510509
Train: epoch: 1, loss = 0.11097297622665983
Train: epoch: 1, loss = 0.11082272497742088
Train: epoch: 1, loss = 0.11024528380630294
Train: epoch: 1, loss = 0.1093877843055419
Train: epoch: 1, loss = 0.10957529078189628
Train: epoch: 1, loss = 0.10877778649361668
Train: epoch: 1, loss = 0.10978952118635643
Train: epoch: 1, loss = 0.11052097762981877
Train: epoch: 1, loss = 0.11046584957221058
Train: epoch: 1, loss = 0.1109809146245451
Train: epoch: 1, loss = 0.11092918286077952
Train: epoch: 1, loss = 0.11176926648393662
Train: epoch: 1, loss = 0.1115791602640961
Train: epoch: 1, loss = 0.11119859698877917
Train: epoch: 1, loss = 0.11110879676284226
Train: epoch: 1, loss = 0.11046063574539457
Train: epoch: 1, loss = 0.11053977545512109
Train: epoch: 1, loss = 0.11017669813993658
Train: epoch: 1, loss = 0.10967942843347397
Train: epoch: 1, loss = 0.10997302427123558
Train: epoch: 1, loss = 0.11048351784912834
Train: epoch: 1, loss = 0.10996220280435227
Train: epoch: 1, loss = 0.11017943700964324
Train: epoch: 1, loss = 0.11019935869646447
Train: epoch: 1, loss = 0.1102044106934485
Train:  Epoch 1, Loss=0.11011969902681719, AUC-ROC=0.676109559795478, AUC-PR=0.09043567177846767
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.10209540097877898, AUC-ROC=0.796374969270727, AUC-PR=0.12539614944698235
Eval task: 2
Eval:  Epoch 1, Loss=0.10827834409629476, AUC-ROC=0.7264587916204308, AUC-PR=0.12207020330910953
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.08470748920507472, AUC-ROC=0.8476405045214027, AUC-PR=0.26755240974731176
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.10144747125691381, AUC-ROC=0.7314047760602458, AUC-PR=0.1204016289646408