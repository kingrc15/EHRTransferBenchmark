Experiment dir: ./exp/Test_phen_midwest
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.43568686619400976
Train: epoch: 1, loss = 0.42449799701571467
Train: epoch: 1, loss = 0.41744411463538805
Train: epoch: 1, loss = 0.41332248285412787
Train: epoch: 1, loss = 0.4116608265340328
Train: epoch: 1, loss = 0.40931921104590097
Train: epoch: 1, loss = 0.4060048267777477
Train: epoch: 1, loss = 0.403606311744079
Train: epoch: 1, loss = 0.40167624961998727
Train: epoch: 1, loss = 0.399848680794239
Train: epoch: 1, loss = 0.3984020600671118
Train: epoch: 1, loss = 0.39736006359259285
Train: epoch: 1, loss = 0.3961034902471762
Train: epoch: 1, loss = 0.39405053805559875
Train: epoch: 1, loss = 0.39303436601658664
Train: epoch: 1, loss = 0.3921838958421722
Train: epoch: 1, loss = 0.39103344701230525
Train: epoch: 1, loss = 0.38981399366839065
Train:  Epoch 1, Loss=0.3894329353825659, AUC-ROC Macro=0.6659459285578175, AUC-ROC Micro=0.7542647285306685
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3699428488810857, AUC-ROC Macro=0.7205671118481751, AUC-ROC Micro=0.7840102244304146
Eval task: 2
Eval:  Epoch 1, Loss=0.30616309121251106, AUC-ROC Macro=0.5086818771250244, AUC-ROC Micro=0.5934519037328716
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.36612452946603297
Train: epoch: 2, loss = 0.3667311494424939
Train: epoch: 2, loss = 0.3677602795759837
Train: epoch: 2, loss = 0.369508108869195
Train: epoch: 2, loss = 0.3698310365229845
Train: epoch: 2, loss = 0.36978437145551046
Train: epoch: 2, loss = 0.36938855931162834
Train: epoch: 2, loss = 0.3692739235516638
Train: epoch: 2, loss = 0.3698871990127696
Train: epoch: 2, loss = 0.36961006344109776
Train: epoch: 2, loss = 0.36910457303578204
Train: epoch: 2, loss = 0.36899859430268406
Train: epoch: 2, loss = 0.36878500004227344
Train: epoch: 2, loss = 0.3680106613838247
Train: epoch: 2, loss = 0.36825641883909704
Train: epoch: 2, loss = 0.3679025214444846
Train: epoch: 2, loss = 0.3680395823980079
Train: epoch: 2, loss = 0.367461008168757
Train:  Epoch 2, Loss=0.3672995893690321, AUC-ROC Macro=0.7274461850004278, AUC-ROC Micro=0.793097081388348
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3608169878522555, AUC-ROC Macro=0.7408132892111222, AUC-ROC Micro=0.7997026253305656
Eval task: 2
Eval:  Epoch 2, Loss=0.316141564399004, AUC-ROC Macro=0.478178257728109, AUC-ROC Micro=0.5545373925729282
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.35891074396669864
Train: epoch: 3, loss = 0.3610193317756057
Train: epoch: 3, loss = 0.3620314733684063
Train: epoch: 3, loss = 0.3606861368007958
Train: epoch: 3, loss = 0.3602864606231451
Train: epoch: 3, loss = 0.3604637429490685
Train: epoch: 3, loss = 0.35967304453253746
Train: epoch: 3, loss = 0.3595381261780858
Train: epoch: 3, loss = 0.3599608385562897
Train: epoch: 3, loss = 0.3599707324355841
Train: epoch: 3, loss = 0.35989724441008136
Train: epoch: 3, loss = 0.3599285623431206
Train: epoch: 3, loss = 0.36019700093911244
Train: epoch: 3, loss = 0.35990119599870274
Train: epoch: 3, loss = 0.3596283362706502
Train: epoch: 3, loss = 0.35949770792853086
Train: epoch: 3, loss = 0.3593296711409793
Train: epoch: 3, loss = 0.35924306141419543
Train:  Epoch 3, Loss=0.3592879958845611, AUC-ROC Macro=0.7458776382794838, AUC-ROC Micro=0.8054889851670474
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.35506807391842204, AUC-ROC Macro=0.7521693945601209, AUC-ROC Micro=0.8079926289198542
Eval task: 2
Eval:  Epoch 3, Loss=0.32547764852643013, AUC-ROC Macro=0.4814703173718153, AUC-ROC Micro=0.5648546237774319
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.35502598755061626
Train: epoch: 4, loss = 0.3543561200425029
Train: epoch: 4, loss = 0.35463481133182845
Train: epoch: 4, loss = 0.3554707877151668
Train: epoch: 4, loss = 0.3559264846891165
Train: epoch: 4, loss = 0.35541834726929666
Train: epoch: 4, loss = 0.3545959527258362
Train: epoch: 4, loss = 0.3553860036935657
Train: epoch: 4, loss = 0.35551455752717126
Train: epoch: 4, loss = 0.3555429778769612
Train: epoch: 4, loss = 0.35493832256983626
Train: epoch: 4, loss = 0.35461245086044074
Train: epoch: 4, loss = 0.3542781098645467
Train: epoch: 4, loss = 0.3544486655560987
Train: epoch: 4, loss = 0.3548979626695315
Train: epoch: 4, loss = 0.35465584790799765
Train: epoch: 4, loss = 0.35405131159021574
Train: epoch: 4, loss = 0.35358355027106075
Train:  Epoch 4, Loss=0.3536452074173169, AUC-ROC Macro=0.7580247550798734, AUC-ROC Micro=0.8137150517534295
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.35392961526910466, AUC-ROC Macro=0.7570751511677253, AUC-ROC Micro=0.8106299407008658
Eval task: 2
Eval:  Epoch 4, Loss=0.3377772383391857, AUC-ROC Macro=0.4761959526515403, AUC-ROC Micro=0.5657548156742347
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.3478975463658571
Train: epoch: 5, loss = 0.3495045329630375
Train: epoch: 5, loss = 0.3510809361189604
Train: epoch: 5, loss = 0.3514900272153318
Train: epoch: 5, loss = 0.3498106641769409
Train: epoch: 5, loss = 0.3488785592963298
Train: epoch: 5, loss = 0.34906408417437756
Train: epoch: 5, loss = 0.3487920007482171
Train: epoch: 5, loss = 0.348946259236998
Train: epoch: 5, loss = 0.3498178157284856
Train: epoch: 5, loss = 0.35011914714493536
Train: epoch: 5, loss = 0.3499644895394643
Train: epoch: 5, loss = 0.3497309819322366
Train: epoch: 5, loss = 0.3498882715084723
Train: epoch: 5, loss = 0.34998785848915576
Train: epoch: 5, loss = 0.34993288265075534
Train: epoch: 5, loss = 0.34949036736698713
Train: epoch: 5, loss = 0.34978314574807884
Train:  Epoch 5, Loss=0.3495991502501007, AUC-ROC Macro=0.7663782521367516, AUC-ROC Micro=0.8194314252995039
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3505297948916753, AUC-ROC Macro=0.7618249662549275, AUC-ROC Micro=0.8146930945181119
Eval task: 2
Eval:  Epoch 5, Loss=0.3414120003581047, AUC-ROC Macro=0.47007797321899925, AUC-ROC Micro=0.5487636509688993
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3403304272890091
Train: epoch: 6, loss = 0.34097080312669276
Train: epoch: 6, loss = 0.34245380414028964
Train: epoch: 6, loss = 0.343873669821769
Train: epoch: 6, loss = 0.34350555402040484
Train: epoch: 6, loss = 0.34429945979267357
Train: epoch: 6, loss = 0.3442346190767629
Train: epoch: 6, loss = 0.3450586310774088
Train: epoch: 6, loss = 0.3448938840544886
Train: epoch: 6, loss = 0.34550075642764566
Train: epoch: 6, loss = 0.3457851051065055
Train: epoch: 6, loss = 0.3456559147189061
Train: epoch: 6, loss = 0.3458323516467443
Train: epoch: 6, loss = 0.3457277337142399
Train: epoch: 6, loss = 0.3457709813763698
Train: epoch: 6, loss = 0.34625800922513006
Train: epoch: 6, loss = 0.346390799761695
Train: epoch: 6, loss = 0.3461889951262209
Train:  Epoch 6, Loss=0.34628258197327966, AUC-ROC Macro=0.7729554917118442, AUC-ROC Micro=0.823845193198516
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.349333534638087, AUC-ROC Macro=0.7651497612489122, AUC-ROC Micro=0.8167244598536346
Eval task: 2
Eval:  Epoch 6, Loss=0.34957967326045036, AUC-ROC Macro=0.47657591672866206, AUC-ROC Micro=0.5620638582846175
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3523452232281367, AUC-ROC Macro=0.7643347185841592, AUC-ROC Micro=0.8155299229106049
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.34922022372484207, AUC-ROC Macro=0.475092544615767, AUC-ROC Micro=0.5569611567317769
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.28461523801088334
Train: epoch: 1, loss = 0.275301028713584
Train: epoch: 1, loss = 0.2719905376434326
Train: epoch: 1, loss = 0.26919366385787724
Train: epoch: 1, loss = 0.26677256961166856
Train: epoch: 1, loss = 0.25971186585724354
Train:  Epoch 1, Loss=0.25559327516791175, AUC-ROC Macro=0.5932947771211167, AUC-ROC Micro=0.7541253308618132
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.36802515263358754, AUC-ROC Macro=0.7405790270704591, AUC-ROC Micro=0.7928941851158806
Eval task: 2
Eval:  Epoch 1, Loss=0.24409988150000572, AUC-ROC Macro=0.6737489052146528, AUC-ROC Micro=0.7942915516063302
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.2538511899113655
Train: epoch: 2, loss = 0.2512479837611318
Train: epoch: 2, loss = 0.25252610504627226
Train: epoch: 2, loss = 0.25174033004790547
Train: epoch: 2, loss = 0.2513325335383415
Train: epoch: 2, loss = 0.24466995028158028
Train:  Epoch 2, Loss=0.2424150658527594, AUC-ROC Macro=0.6868257404710252, AUC-ROC Micro=0.8012275995151544
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.36922798057397205, AUC-ROC Macro=0.7348595825812504, AUC-ROC Micro=0.785839865137451
Eval task: 2
Eval:  Epoch 2, Loss=0.2405877187848091, AUC-ROC Macro=0.6977580926421741, AUC-ROC Micro=0.8075896780061833
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.24766650870442392
Train: epoch: 3, loss = 0.24532192386686802
Train: epoch: 3, loss = 0.2449829126521945
Train: epoch: 3, loss = 0.24569956832565368
Train: epoch: 3, loss = 0.24572571637481452
Train: epoch: 3, loss = 0.24012649084751805
Train:  Epoch 3, Loss=0.23782742090896608, AUC-ROC Macro=0.7152495098044285, AUC-ROC Micro=0.8150421906184067
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.36021480212608975, AUC-ROC Macro=0.7435631326132375, AUC-ROC Micro=0.7978338221788022
Eval task: 2
Eval:  Epoch 3, Loss=0.23365074396133423, AUC-ROC Macro=0.7101727990779279, AUC-ROC Micro=0.8151069865692936
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.23966113869100808
Train: epoch: 4, loss = 0.2396583458967507
Train: epoch: 4, loss = 0.24060911982009808
Train: epoch: 4, loss = 0.24114893619902433
Train: epoch: 4, loss = 0.24119869057834148
Train: epoch: 4, loss = 0.2353956659945349
Train:  Epoch 4, Loss=0.23254383386585725, AUC-ROC Macro=0.7346605207089383, AUC-ROC Micro=0.8240239821424059
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.35978986074527103, AUC-ROC Macro=0.7405742067710414, AUC-ROC Micro=0.7938421949711164
Eval task: 2
Eval:  Epoch 4, Loss=0.23283312283456326, AUC-ROC Macro=0.7136969504080956, AUC-ROC Micro=0.8184054367976934
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.23596051707863808
Train: epoch: 5, loss = 0.23736537527292967
Train: epoch: 5, loss = 0.23735001287112634
Train: epoch: 5, loss = 0.23675278111360967
Train: epoch: 5, loss = 0.23716875471919774
Train: epoch: 5, loss = 0.23190850678210456
Train:  Epoch 5, Loss=0.22957981663714974, AUC-ROC Macro=0.7509826851642228, AUC-ROC Micro=0.8315636387260313
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3653588456412156, AUC-ROC Macro=0.7312115052874896, AUC-ROC Micro=0.7853627053956818
Eval task: 2
Eval:  Epoch 5, Loss=0.23379514925181866, AUC-ROC Macro=0.725167459192189, AUC-ROC Micro=0.8236338553801177
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.2323670791089535
Train: epoch: 6, loss = 0.23272052641958
Train: epoch: 6, loss = 0.2341351556032896
Train: epoch: 6, loss = 0.23486159767955542
Train: epoch: 6, loss = 0.23461281560361386
Train: epoch: 6, loss = 0.22941293673589824
Train:  Epoch 6, Loss=0.22686191532891814, AUC-ROC Macro=0.7597978252110849, AUC-ROC Micro=0.8382388660169423
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3547995078066985, AUC-ROC Macro=0.7439238341812106, AUC-ROC Micro=0.7996664332914475
Eval task: 2
Eval:  Epoch 6, Loss=0.22716984525322914, AUC-ROC Macro=0.7181234910502183, AUC-ROC Micro=0.8200597089719454
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3684696592390537, AUC-ROC Macro=0.7415971556703478, AUC-ROC Micro=0.7987247382454237
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.21196586079895496, AUC-ROC Macro=0.721419774393123, AUC-ROC Micro=0.8199321745343242
{'0': {'precision': 0.5184404636459431, 'recall': 0.3761467889908257, 'f1-score': 0.43597696056712454, 'support': 1308}, '1': {'precision': 0.6371308016877637, 'recall': 0.3756218905472637, 'f1-score': 0.47261345852895154, 'support': 402}, '2': {'precision': 0.4909090909090909, 'recall': 0.041033434650455926, 'f1-score': 0.07573632538569425, 'support': 658}, '3': {'precision': 0.5237642585551331, 'recall': 0.27688442211055275, 'f1-score': 0.3622616699539777, 'support': 1990}, '4': {'precision': 0.5217391304347826, 'recall': 0.11910669975186104, 'f1-score': 0.19393939393939394, 'support': 806}, '5': {'precision': 0.37012987012987014, 'recall': 0.07326478149100257, 'f1-score': 0.1223175965665236, 'support': 778}, '6': {'precision': 0.5662251655629139, 'recall': 0.1313364055299539, 'f1-score': 0.21321695760598505, 'support': 1302}, '7': {'precision': 0.3333333333333333, 'recall': 0.0047169811320754715, 'f1-score': 0.009302325581395349, 'support': 424}, '8': {'precision': 0.5266106442577031, 'recall': 0.34306569343065696, 'f1-score': 0.4154696132596685, 'support': 1644}, '9': {'precision': 0.6793134598012647, 'recall': 0.3702609551944855, 'f1-score': 0.47928616953473546, 'support': 2031}, '10': {'precision': 0.5742857142857143, 'recall': 0.3507853403141361, 'f1-score': 0.43553629469122424, 'support': 573}, '11': {'precision': 0.5082644628099173, 'recall': 0.20918367346938777, 'f1-score': 0.29638554216867474, 'support': 1176}, '12': {'precision': 0.5758754863813229, 'recall': 0.25084745762711863, 'f1-score': 0.3494687131050767, 'support': 1770}, '13': {'precision': 0.5689131754705525, 'recall': 0.36093990755007704, 'f1-score': 0.44166863068583556, 'support': 2596}, '14': {'precision': 0.5173674588665448, 'recall': 0.34787953288260604, 'f1-score': 0.4160235207644249, 'support': 1627}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 484}, '16': {'precision': 0.36787564766839376, 'recall': 0.08930817610062892, 'f1-score': 0.1437246963562753, 'support': 795}, '17': {'precision': 0.2857142857142857, 'recall': 0.014705882352941176, 'f1-score': 0.027972027972027972, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.4411764705882353, 'recall': 0.11450381679389313, 'f1-score': 0.18181818181818182, 'support': 262}, '20': {'precision': 0.3888888888888889, 'recall': 0.012433392539964476, 'f1-score': 0.024096385542168676, 'support': 563}, '21': {'precision': 0.4934210526315789, 'recall': 0.26881720430107525, 'f1-score': 0.34802784222737815, 'support': 837}, '22': {'precision': 0.6360078277886497, 'recall': 0.5985267034990792, 'f1-score': 0.6166982922201139, 'support': 1086}, '23': {'precision': 0.588495575221239, 'recall': 0.3089430894308943, 'f1-score': 0.4051789794364052, 'support': 861}, '24': {'precision': 0.48787878787878786, 'recall': 0.3188118811881188, 'f1-score': 0.3856287425149701, 'support': 505}, 'micro avg': {'precision': 0.5544941020103007, 'recall': 0.26307492216135264, 'f1-score': 0.35684691668225926, 'support': 25373}, 'macro avg': {'precision': 0.4640704421004764, 'recall': 0.2142849644351622, 'f1-score': 0.27409393281704825, 'support': 25373}, 'weighted avg': {'precision': 0.5137730722364503, 'recall': 0.26307492216135264, 'f1-score': 0.3332639428662496, 'support': 25373}, 'samples avg': {'precision': 0.3739147602795064, 'recall': 0.2343467395426265, 'f1-score': 0.26332601222660945, 'support': 25373}}
{'0': {'precision': 0.6167883211678832, 'recall': 0.4043062200956938, 'f1-score': 0.48843930635838145, 'support': 418}, '1': {'precision': 0.532258064516129, 'recall': 0.1527777777777778, 'f1-score': 0.23741007194244604, 'support': 216}, '2': {'precision': 0.47368421052631576, 'recall': 0.03125, 'f1-score': 0.05863192182410424, 'support': 288}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 252}, '4': {'precision': 0.5, 'recall': 0.05555555555555555, 'f1-score': 0.09999999999999999, 'support': 288}, '5': {'precision': 0.6923076923076923, 'recall': 0.03345724907063197, 'f1-score': 0.06382978723404255, 'support': 269}, '6': {'precision': 0.75, 'recall': 0.01060070671378092, 'f1-score': 0.02090592334494774, 'support': 283}, '7': {'precision': 0.8380952380952381, 'recall': 0.34509803921568627, 'f1-score': 0.48888888888888893, 'support': 255}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 177}, '9': {'precision': 0.5, 'recall': 0.05508474576271186, 'f1-score': 0.09923664122137404, 'support': 236}, '10': {'precision': 0.6, 'recall': 0.01639344262295082, 'f1-score': 0.03191489361702128, 'support': 183}, '11': {'precision': 0.5454545454545454, 'recall': 0.05741626794258373, 'f1-score': 0.1038961038961039, 'support': 209}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 160}, '13': {'precision': 0.5714285714285714, 'recall': 0.036036036036036036, 'f1-score': 0.06779661016949153, 'support': 111}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26}, '15': {'precision': 0.7567567567567568, 'recall': 0.6222222222222222, 'f1-score': 0.6829268292682927, 'support': 90}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 69}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 60}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 55}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 25}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8}, 'micro avg': {'precision': 0.6434108527131783, 'recall': 0.10918179426466719, 'f1-score': 0.1866846603688709, 'support': 3801}, 'macro avg': {'precision': 0.2950709360101253, 'recall': 0.07280793052062524, 'f1-score': 0.0977550791106038, 'support': 3801}, 'weighted avg': {'precision': 0.4574422644822343, 'recall': 0.10918179426466719, 'f1-score': 0.14965820882908787, 'support': 3801}, 'samples avg': {'precision': 0.19156901041666666, 'recall': 0.12463146391369047, 'f1-score': 0.14093191964285712, 'support': 3801}}