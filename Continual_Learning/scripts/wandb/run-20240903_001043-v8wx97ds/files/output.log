
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_northeast_baseline
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
northeast_val.csv
test_listfile.csv
northeast_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1748399782180785
Train: epoch: 1, loss = 2.135432079434395
Train: epoch: 1, loss = 2.114792501926422
Train: epoch: 1, loss = 2.1031759010255335
Train: epoch: 1, loss = 2.091629088759422
Train: epoch: 1, loss = 2.0869396257400514
Train: epoch: 1, loss = 2.0837916784627097
Train: epoch: 1, loss = 2.0797818490862845
Train: epoch: 1, loss = 2.075933960609966
Train: epoch: 1, loss = 2.072819082379341
Train: epoch: 1, loss = 2.070605644421144
Train: epoch: 1, loss = 2.0688735121985276
Train: epoch: 1, loss = 2.065807162614969
Train: epoch: 1, loss = 2.063421367108822
Train: epoch: 1, loss = 2.0615381737947462
Train: epoch: 1, loss = 2.0603734597936274
Train: epoch: 1, loss = 2.0582098683890173
Train: epoch: 1, loss = 2.0565756087170706
Train: epoch: 1, loss = 2.0552792629442718
Train: epoch: 1, loss = 2.054043136149645
Train: epoch: 1, loss = 2.0538219178858257
Train: epoch: 1, loss = 2.052607760510661
Train: epoch: 1, loss = 2.052129714359408
Train: epoch: 1, loss = 2.0518857286622127
Train: epoch: 1, loss = 2.0505758068561555
Train: epoch: 1, loss = 2.050101864062823
Train: epoch: 1, loss = 2.049033685039591
Train: epoch: 1, loss = 2.0481079816179615
Train: epoch: 1, loss = 2.048169801851799
Train: epoch: 1, loss = 2.0472636920809744
Train: epoch: 1, loss = 2.0473748207092286
Train: epoch: 1, loss = 2.0463341303169726
Train: epoch: 1, loss = 2.046134733070027
Train: epoch: 1, loss = 2.0461302652955053
Train: epoch: 1, loss = 2.045418989811625
Train: epoch: 1, loss = 2.045141902582513
Train: epoch: 1, loss = 2.0448913892217586
Train: epoch: 1, loss = 2.044439851139721
Train: epoch: 1, loss = 2.043977728287379
Train: epoch: 1, loss = 2.0437629820406435
Train: epoch: 1, loss = 2.0440264906534336
Train: epoch: 1, loss = 2.0437140040312496
Train: epoch: 1, loss = 2.0430745152817216
Train:  Epoch 1, Loss=2.0428829980305263, Cohen Kappa=0.3882972713521913, MAD=0.7176582862401792
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0380822543440194, Cohen Kappa=0.3874538637607443, MAD=0.7222913191685565
Eval task: 2
Eval:  Epoch 1, Loss=1.8739880238260542, Cohen Kappa=0.01415006941782948, MAD=0.610347158499962
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.054727546099959, Cohen Kappa=0.3062558361483103, MAD=0.7200893275293309
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.888157640184675, Cohen Kappa=0.009938044188064876, MAD=0.6094068894335692
northeast_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.8544149738550186
Train: epoch: 1, loss = 1.8515962794423104
Train: epoch: 1, loss = 1.8513053325812021
Train: epoch: 1, loss = 1.854926922470331
Train: epoch: 1, loss = 1.854718672156334
Train: epoch: 1, loss = 1.855335643986861
Train: epoch: 1, loss = 1.854053521496909
Train: epoch: 1, loss = 1.8552505596727134
Train: epoch: 1, loss = 1.8558536833524704
Train: epoch: 1, loss = 1.855282386124134
Train:  Epoch 1, Loss=1.8567566971915108, Cohen Kappa=0.009881249051156837, MAD=0.5858657249751146
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.1112223575855125, Cohen Kappa=0.1349099729619916, MAD=0.7179531769622916
Eval task: 2
Eval:  Epoch 1, Loss=1.8705208812441145, Cohen Kappa=0.0007340128543746882, MAD=0.5591959181123871
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0753705563216376, Cohen Kappa=0.146864677807669, MAD=0.7132855497989574
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8796491112027849, Cohen Kappa=0.004732799324102199, MAD=0.5609654308468077
{'0': {'precision': 0.44727272727272727, 'recall': 0.1207361963190184, 'f1-score': 0.19014492753623186, 'support': 4075}, '1': {'precision': 0.2075077399380805, 'recall': 0.9357766143106457, 'f1-score': 0.33968957871396893, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.4065934065934066, 'recall': 0.03042763157894737, 'f1-score': 0.05661820964039786, 'support': 1216}, '9': {'precision': 0.1917808219178082, 'recall': 0.13047530288909598, 'f1-score': 0.1552967276760954, 'support': 1073}, 'accuracy': 0.22561961206896552, 'macro avg': {'precision': 0.12531546957220224, 'recall': 0.12174157450977074, 'f1-score': 0.07417494435666941, 'support': 14848}, 'weighted avg': {'precision': 0.20995046086303576, 'recall': 0.22561961206896552, 'f1-score': 0.13358919413017512, 'support': 14848}}
{'0': {'precision': 0.3333333333333333, 'recall': 0.05226824457593689, 'f1-score': 0.09036658141517478, 'support': 1014}, '1': {'precision': 0.3637956204379562, 'recall': 0.9681429681429682, 'f1-score': 0.5288624787775892, 'support': 1287}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 689}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 337}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 161}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'micro avg': {'precision': 0.36244419642857145, 'recall': 0.36244419642857145, 'f1-score': 0.36244419642857145, 'support': 3584}, 'macro avg': {'precision': 0.06971289537712895, 'recall': 0.10204112127189051, 'f1-score': 0.06192290601927639, 'support': 3584}, 'weighted avg': {'precision': 0.22494558133472367, 'recall': 0.36244419642857145, 'f1-score': 0.21547927559758495, 'support': 3584}}