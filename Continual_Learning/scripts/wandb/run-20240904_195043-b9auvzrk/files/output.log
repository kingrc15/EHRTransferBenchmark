
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_west
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
west_val.csv
test_listfile.csv
west_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1669744801521302
Train: epoch: 1, loss = 2.1394542875885962
Train: epoch: 1, loss = 2.1250415388743082
Train: epoch: 1, loss = 2.1085704950988293
Train: epoch: 1, loss = 2.1007783415317536
Train: epoch: 1, loss = 2.094138826131821
Train: epoch: 1, loss = 2.0868797209433145
Train: epoch: 1, loss = 2.0813055739551785
Train: epoch: 1, loss = 2.0773604130744934
Train: epoch: 1, loss = 2.073750035762787
Train: epoch: 1, loss = 2.070439236326651
Train: epoch: 1, loss = 2.0685130984087787
Train: epoch: 1, loss = 2.067874579154528
Train: epoch: 1, loss = 2.0655947669489043
Train: epoch: 1, loss = 2.0641341598828635
Train: epoch: 1, loss = 2.0629964192956685
Train: epoch: 1, loss = 2.0620715721565133
Train: epoch: 1, loss = 2.0612581983539795
Train: epoch: 1, loss = 2.059920084758809
Train: epoch: 1, loss = 2.058628228545189
Train: epoch: 1, loss = 2.0584513568594343
Train: epoch: 1, loss = 2.0575092109225013
Train: epoch: 1, loss = 2.056441236242004
Train: epoch: 1, loss = 2.054869321510196
Train: epoch: 1, loss = 2.0532864265203474
Train: epoch: 1, loss = 2.052767241482551
Train: epoch: 1, loss = 2.0529987395692753
Train: epoch: 1, loss = 2.052277327030897
Train: epoch: 1, loss = 2.0517514314117102
Train: epoch: 1, loss = 2.0511353241801262
Train: epoch: 1, loss = 2.0507643429117817
Train: epoch: 1, loss = 2.0507066793181004
Train: epoch: 1, loss = 2.049427375847643
Train: epoch: 1, loss = 2.0493997562282225
Train: epoch: 1, loss = 2.0488947236197337
Train: epoch: 1, loss = 2.04826660061876
Train: epoch: 1, loss = 2.0479922618414905
Train: epoch: 1, loss = 2.04762718288522
Train: epoch: 1, loss = 2.047286859842447
Train: epoch: 1, loss = 2.0462223503291606
Train: epoch: 1, loss = 2.045370428329561
Train: epoch: 1, loss = 2.04511958082517
Train: epoch: 1, loss = 2.045035136037095
Train:  Epoch 1, Loss=2.044888478674207, Cohen Kappa=0.379978714212463, MAD=0.720849176371341
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.039947805733516, Cohen Kappa=0.38168506350624265, MAD=0.6979171677822577
Eval task: 2
Eval:  Epoch 1, Loss=1.8737463745577583, Cohen Kappa=0.0017534445465219317, MAD=0.7276522698424234
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.053606830794236, Cohen Kappa=0.2902681163853117, MAD=0.6950176219228925
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8877872721902256, Cohen Kappa=0.0007052006995881266, MAD=0.7283811749813452
west_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.960050562620163
Train: epoch: 1, loss = 1.9613758987188339
Train: epoch: 1, loss = 1.9573780087629955
Train: epoch: 1, loss = 1.9585636311769485
Train: epoch: 1, loss = 1.9577566986083985
Train: epoch: 1, loss = 1.9559320933620135
Train: epoch: 1, loss = 1.9569961334126336
Train: epoch: 1, loss = 1.9571042538434267
Train: epoch: 1, loss = 1.9568290689256456
Train: epoch: 1, loss = 1.956290200650692
Train: epoch: 1, loss = 1.9564624415744434
Train: epoch: 1, loss = 1.9561694193879764
Train: epoch: 1, loss = 1.9560232233084165
Train: epoch: 1, loss = 1.9565766193185534
Train: epoch: 1, loss = 1.9571886615753173
Train: epoch: 1, loss = 1.9568609545379878
Train: epoch: 1, loss = 1.9573807201315374
Train: epoch: 1, loss = 1.9554374266001913
Train: epoch: 1, loss = 1.950817587093303
Train: epoch: 1, loss = 1.9464732080698013
Train: epoch: 1, loss = 1.9431112169084095
Train:  Epoch 1, Loss=1.9402282360349383, Cohen Kappa=0.0016822965875904483, MAD=0.7266036952986272
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0458722361202897, Cohen Kappa=0.36111897629428036, MAD=0.7084219201023202
Eval task: 2
Eval:  Epoch 1, Loss=1.96327909929999, Cohen Kappa=0.0021376475542614903, MAD=0.721130233261327
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0642107910123366, Cohen Kappa=0.24179601835871078, MAD=0.6998678055150132
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8847509088187382, Cohen Kappa=0.0014673064311426787, MAD=0.7206431393313973
{'0': {'precision': 0.3826444538169549, 'recall': 0.8905521472392638, 'f1-score': 0.5352902131425622, 'support': 4075}, '1': {'precision': 0.1731110322809507, 'recall': 0.17033158813263524, 'f1-score': 0.1717100633356791, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.2558139534883721, 'recall': 0.06332236842105263, 'f1-score': 0.10151615029663809, 'support': 1216}, '9': {'precision': 0.09402852049910873, 'recall': 0.1966449207828518, 'f1-score': 0.12722339463370516, 'support': 1073}, 'accuracy': 0.2966729525862069, 'macro avg': {'precision': 0.09055979600853864, 'recall': 0.13208510245758034, 'f1-score': 0.09357398214085845, 'support': 14848}, 'weighted avg': {'precision': 0.16616390266207023, 'recall': 0.2966729525862069, 'f1-score': 0.19754925183292965, 'support': 14848}}
{'0': {'precision': 0.33487991266375544, 'recall': 0.9903147699757869, 'f1-score': 0.5005098919029166, 'support': 2478}, '1': {'precision': 0.4791666666666667, 'recall': 0.017726396917148363, 'f1-score': 0.03418803418803419, 'support': 2595}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1084}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 501}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 215}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 121}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 103}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 153}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102}, 'accuracy': 0.33674568965517243, 'macro avg': {'precision': 0.08140465793304222, 'recall': 0.10080411668929352, 'f1-score': 0.05346979260909508, 'support': 7424}, 'weighted avg': {'precision': 0.27926588410301534, 'recall': 0.33674568965517243, 'f1-score': 0.17901151142960348, 'support': 7424}}