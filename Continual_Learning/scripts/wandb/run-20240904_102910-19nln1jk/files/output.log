
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
midwest_val.csv
test_listfile.csv
midwest_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1842003160715104
Train: epoch: 1, loss = 2.1541699293255805
Train: epoch: 1, loss = 2.120894185503324
Train: epoch: 1, loss = 2.1062436963617803
Train: epoch: 1, loss = 2.0966636909246446
Train: epoch: 1, loss = 2.0892933611075084
Train: epoch: 1, loss = 2.082347538982119
Train: epoch: 1, loss = 2.0780769046396017
Train: epoch: 1, loss = 2.071900606221623
Train: epoch: 1, loss = 2.0661925901174545
Train: epoch: 1, loss = 2.0641424802216615
Train: epoch: 1, loss = 2.0632218899329504
Train: epoch: 1, loss = 2.0616069110081745
Train: epoch: 1, loss = 2.060487677582673
Train: epoch: 1, loss = 2.05888068207105
Train: epoch: 1, loss = 2.0573567240312696
Train: epoch: 1, loss = 2.0573642406042882
Train: epoch: 1, loss = 2.0564334507783255
Train: epoch: 1, loss = 2.054907503316277
Train: epoch: 1, loss = 2.0541294656991957
Train: epoch: 1, loss = 2.0528393810987473
Train: epoch: 1, loss = 2.0523941800269214
Train: epoch: 1, loss = 2.051569080819254
Train: epoch: 1, loss = 2.0507074151933193
Train: epoch: 1, loss = 2.0496878106355667
Train: epoch: 1, loss = 2.049751667357408
Train: epoch: 1, loss = 2.049408109430914
Train: epoch: 1, loss = 2.0490290856574265
Train: epoch: 1, loss = 2.047976375592166
Train: epoch: 1, loss = 2.047008949061235
Train: epoch: 1, loss = 2.046672318808494
Train: epoch: 1, loss = 2.0462836782447993
Train: epoch: 1, loss = 2.0462120746482504
Train: epoch: 1, loss = 2.0457103826368557
Train: epoch: 1, loss = 2.0458377361808506
Train: epoch: 1, loss = 2.045468617098199
Train: epoch: 1, loss = 2.044929258291786
Train: epoch: 1, loss = 2.0448013843831263
Train: epoch: 1, loss = 2.044830903945825
Train: epoch: 1, loss = 2.044663661569357
Train: epoch: 1, loss = 2.044089738930144
Train: epoch: 1, loss = 2.044005529795374
Train: epoch: 1, loss = 2.043988796514134
Train:  Epoch 1, Loss=2.043608738245283, Cohen Kappa=0.38597505679155575, MAD=0.7181299355237291
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0305566643846444, Cohen Kappa=0.4287402062147423, MAD=0.7310017091871052
Eval task: 2
Eval:  Epoch 1, Loss=1.975811306772561, Cohen Kappa=0.005274339878841738, MAD=0.7407987821027039
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.054114647980394, Cohen Kappa=0.3424022970173902, MAD=0.7303423324320765
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.93970564316059, Cohen Kappa=0.005970126480057569, MAD=0.7394258168733272
midwest_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9892409878969193
Train: epoch: 1, loss = 1.9939324861764909
Train: epoch: 1, loss = 1.9952705293893813
Train: epoch: 1, loss = 1.9941956046223641
Train: epoch: 1, loss = 1.9932145372629166
Train: epoch: 1, loss = 1.9937980510791142
Train: epoch: 1, loss = 1.993807362658637
Train: epoch: 1, loss = 1.9935388028621674
Train: epoch: 1, loss = 1.9927025823460685
Train: epoch: 1, loss = 1.993500910639763
Train: epoch: 1, loss = 1.992328709093007
Train: epoch: 1, loss = 1.991015637665987
Train: epoch: 1, loss = 1.9905295160642038
Train: epoch: 1, loss = 1.9912652603643282
Train: epoch: 1, loss = 1.9909253084262213
Train: epoch: 1, loss = 1.9914603466540575
Train: epoch: 1, loss = 1.990896002650261
Train: epoch: 1, loss = 1.9901734398139848
Train: epoch: 1, loss = 1.9902460766466041
Train: epoch: 1, loss = 1.9899649985730647
Train: epoch: 1, loss = 1.9896707186812446
Train: epoch: 1, loss = 1.989885124862194
Train: epoch: 1, loss = 1.9899221394632174
Train: epoch: 1, loss = 1.9905749111125866
Train: epoch: 1, loss = 1.9904233820915223
Train: epoch: 1, loss = 1.9902330088844666
Train: epoch: 1, loss = 1.9900522874240523
Train: epoch: 1, loss = 1.9903736947689739
Train: epoch: 1, loss = 1.9897657533144129
Train: epoch: 1, loss = 1.989625745554765
Train: epoch: 1, loss = 1.9897497895071583
Train: epoch: 1, loss = 1.9896115121990443
Train: epoch: 1, loss = 1.9895358005978845
Train: epoch: 1, loss = 1.9895751661412857
Train: epoch: 1, loss = 1.989499213388988
Train: epoch: 1, loss = 1.989263723012474
Train: epoch: 1, loss = 1.9893083540491157
Train: epoch: 1, loss = 1.989346019562922
Train: epoch: 1, loss = 1.989198866975613
Train: epoch: 1, loss = 1.9892197631299495
Train: epoch: 1, loss = 1.9891637264519204
Train: epoch: 1, loss = 1.9888868285786538
Train: epoch: 1, loss = 1.9887977351975996
Train:  Epoch 1, Loss=1.988733277143751, Cohen Kappa=0.046887272665869006, MAD=0.6890708982791318
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0269343709123544, Cohen Kappa=0.43356602965373015, MAD=0.7255501756724276
Eval task: 2
Eval:  Epoch 1, Loss=2.0028136989166, Cohen Kappa=0.04780700142969874, MAD=0.6911322312166501
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.047057336774366, Cohen Kappa=0.34866186439261315, MAD=0.7163381090768037
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9246622591183102, Cohen Kappa=0.05021064285378529, MAD=0.6942302861966385
{'0': {'precision': 0.41417016177351706, 'recall': 0.6785276073619632, 'f1-score': 0.5143707562087247, 'support': 4075}, '1': {'precision': 0.26156843643448613, 'recall': 0.374869109947644, 'f1-score': 0.30813369674365226, 'support': 2865}, '2': {'precision': 0.5961538461538461, 'recall': 0.017051705170517052, 'f1-score': 0.033155080213903745, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.16766656141458794, 'recall': 0.43667763157894735, 'f1-score': 0.242299794661191, 'support': 1216}, '9': {'precision': 0.1180637544273908, 'recall': 0.09319664492078285, 'f1-score': 0.10416666666666667, 'support': 1073}, 'accuracy': 0.3031384698275862, 'macro avg': {'precision': 0.1557622760203828, 'recall': 0.1600322698979854, 'f1-score': 0.12021259944941384, 'support': 14848}, 'weighted avg': {'precision': 0.25939585257949266, 'recall': 0.3031384698275862, 'f1-score': 0.23205463309478286, 'support': 14848}}
{'0': {'precision': 0.3181973369750768, 'recall': 0.4405577877570314, 'f1-score': 0.36951134899395377, 'support': 4231}, '1': {'precision': 0.35405912717034255, 'recall': 0.5998807394156231, 'f1-score': 0.4452969383991147, 'support': 5031}, '2': {'precision': 0.14873417721518986, 'recall': 0.01945364238410596, 'f1-score': 0.034407027818448024, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.04, 'recall': 0.0196078431372549, 'f1-score': 0.02631578947368421, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3323679956896552, 'macro avg': {'precision': 0.08609906413606093, 'recall': 0.10795000126940153, 'f1-score': 0.08755311046852007, 'support': 14848}, 'weighted avg': {'precision': 0.23566447829252704, 'recall': 0.3323679956896552, 'f1-score': 0.26231623285746786, 'support': 14848}}