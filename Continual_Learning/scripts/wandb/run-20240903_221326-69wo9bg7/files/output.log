
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_northeast
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
northeast_val.csv
test_listfile.csv
northeast_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.184705156683922
Train: epoch: 1, loss = 2.1511213198304175
Train: epoch: 1, loss = 2.1262116559346516
Train: epoch: 1, loss = 2.1084599229693413
Train: epoch: 1, loss = 2.0994654018878935
Train: epoch: 1, loss = 2.0922026126583417
Train: epoch: 1, loss = 2.083546866093363
Train: epoch: 1, loss = 2.077035557180643
Train: epoch: 1, loss = 2.073042452401585
Train: epoch: 1, loss = 2.0717820531129836
Train: epoch: 1, loss = 2.07029797705737
Train: epoch: 1, loss = 2.0680329189201196
Train: epoch: 1, loss = 2.0663913892324155
Train: epoch: 1, loss = 2.063729386925697
Train: epoch: 1, loss = 2.064174369096756
Train: epoch: 1, loss = 2.063474655598402
Train: epoch: 1, loss = 2.062492494092268
Train: epoch: 1, loss = 2.061508552597629
Train: epoch: 1, loss = 2.061087954514905
Train: epoch: 1, loss = 2.060002070277929
Train: epoch: 1, loss = 2.0584285840534027
Train: epoch: 1, loss = 2.05775647431612
Train: epoch: 1, loss = 2.0561857059986695
Train: epoch: 1, loss = 2.0561594089368977
Train: epoch: 1, loss = 2.05467702999115
Train: epoch: 1, loss = 2.053621237232135
Train: epoch: 1, loss = 2.052968486348788
Train: epoch: 1, loss = 2.0526873579408442
Train: epoch: 1, loss = 2.0522276123227745
Train: epoch: 1, loss = 2.052217322925727
Train: epoch: 1, loss = 2.051506259095284
Train: epoch: 1, loss = 2.051726059857756
Train: epoch: 1, loss = 2.0509355921817547
Train: epoch: 1, loss = 2.0504197212177164
Train: epoch: 1, loss = 2.0505257358210427
Train: epoch: 1, loss = 2.0500947028398513
Train: epoch: 1, loss = 2.0494839208512694
Train: epoch: 1, loss = 2.048777877766835
Train: epoch: 1, loss = 2.049116123379805
Train: epoch: 1, loss = 2.0481364631205796
Train: epoch: 1, loss = 2.0476106950713366
Train: epoch: 1, loss = 2.0479409361595198
Train: epoch: 1, loss = 2.0475918022699133
Train:  Epoch 1, Loss=2.0474647898129055, Cohen Kappa=0.3762495565491264, MAD=0.7181546244417747
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.031716198756777, Cohen Kappa=0.42479635978859076, MAD=0.7328748964100446
Eval task: 2
Eval:  Epoch 1, Loss=1.8795105814933777, Cohen Kappa=0.019510966066394353, MAD=0.6306831750647957
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0565109314589667, Cohen Kappa=0.3311158901028577, MAD=0.7303316636019839
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.896010892731803, Cohen Kappa=0.016688878854679068, MAD=0.6305886246237453
northeast_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9421002072095872
Train: epoch: 1, loss = 1.950220514535904
Train: epoch: 1, loss = 1.950872222383817
Train: epoch: 1, loss = 1.9488558883965015
Train: epoch: 1, loss = 1.9483480305671692
Train: epoch: 1, loss = 1.947550088862578
Train: epoch: 1, loss = 1.9450979485682078
Train: epoch: 1, loss = 1.9444055244326592
Train: epoch: 1, loss = 1.945304886036449
Train: epoch: 1, loss = 1.9445937094688415
Train:  Epoch 1, Loss=1.9446532386779785, Cohen Kappa=0.03320511193510167, MAD=0.5912980417561722
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.023564642873304, Cohen Kappa=0.41919432493371567, MAD=0.7297741166707156
Eval task: 2
Eval:  Epoch 1, Loss=1.9493742074285234, Cohen Kappa=0.016699431059454817, MAD=0.6084708842990543
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0519337201940604, Cohen Kappa=0.3344056745105094, MAD=0.732942392467751
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8856210027422224, Cohen Kappa=0.010547800250797379, MAD=0.6077633318922885
{'0': {'precision': 0.3818332986905009, 'recall': 0.9015950920245399, 'f1-score': 0.5364678396729211, 'support': 4075}, '1': {'precision': 0.22916666666666666, 'recall': 0.10366492146596859, 'f1-score': 0.1427541456380678, 'support': 2865}, '2': {'precision': 0.15384615384615385, 'recall': 0.0022002200220022, 'f1-score': 0.0043383947939262466, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.195368558382257, 'recall': 0.4925986842105263, 'f1-score': 0.2797758056982718, 'support': 1216}, '9': {'precision': 0.06443914081145585, 'recall': 0.05032618825722274, 'f1-score': 0.0565149136577708, 'support': 1073}, 'accuracy': 0.31169181034482757, 'macro avg': {'precision': 0.10246538183970344, 'recall': 0.15503851059802598, 'f1-score': 0.10198510994609578, 'support': 14848}, 'weighted avg': {'precision': 0.1885059849770754, 'recall': 0.31169181034482757, 'f1-score': 0.202305506313272, 'support': 14848}}
{'0': {'precision': 0.29054878048780486, 'recall': 0.9398422090729783, 'f1-score': 0.44387517466231946, 'support': 1014}, '1': {'precision': 0.3881578947368421, 'recall': 0.09168609168609168, 'f1-score': 0.1483343808925204, 'support': 1287}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 689}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 337}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 161}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'micro avg': {'precision': 0.298828125, 'recall': 0.298828125, 'f1-score': 0.298828125, 'support': 3584}, 'macro avg': {'precision': 0.06787066752246469, 'recall': 0.103152830075907, 'f1-score': 0.05922095555548399, 'support': 3584}, 'weighted avg': {'precision': 0.22158919473798827, 'recall': 0.298828125, 'f1-score': 0.1788492676663688, 'support': 3584}}