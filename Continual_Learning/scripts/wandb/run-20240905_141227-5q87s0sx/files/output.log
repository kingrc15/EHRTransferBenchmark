
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_west
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
west_val.csv
test_listfile.csv
west_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1628891837596895
Train: epoch: 1, loss = 2.1293973675370217
Train: epoch: 1, loss = 2.1096286274989446
Train: epoch: 1, loss = 2.10111356317997
Train: epoch: 1, loss = 2.0924579417705536
Train: epoch: 1, loss = 2.08545316974322
Train: epoch: 1, loss = 2.0791163170337676
Train: epoch: 1, loss = 2.0770195603370665
Train: epoch: 1, loss = 2.0715693838066525
Train: epoch: 1, loss = 2.0686011989712716
Train: epoch: 1, loss = 2.066176133264195
Train: epoch: 1, loss = 2.0647286163270473
Train: epoch: 1, loss = 2.062986135345239
Train: epoch: 1, loss = 2.0618016871384213
Train: epoch: 1, loss = 2.0611526683568955
Train: epoch: 1, loss = 2.0614514422044157
Train: epoch: 1, loss = 2.060859377419247
Train: epoch: 1, loss = 2.059070295559035
Train: epoch: 1, loss = 2.0572318646468615
Train: epoch: 1, loss = 2.056569130986929
Train: epoch: 1, loss = 2.05610241095225
Train: epoch: 1, loss = 2.0561118229681794
Train: epoch: 1, loss = 2.055278674338175
Train: epoch: 1, loss = 2.0544008663545053
Train: epoch: 1, loss = 2.0539158057928084
Train: epoch: 1, loss = 2.054222480402543
Train: epoch: 1, loss = 2.0543713258151657
Train: epoch: 1, loss = 2.0539046404830046
Train: epoch: 1, loss = 2.053123011506837
Train: epoch: 1, loss = 2.0527459884285926
Train: epoch: 1, loss = 2.0520871301620236
Train: epoch: 1, loss = 2.051875814739615
Train: epoch: 1, loss = 2.0512766469969894
Train: epoch: 1, loss = 2.05090267801986
Train: epoch: 1, loss = 2.0500606954438347
Train: epoch: 1, loss = 2.049931118256516
Train: epoch: 1, loss = 2.0495686943788787
Train: epoch: 1, loss = 2.0487399524450303
Train: epoch: 1, loss = 2.0484372375255977
Train: epoch: 1, loss = 2.047861673936248
Train: epoch: 1, loss = 2.047506560508798
Train: epoch: 1, loss = 2.0468276851801646
Train: epoch: 1, loss = 2.046589618491572
Train:  Epoch 1, Loss=2.0462748260361807, Cohen Kappa=0.3791059585862141, MAD=0.7172634741265086
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.035506049106861, Cohen Kappa=0.4253552468708146, MAD=0.7291307198884993
Eval task: 2
Eval:  Epoch 1, Loss=1.8758631163629993, Cohen Kappa=0.0029639263637407653, MAD=0.7417946472389431
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.056802330345943, Cohen Kappa=0.34394167969529366, MAD=0.7348557667469827
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8902320327429936, Cohen Kappa=-0.0013328030630237464, MAD=0.7420846412721301
west_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.8736474627256394
Train: epoch: 1, loss = 1.883847367465496
Train: epoch: 1, loss = 1.8836942209800085
Train: epoch: 1, loss = 1.8812384900450707
Train: epoch: 1, loss = 1.878982098698616
Train: epoch: 1, loss = 1.8788580215970676
Train: epoch: 1, loss = 1.880070413351059
Train: epoch: 1, loss = 1.8806091618537903
Train: epoch: 1, loss = 1.8800754274262321
Train: epoch: 1, loss = 1.8778760408759116
Train: epoch: 1, loss = 1.8778238479657607
Train: epoch: 1, loss = 1.8777487577001253
Train: epoch: 1, loss = 1.8775644447253301
Train: epoch: 1, loss = 1.8767694155658994
Train: epoch: 1, loss = 1.8768272500435512
Train: epoch: 1, loss = 1.8775671432167291
Train: epoch: 1, loss = 1.8772058394726585
Train: epoch: 1, loss = 1.87732837435272
Train: epoch: 1, loss = 1.8775765683462746
Train: epoch: 1, loss = 1.8769606559872627
Train: epoch: 1, loss = 1.8765870007446834
Train:  Epoch 1, Loss=1.8766185763495309, Cohen Kappa=0.002272293929593494, MAD=0.7257884690505746
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0522906328069754, Cohen Kappa=0.35343048220748996, MAD=0.7151244792802819
Eval task: 2
Eval:  Epoch 1, Loss=1.8719792489347786, Cohen Kappa=0.0020715394460424363, MAD=0.7156966769104517
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.065054017921974, Cohen Kappa=0.29037241183659657, MAD=0.710853144391785
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8834306906009544, Cohen Kappa=-0.0008227442366657289, MAD=0.7130748084865737
{'0': {'precision': 0.4105950653120464, 'recall': 0.6942331288343558, 'f1-score': 0.5160054719562244, 'support': 4075}, '1': {'precision': 0.22136538897709232, 'recall': 0.3406631762652705, 'f1-score': 0.2683530382183118, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.18092621664050235, 'recall': 0.37911184210526316, 'f1-score': 0.24495217853347503, 'support': 1216}, '9': {'precision': 0.12048192771084337, 'recall': 0.11183597390493942, 'f1-score': 0.11599806669888835, 'support': 1073}, 'accuracy': 0.29539331896551724, 'macro avg': {'precision': 0.09333685986404845, 'recall': 0.1525844121109829, 'f1-score': 0.11453087554068997, 'support': 14848}, 'weighted avg': {'precision': 0.17892444224370588, 'recall': 0.29539331896551724, 'f1-score': 0.221840081316116, 'support': 14848}}
{'0': {'precision': 0.3331418724870764, 'recall': 0.9362389023405973, 'f1-score': 0.49142130904469394, 'support': 2478}, '1': {'precision': 0.41739130434782606, 'recall': 0.07398843930635839, 'f1-score': 0.12569558101472997, 'support': 2595}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1084}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 501}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 215}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 121}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 103}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 153}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102}, 'accuracy': 0.33836206896551724, 'macro avg': {'precision': 0.07505331768349024, 'recall': 0.10102273416469557, 'f1-score': 0.06171168900594239, 'support': 7424}, 'weighted avg': {'precision': 0.2570926717141142, 'recall': 0.33836206896551724, 'f1-score': 0.2079636363881972, 'support': 7424}}