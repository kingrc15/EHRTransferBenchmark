Experiment dir: ./exp/Test_los_west
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
west_val.csv
test_listfile.csv
west_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.185972510576248
Train: epoch: 1, loss = 2.1382516449689866
Train: epoch: 1, loss = 2.1145691299438476
Train: epoch: 1, loss = 2.1051299569010733
Train: epoch: 1, loss = 2.0961616336107256
Train: epoch: 1, loss = 2.0868637986977894
Train: epoch: 1, loss = 2.083701121892248
Train: epoch: 1, loss = 2.0815587088465692
Train: epoch: 1, loss = 2.0758714592456817
Train: epoch: 1, loss = 2.07130837816
Train: epoch: 1, loss = 2.0687202434648166
Train: epoch: 1, loss = 2.0663748652736347
Train: epoch: 1, loss = 2.064991591343513
Train: epoch: 1, loss = 2.06382586560079
Train: epoch: 1, loss = 2.061096336642901
Train: epoch: 1, loss = 2.059597720950842
Train: epoch: 1, loss = 2.0581093803574055
Train: epoch: 1, loss = 2.0572243942485917
Train: epoch: 1, loss = 2.056095052016409
Train: epoch: 1, loss = 2.054493867099285
Train: epoch: 1, loss = 2.054436900615692
Train: epoch: 1, loss = 2.053304037424651
Train: epoch: 1, loss = 2.0516922801214714
Train: epoch: 1, loss = 2.050864409158627
Train: epoch: 1, loss = 2.050024516534805
Train: epoch: 1, loss = 2.0495966549561575
Train: epoch: 1, loss = 2.0484678559391587
Train: epoch: 1, loss = 2.048397195679801
Train: epoch: 1, loss = 2.047919139081034
Train: epoch: 1, loss = 2.0471918999552727
Train: epoch: 1, loss = 2.04720435742409
Train: epoch: 1, loss = 2.0465625677071513
Train: epoch: 1, loss = 2.0462880088163145
Train: epoch: 1, loss = 2.0459796481973984
Train: epoch: 1, loss = 2.045235466650554
Train: epoch: 1, loss = 2.0450290685064263
Train: epoch: 1, loss = 2.0449730672063056
Train: epoch: 1, loss = 2.044674424058513
Train: epoch: 1, loss = 2.0443099352029654
Train: epoch: 1, loss = 2.044076074421406
Train: epoch: 1, loss = 2.04373824895882
Train: epoch: 1, loss = 2.043542361827124
Train: epoch: 1, loss = 2.0435919963481814
Train:  Epoch 1, Loss=2.043685255772727, Cohen Kappa=0.3854782809605716, MAD=0.7198344711874091
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.030948714963321, Cohen Kappa=0.4326845025450481, MAD=0.7420016609676076
Eval task: 2
Eval:  Epoch 1, Loss=1.8775574297740543, Cohen Kappa=0.0018759184861533162, MAD=0.7513450899679799
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.053680000634029, Cohen Kappa=0.33832750378858845, MAD=0.7421790413428395
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8923133817212334, Cohen Kappa=-0.0002738106103596927, MAD=0.7523381795663784
west_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9554546618461608
Train: epoch: 1, loss = 1.9545417162775993
Train: epoch: 1, loss = 1.9551970394452414
Train: epoch: 1, loss = 1.9548193256556987
Train: epoch: 1, loss = 1.9543113057613373
Train: epoch: 1, loss = 1.9546054277817408
Train: epoch: 1, loss = 1.9546360346249172
Train: epoch: 1, loss = 1.9538830722868443
Train: epoch: 1, loss = 1.9542388114664289
Train: epoch: 1, loss = 1.953530033171177
Train: epoch: 1, loss = 1.95386130110784
Train: epoch: 1, loss = 1.954296993215879
Train: epoch: 1, loss = 1.9543860942583817
Train: epoch: 1, loss = 1.9548393089430673
Train: epoch: 1, loss = 1.9547178393602371
Train: epoch: 1, loss = 1.9540200580656528
Train: epoch: 1, loss = 1.9544727956196841
Train: epoch: 1, loss = 1.9544517027669484
Train: epoch: 1, loss = 1.954371700130011
Train: epoch: 1, loss = 1.9540086701214314
Train: epoch: 1, loss = 1.9537121894813718
Train:  Epoch 1, Loss=1.9530663996832711, Cohen Kappa=0.0016451048759406062, MAD=0.7280037015158288
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0304468664629707, Cohen Kappa=0.43064110488641183, MAD=0.7220609351011859
Eval task: 2
Eval:  Epoch 1, Loss=1.9429327085100372, Cohen Kappa=0.0012122745302164395, MAD=0.7215412373909841
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0513805007112436, Cohen Kappa=0.3345104119042521, MAD=0.7147014440311986
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8846499385504887, Cohen Kappa=0.0007372721050056263, MAD=0.7226652551365962
{'0': {'precision': 0.40260065016254065, 'recall': 0.7901840490797546, 'f1-score': 0.5334216847510975, 'support': 4075}, '1': {'precision': 0.2599290780141844, 'recall': 0.2558464223385689, 'f1-score': 0.25787159190853126, 'support': 2865}, '2': {'precision': 0.5, 'recall': 0.00055005500550055, 'f1-score': 0.001098901098901099, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.09508615188257817, 'recall': 0.1225328947368421, 'f1-score': 0.10707869205892921, 'support': 1216}, '9': {'precision': 0.14018691588785046, 'recall': 0.32152842497670087, 'f1-score': 0.19524617996604413, 'support': 1073}, 'accuracy': 0.2995689655172414, 'macro avg': {'precision': 0.13978027959471534, 'recall': 0.1490641846137367, 'f1-score': 0.10947170497835032, 'support': 14848}, 'weighted avg': {'precision': 0.23978581488145678, 'recall': 0.2995689655172414, 'f1-score': 0.21916757267131537, 'support': 14848}}
{'0': {'precision': 0.3343336516164234, 'recall': 0.9891041162227603, 'f1-score': 0.4997451320216128, 'support': 2478}, '1': {'precision': 0.46236559139784944, 'recall': 0.016570327552986513, 'f1-score': 0.031994047619047616, 'support': 2595}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1084}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 501}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 215}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 121}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 103}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 153}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102}, 'accuracy': 0.3359375, 'macro avg': {'precision': 0.07966992430142729, 'recall': 0.10056744437757467, 'f1-score': 0.05317391796406604, 'support': 7424}, 'weighted avg': {'precision': 0.2732108699330437, 'recall': 0.3359375, 'f1-score': 0.1779893575863396, 'support': 7424}}