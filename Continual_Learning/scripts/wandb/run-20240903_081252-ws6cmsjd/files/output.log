
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_west_baseline
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.4338020922243595
Train: epoch: 1, loss = 0.4192485695704818
Train: epoch: 1, loss = 0.4144146522631248
Train: epoch: 1, loss = 0.4103503315337002
Train: epoch: 1, loss = 0.4092193834036589
Train: epoch: 1, loss = 0.4077940902734796
Train: epoch: 1, loss = 0.40603254238409653
Train: epoch: 1, loss = 0.4047025083657354
Train: epoch: 1, loss = 0.4037741618272331
Train: epoch: 1, loss = 0.4020815544426441
Train: epoch: 1, loss = 0.4008355002985759
Train: epoch: 1, loss = 0.39884757581477365
Train: epoch: 1, loss = 0.39743490334313647
Train: epoch: 1, loss = 0.3961180688494018
Train: epoch: 1, loss = 0.3950775599678357
Train: epoch: 1, loss = 0.3935803275508806
Train: epoch: 1, loss = 0.39251271648442043
Train: epoch: 1, loss = 0.3916947179867162
Train:  Epoch 1, Loss=0.3912536860531212, AUC-ROC Macro=0.6604363736967345, AUC-ROC Micro=0.7508751666879362
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3691733255982399, AUC-ROC Macro=0.7239474825127853, AUC-ROC Micro=0.7863798388060654
Eval task: 2
Eval:  Epoch 1, Loss=0.3287859559059143, AUC-ROC Macro=0.5053814472051814, AUC-ROC Micro=0.5509828479268495
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.36762719072401523
Train: epoch: 2, loss = 0.36878769714385273
Train: epoch: 2, loss = 0.3720953117807706
Train: epoch: 2, loss = 0.3731607625633478
Train: epoch: 2, loss = 0.37105448116362094
Train: epoch: 2, loss = 0.37100054970631996
Train: epoch: 2, loss = 0.3703979340514966
Train: epoch: 2, loss = 0.36949662582017484
Train: epoch: 2, loss = 0.3687210110657745
Train: epoch: 2, loss = 0.368636001624167
Train: epoch: 2, loss = 0.3682915554737503
Train: epoch: 2, loss = 0.3682038642714421
Train: epoch: 2, loss = 0.3680358841900642
Train: epoch: 2, loss = 0.3677661510982684
Train: epoch: 2, loss = 0.3671088863909244
Train: epoch: 2, loss = 0.3667509056581184
Train: epoch: 2, loss = 0.3666116712110884
Train: epoch: 2, loss = 0.3664261663249797
Train:  Epoch 2, Loss=0.36631678807633555, AUC-ROC Macro=0.7297071082669865, AUC-ROC Micro=0.7948571004819999
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.36103782430291176, AUC-ROC Macro=0.7427923203480462, AUC-ROC Micro=0.799059966838706
Eval task: 2
Eval:  Epoch 2, Loss=0.3460482284426689, AUC-ROC Macro=0.49163996966968, AUC-ROC Micro=0.5453794515944596
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3503931567817926
Train: epoch: 3, loss = 0.3574887610599399
Train: epoch: 3, loss = 0.35860855800410113
Train: epoch: 3, loss = 0.35761206710711124
Train: epoch: 3, loss = 0.3568154661506414
Train: epoch: 3, loss = 0.3575151463970542
Train: epoch: 3, loss = 0.3581161741167307
Train: epoch: 3, loss = 0.35854977895505724
Train: epoch: 3, loss = 0.3593188080771102
Train: epoch: 3, loss = 0.3596143823191524
Train: epoch: 3, loss = 0.35990559595552357
Train: epoch: 3, loss = 0.3588584196567535
Train: epoch: 3, loss = 0.35962519178023705
Train: epoch: 3, loss = 0.35930529024451974
Train: epoch: 3, loss = 0.3590327434291442
Train: epoch: 3, loss = 0.3586025983188301
Train: epoch: 3, loss = 0.35855684677467625
Train: epoch: 3, loss = 0.3585939622132315
Train:  Epoch 3, Loss=0.35860662286301964, AUC-ROC Macro=0.7472199023410449, AUC-ROC Micro=0.8065400040577598
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3565160942574342, AUC-ROC Macro=0.7530611743620702, AUC-ROC Micro=0.8059946205749524
Eval task: 2
Eval:  Epoch 3, Loss=0.3585507273674011, AUC-ROC Macro=0.49350260103333865, AUC-ROC Micro=0.548451758500254
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.3659721752256155
Train: epoch: 4, loss = 0.3600497200712562
Train: epoch: 4, loss = 0.35996154204010966
Train: epoch: 4, loss = 0.3581360673159361
Train: epoch: 4, loss = 0.35669342893362044
Train: epoch: 4, loss = 0.3557580596332749
Train: epoch: 4, loss = 0.3553255009757621
Train: epoch: 4, loss = 0.3555776944383979
Train: epoch: 4, loss = 0.3557116625044081
Train: epoch: 4, loss = 0.3555056002065539
Train: epoch: 4, loss = 0.3548211588168686
Train: epoch: 4, loss = 0.35486218849817913
Train: epoch: 4, loss = 0.3548490859166934
Train: epoch: 4, loss = 0.354063294625708
Train: epoch: 4, loss = 0.3536555357525746
Train: epoch: 4, loss = 0.35357976601459085
Train: epoch: 4, loss = 0.3534021801457686
Train: epoch: 4, loss = 0.35327876698225735
Train:  Epoch 4, Loss=0.353420265996558, AUC-ROC Macro=0.758380656934076, AUC-ROC Micro=0.8140553544606484
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3527462383111318, AUC-ROC Macro=0.7578831205923464, AUC-ROC Micro=0.8117547125080622
Eval task: 2
Eval:  Epoch 4, Loss=0.37180180102586746, AUC-ROC Macro=0.4867059646636837, AUC-ROC Micro=0.544881012104504
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.34028942361474035
Train: epoch: 5, loss = 0.3460244330763817
Train: epoch: 5, loss = 0.3476677154004574
Train: epoch: 5, loss = 0.34701785577461125
Train: epoch: 5, loss = 0.34786428421735766
Train: epoch: 5, loss = 0.34881790477782487
Train: epoch: 5, loss = 0.3496502973032849
Train: epoch: 5, loss = 0.3502388393878937
Train: epoch: 5, loss = 0.3503894491907623
Train: epoch: 5, loss = 0.35023350593447683
Train: epoch: 5, loss = 0.34982005602256816
Train: epoch: 5, loss = 0.3496717640509208
Train: epoch: 5, loss = 0.34969042831888564
Train: epoch: 5, loss = 0.34957213067582676
Train: epoch: 5, loss = 0.3494300593634446
Train: epoch: 5, loss = 0.3495085568027571
Train: epoch: 5, loss = 0.34996679004062625
Train: epoch: 5, loss = 0.3497065512297882
Train:  Epoch 5, Loss=0.34967372928929125, AUC-ROC Macro=0.7662124681137239, AUC-ROC Micro=0.8192684752876279
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.35085246215264004, AUC-ROC Macro=0.7615738436942513, AUC-ROC Micro=0.8141534673140309
Eval task: 2
Eval:  Epoch 5, Loss=0.3686692789196968, AUC-ROC Macro=0.5029160776736488, AUC-ROC Micro=0.5391057605887202
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.34901633352041245
Train: epoch: 6, loss = 0.34452130895107985
Train: epoch: 6, loss = 0.34815317633251347
Train: epoch: 6, loss = 0.3464616104774177
Train: epoch: 6, loss = 0.34547359062731264
Train: epoch: 6, loss = 0.34546311357369025
Train: epoch: 6, loss = 0.34517990367753165
Train: epoch: 6, loss = 0.34556100678630175
Train: epoch: 6, loss = 0.34519180095858043
Train: epoch: 6, loss = 0.34515638668835164
Train: epoch: 6, loss = 0.34496989395130767
Train: epoch: 6, loss = 0.34514234247306985
Train: epoch: 6, loss = 0.3452585764401234
Train: epoch: 6, loss = 0.34560814717518434
Train: epoch: 6, loss = 0.3455548039476077
Train: epoch: 6, loss = 0.34591727902647107
Train: epoch: 6, loss = 0.34655339617501285
Train: epoch: 6, loss = 0.34638079937547445
Train:  Epoch 6, Loss=0.34632267029774494, AUC-ROC Macro=0.772861117756019, AUC-ROC Micro=0.8237901502119255
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.352116492887338, AUC-ROC Macro=0.7626722473746413, AUC-ROC Micro=0.8146153301499084
Eval task: 2
Eval:  Epoch 6, Loss=0.38221410661935806, AUC-ROC Macro=0.49762674184915623, AUC-ROC Micro=0.5397879256497524
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3540296045442422, AUC-ROC Macro=0.7645038104416692, AUC-ROC Micro=0.8150728060143627
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.37902388721704483, AUC-ROC Macro=0.49174343185235686, AUC-ROC Micro=0.5390177352356995
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.2709430891275406
Train: epoch: 1, loss = 0.2549875567108393
Train: epoch: 1, loss = 0.24770070905486744
Train:  Epoch 1, Loss=0.2453286794720182, AUC-ROC Macro=0.5818340757807123, AUC-ROC Micro=0.7524787405147992
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.4788718968629837, AUC-ROC Macro=0.6799482439328489, AUC-ROC Micro=0.6705163304972985
Eval task: 2
Eval:  Epoch 1, Loss=0.23057307675480843, AUC-ROC Macro=0.6383382476661354, AUC-ROC Micro=0.7929934877439309
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.22888170458376408
Train: epoch: 2, loss = 0.22466212201863528
Train: epoch: 2, loss = 0.2238596591850122
Train:  Epoch 2, Loss=0.22312731477648046, AUC-ROC Macro=0.6866973802924247, AUC-ROC Micro=0.8126578137858669
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.4861217861374219, AUC-ROC Macro=0.6376806047525677, AUC-ROC Micro=0.651090073399657
Eval task: 2
Eval:  Epoch 2, Loss=0.22432028874754906, AUC-ROC Macro=0.6855920918936067, AUC-ROC Micro=0.8052259753386856
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.21611513763666154
Train: epoch: 3, loss = 0.21587892791256308
Train: epoch: 3, loss = 0.2150017286464572
Train:  Epoch 3, Loss=0.21611855308829492, AUC-ROC Macro=0.7355912197105928, AUC-ROC Micro=0.8285487096168169
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.49084706977009773, AUC-ROC Macro=0.6320949535746245, AUC-ROC Micro=0.6441643086829129
Eval task: 2
Eval:  Epoch 3, Loss=0.22291315346956253, AUC-ROC Macro=0.6963668306950749, AUC-ROC Micro=0.8095464673121057
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.2099956237524748
Train: epoch: 4, loss = 0.21212853267788886
Train: epoch: 4, loss = 0.21292537425955135
Train:  Epoch 4, Loss=0.21181974827809372, AUC-ROC Macro=0.7508157437680082, AUC-ROC Micro=0.83799613880446
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.5162377121547858, AUC-ROC Macro=0.6086838022483929, AUC-ROC Micro=0.6351877749092657
Eval task: 2
Eval:  Epoch 4, Loss=0.22124380618333817, AUC-ROC Macro=0.706114937452534, AUC-ROC Micro=0.8149927774318235
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.20692480225116014
Train: epoch: 5, loss = 0.20803928131237626
Train: epoch: 5, loss = 0.2073186391964555
Train:  Epoch 5, Loss=0.2076797092823249, AUC-ROC Macro=0.772644277300695, AUC-ROC Micro=0.8471553612876342
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.5375731562574705, AUC-ROC Macro=0.6021559866546938, AUC-ROC Micro=0.6309168311610266
Eval task: 2
Eval:  Epoch 5, Loss=0.21853139623999596, AUC-ROC Macro=0.7156407997834522, AUC-ROC Micro=0.8216642856877419
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.20217560037970542
Train: epoch: 6, loss = 0.20354719448834657
Train: epoch: 6, loss = 0.203994140625
Train:  Epoch 6, Loss=0.2042594355708149, AUC-ROC Macro=0.7846389539682399, AUC-ROC Micro=0.8537658197787116
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.5420295894145966, AUC-ROC Macro=0.5966713251336965, AUC-ROC Micro=0.6129732038409224
Eval task: 2
Eval:  Epoch 6, Loss=0.21854575350880623, AUC-ROC Macro=0.7126549526011722, AUC-ROC Micro=0.8207279265734767
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.5442447115977606, AUC-ROC Macro=0.5990755530444951, AUC-ROC Micro=0.6156566803209855
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.21557219326496124, AUC-ROC Macro=0.738157588411648, AUC-ROC Micro=0.8282135549238584
{'0': {'precision': 0.28579577866514544, 'recall': 0.3830275229357798, 'f1-score': 0.32734400522704993, 'support': 1308}, '1': {'precision': 0.5925925925925926, 'recall': 0.03980099502487562, 'f1-score': 0.07459207459207458, 'support': 402}, '2': {'precision': 0.3090909090909091, 'recall': 0.025835866261398176, 'f1-score': 0.04768583450210379, 'support': 658}, '3': {'precision': 0.5, 'recall': 0.0020100502512562816, 'f1-score': 0.004004004004004004, 'support': 1990}, '4': {'precision': 0.2275449101796407, 'recall': 0.18858560794044665, 'f1-score': 0.20624151967435547, 'support': 806}, '5': {'precision': 0.2826086956521739, 'recall': 0.016709511568123392, 'f1-score': 0.03155339805825243, 'support': 778}, '6': {'precision': 0.43209876543209874, 'recall': 0.13440860215053763, 'f1-score': 0.20503807850029288, 'support': 1302}, '7': {'precision': 0.04201680672268908, 'recall': 0.01179245283018868, 'f1-score': 0.01841620626151013, 'support': 424}, '8': {'precision': 0.75, 'recall': 0.005474452554744526, 'f1-score': 0.010869565217391304, 'support': 1644}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2031}, '10': {'precision': 1.0, 'recall': 0.0034904013961605585, 'f1-score': 0.006956521739130435, 'support': 573}, '11': {'precision': 0.4489795918367347, 'recall': 0.01870748299319728, 'f1-score': 0.035918367346938776, 'support': 1176}, '12': {'precision': 0.39436619718309857, 'recall': 0.015819209039548022, 'f1-score': 0.030418250950570342, 'support': 1770}, '13': {'precision': 0.3737864077669903, 'recall': 0.029661016949152543, 'f1-score': 0.054960742326909354, 'support': 2596}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1627}, '15': {'precision': 0.09154929577464789, 'recall': 0.026859504132231406, 'f1-score': 0.04153354632587859, 'support': 484}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 795}, '17': {'precision': 0.5714285714285714, 'recall': 0.007352941176470588, 'f1-score': 0.014519056261343014, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.5217391304347826, 'recall': 0.04580152671755725, 'f1-score': 0.08421052631578949, 'support': 262}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 563}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 837}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1086}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 861}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 505}, 'micro avg': {'precision': 0.2919099249374479, 'recall': 0.04138257202538131, 'f1-score': 0.07248878149810148, 'support': 25373}, 'macro avg': {'precision': 0.272943906110403, 'recall': 0.03821348575686674, 'f1-score': 0.04777046789214378, 'support': 25373}, 'weighted avg': {'precision': 0.28724800922738436, 'recall': 0.04138257202538131, 'f1-score': 0.050199908661260874, 'support': 25373}, 'samples avg': {'precision': 0.10380394345238093, 'recall': 0.02778862709067213, 'f1-score': 0.04114587624109108, 'support': 25373}}
{'0': {'precision': 0.6046511627906976, 'recall': 0.3979591836734694, 'f1-score': 0.48000000000000004, 'support': 196}, '1': {'precision': 0.5526315789473685, 'recall': 0.26141078838174275, 'f1-score': 0.35492957746478876, 'support': 241}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 145}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 118}, '4': {'precision': 0.48314606741573035, 'recall': 0.20673076923076922, 'f1-score': 0.2895622895622896, 'support': 208}, '5': {'precision': 0.3333333333333333, 'recall': 0.01, 'f1-score': 0.019417475728155338, 'support': 100}, '6': {'precision': 0.8, 'recall': 0.03636363636363636, 'f1-score': 0.06956521739130435, 'support': 110}, '7': {'precision': 0.9375, 'recall': 0.22556390977443608, 'f1-score': 0.36363636363636365, 'support': 133}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 89}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '11': {'precision': 0.5, 'recall': 0.023255813953488372, 'f1-score': 0.04444444444444444, 'support': 86}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87}, '13': {'precision': 0.35294117647058826, 'recall': 0.0821917808219178, 'f1-score': 0.13333333333333333, 'support': 73}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 45}, '15': {'precision': 0.7631578947368421, 'recall': 0.5686274509803921, 'f1-score': 0.651685393258427, 'support': 51}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'micro avg': {'precision': 0.5925925925925926, 'recall': 0.1283851554663992, 'f1-score': 0.21104699093157464, 'support': 1994}, 'macro avg': {'precision': 0.21309444854778242, 'recall': 0.07248413332719408, 'f1-score': 0.09626296379276425, 'support': 1994}, 'weighted avg': {'precision': 0.3540104374639066, 'recall': 0.1283851554663992, 'f1-score': 0.17281647585717205, 'support': 1994}, 'samples avg': {'precision': 0.218017578125, 'recall': 0.15177641369047618, 'f1-score': 0.16696661086309522, 'support': 1994}}