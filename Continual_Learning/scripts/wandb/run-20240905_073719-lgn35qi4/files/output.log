
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
south_val.csv
test_listfile.csv
south_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1802711021900176
Train: epoch: 1, loss = 2.140796540081501
Train: epoch: 1, loss = 2.1221854519844054
Train: epoch: 1, loss = 2.1087684646248817
Train: epoch: 1, loss = 2.1005168949365616
Train: epoch: 1, loss = 2.0914142712950707
Train: epoch: 1, loss = 2.0831362651075636
Train: epoch: 1, loss = 2.080892431139946
Train: epoch: 1, loss = 2.077720119290882
Train: epoch: 1, loss = 2.075572812616825
Train: epoch: 1, loss = 2.072208448811011
Train: epoch: 1, loss = 2.070126530776421
Train: epoch: 1, loss = 2.0680427347238246
Train: epoch: 1, loss = 2.067381984634059
Train: epoch: 1, loss = 2.0654941670497258
Train: epoch: 1, loss = 2.064313667938113
Train: epoch: 1, loss = 2.062590222323642
Train: epoch: 1, loss = 2.059422250158257
Train: epoch: 1, loss = 2.057993807729922
Train: epoch: 1, loss = 2.0556413019001485
Train: epoch: 1, loss = 2.0539183786085675
Train: epoch: 1, loss = 2.0526567511937834
Train: epoch: 1, loss = 2.052252358690552
Train: epoch: 1, loss = 2.051294564331571
Train: epoch: 1, loss = 2.0511419981479646
Train: epoch: 1, loss = 2.050819409122834
Train: epoch: 1, loss = 2.0502059738503564
Train: epoch: 1, loss = 2.049355116529124
Train: epoch: 1, loss = 2.049259796512538
Train: epoch: 1, loss = 2.0491214948097864
Train: epoch: 1, loss = 2.0479912655392
Train: epoch: 1, loss = 2.0476253779046236
Train: epoch: 1, loss = 2.0472507352539986
Train: epoch: 1, loss = 2.0469606546444052
Train: epoch: 1, loss = 2.0466601333447865
Train: epoch: 1, loss = 2.046439376324415
Train: epoch: 1, loss = 2.0460706411503455
Train: epoch: 1, loss = 2.0458490148657247
Train: epoch: 1, loss = 2.045507173721607
Train: epoch: 1, loss = 2.0453319806158543
Train: epoch: 1, loss = 2.0456670493178253
Train: epoch: 1, loss = 2.0454390176988784
Train: epoch: 1, loss = 2.0447060971481856
Train:  Epoch 1, Loss=2.044610432093484, Cohen Kappa=0.38265041795289456, MAD=0.722475884679971
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.032222355234212, Cohen Kappa=0.4243062954707477, MAD=0.734893103781425
Eval task: 2
Eval:  Epoch 1, Loss=1.92244842134673, Cohen Kappa=0.00015323994978522215, MAD=0.7447553659772342
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.054356276988983, Cohen Kappa=0.33017103205686504, MAD=0.7351232909700429
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9142477204059731, Cohen Kappa=0.0008114611310702236, MAD=0.7449843929656056
south_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9149110800027846
Train: epoch: 1, loss = 1.9086483669281007
Train: epoch: 1, loss = 1.9082033423582714
Train: epoch: 1, loss = 1.911917060762644
Train: epoch: 1, loss = 1.9109938365221024
Train: epoch: 1, loss = 1.9108167923490207
Train: epoch: 1, loss = 1.912040645820754
Train: epoch: 1, loss = 1.9108440019190311
Train: epoch: 1, loss = 1.9110643235180114
Train: epoch: 1, loss = 1.9106233365535736
Train: epoch: 1, loss = 1.9106607016650112
Train: epoch: 1, loss = 1.910850418706735
Train: epoch: 1, loss = 1.91107112128001
Train: epoch: 1, loss = 1.9119102986369814
Train: epoch: 1, loss = 1.912668742020925
Train: epoch: 1, loss = 1.9126211361214518
Train: epoch: 1, loss = 1.9123127537615159
Train: epoch: 1, loss = 1.9122257346245977
Train: epoch: 1, loss = 1.9114989522883767
Train: epoch: 1, loss = 1.9113381673693657
Train: epoch: 1, loss = 1.9114747346015204
Train: epoch: 1, loss = 1.911626880494031
Train: epoch: 1, loss = 1.9115958182708077
Train: epoch: 1, loss = 1.9110917495191098
Train: epoch: 1, loss = 1.9110405147314071
Train: epoch: 1, loss = 1.9112685630183954
Train: epoch: 1, loss = 1.9114103147718642
Train: epoch: 1, loss = 1.911568927168846
Train: epoch: 1, loss = 1.911341373365501
Train: epoch: 1, loss = 1.9111683232188226
Train: epoch: 1, loss = 1.9109047242518393
Train: epoch: 1, loss = 1.9103791413456201
Train: epoch: 1, loss = 1.9098991653232864
Train: epoch: 1, loss = 1.909382113972131
Train: epoch: 1, loss = 1.909203126192093
Train: epoch: 1, loss = 1.9088574245406522
Train: epoch: 1, loss = 1.908744658924438
Train: epoch: 1, loss = 1.9089526092535571
Train: epoch: 1, loss = 1.908743607539397
Train: epoch: 1, loss = 1.9084559500664473
Train: epoch: 1, loss = 1.9084984775868858
Train: epoch: 1, loss = 1.908659628544535
Train: epoch: 1, loss = 1.908546676580296
Train:  Epoch 1, Loss=1.9083850070408412, Cohen Kappa=0.10118569987441717, MAD=0.6950908646164304
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0705153613254943, Cohen Kappa=0.3793645855252086, MAD=0.7221095169371317
Eval task: 2
Eval:  Epoch 1, Loss=1.909501918430986, Cohen Kappa=0.19906050705360645, MAD=0.6954105639083175
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.12442999050535, Cohen Kappa=0.2601433166607401, MAD=0.7303234305507919
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.898764211556007, Cohen Kappa=0.11688498836432049, MAD=0.694485201306949
{'0': {'precision': 0.14150943396226415, 'recall': 0.0036809815950920245, 'f1-score': 0.0071753169098301844, 'support': 4075}, '1': {'precision': 0.24016473393302265, 'recall': 0.7734729493891798, 'f1-score': 0.36652332120410186, 'support': 2865}, '2': {'precision': 0.3076923076923077, 'recall': 0.0022002200220022, 'f1-score': 0.004369197160021846, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.2, 'recall': 0.001644736842105263, 'f1-score': 0.003262642740619902, 'support': 1216}, '9': {'precision': 0.13128186453022578, 'recall': 0.6719478098788444, 'f1-score': 0.21964965727341967, 'support': 1073}, 'accuracy': 0.19921875, 'macro avg': {'precision': 0.10206483401178204, 'recall': 0.14529466977272237, 'f1-score': 0.06009801352879934, 'support': 14848}, 'weighted avg': {'precision': 0.14871854540274004, 'recall': 0.19921875, 'f1-score': 0.08936714627702065, 'support': 14848}}
{'0': {'precision': 0.3412322274881517, 'recall': 0.11346240432237731, 'f1-score': 0.17029903699949317, 'support': 4442}, '1': {'precision': 0.3543938921782487, 'recall': 0.8839875631558493, 'f1-score': 0.5059503948392837, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 176}, '9': {'precision': 0.09848484848484848, 'recall': 0.4642857142857143, 'f1-score': 0.16249999999999998, 'support': 112}, 'accuracy': 0.34381734913793105, 'macro avg': {'precision': 0.0794110968151249, 'recall': 0.1461735681763941, 'f1-score': 0.08387494318387768, 'support': 14848}, 'weighted avg': {'precision': 0.22565293821941945, 'recall': 0.34381734913793105, 'f1-score': 0.22752485548186305, 'support': 14848}}