Experiment dir: ./exp/Test_los_midwest
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
midwest_val.csv
test_listfile.csv
midwest_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1730187970399855
Train: epoch: 1, loss = 2.1361699637770655
Train: epoch: 1, loss = 2.117254825234413
Train: epoch: 1, loss = 2.100793536156416
Train: epoch: 1, loss = 2.090597852945328
Train: epoch: 1, loss = 2.0879803880055747
Train: epoch: 1, loss = 2.0804048639535906
Train: epoch: 1, loss = 2.0762777542322874
Train: epoch: 1, loss = 2.0708499039544
Train: epoch: 1, loss = 2.070017796576023
Train: epoch: 1, loss = 2.0677005442706022
Train: epoch: 1, loss = 2.065947123169899
Train: epoch: 1, loss = 2.063687079686385
Train: epoch: 1, loss = 2.0629269865580966
Train: epoch: 1, loss = 2.061862660328547
Train: epoch: 1, loss = 2.060002258755267
Train: epoch: 1, loss = 2.0575451660506867
Train: epoch: 1, loss = 2.056277273794015
Train: epoch: 1, loss = 2.0556817096785496
Train: epoch: 1, loss = 2.0549398187696934
Train: epoch: 1, loss = 2.0540984960680917
Train: epoch: 1, loss = 2.053778330439871
Train: epoch: 1, loss = 2.0526594405070595
Train: epoch: 1, loss = 2.052532318805655
Train: epoch: 1, loss = 2.0517404660224914
Train: epoch: 1, loss = 2.052163503949459
Train: epoch: 1, loss = 2.0512725197606616
Train: epoch: 1, loss = 2.05104979212795
Train: epoch: 1, loss = 2.050519892614463
Train: epoch: 1, loss = 2.050353007833163
Train: epoch: 1, loss = 2.050154821411256
Train: epoch: 1, loss = 2.0501464944146575
Train: epoch: 1, loss = 2.05009961614103
Train: epoch: 1, loss = 2.0492082677693926
Train: epoch: 1, loss = 2.048628130367824
Train: epoch: 1, loss = 2.04868564306034
Train: epoch: 1, loss = 2.0483765200827575
Train: epoch: 1, loss = 2.04800807650152
Train: epoch: 1, loss = 2.047607247248674
Train: epoch: 1, loss = 2.047832273349166
Train: epoch: 1, loss = 2.047255911245579
Train: epoch: 1, loss = 2.0470254718973524
Train: epoch: 1, loss = 2.0466576309952624
Train:  Epoch 1, Loss=2.046624321269989, Cohen Kappa=0.37742911659885314, MAD=0.7162687335349609
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0332119053807753, Cohen Kappa=0.42789247728032764, MAD=0.740775682000736
Eval task: 2
Eval:  Epoch 1, Loss=1.975067412031108, Cohen Kappa=0.021982236338994654, MAD=0.7429045015417451
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.057318862142234, Cohen Kappa=0.33958090122340356, MAD=0.7365480652474846
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9411095832956249, Cohen Kappa=0.008871071569066968, MAD=0.7420614585389382
midwest_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9806712979078294
Train: epoch: 1, loss = 1.9782028487324714
Train: epoch: 1, loss = 1.9722650219996771
Train: epoch: 1, loss = 1.9682435539364815
Train: epoch: 1, loss = 1.9671200309991836
Train: epoch: 1, loss = 1.966718441049258
Train: epoch: 1, loss = 1.9656878753219331
Train: epoch: 1, loss = 1.964773765131831
Train: epoch: 1, loss = 1.9636615594228108
Train: epoch: 1, loss = 1.961434769809246
Train: epoch: 1, loss = 1.9599845731258392
Train: epoch: 1, loss = 1.9587865133583546
Train: epoch: 1, loss = 1.9578790000768809
Train: epoch: 1, loss = 1.9574172939573016
Train: epoch: 1, loss = 1.9586214267810185
Train: epoch: 1, loss = 1.9581855844706297
Train: epoch: 1, loss = 1.9576782044242411
Train: epoch: 1, loss = 1.9568398780292935
Train: epoch: 1, loss = 1.9562047595099399
Train: epoch: 1, loss = 1.9556613691151141
Train: epoch: 1, loss = 1.9547839947257724
Train: epoch: 1, loss = 1.9547619580680673
Train: epoch: 1, loss = 1.9545448968980623
Train: epoch: 1, loss = 1.9540817085901896
Train: epoch: 1, loss = 1.9536121078968047
Train: epoch: 1, loss = 1.95350209405789
Train: epoch: 1, loss = 1.9534529840063166
Train: epoch: 1, loss = 1.9532265682092735
Train: epoch: 1, loss = 1.953688686675039
Train: epoch: 1, loss = 1.9533839913805326
Train: epoch: 1, loss = 1.9528188459911655
Train: epoch: 1, loss = 1.9529899324476718
Train: epoch: 1, loss = 1.9528383326169216
Train: epoch: 1, loss = 1.9526476941564503
Train: epoch: 1, loss = 1.9518838199887958
Train: epoch: 1, loss = 1.9521118809945053
Train: epoch: 1, loss = 1.9515643458914111
Train: epoch: 1, loss = 1.951646863473089
Train: epoch: 1, loss = 1.9511085500319798
Train: epoch: 1, loss = 1.9509701245576143
Train: epoch: 1, loss = 1.9507534501610733
Train: epoch: 1, loss = 1.9506831047790392
Train: epoch: 1, loss = 1.9506193966366523
Train:  Epoch 1, Loss=1.9506073839732578, Cohen Kappa=0.07428731490612928, MAD=0.6949102403653423
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0548894384811662, Cohen Kappa=0.3822318248726271, MAD=0.7244738993115015
Eval task: 2
Eval:  Epoch 1, Loss=1.9537690816254452, Cohen Kappa=0.0596079099386555, MAD=0.6842093711589107
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.070026368930422, Cohen Kappa=0.25617017293498134, MAD=0.7147781764960954
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9235615565859039, Cohen Kappa=0.06568612143107921, MAD=0.6858502595349872
{'0': {'precision': 0.4215568862275449, 'recall': 0.08638036809815951, 'f1-score': 0.14338085539714868, 'support': 4075}, '1': {'precision': 0.22268986157875048, 'recall': 0.831064572425829, 'f1-score': 0.35125765287305455, 'support': 2865}, '2': {'precision': 0.07017543859649122, 'recall': 0.0022002200220022, 'f1-score': 0.004266666666666667, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.18803680981595092, 'recall': 0.5041118421052632, 'f1-score': 0.27390527256478997, 'support': 1216}, '9': {'precision': 0.5, 'recall': 0.001863932898415657, 'f1-score': 0.0037140204271123487, 'support': 1073}, 'accuracy': 0.2257543103448276, 'macro avg': {'precision': 0.14024589962187375, 'recall': 0.14256209355496693, 'f1-score': 0.07765244679287722, 'support': 14848}, 'weighted avg': {'precision': 0.2187892290480188, 'recall': 0.2257543103448276, 'f1-score': 0.13035027724823264, 'support': 14848}}
{'0': {'precision': 0.43309002433090027, 'recall': 0.04207043252186245, 'f1-score': 0.07669108143041793, 'support': 4231}, '1': {'precision': 0.3430140153157058, 'recall': 0.9437487577022461, 'f1-score': 0.5031526519366291, 'support': 5031}, '2': {'precision': 0.1501597444089457, 'recall': 0.01945364238410596, 'f1-score': 0.03444485159399047, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.08156028368794327, 'recall': 0.07516339869281045, 'f1-score': 0.07823129251700679, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3364762931034483, 'macro avg': {'precision': 0.1007824067743495, 'recall': 0.10804362313010249, 'f1-score': 0.06925198774780442, 'support': 14848}, 'weighted avg': {'precision': 0.26574964933310063, 'recall': 0.3364762931034483, 'f1-score': 0.19955539428788818, 'support': 14848}}