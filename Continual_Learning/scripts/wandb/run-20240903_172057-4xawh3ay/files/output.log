Experiment dir: ./exp/Test_phen_west
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.4354515989124775
Train: epoch: 1, loss = 0.4247507069259882
Train: epoch: 1, loss = 0.4169731514155865
Train: epoch: 1, loss = 0.41431056063622235
Train: epoch: 1, loss = 0.41177745288610457
Train: epoch: 1, loss = 0.40922875930865604
Train: epoch: 1, loss = 0.40841896880950246
Train: epoch: 1, loss = 0.4071533572487533
Train: epoch: 1, loss = 0.4061898314456145
Train: epoch: 1, loss = 0.404793114438653
Train: epoch: 1, loss = 0.40382381028749725
Train: epoch: 1, loss = 0.40281014462312065
Train: epoch: 1, loss = 0.4015722774886168
Train: epoch: 1, loss = 0.39947414156581673
Train: epoch: 1, loss = 0.3983168328454097
Train: epoch: 1, loss = 0.3974295801622793
Train: epoch: 1, loss = 0.3964667042476289
Train: epoch: 1, loss = 0.3954498754151993
Train:  Epoch 1, Loss=0.39515348507807807, AUC-ROC Macro=0.6478890986174426, AUC-ROC Micro=0.7430355787694071
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3714786469936371, AUC-ROC Macro=0.7168241840185435, AUC-ROC Micro=0.7818522784637323
Eval task: 2
Eval:  Epoch 1, Loss=0.35851291567087173, AUC-ROC Macro=0.49508113552169797, AUC-ROC Micro=0.539022211321568
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.3720759944617748
Train: epoch: 2, loss = 0.37617645643651487
Train: epoch: 2, loss = 0.37570815833906335
Train: epoch: 2, loss = 0.3749421583674848
Train: epoch: 2, loss = 0.3741357611566782
Train: epoch: 2, loss = 0.3751919101799528
Train: epoch: 2, loss = 0.37479880660772324
Train: epoch: 2, loss = 0.3742567892279476
Train: epoch: 2, loss = 0.3732278253965908
Train: epoch: 2, loss = 0.3726204420402646
Train: epoch: 2, loss = 0.372310947464271
Train: epoch: 2, loss = 0.37188898152361316
Train: epoch: 2, loss = 0.3713627776045066
Train: epoch: 2, loss = 0.3712334776882614
Train: epoch: 2, loss = 0.37068502786258856
Train: epoch: 2, loss = 0.3704379973420873
Train: epoch: 2, loss = 0.3704993228745811
Train: epoch: 2, loss = 0.3702815198111865
Train:  Epoch 2, Loss=0.37026634477142595, AUC-ROC Macro=0.7204385783580899, AUC-ROC Micro=0.7885121442224814
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3636645848552386, AUC-ROC Macro=0.7343012553562595, AUC-ROC Micro=0.7946395754896234
Eval task: 2
Eval:  Epoch 2, Loss=0.3527190536260605, AUC-ROC Macro=0.4835628121633404, AUC-ROC Micro=0.538048425448285
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.36568015858531
Train: epoch: 3, loss = 0.3673047235235572
Train: epoch: 3, loss = 0.365211099733909
Train: epoch: 3, loss = 0.3637843728251755
Train: epoch: 3, loss = 0.3640489461272955
Train: epoch: 3, loss = 0.3624430722246567
Train: epoch: 3, loss = 0.36259288986878735
Train: epoch: 3, loss = 0.3628081758413464
Train: epoch: 3, loss = 0.36203316509723665
Train: epoch: 3, loss = 0.36204303737729787
Train: epoch: 3, loss = 0.3621944104541432
Train: epoch: 3, loss = 0.3622849849859873
Train: epoch: 3, loss = 0.3625037436244579
Train: epoch: 3, loss = 0.36258227841130325
Train: epoch: 3, loss = 0.36253505472342173
Train: epoch: 3, loss = 0.3622602477669716
Train: epoch: 3, loss = 0.36230828469290455
Train: epoch: 3, loss = 0.3618497013217873
Train:  Epoch 3, Loss=0.3618290880358117, AUC-ROC Macro=0.7398197196496931, AUC-ROC Micro=0.8015949054022404
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.35855798174937564, AUC-ROC Macro=0.7475327393381851, AUC-ROC Micro=0.8040897754876571
Eval task: 2
Eval:  Epoch 3, Loss=0.35734665393829346, AUC-ROC Macro=0.48931443071648817, AUC-ROC Micro=0.5419384300615975
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.3591938342899084
Train: epoch: 4, loss = 0.35479220271110534
Train: epoch: 4, loss = 0.35710222346087295
Train: epoch: 4, loss = 0.3583388007618487
Train: epoch: 4, loss = 0.35692870411276817
Train: epoch: 4, loss = 0.35690894683202107
Train: epoch: 4, loss = 0.3557382882386446
Train: epoch: 4, loss = 0.3563613277953118
Train: epoch: 4, loss = 0.3565102612641123
Train: epoch: 4, loss = 0.35604685297608374
Train: epoch: 4, loss = 0.3567283323203975
Train: epoch: 4, loss = 0.35683704684178036
Train: epoch: 4, loss = 0.3571346532897307
Train: epoch: 4, loss = 0.35632722496454206
Train: epoch: 4, loss = 0.355891447921594
Train: epoch: 4, loss = 0.3559173117391765
Train: epoch: 4, loss = 0.35583469411029534
Train: epoch: 4, loss = 0.3554533167348968
Train:  Epoch 4, Loss=0.35555740686359566, AUC-ROC Macro=0.7536866080814356, AUC-ROC Micro=0.8108707576609488
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3537735926608245, AUC-ROC Macro=0.7554237549644143, AUC-ROC Micro=0.8099926988218682
Eval task: 2
Eval:  Epoch 4, Loss=0.37473317235708237, AUC-ROC Macro=0.4880088006477862, AUC-ROC Micro=0.5312481903763857
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.35415436312556264
Train: epoch: 5, loss = 0.3533520343527198
Train: epoch: 5, loss = 0.35187922723591325
Train: epoch: 5, loss = 0.3507910779491067
Train: epoch: 5, loss = 0.3504783630222082
Train: epoch: 5, loss = 0.3506679269919793
Train: epoch: 5, loss = 0.3512293071725539
Train: epoch: 5, loss = 0.3513472619280219
Train: epoch: 5, loss = 0.35212527905901275
Train: epoch: 5, loss = 0.35175208578258754
Train: epoch: 5, loss = 0.35205177336931226
Train: epoch: 5, loss = 0.35194037582104404
Train: epoch: 5, loss = 0.35129555369798954
Train: epoch: 5, loss = 0.3513066921436361
Train: epoch: 5, loss = 0.351359455883503
Train: epoch: 5, loss = 0.3510519490716979
Train: epoch: 5, loss = 0.35105019266552784
Train: epoch: 5, loss = 0.35111234202980995
Train:  Epoch 5, Loss=0.3511440421587382, AUC-ROC Macro=0.763114101774342, AUC-ROC Micro=0.8173115369523128
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3520340397953987, AUC-ROC Macro=0.7590484048374685, AUC-ROC Micro=0.8126055080163528
Eval task: 2
Eval:  Epoch 5, Loss=0.3843003958463669, AUC-ROC Macro=0.4889729245393173, AUC-ROC Micro=0.5355217635276499
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.34387685179710387
Train: epoch: 6, loss = 0.34461600966751577
Train: epoch: 6, loss = 0.3462519721190135
Train: epoch: 6, loss = 0.3461921735666692
Train: epoch: 6, loss = 0.34571791426837445
Train: epoch: 6, loss = 0.34651688610514003
Train: epoch: 6, loss = 0.34652489403528824
Train: epoch: 6, loss = 0.3467677300795913
Train: epoch: 6, loss = 0.3469783399088515
Train: epoch: 6, loss = 0.3472296470180154
Train: epoch: 6, loss = 0.34710282256657427
Train: epoch: 6, loss = 0.3472173944177727
Train: epoch: 6, loss = 0.3475664923340082
Train: epoch: 6, loss = 0.3474071644086923
Train: epoch: 6, loss = 0.3480072988371054
Train: epoch: 6, loss = 0.3478143389383331
Train: epoch: 6, loss = 0.34749479892061036
Train: epoch: 6, loss = 0.3478904345134894
Train:  Epoch 6, Loss=0.34785778303024095, AUC-ROC Macro=0.769719081316888, AUC-ROC Micro=0.8217141217087369
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.34997877726952237, AUC-ROC Macro=0.7628424748360202, AUC-ROC Micro=0.8156485567757977
Eval task: 2
Eval:  Epoch 6, Loss=0.3908302113413811, AUC-ROC Macro=0.4896212706858427, AUC-ROC Micro=0.5378406830463152
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.35202406719326973, AUC-ROC Macro=0.7638464214250149, AUC-ROC Micro=0.8155144071758448
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.39178022742271423, AUC-ROC Macro=0.49891366118406194, AUC-ROC Micro=0.5339904318564437
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.3117371066659689
Train: epoch: 1, loss = 0.3056087999045849
Train: epoch: 1, loss = 0.29329722819228965
Train:  Epoch 1, Loss=0.28676481676492177, AUC-ROC Macro=0.5327252811765512, AUC-ROC Micro=0.7251723387942324
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3640057183802128, AUC-ROC Macro=0.7421922123594205, AUC-ROC Micro=0.7945299047181956
Eval task: 2
Eval:  Epoch 1, Loss=0.28446002304553986, AUC-ROC Macro=0.602435155845649, AUC-ROC Micro=0.7703893391602286
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.2916666651517153
Train: epoch: 2, loss = 0.28934879969805477
Train: epoch: 2, loss = 0.2788409960269928
Train:  Epoch 2, Loss=0.2721980655269258, AUC-ROC Macro=0.6197544269631817, AUC-ROC Micro=0.7926943005828626
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3531539353231589, AUC-ROC Macro=0.7471661611644344, AUC-ROC Micro=0.8014754509765151
Eval task: 2
Eval:  Epoch 2, Loss=0.27648136764764786, AUC-ROC Macro=0.6586516100986292, AUC-ROC Micro=0.7963616943226527
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.2827684749662876
Train: epoch: 3, loss = 0.2811619757860899
Train: epoch: 3, loss = 0.2726537219186624
Train:  Epoch 3, Loss=0.26632070561991267, AUC-ROC Macro=0.6744640551781839, AUC-ROC Micro=0.8106544600812233
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.34646157672007877, AUC-ROC Macro=0.750451061296961, AUC-ROC Micro=0.8057406842689879
Eval task: 2
Eval:  Epoch 3, Loss=0.27232563495635986, AUC-ROC Macro=0.6804858648050982, AUC-ROC Micro=0.8021816243638116
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.27728454865515234
Train: epoch: 4, loss = 0.27759098552167416
Train: epoch: 4, loss = 0.2686352427303791
Train:  Epoch 4, Loss=0.26240332495960134, AUC-ROC Macro=0.7040828088978328, AUC-ROC Micro=0.8201672672390559
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3463077334066232, AUC-ROC Macro=0.744964553282793, AUC-ROC Micro=0.801357224921583
Eval task: 2
Eval:  Epoch 4, Loss=0.27445364743471146, AUC-ROC Macro=0.6863541945055104, AUC-ROC Micro=0.805690215795791
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.275806640163064
Train: epoch: 5, loss = 0.2741078522801399
Train: epoch: 5, loss = 0.2636259982238213
Train:  Epoch 5, Loss=0.25798348689263684, AUC-ROC Macro=0.7262261763064386, AUC-ROC Micro=0.8280124599999064
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.34576936066150665, AUC-ROC Macro=0.7425013783364833, AUC-ROC Micro=0.7977601875995426
Eval task: 2
Eval:  Epoch 5, Loss=0.2717539444565773, AUC-ROC Macro=0.6923093603802127, AUC-ROC Micro=0.8103963998112205
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.2715400343388319
Train: epoch: 6, loss = 0.2692338114231825
Train: epoch: 6, loss = 0.2614278741925955
Train:  Epoch 6, Loss=0.25585304554263716, AUC-ROC Macro=0.7317778116366409, AUC-ROC Micro=0.8339686602520648
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.34449833010633785, AUC-ROC Macro=0.741020837985492, AUC-ROC Micro=0.7968205680225245
Eval task: 2
Eval:  Epoch 6, Loss=0.26673751696944237, AUC-ROC Macro=0.6968287624320805, AUC-ROC Micro=0.8091233485110785
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3679153695702553, AUC-ROC Macro=0.7425404769844954, AUC-ROC Micro=0.7968946401105813
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.2237517423927784, AUC-ROC Macro=0.7098097445524922, AUC-ROC Micro=0.808790813684806
{'0': {'precision': 0.5082938388625592, 'recall': 0.32798165137614677, 'f1-score': 0.3986988847583643, 'support': 1308}, '1': {'precision': 0.6574074074074074, 'recall': 0.35323383084577115, 'f1-score': 0.4595469255663431, 'support': 402}, '2': {'precision': 0.49333333333333335, 'recall': 0.11246200607902736, 'f1-score': 0.18316831683168316, 'support': 658}, '3': {'precision': 0.4785172704296546, 'recall': 0.28542713567839195, 'f1-score': 0.357570034623859, 'support': 1990}, '4': {'precision': 0.48704663212435234, 'recall': 0.11662531017369727, 'f1-score': 0.18818818818818817, 'support': 806}, '5': {'precision': 0.25, 'recall': 0.010282776349614395, 'f1-score': 0.019753086419753086, 'support': 778}, '6': {'precision': 0.5777126099706745, 'recall': 0.15130568356374807, 'f1-score': 0.2398052343274498, 'support': 1302}, '7': {'precision': 0.2222222222222222, 'recall': 0.014150943396226415, 'f1-score': 0.026607538802660754, 'support': 424}, '8': {'precision': 0.4927169094363521, 'recall': 0.4732360097323601, 'f1-score': 0.48278001861619607, 'support': 1644}, '9': {'precision': 0.6470588235294118, 'recall': 0.4441161989167898, 'f1-score': 0.5267153284671533, 'support': 2031}, '10': {'precision': 0.7383720930232558, 'recall': 0.22164048865619546, 'f1-score': 0.3409395973154362, 'support': 573}, '11': {'precision': 0.4567669172932331, 'recall': 0.2066326530612245, 'f1-score': 0.28454332552693207, 'support': 1176}, '12': {'precision': 0.5809682804674458, 'recall': 0.19661016949152543, 'f1-score': 0.2937948501477417, 'support': 1770}, '13': {'precision': 0.5888501742160279, 'recall': 0.32550077041602465, 'f1-score': 0.4192508062515505, 'support': 2596}, '14': {'precision': 0.5701598579040853, 'recall': 0.1972956361401352, 'f1-score': 0.2931506849315068, 'support': 1627}, '15': {'precision': 0.125, 'recall': 0.002066115702479339, 'f1-score': 0.0040650406504065045, 'support': 484}, '16': {'precision': 0.4396551724137931, 'recall': 0.12830188679245283, 'f1-score': 0.19863680623174293, 'support': 795}, '17': {'precision': 0.5614035087719298, 'recall': 0.058823529411764705, 'f1-score': 0.10648918469217969, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.5, 'recall': 0.026717557251908396, 'f1-score': 0.050724637681159424, 'support': 262}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 563}, '21': {'precision': 0.47288503253796094, 'recall': 0.26045400238948624, 'f1-score': 0.33590138674884434, 'support': 837}, '22': {'precision': 0.6216216216216216, 'recall': 0.6141804788213628, 'f1-score': 0.617878647522001, 'support': 1086}, '23': {'precision': 0.6096938775510204, 'recall': 0.2775842044134727, 'f1-score': 0.38148443735035914, 'support': 861}, '24': {'precision': 0.5388888888888889, 'recall': 0.19207920792079208, 'f1-score': 0.28321167883211673, 'support': 505}, 'micro avg': {'precision': 0.5513730858071691, 'recall': 0.25401016828912626, 'f1-score': 0.34779558577518754, 'support': 25373}, 'macro avg': {'precision': 0.46474297888020927, 'recall': 0.1998683298632239, 'f1-score': 0.25971618561934506, 'support': 25373}, 'weighted avg': {'precision': 0.5093177850176994, 'recall': 0.25401016828912626, 'f1-score': 0.32169663684298944, 'support': 25373}, 'samples avg': {'precision': 0.3678790380084325, 'recall': 0.22042311797955758, 'f1-score': 0.2528811912289261, 'support': 25373}}
{'0': {'precision': 0.5803571428571429, 'recall': 0.33163265306122447, 'f1-score': 0.42207792207792205, 'support': 196}, '1': {'precision': 0.5, 'recall': 0.012448132780082987, 'f1-score': 0.024291497975708502, 'support': 241}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 145}, '3': {'precision': 1.0, 'recall': 0.00847457627118644, 'f1-score': 0.01680672268907563, 'support': 118}, '4': {'precision': 0.4861111111111111, 'recall': 0.16826923076923078, 'f1-score': 0.25, 'support': 208}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 100}, '6': {'precision': 0.5, 'recall': 0.00909090909090909, 'f1-score': 0.01785714285714286, 'support': 110}, '7': {'precision': 0.8181818181818182, 'recall': 0.20300751879699247, 'f1-score': 0.3253012048192771, 'support': 133}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 89}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87}, '13': {'precision': 0.43478260869565216, 'recall': 0.136986301369863, 'f1-score': 0.2083333333333333, 'support': 73}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 45}, '15': {'precision': 0.8205128205128205, 'recall': 0.6274509803921569, 'f1-score': 0.711111111111111, 'support': 51}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'micro avg': {'precision': 0.5958904109589042, 'recall': 0.08726178535606821, 'f1-score': 0.15223097112860892, 'support': 1994}, 'macro avg': {'precision': 0.2055978200543418, 'recall': 0.05989441210126584, 'f1-score': 0.07903115739454282, 'support': 1994}, 'weighted avg': {'precision': 0.3464215532649094, 'recall': 0.08726178535606821, 'f1-score': 0.11999451503108272, 'support': 1994}, 'samples avg': {'precision': 0.14705403645833331, 'recall': 0.10437127976190476, 'f1-score': 0.11454613095238095, 'support': 1994}}