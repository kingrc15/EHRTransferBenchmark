
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
midwest_val.csv
test_listfile.csv
midwest_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.185316389203072
Train: epoch: 1, loss = 2.1470769211649894
Train: epoch: 1, loss = 2.1226325150330863
Train: epoch: 1, loss = 2.106138712465763
Train: epoch: 1, loss = 2.0937301304340363
Train: epoch: 1, loss = 2.088931321501732
Train: epoch: 1, loss = 2.082854047332491
Train: epoch: 1, loss = 2.0782647820562126
Train: epoch: 1, loss = 2.077364807923635
Train: epoch: 1, loss = 2.074546379506588
Train: epoch: 1, loss = 2.071304268620231
Train: epoch: 1, loss = 2.0691451716423033
Train: epoch: 1, loss = 2.067477229787753
Train: epoch: 1, loss = 2.064662178797381
Train: epoch: 1, loss = 2.062732452352842
Train: epoch: 1, loss = 2.06100351087749
Train: epoch: 1, loss = 2.0597033741544273
Train: epoch: 1, loss = 2.05774772465229
Train: epoch: 1, loss = 2.05746383406614
Train: epoch: 1, loss = 2.0563873324096202
Train: epoch: 1, loss = 2.0556724882409685
Train: epoch: 1, loss = 2.055269352089275
Train: epoch: 1, loss = 2.0549241012075674
Train: epoch: 1, loss = 2.0542555442700783
Train: epoch: 1, loss = 2.0531633293867113
Train: epoch: 1, loss = 2.0526483241411357
Train: epoch: 1, loss = 2.0521621566569364
Train: epoch: 1, loss = 2.051671432959182
Train: epoch: 1, loss = 2.0516967960678296
Train: epoch: 1, loss = 2.051042629023393
Train: epoch: 1, loss = 2.050248253133989
Train: epoch: 1, loss = 2.049363276604563
Train: epoch: 1, loss = 2.0490455168846884
Train: epoch: 1, loss = 2.0489691706615334
Train: epoch: 1, loss = 2.0483142554078784
Train: epoch: 1, loss = 2.0483232794536486
Train: epoch: 1, loss = 2.047562138744303
Train: epoch: 1, loss = 2.046761875089846
Train: epoch: 1, loss = 2.0466636693936127
Train: epoch: 1, loss = 2.0463812953978775
Train: epoch: 1, loss = 2.0458589623759433
Train: epoch: 1, loss = 2.0458776516999517
Train: epoch: 1, loss = 2.045144350043563
Train:  Epoch 1, Loss=2.044848547581264, Cohen Kappa=0.3806979180263902, MAD=0.7187580208884023
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0284008979797363, Cohen Kappa=0.4320578149631793, MAD=0.7149276303526068
Eval task: 2
Eval:  Epoch 1, Loss=1.9752541801025127, Cohen Kappa=0.01189745181230839, MAD=0.7391194497396576
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0515209066456763, Cohen Kappa=0.3463736983990974, MAD=0.7148965468682749
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.940847265309301, Cohen Kappa=0.00397557506921753, MAD=0.7375544528928193
midwest_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.987483612895012
Train: epoch: 1, loss = 1.9979766577482223
Train: epoch: 1, loss = 1.9953762499491374
Train: epoch: 1, loss = 1.9994105194509029
Train: epoch: 1, loss = 1.9948194296360016
Train: epoch: 1, loss = 1.9932078164815903
Train: epoch: 1, loss = 1.9931253071342196
Train: epoch: 1, loss = 1.9941507829725742
Train: epoch: 1, loss = 1.9938737985160615
Train: epoch: 1, loss = 1.9944926490783692
Train: epoch: 1, loss = 1.9933557146787644
Train: epoch: 1, loss = 1.9931428901851178
Train: epoch: 1, loss = 1.9931028185899442
Train: epoch: 1, loss = 1.9925960183143616
Train: epoch: 1, loss = 1.991961906949679
Train: epoch: 1, loss = 1.9911679638177155
Train: epoch: 1, loss = 1.9913658396286122
Train: epoch: 1, loss = 1.9915936376319991
Train: epoch: 1, loss = 1.991635119099366
Train: epoch: 1, loss = 1.9914909796714784
Train: epoch: 1, loss = 1.9917608672380447
Train: epoch: 1, loss = 1.9914149375937202
Train: epoch: 1, loss = 1.991329654066459
Train: epoch: 1, loss = 1.9915244036912918
Train: epoch: 1, loss = 1.9914064743041993
Train: epoch: 1, loss = 1.9911031974966709
Train: epoch: 1, loss = 1.9908543455159222
Train: epoch: 1, loss = 1.9906443588009903
Train: epoch: 1, loss = 1.9906333284953546
Train: epoch: 1, loss = 1.9903016303976377
Train: epoch: 1, loss = 1.9899734374784654
Train: epoch: 1, loss = 1.9895356252044438
Train: epoch: 1, loss = 1.9895283461520166
Train: epoch: 1, loss = 1.9895759119531689
Train: epoch: 1, loss = 1.989737102321216
Train: epoch: 1, loss = 1.989768795867761
Train: epoch: 1, loss = 1.989395301631979
Train: epoch: 1, loss = 1.989434456840942
Train: epoch: 1, loss = 1.9894711878513678
Train: epoch: 1, loss = 1.989392476350069
Train: epoch: 1, loss = 1.989143038857274
Train: epoch: 1, loss = 1.989147275686264
Train: epoch: 1, loss = 1.9889845804003783
Train:  Epoch 1, Loss=1.9889667732647487, Cohen Kappa=0.06640287445635873, MAD=0.6914962652090049
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.027787617568312, Cohen Kappa=0.4279755224967837, MAD=0.7161858068670052
Eval task: 2
Eval:  Epoch 1, Loss=1.9784142642185605, Cohen Kappa=0.06275522196871086, MAD=0.6855411390183728
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0436084414350577, Cohen Kappa=0.33464764662812385, MAD=0.7202557870435753
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9219990290444473, Cohen Kappa=0.05452922954606276, MAD=0.6890263345866966
{'0': {'precision': 0.3965693804403482, 'recall': 0.7602453987730061, 'f1-score': 0.5212416926053671, 'support': 4075}, '1': {'precision': 0.2423559703894432, 'recall': 0.2628272251308901, 'f1-score': 0.25217682518419293, 'support': 2865}, '2': {'precision': 0.09090909090909091, 'recall': 0.00055005500550055, 'f1-score': 0.0010934937124111536, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.11646741226378712, 'recall': 0.24835526315789475, 'f1-score': 0.15857180362299814, 'support': 1216}, '9': {'precision': 0.16452830188679246, 'recall': 0.2031686859273066, 'f1-score': 0.18181818181818182, 'support': 1073}, 'accuracy': 0.29445043103448276, 'macro avg': {'precision': 0.1010830155889462, 'recall': 0.1475146627994598, 'f1-score': 0.11149019969431513, 'support': 14848}, 'weighted avg': {'precision': 0.18816042894465212, 'recall': 0.29445043103448276, 'f1-score': 0.21797202959221595, 'support': 14848}}
{'0': {'precision': 0.3356920124730151, 'recall': 0.6615457338690617, 'f1-score': 0.44538149415227946, 'support': 4231}, '1': {'precision': 0.30926844885545063, 'recall': 0.3840190816935003, 'f1-score': 0.3426139386416031, 'support': 5031}, '2': {'precision': 0.13679245283018868, 'recall': 0.012003311258278146, 'f1-score': 0.022070015220700154, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.09803921568627451, 'recall': 0.016339869281045753, 'f1-score': 0.028011204481792718, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.32091864224137934, 'macro avg': {'precision': 0.08797921298449289, 'recall': 0.1073907996101886, 'f1-score': 0.08380766524963754, 'support': 14848}, 'weighted avg': {'precision': 0.22472609354814352, 'recall': 0.32091864224137934, 'f1-score': 0.2471708251891729, 'support': 14848}}