
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.173620197176933
Train: epoch: 1, loss = 2.1398007699847224
Train: epoch: 1, loss = 2.1176551588376364
Train: epoch: 1, loss = 2.1034888777136804
Train: epoch: 1, loss = 2.0925936926603317
Train: epoch: 1, loss = 2.0869674267371496
Train: epoch: 1, loss = 2.084377603530884
Train: epoch: 1, loss = 2.0810105937719343
Train: epoch: 1, loss = 2.0791361108091144
Train: epoch: 1, loss = 2.077788937330246
Train: epoch: 1, loss = 2.0741563765027307
Train: epoch: 1, loss = 2.071643803517024
Train: epoch: 1, loss = 2.068919229048949
Train: epoch: 1, loss = 2.0678156467846462
Train: epoch: 1, loss = 2.0687911485433577
Train: epoch: 1, loss = 2.0664524373412134
Train: epoch: 1, loss = 2.0656056177966735
Train: epoch: 1, loss = 2.064386216269599
Train: epoch: 1, loss = 2.0614465233213024
Train: epoch: 1, loss = 2.060770444124937
Train: epoch: 1, loss = 2.0599085516589026
Train: epoch: 1, loss = 2.057960367365317
Train: epoch: 1, loss = 2.0566878322933033
Train: epoch: 1, loss = 2.0565688785662255
Train: epoch: 1, loss = 2.0553477842330934
Train: epoch: 1, loss = 2.0547471873576826
Train: epoch: 1, loss = 2.053468844625685
Train: epoch: 1, loss = 2.05363970924701
Train: epoch: 1, loss = 2.0522546222292144
Train: epoch: 1, loss = 2.05226706469059
Train: epoch: 1, loss = 2.0517863275351065
Train: epoch: 1, loss = 2.051372465286404
Train: epoch: 1, loss = 2.050896620587869
Train: epoch: 1, loss = 2.050516764013206
Train: epoch: 1, loss = 2.0499338605063304
Train: epoch: 1, loss = 2.0488183766934607
Train: epoch: 1, loss = 2.0480850833171123
Train: epoch: 1, loss = 2.0477857077906005
Train: epoch: 1, loss = 2.0473470718432694
Train: epoch: 1, loss = 2.046762789204717
Train: epoch: 1, loss = 2.0460178914011977
Train: epoch: 1, loss = 2.045854638956842
Train: epoch: 1, loss = 2.0452483484079673
Train:  Epoch 1, Loss=2.0451465650013514, Cohen Kappa=0.3793236342698161, MAD=0.7193109214557442
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.030437202289187, Cohen Kappa=0.4380010273900432, MAD=0.7138166073710682
Eval task: 2
Eval:  Epoch 1, Loss=1.9838380813598633, Cohen Kappa=0.002589157289939581, MAD=0.7559383390093022
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0507277311949896, Cohen Kappa=0.3420238255136421, MAD=0.717973440711178
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.94898273204935, Cohen Kappa=0.003207874434643654, MAD=0.7545443613526734
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9596537911891938
Train: epoch: 1, loss = 1.967912768125534
Train: epoch: 1, loss = 1.974732984105746
Train: epoch: 1, loss = 1.9722744131088257
Train: epoch: 1, loss = 1.972989571094513
Train: epoch: 1, loss = 1.973970118065675
Train: epoch: 1, loss = 1.9740131821802684
Train: epoch: 1, loss = 1.9743636380136014
Train: epoch: 1, loss = 1.9739569261338976
Train: epoch: 1, loss = 1.9750611934065818
Train: epoch: 1, loss = 1.9743756733157418
Train: epoch: 1, loss = 1.9744616260627905
Train: epoch: 1, loss = 1.974253482910303
Train: epoch: 1, loss = 1.9743139195442199
Train: epoch: 1, loss = 1.9739582384030023
Train: epoch: 1, loss = 1.9737626979872585
Train: epoch: 1, loss = 1.9738059193246504
Train: epoch: 1, loss = 1.9739043180478943
Train: epoch: 1, loss = 1.974155297969517
Train: epoch: 1, loss = 1.9742315009236335
Train: epoch: 1, loss = 1.9738847583532333
Train: epoch: 1, loss = 1.9733812023021957
Train: epoch: 1, loss = 1.9730900383773058
Train: epoch: 1, loss = 1.9734779518097638
Train: epoch: 1, loss = 1.973833882856369
Train: epoch: 1, loss = 1.9736231295420574
Train: epoch: 1, loss = 1.9731006522090346
Train: epoch: 1, loss = 1.9730854611524513
Train: epoch: 1, loss = 1.9730251516350383
Train: epoch: 1, loss = 1.972559322277705
Train: epoch: 1, loss = 1.97227184176445
Train: epoch: 1, loss = 1.971736611612141
Train: epoch: 1, loss = 1.971535229195248
Train: epoch: 1, loss = 1.9712528315361808
Train: epoch: 1, loss = 1.9715150633028575
Train: epoch: 1, loss = 1.9708484254777432
Train: epoch: 1, loss = 1.9701076391258756
Train: epoch: 1, loss = 1.9693718394793962
Train: epoch: 1, loss = 1.9686207575064438
Train: epoch: 1, loss = 1.9681576433032758
Train: epoch: 1, loss = 1.9676362585294538
Train: epoch: 1, loss = 1.9667244406966935
Train: epoch: 1, loss = 1.9660647483204687
------------- 1, Loss=1.9662433242252895, Cohen Kappa=0.06283565598490348, MAD=0.6894825157069617
------------- 1, Loss=1.9662433242252895, Cohen Kappa=0.06283565598490348, MAD=0.6894825157069617
Eval task: 1
Eval:  Epoch 1, Loss=2.0336704870750166, Cohen Kappa=0.4386219034197715, MAD=0.727252172872134
Eval task: 2
Eval:  Epoch 1, Loss=1.9676816915643627, Cohen Kappa=0.09478548885346971, MAD=0.6770262780763006
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0532363776502938, Cohen Kappa=0.35248055891941577, MAD=0.7216737718768796
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9248800709329803, Cohen Kappa=0.10217473954144529, MAD=0.6801619918335373
{'0': {'precision': 0.4246300863131936, 'recall': 0.6760736196319018, 'f1-score': 0.5216321120893685, 'support': 4075}, '1': {'precision': 0.28164397377710537, 'recall': 0.3898778359511344, 'f1-score': 0.3270385009515444, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.17742350218565184, 'recall': 0.5674342105263158, 'f1-score': 0.2703232125367287, 'support': 1216}, '9': {'precision': 0.22782258064516128, 'recall': 0.10531220876048462, 'f1-score': 0.14404079031230085, 'support': 1073}, 'accuracy': 0.3148572198275862, 'macro avg': {'precision': 0.11115201429211122, 'recall': 0.17386978748698367, 'f1-score': 0.12630346158899425, 'support': 14848}, 'weighted avg': {'precision': 0.20187757235234924, 'recall': 0.3148572198275862, 'f1-score': 0.23881229501886533, 'support': 14848}}
{'0': {'precision': 0.43735982057033, 'recall': 0.3226187662491137, 'f1-score': 0.37132752992383017, 'support': 4231}, '1': {'precision': 0.3371514828627242, 'recall': 0.7547207314649175, 'f1-score': 0.46608973178665675, 'support': 5031}, '2': {'precision': 0.21666666666666667, 'recall': 0.01076158940397351, 'f1-score': 0.02050473186119874, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.0782608695652174, 'recall': 0.08823529411764706, 'f1-score': 0.08294930875576037, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3512257543103448, 'macro avg': {'precision': 0.10694388396649383, 'recall': 0.11763363812356516, 'f1-score': 0.09408713023274459, 'support': 14848}, 'weighted avg': {'precision': 0.2757336344200603, 'recall': 0.3512257543103448, 'f1-score': 0.26878408811842097, 'support': 14848}}