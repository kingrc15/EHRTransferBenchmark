
Experiment dir: ./exp/Test_los_south
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.16977421939373
Train: epoch: 1, loss = 2.13634699344635
Train: epoch: 1, loss = 2.1156146373351414
Train: epoch: 1, loss = 2.10106954485178
Train: epoch: 1, loss = 2.0914212709665296
Train: epoch: 1, loss = 2.0854450115561485
Train: epoch: 1, loss = 2.078281443970544
Train: epoch: 1, loss = 2.0756500206142663
Train: epoch: 1, loss = 2.0729710117975872
Train: epoch: 1, loss = 2.0723050624132155
Train: epoch: 1, loss = 2.0705346576734023
Train: epoch: 1, loss = 2.069364870886008
Train: epoch: 1, loss = 2.06732495367527
Train: epoch: 1, loss = 2.065646450434412
Train: epoch: 1, loss = 2.063598994255066
Train: epoch: 1, loss = 2.061491898223758
Train: epoch: 1, loss = 2.0591566365606644
Train: epoch: 1, loss = 2.0582143352097937
Train: epoch: 1, loss = 2.056588785146412
Train: epoch: 1, loss = 2.056259853243828
Train: epoch: 1, loss = 2.0557660763036636
Train: epoch: 1, loss = 2.0555683082342147
Train: epoch: 1, loss = 2.0554361549926843
Train: epoch: 1, loss = 2.0551806930204233
Train: epoch: 1, loss = 2.054765513753891
Train: epoch: 1, loss = 2.0541973691032482
Train: epoch: 1, loss = 2.0538005076072836
Train: epoch: 1, loss = 2.0526576962002685
Train: epoch: 1, loss = 2.0521805669727
Train: epoch: 1, loss = 2.051732172151407
Train: epoch: 1, loss = 2.0503672387330765
Train: epoch: 1, loss = 2.0502455040626226
Train: epoch: 1, loss = 2.0500883120117765
Train: epoch: 1, loss = 2.049001096416922
Train: epoch: 1, loss = 2.0487924129281727
Train: epoch: 1, loss = 2.047455499370893
Train: epoch: 1, loss = 2.0473043375079696
Train: epoch: 1, loss = 2.047284867355698
Train: epoch: 1, loss = 2.0466677888234455
Train: epoch: 1, loss = 2.0465124850720167
Train: epoch: 1, loss = 2.046283794307127
Train: epoch: 1, loss = 2.045974723867008
Train: epoch: 1, loss = 2.0454284652166588
Train:  Epoch 1, Loss=2.045071356337411, Cohen Kappa=0.3793742012542356, MAD=0.7187156437151273
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.032528710776362, Cohen Kappa=0.428585980080331, MAD=0.7382728551951037
Eval task: 2
Eval:  Epoch 1, Loss=1.9301319759467552, Cohen Kappa=0.0036212499125232167, MAD=0.7602688555116438
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.051079006030642, Cohen Kappa=0.33776147851424687, MAD=0.7422594360979973
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9237854809596622, Cohen Kappa=0.00453624403204822, MAD=0.7609711565546875
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.922330983877182
Train: epoch: 1, loss = 1.91711269646883
Train: epoch: 1, loss = 1.9154899285236995
Train: epoch: 1, loss = 1.9139849554002284
Train: epoch: 1, loss = 1.9122183940410613
Train: epoch: 1, loss = 1.9130587602655094
Train: epoch: 1, loss = 1.911000481247902
Train: epoch: 1, loss = 1.9103534242510796
Train: epoch: 1, loss = 1.9115206232998105
Train: epoch: 1, loss = 1.9114641251564026
Train: epoch: 1, loss = 1.9116629535501652
Train: epoch: 1, loss = 1.9122086005906265
Train: epoch: 1, loss = 1.9120947587031585
Train: epoch: 1, loss = 1.9120583988939013
Train: epoch: 1, loss = 1.9119953098694484
Train: epoch: 1, loss = 1.9113425669446586
Train: epoch: 1, loss = 1.9115012023729436
Train: epoch: 1, loss = 1.911073314083947
Train: epoch: 1, loss = 1.9106035347361314
Train: epoch: 1, loss = 1.9104146140813827
Train: epoch: 1, loss = 1.9109618909869874
Train: epoch: 1, loss = 1.9114572868292983
Train: epoch: 1, loss = 1.9107462628250538
Train: epoch: 1, loss = 1.909863243450721
Train: epoch: 1, loss = 1.9097030346393584
Train: epoch: 1, loss = 1.908949167590875
Train: epoch: 1, loss = 1.9088502229143072
Train: epoch: 1, loss = 1.9088476791977882
Train: epoch: 1, loss = 1.9086704968789527
Train: epoch: 1, loss = 1.9085445594787598
Train: epoch: 1, loss = 1.9079863945322653
Train: epoch: 1, loss = 1.907689159810543
Train: epoch: 1, loss = 1.9077001925309498
Train: epoch: 1, loss = 1.9074171231599415
Train: epoch: 1, loss = 1.9073251263925008
Train: epoch: 1, loss = 1.9074098141491413
Train: epoch: 1, loss = 1.9069299020638337
Train: epoch: 1, loss = 1.9065926177407566
Train: epoch: 1, loss = 1.906208012012335
Train: epoch: 1, loss = 1.9061873822063207
Train: epoch: 1, loss = 1.9056878927277356
Train: epoch: 1, loss = 1.905754864513874
Train: epoch: 1, loss = 1.9054602256625197
Train:  Epoch 1, Loss=1.905416487121582, Cohen Kappa=0.14442430026053432, MAD=0.6929415853083237
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0655339504110404, Cohen Kappa=0.353019745642453, MAD=0.7235416265143007
Eval task: 2
Eval:  Epoch 1, Loss=1.909762662032555, Cohen Kappa=0.04118740533173437, MAD=0.689638602437441
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0559444530256865, Cohen Kappa=0.3014956589722326, MAD=0.7214321486343549
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8965768259147118, Cohen Kappa=0.04813570418149049, MAD=0.6921519978738486
{'0': {'precision': 0.4664179104477612, 'recall': 0.5214723926380368, 'f1-score': 0.4924110763526822, 'support': 4075}, '1': {'precision': 0.22716191022515417, 'recall': 0.5528795811518324, 'f1-score': 0.32201667005488915, 'support': 2865}, '2': {'precision': 0.021739130434782608, 'recall': 0.00055005500550055, 'f1-score': 0.001072961373390558, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1216}, '9': {'precision': 0.1614002478314746, 'recall': 0.48555452003727867, 'f1-score': 0.24226923971169498, 'support': 1073}, 'accuracy': 0.2849542025862069, 'macro avg': {'precision': 0.08767191989391725, 'recall': 0.15604565488326486, 'f1-score': 0.10577699474926568, 'support': 14848}, 'weighted avg': {'precision': 0.18616487492748526, 'recall': 0.2849542025862069, 'f1-score': 0.2149150346061362, 'support': 14848}}
{'0': {'precision': 0.35631973660142674, 'recall': 0.4385411976587123, 'f1-score': 0.39317791906347765, 'support': 4442}, '1': {'precision': 0.3346991589389692, 'recall': 0.6031869413136417, 'f1-score': 0.4305131761442441, 'support': 5146}, '2': {'precision': 0.0967741935483871, 'recall': 0.0011811023622047244, 'f1-score': 0.002333722287047841, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 176}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.34044989224137934, 'macro avg': {'precision': 0.07877930890887831, 'recall': 0.10429092413345589, 'f1-score': 0.08260248174947696, 'support': 14848}, 'weighted avg': {'precision': 0.23915278781629687, 'recall': 0.34044989224137934, 'f1-score': 0.26723092507592605, 'support': 14848}}