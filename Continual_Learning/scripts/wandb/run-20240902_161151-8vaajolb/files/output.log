
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest_baseline
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
midwest_val.csv
test_listfile.csv
midwest_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1923083484172823
Train: epoch: 1, loss = 2.152565069794655
Train: epoch: 1, loss = 2.1224077528715135
Train: epoch: 1, loss = 2.1101298576593397
Train: epoch: 1, loss = 2.1011218247413637
Train: epoch: 1, loss = 2.0921471511324246
Train: epoch: 1, loss = 2.0881511638845716
Train: epoch: 1, loss = 2.0829702047258616
Train: epoch: 1, loss = 2.0781962997383543
Train: epoch: 1, loss = 2.074679823875427
Train: epoch: 1, loss = 2.0723826888474552
Train: epoch: 1, loss = 2.0687783002853393
Train: epoch: 1, loss = 2.0662295047136454
Train: epoch: 1, loss = 2.0649625426530838
Train: epoch: 1, loss = 2.0631736383835473
Train: epoch: 1, loss = 2.0623610688745977
Train: epoch: 1, loss = 2.061681901076261
Train: epoch: 1, loss = 2.0619275820586416
Train: epoch: 1, loss = 2.0607534317907534
Train: epoch: 1, loss = 2.058670895576477
Train: epoch: 1, loss = 2.057061562225932
Train: epoch: 1, loss = 2.0560838419740852
Train: epoch: 1, loss = 2.0552231023104293
Train: epoch: 1, loss = 2.0535643125822145
Train: epoch: 1, loss = 2.052843889427185
Train: epoch: 1, loss = 2.0519499856692094
Train: epoch: 1, loss = 2.050811070005099
Train: epoch: 1, loss = 2.050056880414486
Train: epoch: 1, loss = 2.049451043441378
Train: epoch: 1, loss = 2.0486166230042775
Train: epoch: 1, loss = 2.0481159095802615
Train: epoch: 1, loss = 2.0484202089719474
Train: epoch: 1, loss = 2.0477279656583613
Train: epoch: 1, loss = 2.0470373197162854
Train: epoch: 1, loss = 2.046870372584888
Train: epoch: 1, loss = 2.0464275757802857
Train: epoch: 1, loss = 2.0458486573760575
Train: epoch: 1, loss = 2.045833034515381
Train: epoch: 1, loss = 2.045776889079656
Train: epoch: 1, loss = 2.0449487108290194
Train: epoch: 1, loss = 2.0441863465309145
Train: epoch: 1, loss = 2.044315436085065
Train: epoch: 1, loss = 2.0442565102078194
Train:  Epoch 1, Loss=2.044181078011649, Cohen Kappa=0.3873146664477698, MAD=0.7189418899022852
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.030509354739354, Cohen Kappa=0.4307092258123699, MAD=0.746363094538006
Eval task: 2
Eval:  Epoch 1, Loss=1.9807023056622208, Cohen Kappa=0.011245372729664527, MAD=0.756233541470483
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.059214949607849, Cohen Kappa=0.34283405553369084, MAD=0.7427988183198148
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9461769523291752, Cohen Kappa=0.005226806446580912, MAD=0.7553489166485025
midwest_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.959426670074463
Train: epoch: 1, loss = 1.967239409983158
Train: epoch: 1, loss = 1.962232570052147
Train: epoch: 1, loss = 1.9594174161553384
Train: epoch: 1, loss = 1.9568634632825852
Train: epoch: 1, loss = 1.955794448653857
Train: epoch: 1, loss = 1.9558686051198415
Train: epoch: 1, loss = 1.954739045277238
Train: epoch: 1, loss = 1.9537870264053345
Train: epoch: 1, loss = 1.9539538326859474
Train: epoch: 1, loss = 1.9548366329886697
Train: epoch: 1, loss = 1.9534514362116655
Train: epoch: 1, loss = 1.9545266140882787
Train: epoch: 1, loss = 1.953344433903694
Train: epoch: 1, loss = 1.9529558747609457
Train: epoch: 1, loss = 1.9524885826185345
Train: epoch: 1, loss = 1.9519596356504103
Train: epoch: 1, loss = 1.9519254348013135
Train: epoch: 1, loss = 1.9515898046054339
Train: epoch: 1, loss = 1.9512521933913232
Train: epoch: 1, loss = 1.9518896497715088
Train: epoch: 1, loss = 1.951544297418811
Train: epoch: 1, loss = 1.9515557442281557
Train: epoch: 1, loss = 1.950616118485729
Train: epoch: 1, loss = 1.9497622916936874
Train: epoch: 1, loss = 1.949483935534954
Train: epoch: 1, loss = 1.9493603452046713
Train: epoch: 1, loss = 1.949107360116073
Train: epoch: 1, loss = 1.9490676636120368
Train: epoch: 1, loss = 1.9487504734794299
Train: epoch: 1, loss = 1.948344951098965
Train: epoch: 1, loss = 1.947990663163364
Train: epoch: 1, loss = 1.9479562477993242
Train: epoch: 1, loss = 1.9481389194902252
Train: epoch: 1, loss = 1.9477199637208666
Train: epoch: 1, loss = 1.9478699731826783
Train: epoch: 1, loss = 1.9475474463443498
Train: epoch: 1, loss = 1.9474819773906156
Train: epoch: 1, loss = 1.947390309893168
Train: epoch: 1, loss = 1.9471910172700881
Train: epoch: 1, loss = 1.9469386102077437
Train: epoch: 1, loss = 1.9469037433465322
Train: epoch: 1, loss = 1.946736528249674
Train:  Epoch 1, Loss=1.9465594808033535, Cohen Kappa=0.09130552687683124, MAD=0.6875518754406826
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.160537057909472, Cohen Kappa=0.04355640722550114, MAD=0.736481913652674
Eval task: 2
Eval:  Epoch 1, Loss=1.950443748770089, Cohen Kappa=0.12339380352396623, MAD=0.672433680481304
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.106831865064029, Cohen Kappa=0.03990054366442608, MAD=0.7344142092895648
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9242762635494102, Cohen Kappa=0.10639955675148127, MAD=0.6774458848811447
{'0': {'precision': 0.42203389830508475, 'recall': 0.5499386503067485, 'f1-score': 0.4775705913692062, 'support': 4075}, '1': {'precision': 0.17104986324426677, 'recall': 0.5675392670157068, 'f1-score': 0.26287284778918435, 'support': 2865}, '2': {'precision': 0.125, 'recall': 0.0016501650165016502, 'f1-score': 0.003257328990228013, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.2606411637931034, 'macro avg': {'precision': 0.07180837615493516, 'recall': 0.11191280823389571, 'f1-score': 0.07437007681486185, 'support': 14848}, 'weighted avg': {'precision': 0.16413631423680258, 'recall': 0.2606411637931034, 'f1-score': 0.18218970183524807, 'support': 14848}}
{'0': {'precision': 0.4255254340542187, 'recall': 0.3301819900732687, 'f1-score': 0.3718392334309289, 'support': 4231}, '1': {'precision': 0.3332706943530959, 'recall': 0.7050288213078911, 'f1-score': 0.45259665688401174, 'support': 5031}, '2': {'precision': 0.17470881863560733, 'recall': 0.04346026490066225, 'f1-score': 0.06960556844547564, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.0778816199376947, 'recall': 0.08169934640522876, 'f1-score': 0.07974481658692185, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.34172952586206895, 'macro avg': {'precision': 0.10113865669806166, 'recall': 0.11603704226870508, 'f1-score': 0.09737862753473382, 'support': 14848}, 'weighted avg': {'precision': 0.2642114262054409, 'recall': 0.34172952586206895, 'f1-score': 0.27228142138130323, 'support': 14848}}