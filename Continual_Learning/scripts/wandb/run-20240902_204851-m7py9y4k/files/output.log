
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_west_baseline
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
west_val.csv
test_listfile.csv
west_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1826317048072816
Train: epoch: 1, loss = 2.1463143771886823
Train: epoch: 1, loss = 2.1238591529925666
Train: epoch: 1, loss = 2.110345305800438
Train: epoch: 1, loss = 2.1006134366989135
Train: epoch: 1, loss = 2.091724702914556
Train: epoch: 1, loss = 2.0824334835154668
Train: epoch: 1, loss = 2.0778118577599525
Train: epoch: 1, loss = 2.0735301821099386
Train: epoch: 1, loss = 2.0706464453339577
Train: epoch: 1, loss = 2.06739693663337
Train: epoch: 1, loss = 2.0655792582035066
Train: epoch: 1, loss = 2.0635723792589626
Train: epoch: 1, loss = 2.0620637221421516
Train: epoch: 1, loss = 2.0611046700874964
Train: epoch: 1, loss = 2.0611245173588397
Train: epoch: 1, loss = 2.0590996041368035
Train: epoch: 1, loss = 2.0583433623777494
Train: epoch: 1, loss = 2.0573145289483823
Train: epoch: 1, loss = 2.0556994312405585
Train: epoch: 1, loss = 2.0547832755531585
Train: epoch: 1, loss = 2.054128785323013
Train: epoch: 1, loss = 2.0535148606870486
Train: epoch: 1, loss = 2.052876671080788
Train: epoch: 1, loss = 2.0523142341136933
Train: epoch: 1, loss = 2.0526316961416833
Train: epoch: 1, loss = 2.052832782467206
Train: epoch: 1, loss = 2.0520247577130792
Train: epoch: 1, loss = 2.0517961243514358
Train: epoch: 1, loss = 2.051195812344551
Train: epoch: 1, loss = 2.051096891568553
Train: epoch: 1, loss = 2.0499135052785276
Train: epoch: 1, loss = 2.049124403577862
Train: epoch: 1, loss = 2.0487370143392507
Train: epoch: 1, loss = 2.048590821845191
Train: epoch: 1, loss = 2.04804365767373
Train: epoch: 1, loss = 2.048073494804872
Train: epoch: 1, loss = 2.048083767781132
Train: epoch: 1, loss = 2.0480666086765438
Train: epoch: 1, loss = 2.047848839521408
Train: epoch: 1, loss = 2.0474481799398982
Train: epoch: 1, loss = 2.0472329349602973
Train: epoch: 1, loss = 2.0464488934777503
Train:  Epoch 1, Loss=2.0461322178568158, Cohen Kappa=0.37658170520793044, MAD=0.7196284712418628
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.031678347752012, Cohen Kappa=0.4227775106779076, MAD=0.7421475203394322
Eval task: 2
Eval:  Epoch 1, Loss=1.8793693287619229, Cohen Kappa=0.0011225526296395616, MAD=0.757060072952069
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0544567848074027, Cohen Kappa=0.3310808368224978, MAD=0.7371722073308883
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8929240539156158, Cohen Kappa=0.0007965919207000294, MAD=0.757359903155851
west_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.8713841074705124
Train: epoch: 1, loss = 1.8691095024347306
Train: epoch: 1, loss = 1.8697657885154089
Train: epoch: 1, loss = 1.8707925921678543
Train: epoch: 1, loss = 1.8710289648771286
Train: epoch: 1, loss = 1.8720032392938932
Train: epoch: 1, loss = 1.8752459470714842
Train: epoch: 1, loss = 1.8748413267731667
Train: epoch: 1, loss = 1.8741458059019513
Train: epoch: 1, loss = 1.8746454943418502
Train: epoch: 1, loss = 1.8746213031898846
Train: epoch: 1, loss = 1.8757379424075287
Train: epoch: 1, loss = 1.8747844462669814
Train: epoch: 1, loss = 1.8754671074237141
Train: epoch: 1, loss = 1.8745476584037144
Train: epoch: 1, loss = 1.872928922176361
Train: epoch: 1, loss = 1.8736447904741063
Train: epoch: 1, loss = 1.874332264860471
Train: epoch: 1, loss = 1.8744172507210781
Train: epoch: 1, loss = 1.8750783351659774
Train: epoch: 1, loss = 1.875403662551017
Train:  Epoch 1, Loss=1.875944925580706, Cohen Kappa=0.010014031617736618, MAD=0.7251969155031552
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.121106238200747, Cohen Kappa=0.17346626432009815, MAD=0.754871588252216
Eval task: 2
Eval:  Epoch 1, Loss=1.870971494707568, Cohen Kappa=-0.013405270494469379, MAD=0.7152949862829439
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0914020065603585, Cohen Kappa=0.1158841329239434, MAD=0.7402401671909213
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.882331654943269, Cohen Kappa=0.012449797268321183, MAD=0.7172188141533511
{'0': {'precision': 0.35912343470483005, 'recall': 0.19705521472392637, 'f1-score': 0.254476311202662, 'support': 4075}, '1': {'precision': 0.20740351798372275, 'recall': 0.8272251308900523, 'f1-score': 0.33165407220822835, 'support': 2865}, '2': {'precision': 0.0911062906724512, 'recall': 0.0231023102310231, 'f1-score': 0.036858271171566474, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.31407407407407406, 'recall': 0.17434210526315788, 'f1-score': 0.2242199894235854, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.23080549568965517, 'macro avg': {'precision': 0.09717073174350781, 'recall': 0.12217247611081597, 'f1-score': 0.08472086440060422, 'support': 14848}, 'weighted avg': {'precision': 0.17545692254594142, 'recall': 0.23080549568965517, 'f1-score': 0.15671064986236596, 'support': 14848}}
{'0': {'precision': 0.32562277580071175, 'recall': 0.07384987893462469, 'f1-score': 0.12039473684210525, 'support': 2478}, '1': {'precision': 0.3548387096774194, 'recall': 0.9240847784200386, 'f1-score': 0.5127766492034642, 'support': 2595}, '2': {'precision': 0.038461538461538464, 'recall': 0.0036900369003690036, 'f1-score': 0.006734006734006734, 'support': 1084}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 501}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 215}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 121}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 103}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 153}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102}, 'accuracy': 0.3481950431034483, 'macro avg': {'precision': 0.07189230239396696, 'recall': 0.10016246942550322, 'f1-score': 0.06399053927795761, 'support': 7424}, 'weighted avg': {'precision': 0.2383340514196356, 'recall': 0.3481950431034483, 'f1-score': 0.22040587633046738, 'support': 7424}}