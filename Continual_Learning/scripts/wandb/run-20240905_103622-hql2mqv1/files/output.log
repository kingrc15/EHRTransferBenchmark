
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
midwest_val.csv
test_listfile.csv
midwest_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.18425882935524
Train: epoch: 1, loss = 2.1361395648121833
Train: epoch: 1, loss = 2.110309208432833
Train: epoch: 1, loss = 2.096009760648012
Train: epoch: 1, loss = 2.0900507493019105
Train: epoch: 1, loss = 2.0813031515479086
Train: epoch: 1, loss = 2.0771043503284456
Train: epoch: 1, loss = 2.074342029392719
Train: epoch: 1, loss = 2.071747626993391
Train: epoch: 1, loss = 2.068606764256954
Train: epoch: 1, loss = 2.0660788707299664
Train: epoch: 1, loss = 2.0643256811797617
Train: epoch: 1, loss = 2.0617544306700046
Train: epoch: 1, loss = 2.059954362937382
Train: epoch: 1, loss = 2.0588211322625476
Train: epoch: 1, loss = 2.0578957372158766
Train: epoch: 1, loss = 2.058256760309724
Train: epoch: 1, loss = 2.058599433104197
Train: epoch: 1, loss = 2.056690090957441
Train: epoch: 1, loss = 2.055481538593769
Train: epoch: 1, loss = 2.0538174665541877
Train: epoch: 1, loss = 2.0529874905943872
Train: epoch: 1, loss = 2.051928771164106
Train: epoch: 1, loss = 2.051444238498807
Train: epoch: 1, loss = 2.050898431324959
Train: epoch: 1, loss = 2.0499461137789945
Train: epoch: 1, loss = 2.049471689330207
Train: epoch: 1, loss = 2.0485428796921457
Train: epoch: 1, loss = 2.047650925640402
Train: epoch: 1, loss = 2.04674426929156
Train: epoch: 1, loss = 2.0457916572017054
Train: epoch: 1, loss = 2.045576539821923
Train: epoch: 1, loss = 2.045261831247445
Train: epoch: 1, loss = 2.045306540692554
Train: epoch: 1, loss = 2.044972720895495
Train: epoch: 1, loss = 2.045194119728274
Train: epoch: 1, loss = 2.044612248427159
Train: epoch: 1, loss = 2.044702825263927
Train: epoch: 1, loss = 2.0447783687023016
Train: epoch: 1, loss = 2.0441584516614677
Train: epoch: 1, loss = 2.0438792276091693
Train: epoch: 1, loss = 2.0438278927405675
Train: epoch: 1, loss = 2.043625812447348
Train:  Epoch 1, Loss=2.043498621245793, Cohen Kappa=0.38858444102533074, MAD=0.7224945070515286
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0432010642413436, Cohen Kappa=0.37913209229867384, MAD=0.7094609928318074
Eval task: 2
Eval:  Epoch 1, Loss=1.979190507839466, Cohen Kappa=0.002838602084060171, MAD=0.7510849551978177
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0566876119580764, Cohen Kappa=0.25960662962373793, MAD=0.7041417998346096
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9435730925921737, Cohen Kappa=0.0012809711745989105, MAD=0.7494258830221756
midwest_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9601994735002517
Train: epoch: 1, loss = 1.9664822962880135
Train: epoch: 1, loss = 1.9623091854651769
Train: epoch: 1, loss = 1.9627580718696118
Train: epoch: 1, loss = 1.9613380872011186
Train: epoch: 1, loss = 1.9576989483833314
Train: epoch: 1, loss = 1.9569835639851434
Train: epoch: 1, loss = 1.9551713491231204
Train: epoch: 1, loss = 1.9569118671284782
Train: epoch: 1, loss = 1.955358880341053
Train: epoch: 1, loss = 1.954811532551592
Train: epoch: 1, loss = 1.954664508452018
Train: epoch: 1, loss = 1.9559448786423757
Train: epoch: 1, loss = 1.9552840485317367
Train: epoch: 1, loss = 1.9554417036771774
Train: epoch: 1, loss = 1.9548774721845985
Train: epoch: 1, loss = 1.955429087596781
Train: epoch: 1, loss = 1.9553395423955386
Train: epoch: 1, loss = 1.9551734775932212
Train: epoch: 1, loss = 1.954610596060753
Train: epoch: 1, loss = 1.953804473167374
Train: epoch: 1, loss = 1.953243519853462
Train: epoch: 1, loss = 1.9523287483920222
Train: epoch: 1, loss = 1.9520558239271244
Train: epoch: 1, loss = 1.9514153502464295
Train: epoch: 1, loss = 1.9513090296433522
Train: epoch: 1, loss = 1.9509714795041968
Train: epoch: 1, loss = 1.9507312327623367
Train: epoch: 1, loss = 1.9509877280120191
Train: epoch: 1, loss = 1.9507751380006473
Train: epoch: 1, loss = 1.9508925154324501
Train: epoch: 1, loss = 1.9508871410042048
Train: epoch: 1, loss = 1.9513551958763238
Train: epoch: 1, loss = 1.9510296204686164
Train: epoch: 1, loss = 1.95064171564579
Train: epoch: 1, loss = 1.9506861866845024
Train: epoch: 1, loss = 1.9501150624494294
Train: epoch: 1, loss = 1.9505378852706206
Train: epoch: 1, loss = 1.950487049512374
Train: epoch: 1, loss = 1.9506129475086929
Train: epoch: 1, loss = 1.9504147232596467
Train: epoch: 1, loss = 1.9504717792499633
Train: epoch: 1, loss = 1.950561534041582
Train:  Epoch 1, Loss=1.9507189030919756, Cohen Kappa=0.0893563415891403, MAD=0.691028712529726
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.061551135161827, Cohen Kappa=0.3518409037140109, MAD=0.6861454370448581
Eval task: 2
Eval:  Epoch 1, Loss=1.9599118664346893, Cohen Kappa=0.11577950387267621, MAD=0.6730535573836437
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.063903307092601, Cohen Kappa=0.28416484937771846, MAD=0.6739313612272034
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9296055908860832, Cohen Kappa=0.08491647125816992, MAD=0.6743831831410773
{'0': {'precision': 0.717391304347826, 'recall': 0.016196319018404907, 'f1-score': 0.031677465802735776, 'support': 4075}, '1': {'precision': 0.22673377121897126, 'recall': 0.9277486910994764, 'f1-score': 0.364409103372635, 'support': 2865}, '2': {'precision': 0.1656441717791411, 'recall': 0.01485148514851485, 'f1-score': 0.027258960121150932, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.23966337358214415, 'recall': 0.5386513157894737, 'f1-score': 0.3317295517852621, 'support': 1216}, '9': {'precision': 0.43283582089552236, 'recall': 0.05405405405405406, 'f1-score': 0.09610604805302403, 'support': 1073}, 'accuracy': 0.23329741379310345, 'macro avg': {'precision': 0.17822684418236048, 'recall': 0.15515018651099238, 'f1-score': 0.08511811291348079, 'support': 14848}, 'weighted avg': {'precision': 0.3118242471815063, 'recall': 0.23329741379310345, 'f1-score': 0.11645874652079562, 'support': 14848}}
{'0': {'precision': 0.25510204081632654, 'recall': 0.00590876861262113, 'f1-score': 0.01155001155001155, 'support': 4231}, '1': {'precision': 0.34634634634634637, 'recall': 0.9628304512025442, 'f1-score': 0.5094389230688331, 'support': 5031}, '2': {'precision': 0.20242914979757085, 'recall': 0.020695364238410598, 'f1-score': 0.03755163349605708, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.10465116279069768, 'recall': 0.17647058823529413, 'f1-score': 0.13138686131386865, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3349272629310345, 'macro avg': {'precision': 0.09085286997509415, 'recall': 0.116590517228887, 'f1-score': 0.06899274294287704, 'support': 14848}, 'weighted avg': {'precision': 0.22514125032915078, 'recall': 0.3349272629310345, 'f1-score': 0.18472416803043618, 'support': 14848}}