
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south_baseline
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
south_val.csv
test_listfile.csv
south_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.174033441543579
Train: epoch: 1, loss = 2.136123102605343
Train: epoch: 1, loss = 2.118629606763522
Train: epoch: 1, loss = 2.1017540849745275
Train: epoch: 1, loss = 2.091779397368431
Train: epoch: 1, loss = 2.083309855957826
Train: epoch: 1, loss = 2.0766388337101254
Train: epoch: 1, loss = 2.0714952395111323
Train: epoch: 1, loss = 2.0682118568817773
Train: epoch: 1, loss = 2.0664863749146463
Train: epoch: 1, loss = 2.0646836484562265
Train: epoch: 1, loss = 2.061583917637666
Train: epoch: 1, loss = 2.0611200673305072
Train: epoch: 1, loss = 2.0594963614855493
Train: epoch: 1, loss = 2.058681918819745
Train: epoch: 1, loss = 2.0565161930024622
Train: epoch: 1, loss = 2.0560126085141124
Train: epoch: 1, loss = 2.05483114944564
Train: epoch: 1, loss = 2.05323230301079
Train: epoch: 1, loss = 2.0521088223457338
Train: epoch: 1, loss = 2.0518836886826017
Train: epoch: 1, loss = 2.051135662577369
Train: epoch: 1, loss = 2.0503084775675897
Train: epoch: 1, loss = 2.049733578612407
Train: epoch: 1, loss = 2.0486764610528945
Train: epoch: 1, loss = 2.0481419540368595
Train: epoch: 1, loss = 2.0479070361455283
Train: epoch: 1, loss = 2.0470193961475576
Train: epoch: 1, loss = 2.046236132794413
Train: epoch: 1, loss = 2.0462772031029064
Train: epoch: 1, loss = 2.0459180817680975
Train: epoch: 1, loss = 2.0453277740255
Train: epoch: 1, loss = 2.044843729878917
Train: epoch: 1, loss = 2.0443774090970264
Train: epoch: 1, loss = 2.044401077372687
Train: epoch: 1, loss = 2.0444256125059392
Train: epoch: 1, loss = 2.044121923559421
Train: epoch: 1, loss = 2.043998119956569
Train: epoch: 1, loss = 2.043742804680115
Train: epoch: 1, loss = 2.0434335204809906
Train: epoch: 1, loss = 2.043070515917569
Train: epoch: 1, loss = 2.0430532334532057
Train: epoch: 1, loss = 2.043046075729437
Train:  Epoch 1, Loss=2.0426654484476363, Cohen Kappa=0.38915802729948556, MAD=0.7218121030224289
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.040144846357148, Cohen Kappa=0.4065847776477167, MAD=0.7209623529280433
Eval task: 2
Eval:  Epoch 1, Loss=1.9243338190276047, Cohen Kappa=0.0017440753079936977, MAD=0.7429528670487626
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0613635757873796, Cohen Kappa=0.3271089201311276, MAD=0.7188400422300977
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9163608304385482, Cohen Kappa=0.003511180740799924, MAD=0.7432706655763656
south_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9245045298337937
Train: epoch: 1, loss = 1.9201699906587602
Train: epoch: 1, loss = 1.917270255088806
Train: epoch: 1, loss = 1.9160297609865666
Train: epoch: 1, loss = 1.912504824399948
Train: epoch: 1, loss = 1.910957169731458
Train: epoch: 1, loss = 1.9102088035855975
Train: epoch: 1, loss = 1.9105341105908156
Train: epoch: 1, loss = 1.9115651022725635
Train: epoch: 1, loss = 1.9104325681328773
Train: epoch: 1, loss = 1.9104223826798525
Train: epoch: 1, loss = 1.9101941242814064
Train: epoch: 1, loss = 1.9092287591787485
Train: epoch: 1, loss = 1.909599729520934
Train: epoch: 1, loss = 1.9101030552387237
Train: epoch: 1, loss = 1.909587971381843
Train: epoch: 1, loss = 1.9092768772209392
Train: epoch: 1, loss = 1.9096812031666437
Train: epoch: 1, loss = 1.9089585899051866
Train: epoch: 1, loss = 1.9083054759800435
Train: epoch: 1, loss = 1.9076493848221643
Train: epoch: 1, loss = 1.907577109391039
Train: epoch: 1, loss = 1.907071792561075
Train: epoch: 1, loss = 1.9073992014924686
Train: epoch: 1, loss = 1.9075219360351563
Train: epoch: 1, loss = 1.907409548186339
Train: epoch: 1, loss = 1.9075845290334137
Train: epoch: 1, loss = 1.9067966016062667
Train: epoch: 1, loss = 1.906491746655826
Train: epoch: 1, loss = 1.9067292120258013
Train: epoch: 1, loss = 1.9070944657825655
Train: epoch: 1, loss = 1.906808055471629
Train: epoch: 1, loss = 1.9074111635576596
Train: epoch: 1, loss = 1.9067907330744407
Train: epoch: 1, loss = 1.9069465233768736
Train: epoch: 1, loss = 1.9067953535252147
Train: epoch: 1, loss = 1.9067824165080045
Train: epoch: 1, loss = 1.906551002452248
Train: epoch: 1, loss = 1.906269816664549
Train: epoch: 1, loss = 1.9063286104351282
Train: epoch: 1, loss = 1.905812245258471
Train: epoch: 1, loss = 1.90588326359079
Train: epoch: 1, loss = 1.9060599643269251
Train:  Epoch 1, Loss=1.906056367274693, Cohen Kappa=0.10628007982078924, MAD=0.6945684289223909
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.171980068601411, Cohen Kappa=0.004803901760097706, MAD=0.6875684837639541
Eval task: 2
Eval:  Epoch 1, Loss=1.907825178113477, Cohen Kappa=0.08403005263410179, MAD=0.6994183822354331
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.119641686307973, Cohen Kappa=-0.004123737597964583, MAD=0.6987331238229977
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8971028040195335, Cohen Kappa=0.03573507737723558, MAD=0.6987746039004799
{'0': {'precision': 1.0, 'recall': 0.00147239263803681, 'f1-score': 0.00294045577064445, 'support': 4075}, '1': {'precision': 0.1935000340669074, 'recall': 0.9912739965095986, 'f1-score': 0.323794322198153, 'support': 2865}, '2': {'precision': 0.7, 'recall': 0.01155115511551155, 'f1-score': 0.022727272727272728, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.19308997844827586, 'macro avg': {'precision': 0.18935000340669073, 'recall': 0.1004297544263147, 'f1-score': 0.034946205069607016, 'support': 14848}, 'weighted avg': {'precision': 0.39749310328675175, 'recall': 0.19308997844827586, 'f1-score': 0.06606756951651847, 'support': 14848}}
{'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4442}, '1': {'precision': 0.3482739800791377, 'recall': 0.9920326467158959, 'f1-score': 0.5155524136538072, 'support': 5146}, '2': {'precision': 0.09375, 'recall': 0.0011811023622047244, 'f1-score': 0.002332814930015552, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0989010989010989, 'recall': 0.05113636363636364, 'f1-score': 0.06741573033707866, 'support': 176}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.3446255387931034, 'macro avg': {'precision': 0.05409250789802365, 'recall': 0.10443501127144642, 'f1-score': 0.05853009589209015, 'support': 14848}, 'weighted avg': {'precision': 0.13791416317981114, 'recall': 0.3446255387931034, 'f1-score': 0.17987764272117843, 'support': 14848}}