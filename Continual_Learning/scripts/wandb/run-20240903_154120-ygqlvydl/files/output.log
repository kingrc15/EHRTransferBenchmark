
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_midwest
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.42982017204165457
Train: epoch: 1, loss = 0.414476926997304
Train: epoch: 1, loss = 0.4133015710612138
Train: epoch: 1, loss = 0.41090661987662314
Train: epoch: 1, loss = 0.4095312425494194
Train: epoch: 1, loss = 0.4081878393640121
Train: epoch: 1, loss = 0.4077941132869039
Train: epoch: 1, loss = 0.4069564663618803
Train: epoch: 1, loss = 0.4056805760330624
Train: epoch: 1, loss = 0.4039567781686783
Train: epoch: 1, loss = 0.40214936685833064
Train: epoch: 1, loss = 0.4005250847029189
Train: epoch: 1, loss = 0.39875627388174717
Train: epoch: 1, loss = 0.3975594828916448
Train: epoch: 1, loss = 0.3963555553356806
Train: epoch: 1, loss = 0.39461337549611925
Train: epoch: 1, loss = 0.39363251139135924
Train: epoch: 1, loss = 0.3926186206108994
Train:  Epoch 1, Loss=0.3922875042491489, AUC-ROC Macro=0.6577170929986745, AUC-ROC Micro=0.7486024816528738
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3709491553405921, AUC-ROC Macro=0.7180346679198698, AUC-ROC Micro=0.7829668915023733
Eval task: 2
Eval:  Epoch 1, Loss=0.3265081010758877, AUC-ROC Macro=0.4835364704073789, AUC-ROC Micro=0.5595898367151749
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.3734419572353363
Train: epoch: 2, loss = 0.374692257642746
Train: epoch: 2, loss = 0.3737317780405283
Train: epoch: 2, loss = 0.3696839078702033
Train: epoch: 2, loss = 0.37153511999547484
Train: epoch: 2, loss = 0.37163990480204423
Train: epoch: 2, loss = 0.3710109809360334
Train: epoch: 2, loss = 0.3713941609021276
Train: epoch: 2, loss = 0.37136451832122275
Train: epoch: 2, loss = 0.37082764799147844
Train: epoch: 2, loss = 0.3709310608560389
Train: epoch: 2, loss = 0.3706162207449476
Train: epoch: 2, loss = 0.3704159449442075
Train: epoch: 2, loss = 0.36995684678533247
Train: epoch: 2, loss = 0.3692824659794569
Train: epoch: 2, loss = 0.36892838414292783
Train: epoch: 2, loss = 0.3687066676467657
Train: epoch: 2, loss = 0.36834068664246133
Train:  Epoch 2, Loss=0.36824404548987366, AUC-ROC Macro=0.7253590331196215, AUC-ROC Micro=0.7916535133056221
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3598611180981, AUC-ROC Macro=0.7413233635704765, AUC-ROC Micro=0.8006084610453372
Eval task: 2
Eval:  Epoch 2, Loss=0.3293847292661667, AUC-ROC Macro=0.47695634584223806, AUC-ROC Micro=0.5530670688860738
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.35893366366624835
Train: epoch: 3, loss = 0.3599901618808508
Train: epoch: 3, loss = 0.3621775238464276
Train: epoch: 3, loss = 0.3622025284171104
Train: epoch: 3, loss = 0.36174502612650394
Train: epoch: 3, loss = 0.3610246644789974
Train: epoch: 3, loss = 0.3614710973522493
Train: epoch: 3, loss = 0.3613257436174899
Train: epoch: 3, loss = 0.36094837847683164
Train: epoch: 3, loss = 0.3614677514731884
Train: epoch: 3, loss = 0.3611861084943468
Train: epoch: 3, loss = 0.36117830345407126
Train: epoch: 3, loss = 0.36074583631295426
Train: epoch: 3, loss = 0.3602323806126203
Train: epoch: 3, loss = 0.3601851020157337
Train: epoch: 3, loss = 0.3599639620818198
Train: epoch: 3, loss = 0.3597464911157594
Train: epoch: 3, loss = 0.35975964753578105
Train:  Epoch 3, Loss=0.3598300704140948, AUC-ROC Macro=0.744892254325201, AUC-ROC Micro=0.8045758153710765
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3558257383604844, AUC-ROC Macro=0.7520924039719774, AUC-ROC Micro=0.8067822530530208
Eval task: 2
Eval:  Epoch 3, Loss=0.3397691361606121, AUC-ROC Macro=0.4724317086038189, AUC-ROC Micro=0.555872769984695
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.35190302789211275
Train: epoch: 4, loss = 0.3505723648145795
Train: epoch: 4, loss = 0.35256756720443566
Train: epoch: 4, loss = 0.3529448787495494
Train: epoch: 4, loss = 0.35322505724430087
Train: epoch: 4, loss = 0.3533316601688663
Train: epoch: 4, loss = 0.353564337598426
Train: epoch: 4, loss = 0.3540152072906494
Train: epoch: 4, loss = 0.3543132810956902
Train: epoch: 4, loss = 0.35352001708000896
Train: epoch: 4, loss = 0.35378380085256966
Train: epoch: 4, loss = 0.3537019767550131
Train: epoch: 4, loss = 0.3534300259844615
Train: epoch: 4, loss = 0.35363425088248085
Train: epoch: 4, loss = 0.35399449931581817
Train: epoch: 4, loss = 0.35427905709017066
Train: epoch: 4, loss = 0.3540395806510659
Train: epoch: 4, loss = 0.35394293922103115
Train:  Epoch 4, Loss=0.3538418622261439, AUC-ROC Macro=0.7575148321803641, AUC-ROC Micro=0.8134090524178215
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3565717314680417, AUC-ROC Macro=0.7564926626478102, AUC-ROC Micro=0.8089801501679678
Eval task: 2
Eval:  Epoch 4, Loss=0.3417513072490692, AUC-ROC Macro=0.47319367149096786, AUC-ROC Micro=0.5582563807942675
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.35269258938729764
Train: epoch: 5, loss = 0.35094691209495066
Train: epoch: 5, loss = 0.35033660824100177
Train: epoch: 5, loss = 0.3499172755144537
Train: epoch: 5, loss = 0.3498788395524025
Train: epoch: 5, loss = 0.35140988719960053
Train: epoch: 5, loss = 0.3507276373250144
Train: epoch: 5, loss = 0.3506377629097551
Train: epoch: 5, loss = 0.35067328913344276
Train: epoch: 5, loss = 0.3506523220092058
Train: epoch: 5, loss = 0.3504749814082276
Train: epoch: 5, loss = 0.3503024626274904
Train: epoch: 5, loss = 0.3500697858230426
Train: epoch: 5, loss = 0.3500401394973908
Train: epoch: 5, loss = 0.34975620050231615
Train: epoch: 5, loss = 0.3496502500306815
Train: epoch: 5, loss = 0.35000514892094275
Train: epoch: 5, loss = 0.34965172710931963
Train:  Epoch 5, Loss=0.34955920665895834, AUC-ROC Macro=0.7666980442849806, AUC-ROC Micro=0.8196052661162727
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3505133204162121, AUC-ROC Macro=0.7630763972078316, AUC-ROC Micro=0.8153970877878283
Eval task: 2
Eval:  Epoch 5, Loss=0.3576638028025627, AUC-ROC Macro=0.47252364356925314, AUC-ROC Micro=0.5469001069036963
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3442298538982868
Train: epoch: 6, loss = 0.34602887753397227
Train: epoch: 6, loss = 0.34813758442799253
Train: epoch: 6, loss = 0.3480697070620954
Train: epoch: 6, loss = 0.34802291297912596
Train: epoch: 6, loss = 0.3473538427427411
Train: epoch: 6, loss = 0.34699938941214764
Train: epoch: 6, loss = 0.3475136260408908
Train: epoch: 6, loss = 0.3475711103114817
Train: epoch: 6, loss = 0.34777247485518453
Train: epoch: 6, loss = 0.34749505032869904
Train: epoch: 6, loss = 0.34716220172743
Train: epoch: 6, loss = 0.3472162462427066
Train: epoch: 6, loss = 0.34696467975952794
Train: epoch: 6, loss = 0.3466358975172043
Train: epoch: 6, loss = 0.346543603236787
Train: epoch: 6, loss = 0.3463283176106565
Train: epoch: 6, loss = 0.3462712337076664
Train:  Epoch 6, Loss=0.3461290397460644, AUC-ROC Macro=0.7734927988790753, AUC-ROC Micro=0.8242226142398659
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3503715644280116, AUC-ROC Macro=0.7638521372756558, AUC-ROC Micro=0.8163021635158808
Eval task: 2
Eval:  Epoch 6, Loss=0.3474240079522133, AUC-ROC Macro=0.4722888584325393, AUC-ROC Micro=0.557624022907214
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.35240429018934566, AUC-ROC Macro=0.7645641986799434, AUC-ROC Micro=0.816437980899392
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.34828733652830124, AUC-ROC Macro=0.48294787711649706, AUC-ROC Micro=0.5577686478165881
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.28355808816850187
Train: epoch: 1, loss = 0.27522827018052337
Train: epoch: 1, loss = 0.27124680928885936
Train: epoch: 1, loss = 0.26772146750241516
Train: epoch: 1, loss = 0.2663016246408224
Train: epoch: 1, loss = 0.2598549142728249
Train:  Epoch 1, Loss=0.25554074257857423, AUC-ROC Macro=0.6066712368131951, AUC-ROC Micro=0.7552520468654491
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3742207946876685, AUC-ROC Macro=0.7334701213348203, AUC-ROC Micro=0.7803649031155286
Eval task: 2
Eval:  Epoch 1, Loss=0.251015018671751, AUC-ROC Macro=0.684298445110524, AUC-ROC Micro=0.7914208470592902
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.24819442354142665
Train: epoch: 2, loss = 0.24881083369255066
Train: epoch: 2, loss = 0.24988304582734902
Train: epoch: 2, loss = 0.2507859358470887
Train: epoch: 2, loss = 0.2507588991597295
Train: epoch: 2, loss = 0.24511292850598693
Train:  Epoch 2, Loss=0.24178485023993204, AUC-ROC Macro=0.6928485553090874, AUC-ROC Micro=0.8028282224350999
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3769261799752712, AUC-ROC Macro=0.7282155057789924, AUC-ROC Micro=0.7748052342405127
Eval task: 2
Eval:  Epoch 2, Loss=0.24664515629410744, AUC-ROC Macro=0.6987399916633978, AUC-ROC Micro=0.8009537743615603
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.2443028486147523
Train: epoch: 3, loss = 0.2436478405445814
Train: epoch: 3, loss = 0.24352346251408258
Train: epoch: 3, loss = 0.24431611217558383
Train: epoch: 3, loss = 0.24409377872943877
Train: epoch: 3, loss = 0.23876844108725587
Train:  Epoch 3, Loss=0.23601120926590222, AUC-ROC Macro=0.7239877867542559, AUC-ROC Micro=0.8178455972326678
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3668522387742996, AUC-ROC Macro=0.7389637040926345, AUC-ROC Micro=0.791712783742722
Eval task: 2
Eval:  Epoch 3, Loss=0.23942693881690502, AUC-ROC Macro=0.7175051071966734, AUC-ROC Micro=0.8169178728347727
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.23975881837308408
Train: epoch: 4, loss = 0.2385558171197772
Train: epoch: 4, loss = 0.2394714646662275
Train: epoch: 4, loss = 0.24021051242016256
Train: epoch: 4, loss = 0.24094353014975786
Train: epoch: 4, loss = 0.23521607929840685
Train:  Epoch 4, Loss=0.23262553973013372, AUC-ROC Macro=0.7403091195486948, AUC-ROC Micro=0.8266674478017231
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3641931116580963, AUC-ROC Macro=0.7375942506959123, AUC-ROC Micro=0.7911924691423327
Eval task: 2
Eval:  Epoch 4, Loss=0.2351621501147747, AUC-ROC Macro=0.7232959705601779, AUC-ROC Micro=0.8219455781318207
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.2341501285880804
Train: epoch: 5, loss = 0.23363796381279825
Train: epoch: 5, loss = 0.23571820424248774
Train: epoch: 5, loss = 0.23684434237889945
Train: epoch: 5, loss = 0.23764087269455195
Train: epoch: 5, loss = 0.2316109177780648
Train:  Epoch 5, Loss=0.22829015267122657, AUC-ROC Macro=0.7583432532256071, AUC-ROC Micro=0.8353663345239104
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3607112852235635, AUC-ROC Macro=0.7399705185539355, AUC-ROC Micro=0.7955516179178292
Eval task: 2
Eval:  Epoch 5, Loss=0.23595034144818783, AUC-ROC Macro=0.725346487677237, AUC-ROC Micro=0.8204395208682271
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.23359391301870347
Train: epoch: 6, loss = 0.23299793982878328
Train: epoch: 6, loss = 0.23274870317429305
Train: epoch: 6, loss = 0.23322420549578965
Train: epoch: 6, loss = 0.23283547657728196
Train: epoch: 6, loss = 0.22757231142371892
Train:  Epoch 6, Loss=0.22519554541618322, AUC-ROC Macro=0.7680904587557982, AUC-ROC Micro=0.8414302471341626
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.36384205768505734, AUC-ROC Macro=0.7318783406242401, AUC-ROC Micro=0.788858234352677
Eval task: 2
Eval:  Epoch 6, Loss=0.23583415895700455, AUC-ROC Macro=0.7227540117932335, AUC-ROC Micro=0.8223899767339621
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.37517902503410977, AUC-ROC Macro=0.7324065367142373, AUC-ROC Micro=0.7888526315112924
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.2122235931456089, AUC-ROC Macro=0.7273460082715555, AUC-ROC Micro=0.8203271044779695
{'0': {'precision': 0.5564024390243902, 'recall': 0.2790519877675841, 'f1-score': 0.37169042769857435, 'support': 1308}, '1': {'precision': 0.6918604651162791, 'recall': 0.2960199004975124, 'f1-score': 0.4146341463414634, 'support': 402}, '2': {'precision': 0.4583333333333333, 'recall': 0.016717325227963525, 'f1-score': 0.03225806451612903, 'support': 658}, '3': {'precision': 0.59375, 'recall': 0.1527638190954774, 'f1-score': 0.24300559552358114, 'support': 1990}, '4': {'precision': 0.44609665427509293, 'recall': 0.1488833746898263, 'f1-score': 0.22325581395348837, 'support': 806}, '5': {'precision': 0.34210526315789475, 'recall': 0.016709511568123392, 'f1-score': 0.031862745098039214, 'support': 778}, '6': {'precision': 0.5305343511450382, 'recall': 0.10675883256528418, 'f1-score': 0.17774936061381075, 'support': 1302}, '7': {'precision': 0.2, 'recall': 0.0023584905660377358, 'f1-score': 0.004662004662004662, 'support': 424}, '8': {'precision': 0.6, 'recall': 0.20437956204379562, 'f1-score': 0.3049001814882033, 'support': 1644}, '9': {'precision': 0.7091787439613526, 'recall': 0.36139832594780896, 'f1-score': 0.4787997390737116, 'support': 2031}, '10': {'precision': 0.544, 'recall': 0.23734729493891799, 'f1-score': 0.330498177399757, 'support': 573}, '11': {'precision': 0.4624664879356568, 'recall': 0.29336734693877553, 'f1-score': 0.35900104058272636, 'support': 1176}, '12': {'precision': 0.5816901408450704, 'recall': 0.23333333333333334, 'f1-score': 0.3330645161290323, 'support': 1770}, '13': {'precision': 0.6119536128456735, 'recall': 0.2642526964560863, 'f1-score': 0.3691148775894539, 'support': 2596}, '14': {'precision': 0.5891472868217055, 'recall': 0.14013521819299324, 'f1-score': 0.22641509433962265, 'support': 1627}, '15': {'precision': 0.1111111111111111, 'recall': 0.006198347107438017, 'f1-score': 0.011741682974559688, 'support': 484}, '16': {'precision': 0.43568464730290457, 'recall': 0.1320754716981132, 'f1-score': 0.20270270270270271, 'support': 795}, '17': {'precision': 0.43478260869565216, 'recall': 0.01838235294117647, 'f1-score': 0.035273368606701945, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.5384615384615384, 'recall': 0.026717557251908396, 'f1-score': 0.05090909090909091, 'support': 262}, '20': {'precision': 0.25, 'recall': 0.0017761989342806395, 'f1-score': 0.003527336860670194, 'support': 563}, '21': {'precision': 0.5336322869955157, 'recall': 0.14217443249701314, 'f1-score': 0.22452830188679246, 'support': 837}, '22': {'precision': 0.6958677685950413, 'recall': 0.3876611418047882, 'f1-score': 0.4979302188054406, 'support': 1086}, '23': {'precision': 0.6203703703703703, 'recall': 0.23344947735191637, 'f1-score': 0.3392405063291139, 'support': 861}, '24': {'precision': 0.5622119815668203, 'recall': 0.24158415841584158, 'f1-score': 0.3379501385041551, 'support': 505}, 'micro avg': {'precision': 0.5863010446343779, 'recall': 0.19465573641272219, 'f1-score': 0.2922744622303755, 'support': 25373}, 'macro avg': {'precision': 0.48398564366241764, 'recall': 0.15773984631327986, 'f1-score': 0.224188605303553, 'support': 25373}, 'weighted avg': {'precision': 0.5394833220986018, 'recall': 0.19465573641272219, 'f1-score': 0.2754881582583879, 'support': 25373}, 'samples avg': {'precision': 0.3058121172989337, 'recall': 0.16999735559090454, 'f1-score': 0.19924832876099988, 'support': 25373}}
{'0': {'precision': 0.6194690265486725, 'recall': 0.3349282296650718, 'f1-score': 0.43478260869565216, 'support': 418}, '1': {'precision': 0.5285714285714286, 'recall': 0.1712962962962963, 'f1-score': 0.25874125874125875, 'support': 216}, '2': {'precision': 0.45454545454545453, 'recall': 0.034722222222222224, 'f1-score': 0.06451612903225808, 'support': 288}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 252}, '4': {'precision': 0.4827586206896552, 'recall': 0.14583333333333334, 'f1-score': 0.22400000000000003, 'support': 288}, '5': {'precision': 0.47619047619047616, 'recall': 0.03717472118959108, 'f1-score': 0.06896551724137931, 'support': 269}, '6': {'precision': 0.391304347826087, 'recall': 0.03180212014134275, 'f1-score': 0.058823529411764705, 'support': 283}, '7': {'precision': 0.8695652173913043, 'recall': 0.39215686274509803, 'f1-score': 0.5405405405405406, 'support': 255}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 177}, '9': {'precision': 0.75, 'recall': 0.07627118644067797, 'f1-score': 0.13846153846153847, 'support': 236}, '10': {'precision': 0.4, 'recall': 0.01092896174863388, 'f1-score': 0.02127659574468085, 'support': 183}, '11': {'precision': 0.8333333333333334, 'recall': 0.023923444976076555, 'f1-score': 0.046511627906976744, 'support': 209}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 160}, '13': {'precision': 0.25, 'recall': 0.018018018018018018, 'f1-score': 0.03361344537815126, 'support': 111}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 26}, '15': {'precision': 0.6666666666666666, 'recall': 0.7555555555555555, 'f1-score': 0.7083333333333334, 'support': 90}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 69}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 60}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 55}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 25}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 21}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8}, 'micro avg': {'precision': 0.6221910112359551, 'recall': 0.11654827676927125, 'f1-score': 0.19632173720363394, 'support': 3801}, 'macro avg': {'precision': 0.26889618287052314, 'recall': 0.0813044380932767, 'f1-score': 0.10394264497950136, 'support': 3801}, 'weighted avg': {'precision': 0.42508372032832287, 'recall': 0.11654827676927125, 'f1-score': 0.15983400974775475, 'support': 3801}, 'samples avg': {'precision': 0.19840494791666666, 'recall': 0.138671875, 'f1-score': 0.15361444382440476, 'support': 3801}}