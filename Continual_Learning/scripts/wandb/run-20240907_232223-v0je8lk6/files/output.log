
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.151912332773209
Train: epoch: 1, loss = 2.108781520426273
Train: epoch: 1, loss = 2.0962773009141284
Train: epoch: 1, loss = 2.090358228981495
Train: epoch: 1, loss = 2.084346364617348
Train: epoch: 1, loss = 2.0770959929625192
Train: epoch: 1, loss = 2.0732969342810765
Train: epoch: 1, loss = 2.069675901159644
Train: epoch: 1, loss = 2.0670809945132995
Train: epoch: 1, loss = 2.0634647407531737
Train: epoch: 1, loss = 2.0615668631141837
Train: epoch: 1, loss = 2.0616473639011383
Train: epoch: 1, loss = 2.0603599822979706
Train: epoch: 1, loss = 2.0602795902746065
Train: epoch: 1, loss = 2.059370053768158
Train: epoch: 1, loss = 2.0586591542139647
Train: epoch: 1, loss = 2.058296634169186
Train: epoch: 1, loss = 2.0567227987117236
Train: epoch: 1, loss = 2.0559894623881894
Train: epoch: 1, loss = 2.054985422074795
Train: epoch: 1, loss = 2.0550314623117445
Train: epoch: 1, loss = 2.054574333917011
Train: epoch: 1, loss = 2.0535998952647914
Train: epoch: 1, loss = 2.052605813592672
Train: epoch: 1, loss = 2.051638597822189
Train: epoch: 1, loss = 2.0510969631717755
Train: epoch: 1, loss = 2.0513058959113226
Train: epoch: 1, loss = 2.0512703401701793
Train: epoch: 1, loss = 2.0503817373514175
Train: epoch: 1, loss = 2.049773254732291
Train: epoch: 1, loss = 2.04936831026308
Train: epoch: 1, loss = 2.0488034762255847
Train: epoch: 1, loss = 2.0481585391001267
Train: epoch: 1, loss = 2.048037273533204
Train: epoch: 1, loss = 2.0474774881090436
Train: epoch: 1, loss = 2.0468043124510182
Train: epoch: 1, loss = 2.0465614904584113
Train: epoch: 1, loss = 2.0459440761647727
Train: epoch: 1, loss = 2.0461292899113435
Train: epoch: 1, loss = 2.0461479577869177
Train: epoch: 1, loss = 2.046018648089432
Train: epoch: 1, loss = 2.0460399711273967
Train: epoch: 1, loss = 2.0457904096952704
Train:  Epoch 1, Loss=2.045600099495479, Cohen Kappa=0.38181095141269783, MAD=0.7235734356283572
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.027017700261083, Cohen Kappa=0.42774578043284817, MAD=0.7281130151508417
Eval task: 2
Eval:  Epoch 1, Loss=1.9778397556008964, Cohen Kappa=0.0014939466346303165, MAD=0.742972512057728
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.050748919618541, Cohen Kappa=0.33553176845584576, MAD=0.7284823354302734
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.942004436048968, Cohen Kappa=0.003763885076097484, MAD=0.7416821752335371
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9717708545923234
Train: epoch: 1, loss = 1.967758331298828
Train: epoch: 1, loss = 1.9675589823722839
Train: epoch: 1, loss = 1.9680726443231107
Train: epoch: 1, loss = 1.9697190064191819
Train: epoch: 1, loss = 1.970594130853812
Train: epoch: 1, loss = 1.967743985567774
Train: epoch: 1, loss = 1.9705581212043761
Train: epoch: 1, loss = 1.9708248802026114
Train: epoch: 1, loss = 1.9715923891067504
Train: epoch: 1, loss = 1.972380836876956
Train: epoch: 1, loss = 1.9703789198895296
Train: epoch: 1, loss = 1.9719499047444418
Train: epoch: 1, loss = 1.9716075472320829
Train: epoch: 1, loss = 1.9719378550450006
Train: epoch: 1, loss = 1.9720179871097208
Train: epoch: 1, loss = 1.971550745999112
Train: epoch: 1, loss = 1.9713662765754594
Train: epoch: 1, loss = 1.9718339350035317
Train: epoch: 1, loss = 1.9712969351708889
Train: epoch: 1, loss = 1.9708674936635153
Train: epoch: 1, loss = 1.9702855742790482
Train: epoch: 1, loss = 1.9702471282689469
Train: epoch: 1, loss = 1.9701414150993029
Train: epoch: 1, loss = 1.9700447151184082
Train: epoch: 1, loss = 1.9696838763356208
Train: epoch: 1, loss = 1.9700168666353932
Train: epoch: 1, loss = 1.9698356474510261
Train: epoch: 1, loss = 1.9694362727321428
Train: epoch: 1, loss = 1.968725388467312
Train: epoch: 1, loss = 1.9687484432997242
Train: epoch: 1, loss = 1.9681819611229003
Train: epoch: 1, loss = 1.9677851500113805
Train: epoch: 1, loss = 1.9675004714902709
Train: epoch: 1, loss = 1.9672447442667824
Train: epoch: 1, loss = 1.966917614572578
Train: epoch: 1, loss = 1.9666503431184872
Train: epoch: 1, loss = 1.9659258283282581
Train: epoch: 1, loss = 1.9652321174664376
Train: epoch: 1, loss = 1.9650391052216292
Train: epoch: 1, loss = 1.9649509651341088
Train: epoch: 1, loss = 1.9642957673895927
Train: epoch: 1, loss = 1.9634704323147618
Train:  Epoch 1, Loss=1.9632203828675405, Cohen Kappa=0.09347427981460577, MAD=0.6857503325581141
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.073574732089865, Cohen Kappa=0.3307226494131281, MAD=0.7359407387054362
Eval task: 2
Eval:  Epoch 1, Loss=1.981765126359874, Cohen Kappa=0.08966492118385283, MAD=0.6599246143955361
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0741357967771332, Cohen Kappa=0.23916352053989887, MAD=0.7333372070996983
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9232079962204243, Cohen Kappa=0.1004976882095775, MAD=0.6654965867183942
{'0': {'precision': 0.4182058047493404, 'recall': 0.6223312883435583, 'f1-score': 0.5002465726402998, 'support': 4075}, '1': {'precision': 0.21888341543513956, 'recall': 0.4652705061082024, 'f1-score': 0.2977107761027359, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.07736389684813753, 'recall': 0.044407894736842105, 'f1-score': 0.05642633228840125, 'support': 1216}, '9': {'precision': 0.12781954887218044, 'recall': 0.23765144454799628, 'f1-score': 0.166232073011734, 'support': 1073}, 'accuracy': 0.28138469827586204, 'macro avg': {'precision': 0.08422726659047979, 'recall': 0.13696611337365988, 'f1-score': 0.10206157540431708, 'support': 14848}, 'weighted avg': {'precision': 0.17258314345921485, 'recall': 0.28138469827586204, 'f1-score': 0.21137039274298536, 'support': 14848}}
{'0': {'precision': 0.43381725021349277, 'recall': 0.3601985346253841, 'f1-score': 0.39359504132231404, 'support': 4231}, '1': {'precision': 0.3305084745762712, 'recall': 0.7209302325581395, 'f1-score': 0.4532333645735708, 'support': 5031}, '2': {'precision': 0.23809523809523808, 'recall': 0.006208609271523178, 'f1-score': 0.012101653892698669, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.1040268456375839, 'recall': 0.10130718954248366, 'f1-score': 0.10264900662251657, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3500134698275862, 'macro avg': {'precision': 0.1106447808522586, 'recall': 0.11886445659975305, 'f1-score': 0.09615790664111, 'support': 14848}, 'weighted avg': {'precision': 0.2764910581391234, 'recall': 0.3500134698275862, 'f1-score': 0.2698118176748111, 'support': 14848}}