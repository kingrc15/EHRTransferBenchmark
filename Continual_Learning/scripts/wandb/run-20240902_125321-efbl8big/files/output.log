
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_decomp_south_baseline
['/data/datasets/mimic3-benchmarks/data/decompensation', '/data/datasets/eICU2MIMIC/decompensation_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.14605843702331187
Train: epoch: 1, loss = 0.12358841469162143
Train: epoch: 1, loss = 0.11239816487378751
Train: epoch: 1, loss = 0.10632526503992266
Train: epoch: 1, loss = 0.10220860448200256
Train: epoch: 1, loss = 0.10000941682917376
Train: epoch: 1, loss = 0.09894145562795789
Train: epoch: 1, loss = 0.0969066241184919
Train: epoch: 1, loss = 0.09456059185910919
Train: epoch: 1, loss = 0.09275612560618901
Train: epoch: 1, loss = 0.09329595879688647
Train: epoch: 1, loss = 0.09163458749326917
Train: epoch: 1, loss = 0.08984837943307447
Train: epoch: 1, loss = 0.08867951264002061
Train: epoch: 1, loss = 0.08863994212180842
Train: epoch: 1, loss = 0.08842146784070792
Train: epoch: 1, loss = 0.08923444693254115
Train: epoch: 1, loss = 0.08834769717705462
Train: epoch: 1, loss = 0.08876598165459368
Train: epoch: 1, loss = 0.0884531662860827
Train: epoch: 1, loss = 0.08845301290727331
Train: epoch: 1, loss = 0.08858167226344284
Train: epoch: 1, loss = 0.08780322418707605
Train: epoch: 1, loss = 0.08691827505106631
Train: epoch: 1, loss = 0.08613304136411752
Train: epoch: 1, loss = 0.08575935941682054
Train: epoch: 1, loss = 0.08508200192709747
Train: epoch: 1, loss = 0.08513746702147598
Train: epoch: 1, loss = 0.08473618448131862
Train: epoch: 1, loss = 0.08405761810192296
Train: epoch: 1, loss = 0.08386514248880332
Train: epoch: 1, loss = 0.08405718765932761
Train: epoch: 1, loss = 0.08419736333401295
Train: epoch: 1, loss = 0.08389748780777583
Train: epoch: 1, loss = 0.08373445044665796
Train: epoch: 1, loss = 0.08382399172643394
Train: epoch: 1, loss = 0.0838711056127559
Train: epoch: 1, loss = 0.08387840380437218
Train: epoch: 1, loss = 0.08369571740555469
Train: epoch: 1, loss = 0.08340583143003459
Train: epoch: 1, loss = 0.08325510055898609
Train: epoch: 1, loss = 0.08296099401454696
Train: epoch: 1, loss = 0.08340956306876886
Train:  Epoch 1, Loss=0.083187018610098, AUC-ROC=0.8225644996215471, AUC-PR=0.15004817258279946
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.08627424954340376, AUC-ROC=0.8618950456959443, AUC-PR=0.22428331411295485
Eval task: 2
Eval:  Epoch 1, Loss=0.1743537382832889, AUC-ROC=0.6488051141692414, AUC-PR=0.08947863113123154
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.0887207503888178, AUC-ROC=0.8606103494029191, AUC-PR=0.222797321297103
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.14821919920886384, AUC-ROC=0.6860342338707823, AUC-PR=0.10237815629526989
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.13563435534480958
Train: epoch: 1, loss = 0.12385471493471414
Train: epoch: 1, loss = 0.12175691693400344
Train: epoch: 1, loss = 0.11953293597558513
Train: epoch: 1, loss = 0.11996839831210673
Train: epoch: 1, loss = 0.12209334678559874
Train: epoch: 1, loss = 0.11911064404861203
Train: epoch: 1, loss = 0.11943204155832063
Train: epoch: 1, loss = 0.1188965444603107
Train: epoch: 1, loss = 0.12023273809533566
Train: epoch: 1, loss = 0.12105103877542371
Train: epoch: 1, loss = 0.1205271333832449
Train: epoch: 1, loss = 0.1201329238490703
Train: epoch: 1, loss = 0.11896591103120174
Train: epoch: 1, loss = 0.11798357569255556
Train: epoch: 1, loss = 0.11691648121748585
Train: epoch: 1, loss = 0.11696031690027346
Train: epoch: 1, loss = 0.11664206375277394
Train: epoch: 1, loss = 0.11525368115668626
Train: epoch: 1, loss = 0.1152906947741285
Train: epoch: 1, loss = 0.11511057562793472
Train: epoch: 1, loss = 0.11447347514807585
Train: epoch: 1, loss = 0.11378805501578862
Train: epoch: 1, loss = 0.11364034978410928
Train: epoch: 1, loss = 0.11351660589454696
Train: epoch: 1, loss = 0.11334542812457164
Train: epoch: 1, loss = 0.1135855774911707
Train: epoch: 1, loss = 0.11292048354624837
Train: epoch: 1, loss = 0.11349577532655655
Train: epoch: 1, loss = 0.11385992489856046
Train: epoch: 1, loss = 0.11357284474006343
Train: epoch: 1, loss = 0.11412733492688858
Train: epoch: 1, loss = 0.11472927034888981
Train: epoch: 1, loss = 0.11459837952635579
Train: epoch: 1, loss = 0.11443759543681517
Train: epoch: 1, loss = 0.11359735070669558
Train: epoch: 1, loss = 0.113461119834384
Train: epoch: 1, loss = 0.1138979102354987
Train: epoch: 1, loss = 0.114080411482674
Train: epoch: 1, loss = 0.1143254710159963
Train: epoch: 1, loss = 0.11415898848097862
Train: epoch: 1, loss = 0.11413434214579563
Train: epoch: 1, loss = 0.11374941495079331
Train:  Epoch 1, Loss=0.11378723062516323, AUC-ROC=0.756566526045503, AUC-PR=0.14103711365412294
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.10919411570347588, AUC-ROC=0.8157543343428367, AUC-PR=0.14931717716922738
Eval task: 2
Eval:  Epoch 1, Loss=0.12923847350837855, AUC-ROC=0.7452213629676753, AUC-PR=0.1249071362190663
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.08306635198472388, AUC-ROC=0.870428587414674, AUC-PR=0.2893314351654714
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.10438889579783225, AUC-ROC=0.8346546979748912, AUC-PR=0.1946163122823077