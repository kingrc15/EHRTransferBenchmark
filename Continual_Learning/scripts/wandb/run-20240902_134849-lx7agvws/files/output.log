
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_decomp_midwest_baseline
['/data/datasets/mimic3-benchmarks/data/decompensation', '/data/datasets/eICU2MIMIC/decompensation_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.14122182384599
Train: epoch: 1, loss = 0.1248762561485637
Train: epoch: 1, loss = 0.10966395186493173
Train: epoch: 1, loss = 0.10380201711406699
Train: epoch: 1, loss = 0.09847471942775883
Train: epoch: 1, loss = 0.09702216228994075
Train: epoch: 1, loss = 0.09200213258745082
Train: epoch: 1, loss = 0.09091021616746729
Train: epoch: 1, loss = 0.08923823061651395
Train: epoch: 1, loss = 0.0910838946630829
Train: epoch: 1, loss = 0.08961870257250584
Train: epoch: 1, loss = 0.08762912569514204
Train: epoch: 1, loss = 0.08746840789838013
Train: epoch: 1, loss = 0.08931551523751945
Train: epoch: 1, loss = 0.09004484501942837
Train: epoch: 1, loss = 0.08801047414017375
Train: epoch: 1, loss = 0.08779741549385055
Train: epoch: 1, loss = 0.08746412967900849
Train: epoch: 1, loss = 0.08608703458491762
Train: epoch: 1, loss = 0.08552500184153905
Train: epoch: 1, loss = 0.08558338126040152
Train: epoch: 1, loss = 0.08490423026219518
Train: epoch: 1, loss = 0.0850346731709863
Train: epoch: 1, loss = 0.0846075727804661
Train: epoch: 1, loss = 0.08396146025396883
Train: epoch: 1, loss = 0.08429682309685561
Train: epoch: 1, loss = 0.08437788674819145
Train: epoch: 1, loss = 0.08410853358746473
Train: epoch: 1, loss = 0.08394297869586996
Train: epoch: 1, loss = 0.08384521642432083
Train: epoch: 1, loss = 0.08396386097113963
Train: epoch: 1, loss = 0.08320271474147375
Train: epoch: 1, loss = 0.08287375780792597
Train: epoch: 1, loss = 0.08317193312810131
Train: epoch: 1, loss = 0.08272805132056653
Train: epoch: 1, loss = 0.08285232212157603
Train: epoch: 1, loss = 0.08304082817652081
Train: epoch: 1, loss = 0.08315677055365277
Train: epoch: 1, loss = 0.08307507530874901
Train: epoch: 1, loss = 0.08320164195761753
Train: epoch: 1, loss = 0.08310234956612964
Train: epoch: 1, loss = 0.0825813647006691
Train: epoch: 1, loss = 0.08268378150369837
Train:  Epoch 1, Loss=0.08230424986010018, AUC-ROC=0.8253115043523025, AUC-PR=0.16662530881690596
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.08880116784110151, AUC-ROC=0.8685206446062449, AUC-PR=0.22069789442493437
Eval task: 2
Eval:  Epoch 1, Loss=0.13924112485657478, AUC-ROC=0.6299278756542693, AUC-PR=0.05221723422661257
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.0904843942021373, AUC-ROC=0.8928179769054103, AUC-PR=0.2547936615576738
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.13001081944796547, AUC-ROC=0.6046961950059453, AUC-PR=0.04132779673411621
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.1483979928540066
Train: epoch: 1, loss = 0.1351396338851191
Train: epoch: 1, loss = 0.13229944567661733
Train: epoch: 1, loss = 0.1331846262025647
Train: epoch: 1, loss = 0.13096303805429488
Train: epoch: 1, loss = 0.12747017643026387
Train: epoch: 1, loss = 0.12444406411477497
Train: epoch: 1, loss = 0.12274132929043845
Train: epoch: 1, loss = 0.12175185312620468
Train: epoch: 1, loss = 0.12081729366723448
Train: epoch: 1, loss = 0.12008565607480705
Train: epoch: 1, loss = 0.11840745403858212
Train: epoch: 1, loss = 0.11940038230628348
Train: epoch: 1, loss = 0.120368759737217
Train: epoch: 1, loss = 0.11918840535761167
Train: epoch: 1, loss = 0.11880213271186221
Train: epoch: 1, loss = 0.1184819122343598
Train: epoch: 1, loss = 0.11811091506310428
Train: epoch: 1, loss = 0.11803052294656242
Train: epoch: 1, loss = 0.11691360810655169
Train: epoch: 1, loss = 0.11651172948180742
Train: epoch: 1, loss = 0.11612321860029955
Train: epoch: 1, loss = 0.11584480388494937
Train: epoch: 1, loss = 0.116241682121763
Train: epoch: 1, loss = 0.11575537586417049
Train: epoch: 1, loss = 0.11491782943010688
Train: epoch: 1, loss = 0.1140351106392875
Train: epoch: 1, loss = 0.11444186320403657
Train: epoch: 1, loss = 0.11399996730185852
Train: epoch: 1, loss = 0.11380121099196064
Train: epoch: 1, loss = 0.11255735849293189
Train: epoch: 1, loss = 0.11281057597792823
Train: epoch: 1, loss = 0.11248084991083791
Train: epoch: 1, loss = 0.1118415867752286
Train: epoch: 1, loss = 0.11192647038619699
Train: epoch: 1, loss = 0.11180622839957424
Train: epoch: 1, loss = 0.11163864797591609
Train: epoch: 1, loss = 0.11172034337742891
Train: epoch: 1, loss = 0.11121416685219185
Train: epoch: 1, loss = 0.11105005140358117
Train: epoch: 1, loss = 0.11128721281579446
Train: epoch: 1, loss = 0.11105207388571996
Train: epoch: 1, loss = 0.11109172803181938
Train:  Epoch 1, Loss=0.11106296435291213, AUC-ROC=0.6624046727933842, AUC-PR=0.08375766435905443
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.11636747471217451, AUC-ROC=0.7639901411946747, AUC-PR=0.09940104817465166
Eval task: 2
Eval:  Epoch 1, Loss=0.1124071015109276, AUC-ROC=0.6915504345629361, AUC-PR=0.11406092168860155
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.09215815397429056, AUC-ROC=0.840457095964575, AUC-PR=0.232740678375126
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.10479599918270933, AUC-ROC=0.7259024970273484, AUC-PR=0.10651579203558582