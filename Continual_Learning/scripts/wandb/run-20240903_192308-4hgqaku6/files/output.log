Experiment dir: ./exp/Test_phen_west
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.428889572173357
Train: epoch: 1, loss = 0.4194359465688467
Train: epoch: 1, loss = 0.41385202507177987
Train: epoch: 1, loss = 0.41095893386751414
Train: epoch: 1, loss = 0.40992713192105296
Train: epoch: 1, loss = 0.40778750598430635
Train: epoch: 1, loss = 0.4047209746922765
Train: epoch: 1, loss = 0.40348116893321273
Train: epoch: 1, loss = 0.4008815964559714
Train: epoch: 1, loss = 0.39905854226648807
Train: epoch: 1, loss = 0.39783893573690543
Train: epoch: 1, loss = 0.39657373188063505
Train: epoch: 1, loss = 0.39552260817816626
Train: epoch: 1, loss = 0.39415771801024674
Train: epoch: 1, loss = 0.39335878178477285
Train: epoch: 1, loss = 0.3923102311324328
Train: epoch: 1, loss = 0.39150795521105036
Train: epoch: 1, loss = 0.3905931724442376
Train:  Epoch 1, Loss=0.39021425958168815, AUC-ROC Macro=0.6639548223613483, AUC-ROC Micro=0.7526392408768013
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.36934538433949154, AUC-ROC Macro=0.7230102277403714, AUC-ROC Micro=0.7862964956137827
Eval task: 2
Eval:  Epoch 1, Loss=0.3629571944475174, AUC-ROC Macro=0.49968581719223565, AUC-ROC Micro=0.5565808080888517
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.3738218206167221
Train: epoch: 2, loss = 0.37127021662890913
Train: epoch: 2, loss = 0.36987993272642294
Train: epoch: 2, loss = 0.3708940416574478
Train: epoch: 2, loss = 0.3710695933997631
Train: epoch: 2, loss = 0.3703433056920767
Train: epoch: 2, loss = 0.37036642631249767
Train: epoch: 2, loss = 0.3696647168044001
Train: epoch: 2, loss = 0.36951371466947924
Train: epoch: 2, loss = 0.36962545328587293
Train: epoch: 2, loss = 0.36894365681165997
Train: epoch: 2, loss = 0.36903396134575206
Train: epoch: 2, loss = 0.3687756743454016
Train: epoch: 2, loss = 0.36851876734622885
Train: epoch: 2, loss = 0.36865961746871473
Train: epoch: 2, loss = 0.3682176328683272
Train: epoch: 2, loss = 0.368267247882836
Train: epoch: 2, loss = 0.3681084153635634
Train:  Epoch 2, Loss=0.3678734383929489, AUC-ROC Macro=0.7259456020387864, AUC-ROC Micro=0.7922438423232875
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.36024460941553116, AUC-ROC Macro=0.740574911587266, AUC-ROC Micro=0.8004079164452496
Eval task: 2
Eval:  Epoch 2, Loss=0.3551480546593666, AUC-ROC Macro=0.4851137174400249, AUC-ROC Micro=0.5304523541431423
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3532372485101223
Train: epoch: 3, loss = 0.3576438559964299
Train: epoch: 3, loss = 0.35917026256521545
Train: epoch: 3, loss = 0.36008657751604917
Train: epoch: 3, loss = 0.36031141762435437
Train: epoch: 3, loss = 0.3593872378021479
Train: epoch: 3, loss = 0.35976228636290347
Train: epoch: 3, loss = 0.35964813562110065
Train: epoch: 3, loss = 0.3599883521762159
Train: epoch: 3, loss = 0.35974407839775085
Train: epoch: 3, loss = 0.36010791374201123
Train: epoch: 3, loss = 0.3600879758285979
Train: epoch: 3, loss = 0.3599528117592518
Train: epoch: 3, loss = 0.36018302047891276
Train: epoch: 3, loss = 0.3600806453178326
Train: epoch: 3, loss = 0.3600669024931267
Train: epoch: 3, loss = 0.35981152456472904
Train: epoch: 3, loss = 0.3600849737309747
Train:  Epoch 3, Loss=0.3598882956912375, AUC-ROC Macro=0.7443208284630839, AUC-ROC Micro=0.8044914191281685
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3583558698495229, AUC-ROC Macro=0.7475893954853916, AUC-ROC Micro=0.8045054357567347
Eval task: 2
Eval:  Epoch 3, Loss=0.37415318191051483, AUC-ROC Macro=0.48280755891896604, AUC-ROC Micro=0.5087237899875722
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.35394767113029957
Train: epoch: 4, loss = 0.35086720243096353
Train: epoch: 4, loss = 0.3504653105388085
Train: epoch: 4, loss = 0.35119812248274684
Train: epoch: 4, loss = 0.35144062256813047
Train: epoch: 4, loss = 0.3531003948425253
Train: epoch: 4, loss = 0.35261610412171907
Train: epoch: 4, loss = 0.3530799894873053
Train: epoch: 4, loss = 0.35297037032743295
Train: epoch: 4, loss = 0.35359882766753437
Train: epoch: 4, loss = 0.3537869730117646
Train: epoch: 4, loss = 0.35371583005413415
Train: epoch: 4, loss = 0.35432389434713585
Train: epoch: 4, loss = 0.3541112123110465
Train: epoch: 4, loss = 0.35403226992984616
Train: epoch: 4, loss = 0.35424190235789865
Train: epoch: 4, loss = 0.35410566505263835
Train: epoch: 4, loss = 0.35416113231745033
Train:  Epoch 4, Loss=0.3541247114768395, AUC-ROC Macro=0.7563550194140279, AUC-ROC Micro=0.8129863767048643
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3532407730817795, AUC-ROC Macro=0.7582998651737608, AUC-ROC Micro=0.8128865584318355
Eval task: 2
Eval:  Epoch 4, Loss=0.3924061059951782, AUC-ROC Macro=0.4798816457994823, AUC-ROC Micro=0.5282091375441357
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.3480924364179373
Train: epoch: 5, loss = 0.3487092808261514
Train: epoch: 5, loss = 0.34873273034890495
Train: epoch: 5, loss = 0.3492394109256566
Train: epoch: 5, loss = 0.34957625925540925
Train: epoch: 5, loss = 0.3499300252397855
Train: epoch: 5, loss = 0.34993779157953603
Train: epoch: 5, loss = 0.35002370804548266
Train: epoch: 5, loss = 0.35035902866058877
Train: epoch: 5, loss = 0.35075907123088834
Train: epoch: 5, loss = 0.3508737528865988
Train: epoch: 5, loss = 0.35056722357869147
Train: epoch: 5, loss = 0.35029540287760585
Train: epoch: 5, loss = 0.350649556789015
Train: epoch: 5, loss = 0.3502115117361148
Train: epoch: 5, loss = 0.3503175038145855
Train: epoch: 5, loss = 0.35030605176792423
Train: epoch: 5, loss = 0.3501824445277453
Train:  Epoch 5, Loss=0.34991003087341277, AUC-ROC Macro=0.7651390996881746, AUC-ROC Micro=0.8188903616846801
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3515990922848384, AUC-ROC Macro=0.7610761292685965, AUC-ROC Micro=0.8138163090473253
Eval task: 2
Eval:  Epoch 5, Loss=0.3934735134243965, AUC-ROC Macro=0.4771234373375918, AUC-ROC Micro=0.5195759787097484
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3432935028523207
Train: epoch: 6, loss = 0.34092109195888043
Train: epoch: 6, loss = 0.3439686529090007
Train: epoch: 6, loss = 0.34459747944027186
Train: epoch: 6, loss = 0.3439494199156761
Train: epoch: 6, loss = 0.3443001342192292
Train: epoch: 6, loss = 0.3437227346322366
Train: epoch: 6, loss = 0.34447549835778773
Train: epoch: 6, loss = 0.34505889491074615
Train: epoch: 6, loss = 0.3445610789358616
Train: epoch: 6, loss = 0.34492438466034153
Train: epoch: 6, loss = 0.34533212102328736
Train: epoch: 6, loss = 0.3454327909075297
Train: epoch: 6, loss = 0.34557302358427217
Train: epoch: 6, loss = 0.34635881321628886
Train: epoch: 6, loss = 0.3468138649314642
Train: epoch: 6, loss = 0.3469269830996499
Train: epoch: 6, loss = 0.3467337007655038
Train:  Epoch 6, Loss=0.34678122601753625, AUC-ROC Macro=0.771832338557488, AUC-ROC Micro=0.8231557021145514
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.35006582736968994, AUC-ROC Macro=0.7636922950086913, AUC-ROC Micro=0.8155702340595083
Eval task: 2
Eval:  Epoch 6, Loss=0.40322766453027725, AUC-ROC Macro=0.4852921604285718, AUC-ROC Micro=0.5310368486350381
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.35174720734357834, AUC-ROC Macro=0.7651262515084822, AUC-ROC Micro=0.8158267407714875
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.4042556807398796, AUC-ROC Macro=0.5025165734121686, AUC-ROC Micro=0.5326176466364272
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.318769401088357
Train: epoch: 1, loss = 0.30910278972238303
Train: epoch: 1, loss = 0.29526975433031716
Train:  Epoch 1, Loss=0.28801303225500785, AUC-ROC Macro=0.5305990182701525, AUC-ROC Micro=0.7174365420873176
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3557994489868482, AUC-ROC Macro=0.7512498350089303, AUC-ROC Micro=0.8067706537867618
Eval task: 2
Eval:  Epoch 1, Loss=0.28764890134334564, AUC-ROC Macro=0.6011038656324097, AUC-ROC Micro=0.7752685038162023
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.2892620878666639
Train: epoch: 2, loss = 0.28856509521603585
Train: epoch: 2, loss = 0.27811656254033246
Train:  Epoch 2, Loss=0.27202959783354924, AUC-ROC Macro=0.6337514405143186, AUC-ROC Micro=0.7906268174246784
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.349491694321235, AUC-ROC Macro=0.7560641983007145, AUC-ROC Micro=0.8109517761389303
Eval task: 2
Eval:  Epoch 2, Loss=0.2811332195997238, AUC-ROC Macro=0.6462047640186168, AUC-ROC Micro=0.7962131976838942
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.28069947339594364
Train: epoch: 3, loss = 0.2820780558884144
Train: epoch: 3, loss = 0.27205158000191054
Train:  Epoch 3, Loss=0.26646069856640203, AUC-ROC Macro=0.6727658205837949, AUC-ROC Micro=0.8069424666744691
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3504954253633817, AUC-ROC Macro=0.7510898309577578, AUC-ROC Micro=0.806466201803094
Eval task: 2
Eval:  Epoch 3, Loss=0.2785927280783653, AUC-ROC Macro=0.6634477028629487, AUC-ROC Micro=0.8016601767073902
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.27738257266581057
Train: epoch: 4, loss = 0.2778638795390725
Train: epoch: 4, loss = 0.2678810326009989
Train:  Epoch 4, Loss=0.26159852902329545, AUC-ROC Macro=0.7011163195328539, AUC-ROC Micro=0.8183964407899555
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.34800663342078525, AUC-ROC Macro=0.7504779472186663, AUC-ROC Micro=0.8065967139995367
Eval task: 2
Eval:  Epoch 4, Loss=0.27320466190576553, AUC-ROC Macro=0.6838565205856417, AUC-ROC Micro=0.8083648753317311
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.27187353029847144
Train: epoch: 5, loss = 0.2744009879603982
Train: epoch: 5, loss = 0.26334861723085246
Train:  Epoch 5, Loss=0.25788348224132684, AUC-ROC Macro=0.7220360357871379, AUC-ROC Micro=0.8269795588812154
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3467349161704381, AUC-ROC Macro=0.7535917197943511, AUC-ROC Micro=0.8078824010421486
Eval task: 2
Eval:  Epoch 5, Loss=0.2729298695921898, AUC-ROC Macro=0.697469031608183, AUC-ROC Micro=0.8130905318793702
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.269057746604085
Train: epoch: 6, loss = 0.26959825925529
Train: epoch: 6, loss = 0.2601640122880538
Train:  Epoch 6, Loss=0.254754545010145, AUC-ROC Macro=0.7451548831866606, AUC-ROC Micro=0.8347582771008024
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3452775093416373, AUC-ROC Macro=0.749224241196153, AUC-ROC Micro=0.8047797619351474
Eval task: 2
Eval:  Epoch 6, Loss=0.26778268069028854, AUC-ROC Macro=0.6992947411243965, AUC-ROC Micro=0.8142889738644428
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.36332371706763905, AUC-ROC Macro=0.7485916463793181, AUC-ROC Micro=0.8039625506849475
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.221811193972826, AUC-ROC Macro=0.7153906670697726, AUC-ROC Micro=0.8138431540491168
{'0': {'precision': 0.566420664206642, 'recall': 0.23470948012232415, 'f1-score': 0.3318918918918919, 'support': 1308}, '1': {'precision': 0.6557377049180327, 'recall': 0.39800995024875624, 'f1-score': 0.49535603715170273, 'support': 402}, '2': {'precision': 0.6551724137931034, 'recall': 0.057750759878419454, 'f1-score': 0.10614525139664804, 'support': 658}, '3': {'precision': 0.5161023947151114, 'recall': 0.314070351758794, 'f1-score': 0.39050296782255545, 'support': 1990}, '4': {'precision': 0.5982142857142857, 'recall': 0.08312655086848635, 'f1-score': 0.1459694989106754, 'support': 806}, '5': {'precision': 0.37142857142857144, 'recall': 0.016709511568123392, 'f1-score': 0.03198031980319803, 'support': 778}, '6': {'precision': 0.5991902834008097, 'recall': 0.11367127496159754, 'f1-score': 0.19109102646868945, 'support': 1302}, '7': {'precision': 0.18181818181818182, 'recall': 0.0047169811320754715, 'f1-score': 0.009195402298850575, 'support': 424}, '8': {'precision': 0.5571245186136072, 'recall': 0.2639902676399027, 'f1-score': 0.3582335947172926, 'support': 1644}, '9': {'precision': 0.6819571865443425, 'recall': 0.43919251600196946, 'f1-score': 0.5342917041030247, 'support': 2031}, '10': {'precision': 0.6548042704626335, 'recall': 0.32111692844677137, 'f1-score': 0.43091334894613587, 'support': 573}, '11': {'precision': 0.5070707070707071, 'recall': 0.21343537414965985, 'f1-score': 0.3004189108318372, 'support': 1176}, '12': {'precision': 0.5939675174013921, 'recall': 0.28926553672316385, 'f1-score': 0.3890577507598784, 'support': 1770}, '13': {'precision': 0.5815450643776824, 'recall': 0.41756548536209553, 'f1-score': 0.4860986547085202, 'support': 2596}, '14': {'precision': 0.5483425414364641, 'recall': 0.24400737553779964, 'f1-score': 0.3377286261165462, 'support': 1627}, '15': {'precision': 0.2, 'recall': 0.004132231404958678, 'f1-score': 0.008097165991902836, 'support': 484}, '16': {'precision': 0.4797687861271676, 'recall': 0.10440251572327044, 'f1-score': 0.17148760330578514, 'support': 795}, '17': {'precision': 0.5925925925925926, 'recall': 0.029411764705882353, 'f1-score': 0.056042031523642725, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.45, 'recall': 0.06870229007633588, 'f1-score': 0.11920529801324505, 'support': 262}, '20': {'precision': 0.5, 'recall': 0.0017761989342806395, 'f1-score': 0.003539823008849558, 'support': 563}, '21': {'precision': 0.5138339920948617, 'recall': 0.15531660692951016, 'f1-score': 0.23853211009174313, 'support': 837}, '22': {'precision': 0.69693094629156, 'recall': 0.501841620626151, 'f1-score': 0.5835117773019273, 'support': 1086}, '23': {'precision': 0.63671875, 'recall': 0.18931475029036005, 'f1-score': 0.2918531781557744, 'support': 861}, '24': {'precision': 0.5767195767195767, 'recall': 0.21584158415841584, 'f1-score': 0.31412103746397696, 'support': 505}, 'micro avg': {'precision': 0.5883864826273203, 'recall': 0.24360540732274466, 'f1-score': 0.3445565527621384, 'support': 25373}, 'macro avg': {'precision': 0.516618437989093, 'recall': 0.1872831162899642, 'f1-score': 0.25301060043137175, 'support': 25373}, 'weighted avg': {'precision': 0.5534640841071096, 'recall': 0.24360540732274466, 'f1-score': 0.319117410949934, 'support': 25373}, 'samples avg': {'precision': 0.3561028123894334, 'recall': 0.21574075336066953, 'f1-score': 0.24621593158072316, 'support': 25373}}
{'0': {'precision': 0.5641025641025641, 'recall': 0.336734693877551, 'f1-score': 0.4217252396166134, 'support': 196}, '1': {'precision': 0.5217391304347826, 'recall': 0.24896265560165975, 'f1-score': 0.33707865168539325, 'support': 241}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 145}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 118}, '4': {'precision': 0.5, 'recall': 0.04326923076923077, 'f1-score': 0.07964601769911504, 'support': 208}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 100}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '7': {'precision': 0.8076923076923077, 'recall': 0.15789473684210525, 'f1-score': 0.26415094339622636, 'support': 133}, '8': {'precision': 1.0, 'recall': 0.011235955056179775, 'f1-score': 0.02222222222222222, 'support': 89}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '11': {'precision': 0.25, 'recall': 0.011627906976744186, 'f1-score': 0.02222222222222222, 'support': 86}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87}, '13': {'precision': 0.3888888888888889, 'recall': 0.0958904109589041, 'f1-score': 0.15384615384615383, 'support': 73}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 45}, '15': {'precision': 0.7659574468085106, 'recall': 0.7058823529411765, 'f1-score': 0.7346938775510204, 'support': 51}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'micro avg': {'precision': 0.5694050991501416, 'recall': 0.10080240722166499, 'f1-score': 0.17128248828291434, 'support': 1994}, 'macro avg': {'precision': 0.19193521351708212, 'recall': 0.06445991772094205, 'f1-score': 0.08142341312955867, 'support': 1994}, 'weighted avg': {'precision': 0.31378085686965146, 'recall': 0.10080240722166499, 'f1-score': 0.13449428036555175, 'support': 1994}, 'samples avg': {'precision': 0.179931640625, 'recall': 0.11950102306547618, 'f1-score': 0.134184337797619, 'support': 1994}}