
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_northeast
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.43427039325237277
Train: epoch: 1, loss = 0.4232911735028029
Train: epoch: 1, loss = 0.4176100353896618
Train: epoch: 1, loss = 0.4153099446371198
Train: epoch: 1, loss = 0.4124662227928638
Train: epoch: 1, loss = 0.41032654111584027
Train: epoch: 1, loss = 0.40879858561924526
Train: epoch: 1, loss = 0.4069123930297792
Train: epoch: 1, loss = 0.40478350602090357
Train: epoch: 1, loss = 0.40345524928718807
Train: epoch: 1, loss = 0.4012339862368324
Train: epoch: 1, loss = 0.39945682415738704
Train: epoch: 1, loss = 0.398424912496255
Train: epoch: 1, loss = 0.3974858345038125
Train: epoch: 1, loss = 0.39626383746167027
Train: epoch: 1, loss = 0.39496298810932784
Train: epoch: 1, loss = 0.3940668963816236
Train: epoch: 1, loss = 0.3926879113043348
Train:  Epoch 1, Loss=0.3923334733013414, AUC-ROC Macro=0.6577704378198207, AUC-ROC Micro=0.7484486689750319
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.37098024785518646, AUC-ROC Macro=0.7188904441429494, AUC-ROC Micro=0.7835305964392941
Eval task: 2
Eval:  Epoch 1, Loss=0.41710153222084045, AUC-ROC Macro=0.4875124078699705, AUC-ROC Micro=0.5812889774533763
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.37517462857067585
Train: epoch: 2, loss = 0.3745061941817403
Train: epoch: 2, loss = 0.3746450181802114
Train: epoch: 2, loss = 0.37442647878080604
Train: epoch: 2, loss = 0.3732233650535345
Train: epoch: 2, loss = 0.3720498825982213
Train: epoch: 2, loss = 0.37100799919239114
Train: epoch: 2, loss = 0.37062080974690614
Train: epoch: 2, loss = 0.37001386663152114
Train: epoch: 2, loss = 0.3696459573507309
Train: epoch: 2, loss = 0.3686559259010987
Train: epoch: 2, loss = 0.3680198726989329
Train: epoch: 2, loss = 0.3679895568581728
Train: epoch: 2, loss = 0.36788277257766044
Train: epoch: 2, loss = 0.36767423860728743
Train: epoch: 2, loss = 0.36760016922838984
Train: epoch: 2, loss = 0.3675968276183395
Train: epoch: 2, loss = 0.3675553397130635
Train:  Epoch 2, Loss=0.3676380638526036, AUC-ROC Macro=0.7270122952172994, AUC-ROC Micro=0.792573129862904
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.360708383222421, AUC-ROC Macro=0.7417754362287053, AUC-ROC Micro=0.7998358227823714
Eval task: 2
Eval:  Epoch 2, Loss=0.41045787930488586, AUC-ROC Macro=0.4890076430867976, AUC-ROC Micro=0.5898839209935156
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3660045345127583
Train: epoch: 3, loss = 0.3618004989251494
Train: epoch: 3, loss = 0.36143195174634457
Train: epoch: 3, loss = 0.3620055282488465
Train: epoch: 3, loss = 0.36011141568422317
Train: epoch: 3, loss = 0.35966952635596194
Train: epoch: 3, loss = 0.35964881687292033
Train: epoch: 3, loss = 0.3586654459964484
Train: epoch: 3, loss = 0.3589965538928906
Train: epoch: 3, loss = 0.3594585130363703
Train: epoch: 3, loss = 0.3599793339046565
Train: epoch: 3, loss = 0.36033136025692025
Train: epoch: 3, loss = 0.3601821998850657
Train: epoch: 3, loss = 0.36020435503018755
Train: epoch: 3, loss = 0.36012791221340495
Train: epoch: 3, loss = 0.35983721187338236
Train: epoch: 3, loss = 0.3595130977604319
Train: epoch: 3, loss = 0.35906201356401046
Train:  Epoch 3, Loss=0.35885608232938326, AUC-ROC Macro=0.7464904869828919, AUC-ROC Micro=0.8060226332523914
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3549008332192898, AUC-ROC Macro=0.7530529903786722, AUC-ROC Micro=0.8089631186110163
Eval task: 2
Eval:  Epoch 3, Loss=0.41897159814834595, AUC-ROC Macro=0.4896402619048501, AUC-ROC Micro=0.5915888195313272
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.3585674921423197
Train: epoch: 4, loss = 0.35620007053017616
Train: epoch: 4, loss = 0.35758672915399076
Train: epoch: 4, loss = 0.35655452830716966
Train: epoch: 4, loss = 0.35465494374930856
Train: epoch: 4, loss = 0.3560280658180515
Train: epoch: 4, loss = 0.35656327392373766
Train: epoch: 4, loss = 0.35624194382689894
Train: epoch: 4, loss = 0.35619110270506804
Train: epoch: 4, loss = 0.3562074479907751
Train: epoch: 4, loss = 0.35575269839980384
Train: epoch: 4, loss = 0.35531440828616423
Train: epoch: 4, loss = 0.3553916552892098
Train: epoch: 4, loss = 0.3552369393727609
Train: epoch: 4, loss = 0.3547350283662478
Train: epoch: 4, loss = 0.3541926988726482
Train: epoch: 4, loss = 0.3540419567376375
Train: epoch: 4, loss = 0.3539355329465535
Train:  Epoch 4, Loss=0.3539723926283355, AUC-ROC Macro=0.7573648007823724, AUC-ROC Micro=0.8132164873337545
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3536439885695775, AUC-ROC Macro=0.7569612498629366, AUC-ROC Micro=0.8109498095801585
Eval task: 2
Eval:  Epoch 4, Loss=0.44492581486701965, AUC-ROC Macro=0.4868394894755496, AUC-ROC Micro=0.580310141709008
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.3534078449755907
Train: epoch: 5, loss = 0.3483658265322447
Train: epoch: 5, loss = 0.3488946142544349
Train: epoch: 5, loss = 0.34958150768652557
Train: epoch: 5, loss = 0.3505386057347059
Train: epoch: 5, loss = 0.35180411516378324
Train: epoch: 5, loss = 0.3502190040158374
Train: epoch: 5, loss = 0.3504720044974238
Train: epoch: 5, loss = 0.3508621868491173
Train: epoch: 5, loss = 0.35015927912294864
Train: epoch: 5, loss = 0.350360784991221
Train: epoch: 5, loss = 0.3505987341205279
Train: epoch: 5, loss = 0.3501396034543331
Train: epoch: 5, loss = 0.3502994933032564
Train: epoch: 5, loss = 0.3503730387588342
Train: epoch: 5, loss = 0.34996829434297977
Train: epoch: 5, loss = 0.3499830900395618
Train: epoch: 5, loss = 0.3499890289745397
Train:  Epoch 5, Loss=0.3498158792960338, AUC-ROC Macro=0.765800943219669, AUC-ROC Micro=0.8190536206665106
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3528614242871602, AUC-ROC Macro=0.7601357508047293, AUC-ROC Micro=0.8117887663084019
Eval task: 2
Eval:  Epoch 5, Loss=0.45031021535396576, AUC-ROC Macro=0.48657453861176164, AUC-ROC Micro=0.5778624795769404
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.33994901061058047
Train: epoch: 6, loss = 0.3386627823859453
Train: epoch: 6, loss = 0.3420630639046431
Train: epoch: 6, loss = 0.3451922640018165
Train: epoch: 6, loss = 0.3457952141314745
Train: epoch: 6, loss = 0.3465385594839851
Train: epoch: 6, loss = 0.346535431476576
Train: epoch: 6, loss = 0.3464648267813027
Train: epoch: 6, loss = 0.3466007397323847
Train: epoch: 6, loss = 0.34593375311791896
Train: epoch: 6, loss = 0.34582304905761374
Train: epoch: 6, loss = 0.3461987763270736
Train: epoch: 6, loss = 0.3466438421721642
Train: epoch: 6, loss = 0.3468636351344841
Train: epoch: 6, loss = 0.3469932173291842
Train: epoch: 6, loss = 0.3471148833492771
Train: epoch: 6, loss = 0.346682469932472
Train: epoch: 6, loss = 0.3463226595024268
Train:  Epoch 6, Loss=0.3464790010584725, AUC-ROC Macro=0.7728840572249512, AUC-ROC Micro=0.8237305097329058
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.34861525148153305, AUC-ROC Macro=0.765562498400984, AUC-ROC Micro=0.8177106115423476
Eval task: 2
Eval:  Epoch 6, Loss=0.45574162900447845, AUC-ROC Macro=0.47470792844601944, AUC-ROC Micro=0.5638168950727271
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3513341148694356, AUC-ROC Macro=0.7658981489881396, AUC-ROC Micro=0.8168562867129464
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.4679257273674011, AUC-ROC Macro=0.4750530526357021, AUC-ROC Micro=0.5729956465834233
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.3492227092385292
Train:  Epoch 1, Loss=0.33903744359561755, AUC-ROC Macro=0.5546781809834591, AUC-ROC Micro=0.7247276242429568
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.35241004452109337, AUC-ROC Macro=0.7599183356176309, AUC-ROC Micro=0.8132515869141275
Eval task: 2
Eval:  Epoch 1, Loss=0.2904033958911896, AUC-ROC Macro=0.6297203674755076, AUC-ROC Micro=0.7793209237339541
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.318572413995862
Train:  Epoch 2, Loss=0.3172744406150807, AUC-ROC Macro=0.6604543477453375, AUC-ROC Micro=0.801380576860141
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.34745872020721436, AUC-ROC Macro=0.7589495454477351, AUC-ROC Micro=0.8121293592618188
Eval task: 2
Eval:  Epoch 2, Loss=0.28418056666851044, AUC-ROC Macro=0.6826168510940824, AUC-ROC Micro=0.8031415412162198
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.3115489090234041
Train:  Epoch 3, Loss=0.3091488518392358, AUC-ROC Macro=0.7067642819508586, AUC-ROC Micro=0.8233953585649336
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3453797586262226, AUC-ROC Macro=0.7575221886004, AUC-ROC Micro=0.8111211802211026
Eval task: 2
Eval:  Epoch 3, Loss=0.2781226634979248, AUC-ROC Macro=0.7007646179354277, AUC-ROC Micro=0.8178169931070308
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.3036971930414438
Train:  Epoch 4, Loss=0.3023026665799954, AUC-ROC Macro=0.7344572997416491, AUC-ROC Micro=0.8366197398616287
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3438005670905113, AUC-ROC Macro=0.7551091917057421, AUC-ROC Micro=0.8092706732528843
Eval task: 2
Eval:  Epoch 4, Loss=0.2778082937002182, AUC-ROC Macro=0.7115590422905206, AUC-ROC Micro=0.8209595773696552
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.2989087375998497
Train:  Epoch 5, Loss=0.2972090620043554, AUC-ROC Macro=0.7503699266763938, AUC-ROC Micro=0.844519129772655
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3434199181695779, AUC-ROC Macro=0.7528655668113848, AUC-ROC Micro=0.8075409436348836
Eval task: 2
Eval:  Epoch 5, Loss=0.275187149643898, AUC-ROC Macro=0.700106127218641, AUC-ROC Micro=0.8199902375679872
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.2947509974241257
Train:  Epoch 6, Loss=0.292752867795766, AUC-ROC Macro=0.76985487775585, AUC-ROC Micro=0.8520004176301391
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3410041369497776, AUC-ROC Macro=0.7508936654421445, AUC-ROC Micro=0.8056185963452669
Eval task: 2
Eval:  Epoch 6, Loss=0.2735148221254349, AUC-ROC Macro=0.7098060795324398, AUC-ROC Micro=0.8260439764039993
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.36261556421717006, AUC-ROC Macro=0.7514577136175012, AUC-ROC Micro=0.8063899422906169
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.2920052707195282, AUC-ROC Macro=0.6969874370297826, AUC-ROC Micro=0.81671921540415
{'0': {'precision': 0.5317545748116254, 'recall': 0.37767584097859325, 'f1-score': 0.4416629414394277, 'support': 1308}, '1': {'precision': 0.6083916083916084, 'recall': 0.43283582089552236, 'f1-score': 0.5058139534883721, 'support': 402}, '2': {'precision': 0.6, 'recall': 0.0729483282674772, 'f1-score': 0.13008130081300812, 'support': 658}, '3': {'precision': 0.5281615302869288, 'recall': 0.24974874371859296, 'f1-score': 0.3391334015694303, 'support': 1990}, '4': {'precision': 0.44256756756756754, 'recall': 0.16253101736972705, 'f1-score': 0.2377495462794918, 'support': 806}, '5': {'precision': 0.2222222222222222, 'recall': 0.010282776349614395, 'f1-score': 0.019656019656019656, 'support': 778}, '6': {'precision': 0.5766423357664233, 'recall': 0.12135176651305683, 'f1-score': 0.200507614213198, 'support': 1302}, '7': {'precision': 0.1, 'recall': 0.0023584905660377358, 'f1-score': 0.004608294930875576, 'support': 424}, '8': {'precision': 0.5376884422110553, 'recall': 0.3905109489051095, 'f1-score': 0.452431289640592, 'support': 1644}, '9': {'precision': 0.6403454657618753, 'recall': 0.5110782865583456, 'f1-score': 0.5684556407447973, 'support': 2031}, '10': {'precision': 0.6353790613718412, 'recall': 0.30715532286212915, 'f1-score': 0.41411764705882353, 'support': 573}, '11': {'precision': 0.5108359133126935, 'recall': 0.28061224489795916, 'f1-score': 0.3622392974753018, 'support': 1176}, '12': {'precision': 0.5637362637362637, 'recall': 0.28983050847457625, 'f1-score': 0.38283582089552237, 'support': 1770}, '13': {'precision': 0.5947399880454274, 'recall': 0.3832819722650231, 'f1-score': 0.46615132349496363, 'support': 2596}, '14': {'precision': 0.5142594296228151, 'recall': 0.3435771358328211, 'f1-score': 0.4119380987472365, 'support': 1627}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 484}, '16': {'precision': 0.4092526690391459, 'recall': 0.14465408805031446, 'f1-score': 0.2137546468401487, 'support': 795}, '17': {'precision': 0.42857142857142855, 'recall': 0.022058823529411766, 'f1-score': 0.04195804195804196, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.4722222222222222, 'recall': 0.0648854961832061, 'f1-score': 0.11409395973154363, 'support': 262}, '20': {'precision': 0.22727272727272727, 'recall': 0.008880994671403197, 'f1-score': 0.017094017094017092, 'support': 563}, '21': {'precision': 0.5580524344569289, 'recall': 0.17801672640382318, 'f1-score': 0.2699275362318841, 'support': 837}, '22': {'precision': 0.6666666666666666, 'recall': 0.565377532228361, 'f1-score': 0.611858495266567, 'support': 1086}, '23': {'precision': 0.5555555555555556, 'recall': 0.3600464576074332, 'f1-score': 0.43692741367159976, 'support': 861}, '24': {'precision': 0.5346938775510204, 'recall': 0.2594059405940594, 'f1-score': 0.34933333333333333, 'support': 505}, 'micro avg': {'precision': 0.563812089043809, 'recall': 0.2804950143853703, 'f1-score': 0.3746183808821981, 'support': 25373}, 'macro avg': {'precision': 0.4583604793777617, 'recall': 0.2215642105489039, 'f1-score': 0.27969318538296783, 'support': 25373}, 'weighted avg': {'precision': 0.5118090338159311, 'recall': 0.2804950143853703, 'f1-score': 0.34707411918169834, 'support': 25373}, 'samples avg': {'precision': 0.3840326588739675, 'recall': 0.24956366134057428, 'f1-score': 0.27730354979377664, 'support': 25373}}
{'0': {'precision': 0.6376811594202898, 'recall': 0.3384615384615385, 'f1-score': 0.4422110552763819, 'support': 130}, '1': {'precision': 0.5772357723577236, 'recall': 0.5220588235294118, 'f1-score': 0.5482625482625483, 'support': 136}, '2': {'precision': 0.4418604651162791, 'recall': 0.1386861313868613, 'f1-score': 0.21111111111111108, 'support': 137}, '3': {'precision': 0.6374501992031872, 'recall': 0.7511737089201878, 'f1-score': 0.689655172413793, 'support': 213}, '4': {'precision': 0.42857142857142855, 'recall': 0.04, 'f1-score': 0.07317073170731708, 'support': 75}, '5': {'precision': 0.46153846153846156, 'recall': 0.06382978723404255, 'f1-score': 0.11214953271028037, 'support': 94}, '6': {'precision': 0.5625, 'recall': 0.12162162162162163, 'f1-score': 0.20000000000000004, 'support': 74}, '7': {'precision': 0.4166666666666667, 'recall': 0.25, 'f1-score': 0.3125, 'support': 40}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '9': {'precision': 1.0, 'recall': 0.03076923076923077, 'f1-score': 0.059701492537313446, 'support': 65}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 63}, '11': {'precision': 1.0, 'recall': 0.03571428571428571, 'f1-score': 0.0689655172413793, 'support': 56}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 52}, '13': {'precision': 0.45454545454545453, 'recall': 0.09090909090909091, 'f1-score': 0.15151515151515152, 'support': 55}, '14': {'precision': 0.5833333333333334, 'recall': 0.1111111111111111, 'f1-score': 0.18666666666666668, 'support': 63}, '15': {'precision': 1.0, 'recall': 0.10526315789473684, 'f1-score': 0.1904761904761905, 'support': 19}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}, '17': {'precision': 0.375, 'recall': 0.14634146341463414, 'f1-score': 0.21052631578947364, 'support': 82}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, 'micro avg': {'precision': 0.5799011532125206, 'recall': 0.22901756668835394, 'f1-score': 0.3283582089552239, 'support': 1537}, 'macro avg': {'precision': 0.34305531763011304, 'recall': 0.10983759803867013, 'f1-score': 0.13827645942830424, 'support': 1537}, 'weighted avg': {'precision': 0.4710693110674277, 'recall': 0.22901756668835394, 'f1-score': 0.26019387343940914, 'support': 1537}, 'samples avg': {'precision': 0.358984375, 'recall': 0.20461852058531746, 'f1-score': 0.24117460230741483, 'support': 1537}}