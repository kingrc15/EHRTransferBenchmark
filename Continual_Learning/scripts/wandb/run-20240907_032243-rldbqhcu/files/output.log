
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.167954807281494
Train: epoch: 1, loss = 2.1303917992115022
Train: epoch: 1, loss = 2.1135086448987326
Train: epoch: 1, loss = 2.1021819899976255
Train: epoch: 1, loss = 2.0967773339748383
Train: epoch: 1, loss = 2.0917846766114234
Train: epoch: 1, loss = 2.0878714672156744
Train: epoch: 1, loss = 2.086246330216527
Train: epoch: 1, loss = 2.079438597758611
Train: epoch: 1, loss = 2.075253613173962
Train: epoch: 1, loss = 2.071651731025089
Train: epoch: 1, loss = 2.067042330255111
Train: epoch: 1, loss = 2.064652228126159
Train: epoch: 1, loss = 2.0648118725419042
Train: epoch: 1, loss = 2.0636807779073716
Train: epoch: 1, loss = 2.061829734928906
Train: epoch: 1, loss = 2.060839043294682
Train: epoch: 1, loss = 2.059886597229375
Train: epoch: 1, loss = 2.0596034616859336
Train: epoch: 1, loss = 2.0588491424322126
Train: epoch: 1, loss = 2.058203908659163
Train: epoch: 1, loss = 2.057809391726147
Train: epoch: 1, loss = 2.057739961743355
Train: epoch: 1, loss = 2.0560376012325285
Train: epoch: 1, loss = 2.0551232939481734
Train: epoch: 1, loss = 2.055030752030703
Train: epoch: 1, loss = 2.0545798274985065
Train: epoch: 1, loss = 2.0535963922100406
Train: epoch: 1, loss = 2.052696767819339
Train: epoch: 1, loss = 2.051976007044315
Train: epoch: 1, loss = 2.051583616791233
Train: epoch: 1, loss = 2.051097922697663
Train: epoch: 1, loss = 2.050325187191819
Train: epoch: 1, loss = 2.0500823788257208
Train: epoch: 1, loss = 2.0496099773475103
Train: epoch: 1, loss = 2.0489461191826397
Train: epoch: 1, loss = 2.048460704168758
Train: epoch: 1, loss = 2.0478811302310542
Train: epoch: 1, loss = 2.047508009244234
Train: epoch: 1, loss = 2.0475673997104167
Train: epoch: 1, loss = 2.047126964708654
Train: epoch: 1, loss = 2.0469765089807055
Train: epoch: 1, loss = 2.0468362681117167
Train:  Epoch 1, Loss=2.046597862121037, Cohen Kappa=0.37355266532958786, MAD=0.7189424833962569
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0281313390567384, Cohen Kappa=0.430347329799592, MAD=0.7205430095435766
Eval task: 2
Eval:  Epoch 1, Loss=1.9179461043456505, Cohen Kappa=0.0013528305798607976, MAD=0.7215564312606283
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.050527268442614, Cohen Kappa=0.3395257966914115, MAD=0.7160445878881199
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.90805360983158, Cohen Kappa=0.008253473130809152, MAD=0.7218256127936942
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.94302630007267
Train: epoch: 1, loss = 1.9416937959194183
Train: epoch: 1, loss = 1.9386965050299962
Train: epoch: 1, loss = 1.9363939356803894
Train: epoch: 1, loss = 1.940269065618515
Train: epoch: 1, loss = 1.9391363946596782
Train: epoch: 1, loss = 1.9388439573560443
Train: epoch: 1, loss = 1.9384569358825683
Train: epoch: 1, loss = 1.937989070283042
Train: epoch: 1, loss = 1.9382751298546792
Train: epoch: 1, loss = 1.9385029313781044
Train: epoch: 1, loss = 1.939087999711434
Train: epoch: 1, loss = 1.940367945570212
Train: epoch: 1, loss = 1.9397918773974692
Train: epoch: 1, loss = 1.9402040640910467
Train: epoch: 1, loss = 1.9402231819927693
Train: epoch: 1, loss = 1.9406029136391247
Train: epoch: 1, loss = 1.9404663435286946
Train: epoch: 1, loss = 1.9408428394480755
Train: epoch: 1, loss = 1.9411198919117452
Train: epoch: 1, loss = 1.9410031416586466
Train: epoch: 1, loss = 1.941445355144414
Train: epoch: 1, loss = 1.9411085579447125
Train: epoch: 1, loss = 1.9418066432575385
Train: epoch: 1, loss = 1.941742354774475
Train: epoch: 1, loss = 1.9420184406179648
Train: epoch: 1, loss = 1.9418854407027917
Train: epoch: 1, loss = 1.9416603476021972
Train: epoch: 1, loss = 1.9415322273147517
Train: epoch: 1, loss = 1.9417631515661875
Train: epoch: 1, loss = 1.9422574247660176
Train: epoch: 1, loss = 1.942464772220701
Train: epoch: 1, loss = 1.9423796207254582
Train: epoch: 1, loss = 1.9423426306773635
Train: epoch: 1, loss = 1.9423749623468944
Train: epoch: 1, loss = 1.9409723191459973
Train: epoch: 1, loss = 1.9405895193203075
Train: epoch: 1, loss = 1.93975720455772
Train: epoch: 1, loss = 1.9388529824293577
Train: epoch: 1, loss = 1.9378273604810239
Train: epoch: 1, loss = 1.9369739195341018
Train: epoch: 1, loss = 1.9361713004963739
Train: epoch: 1, loss = 1.9357463364961536
Train:  Epoch 1, Loss=1.9354277473449708, Cohen Kappa=0.04406682780413129, MAD=0.6948038062157742
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0502496402839134, Cohen Kappa=0.42992738542003917, MAD=0.7024922877703264
Eval task: 2
Eval:  Epoch 1, Loss=1.939530966610744, Cohen Kappa=0.13108265248112538, MAD=0.6734878369888658
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0590380389114906, Cohen Kappa=0.3260214282224043, MAD=0.6974477601185366
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.899676263332367, Cohen Kappa=0.05921943693331644, MAD=0.6751595458480938
{'0': {'precision': 0.5046136101499423, 'recall': 0.4294478527607362, 'f1-score': 0.4640063635158425, 'support': 4075}, '1': {'precision': 0.24350205198358413, 'recall': 0.6212914485165794, 'f1-score': 0.34987714987714985, 'support': 2865}, '2': {'precision': 0.23529411764705882, 'recall': 0.0044004400440044, 'f1-score': 0.008639308855291575, 'support': 1818}, '3': {'precision': 0.8333333333333334, 'recall': 0.0040032025620496394, 'f1-score': 0.00796812749003984, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.15815085158150852, 'recall': 0.26726973684210525, 'f1-score': 0.1987159889941914, 'support': 1216}, '9': {'precision': 0.10227848101265823, 'recall': 0.18825722273998136, 'f1-score': 0.1325459317585302, 'support': 1073}, 'accuracy': 0.27411099137931033, 'macro avg': {'precision': 0.2077172445708085, 'recall': 0.15146699034654562, 'f1-score': 0.11617528704910454, 'support': 14848}, 'weighted avg': {'precision': 0.30472710972247896, 'recall': 0.27411099137931033, 'f1-score': 0.22243688361078343, 'support': 14848}}
{'0': {'precision': 0.3096473029045643, 'recall': 0.1343989194056731, 'f1-score': 0.18744113029827317, 'support': 4442}, '1': {'precision': 0.35684385119658796, 'recall': 0.877963466770307, 'f1-score': 0.5074408940304375, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.4, 'recall': 0.004611837048424289, 'f1-score': 0.00911854103343465, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.1935483870967742, 'recall': 0.03409090909090909, 'f1-score': 0.05797101449275362, 'support': 176}, '9': {'precision': 0.09433962264150944, 'recall': 0.17857142857142858, 'f1-score': 0.1234567901234568, 'support': 112}, 'accuracy': 0.3466460129310345, 'macro avg': {'precision': 0.1354379163839436, 'recall': 0.12296365608867421, 'f1-score': 0.08854283699783558, 'support': 14848}, 'weighted avg': {'precision': 0.25436438117083765, 'recall': 0.3466460129310345, 'f1-score': 0.23436137004274052, 'support': 14848}}