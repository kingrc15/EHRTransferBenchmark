
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest_baseline
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1638222086429595
Train: epoch: 1, loss = 2.128448472619057
Train: epoch: 1, loss = 2.1084916148583095
Train: epoch: 1, loss = 2.0997701443731787
Train: epoch: 1, loss = 2.0933262395858763
Train: epoch: 1, loss = 2.088013179500898
Train: epoch: 1, loss = 2.0828329672983714
Train: epoch: 1, loss = 2.0781210370361807
Train: epoch: 1, loss = 2.0777049768633313
Train: epoch: 1, loss = 2.0760885245203973
Train: epoch: 1, loss = 2.0729637316682124
Train: epoch: 1, loss = 2.0705201520522434
Train: epoch: 1, loss = 2.0685193264942905
Train: epoch: 1, loss = 2.0672682681679726
Train: epoch: 1, loss = 2.0670631413857143
Train: epoch: 1, loss = 2.065152131617069
Train: epoch: 1, loss = 2.063593762306606
Train: epoch: 1, loss = 2.062228797011905
Train: epoch: 1, loss = 2.0614741683006286
Train: epoch: 1, loss = 2.059813435822725
Train: epoch: 1, loss = 2.0584502818187076
Train: epoch: 1, loss = 2.0573289708657696
Train: epoch: 1, loss = 2.057251972400624
Train: epoch: 1, loss = 2.056308426310619
Train: epoch: 1, loss = 2.0556422560691834
Train: epoch: 1, loss = 2.0540705074484533
Train: epoch: 1, loss = 2.0537427918116253
Train: epoch: 1, loss = 2.0537044844669956
Train: epoch: 1, loss = 2.0529561069710502
Train: epoch: 1, loss = 2.0526090927521388
Train: epoch: 1, loss = 2.0517554075487197
Train: epoch: 1, loss = 2.050934630278498
Train: epoch: 1, loss = 2.050482290730332
Train: epoch: 1, loss = 2.0503735656773343
Train: epoch: 1, loss = 2.049930521334921
Train: epoch: 1, loss = 2.0491865343683298
Train: epoch: 1, loss = 2.048488614833033
Train: epoch: 1, loss = 2.04759501843076
Train: epoch: 1, loss = 2.0472214140494667
Train: epoch: 1, loss = 2.0469588332027198
Train: epoch: 1, loss = 2.0467867297515636
Train: epoch: 1, loss = 2.0464016984757922
Train: epoch: 1, loss = 2.045594496200251
Train:  Epoch 1, Loss=2.0455179071562632, Cohen Kappa=0.3742034628328168, MAD=0.7176988635757452
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0317929510412545, Cohen Kappa=0.44072140127563797, MAD=0.7002659966382148
Eval task: 2
Eval:  Epoch 1, Loss=1.9786153764560306, Cohen Kappa=0.002894601317627754, MAD=0.7473887047300227
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0484382592398545, Cohen Kappa=0.3469137875482694, MAD=0.7029361438462065
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9440555120336598, Cohen Kappa=0.005099125454335662, MAD=0.7461696032215535
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9450099563598633
Train: epoch: 1, loss = 1.9572036683559417
Train: epoch: 1, loss = 1.9586661980549493
Train: epoch: 1, loss = 1.9593583457171917
Train: epoch: 1, loss = 1.9562546926736832
Train: epoch: 1, loss = 1.9566900910933813
Train: epoch: 1, loss = 1.9549434391941343
Train: epoch: 1, loss = 1.9556337162852286
Train: epoch: 1, loss = 1.9548825499084261
Train: epoch: 1, loss = 1.9530087939500809
Train: epoch: 1, loss = 1.9518304974924434
Train: epoch: 1, loss = 1.9515386335055034
Train: epoch: 1, loss = 1.951587349313956
Train: epoch: 1, loss = 1.951316564125674
Train: epoch: 1, loss = 1.951069687684377
Train: epoch: 1, loss = 1.9506813947483896
Train: epoch: 1, loss = 1.9507666914252675
Train: epoch: 1, loss = 1.949864235487249
Train: epoch: 1, loss = 1.9493821342367874
Train: epoch: 1, loss = 1.9486189089417458
Train: epoch: 1, loss = 1.948486440323648
Train: epoch: 1, loss = 1.9476532006263734
Train: epoch: 1, loss = 1.947458384555319
Train: epoch: 1, loss = 1.947413469304641
Train: epoch: 1, loss = 1.9475144329309464
Train: epoch: 1, loss = 1.9472970463908637
Train: epoch: 1, loss = 1.9470100404818853
Train: epoch: 1, loss = 1.9470250430277416
Train: epoch: 1, loss = 1.94715829341576
Train: epoch: 1, loss = 1.9468400964935622
Train: epoch: 1, loss = 1.9471891157281014
Train: epoch: 1, loss = 1.9474948295205832
Train: epoch: 1, loss = 1.9473183744965177
Train: epoch: 1, loss = 1.9472746367138976
Train: epoch: 1, loss = 1.9470977887766703
Train: epoch: 1, loss = 1.9469063249395953
Train: epoch: 1, loss = 1.9473173677276923
Train: epoch: 1, loss = 1.9469947199131312
Train: epoch: 1, loss = 1.9471024551452734
Train: epoch: 1, loss = 1.9473893259167672
Train: epoch: 1, loss = 1.9472445205944342
Train: epoch: 1, loss = 1.9470968782617932
Train: epoch: 1, loss = 1.9469354006301525
------------- 1, Loss=1.9469332872935703, Cohen Kappa=0.08603634895187073, MAD=0.6880493471023584
------------- 1, Loss=1.9469332872935703, Cohen Kappa=0.08603634895187073, MAD=0.6880493471023584
Eval task: 1
Eval:  Epoch 1, Loss=2.163016471369513, Cohen Kappa=0.04986441328990898, MAD=0.7340535041237665
Eval task: 2
Eval:  Epoch 1, Loss=1.9494369132765408, Cohen Kappa=0.13622996494547934, MAD=0.6734993342925354
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.1077631198126694, Cohen Kappa=0.06151041356549358, MAD=0.7333654737264056
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.924508892256638, Cohen Kappa=0.11516820458953991, MAD=0.6773620312617936
{'0': {'precision': 0.40505865102639294, 'recall': 0.5423312883435583, 'f1-score': 0.463749868849019, 'support': 4075}, '1': {'precision': 0.17717685235262304, 'recall': 0.5717277486910994, 'f1-score': 0.2705202312138728, 'support': 2865}, '2': {'precision': 0.6875, 'recall': 0.0121012101210121, 'f1-score': 0.023783783783783784, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.6521739130434783, 'recall': 0.061677631578947366, 'f1-score': 0.11269722013523666, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.26569234913793105, 'macro avg': {'precision': 0.19219094164224942, 'recall': 0.11878378787346171, 'f1-score': 0.08707511039819121, 'support': 14848}, 'weighted avg': {'precision': 0.2829434377144185, 'recall': 0.26569234913793105, 'f1-score': 0.19161502671005282, 'support': 14848}}
{'0': {'precision': 0.46905697445972494, 'recall': 0.22571496100212715, 'f1-score': 0.3047710228179352, 'support': 4231}, '1': {'precision': 0.34181172891668077, 'recall': 0.8040151063406877, 'f1-score': 0.4796916691372665, 'support': 5031}, '2': {'precision': 0.19148936170212766, 'recall': 0.04470198675496689, 'f1-score': 0.07248322147651005, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.10144927536231885, 'recall': 0.13725490196078433, 'f1-score': 0.11666666666666668, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.34684806034482757, 'macro avg': {'precision': 0.11038073404408522, 'recall': 0.12116869560585661, 'f1-score': 0.09736125800983786, 'support': 14848}, 'weighted avg': {'precision': 0.28272606702937286, 'recall': 0.34684806034482757, 'f1-score': 0.2635799062540086, 'support': 14848}}