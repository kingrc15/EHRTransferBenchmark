
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_west_baseline
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
west_val.csv
test_listfile.csv
west_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1671926760673523
Train: epoch: 1, loss = 2.1414356887340547
Train: epoch: 1, loss = 2.1180800783634184
Train: epoch: 1, loss = 2.1075599080324174
Train: epoch: 1, loss = 2.091432900071144
Train: epoch: 1, loss = 2.083120973408222
Train: epoch: 1, loss = 2.0784762081929617
Train: epoch: 1, loss = 2.0732727529853583
Train: epoch: 1, loss = 2.0709663398398295
Train: epoch: 1, loss = 2.0697661212682723
Train: epoch: 1, loss = 2.068216361024163
Train: epoch: 1, loss = 2.0659562714894615
Train: epoch: 1, loss = 2.0634807604551315
Train: epoch: 1, loss = 2.062316521406174
Train: epoch: 1, loss = 2.0619092387755713
Train: epoch: 1, loss = 2.0607642260938883
Train: epoch: 1, loss = 2.0587644087216432
Train: epoch: 1, loss = 2.056886773539914
Train: epoch: 1, loss = 2.0556226705563696
Train: epoch: 1, loss = 2.054974247664213
Train: epoch: 1, loss = 2.0542670773892175
Train: epoch: 1, loss = 2.0535343368486925
Train: epoch: 1, loss = 2.052861386071081
Train: epoch: 1, loss = 2.0518183026462795
Train: epoch: 1, loss = 2.0511951789617537
Train: epoch: 1, loss = 2.051073199877372
Train: epoch: 1, loss = 2.05068701547605
Train: epoch: 1, loss = 2.0501695751930984
Train: epoch: 1, loss = 2.0496285972513
Train: epoch: 1, loss = 2.049769630094369
Train: epoch: 1, loss = 2.049798593328845
Train: epoch: 1, loss = 2.049504264369607
Train: epoch: 1, loss = 2.0492067895152353
Train: epoch: 1, loss = 2.0490526910213864
Train: epoch: 1, loss = 2.0483132619006295
Train: epoch: 1, loss = 2.048217273106178
Train: epoch: 1, loss = 2.0476158843813717
Train: epoch: 1, loss = 2.0475126338632483
Train: epoch: 1, loss = 2.0469607327076105
Train: epoch: 1, loss = 2.04666115321219
Train: epoch: 1, loss = 2.045982216712905
Train: epoch: 1, loss = 2.0453657219949224
Train: epoch: 1, loss = 2.0449493595056754
Train:  Epoch 1, Loss=2.044650036280496, Cohen Kappa=0.38529674273788916, MAD=0.7207813032394392
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.03442238528153, Cohen Kappa=0.41121611706774497, MAD=0.7180780613657518
Eval task: 2
Eval:  Epoch 1, Loss=1.8756071534650078, Cohen Kappa=0.00034678801068965814, MAD=0.7349481603035146
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.055121427979963, Cohen Kappa=0.30767441877547774, MAD=0.717558993370663
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8895117537728672, Cohen Kappa=-8.246211410534166e-05, MAD=0.7361299493680563
west_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.8766230434179305
Train: epoch: 1, loss = 1.8798907828330993
Train: epoch: 1, loss = 1.8798598935206732
Train: epoch: 1, loss = 1.8794722300767899
Train: epoch: 1, loss = 1.8813119995594025
Train: epoch: 1, loss = 1.8830423380931218
Train: epoch: 1, loss = 1.8796370452642441
Train: epoch: 1, loss = 1.8782063321769238
Train: epoch: 1, loss = 1.878293664654096
Train: epoch: 1, loss = 1.8772798463106155
Train: epoch: 1, loss = 1.877016871950843
Train: epoch: 1, loss = 1.8769815105199814
Train: epoch: 1, loss = 1.8762003712929212
Train: epoch: 1, loss = 1.8768835075838226
Train: epoch: 1, loss = 1.8767216725349427
Train: epoch: 1, loss = 1.8758982095867396
Train: epoch: 1, loss = 1.8757917744271895
Train: epoch: 1, loss = 1.8763634431693288
Train: epoch: 1, loss = 1.8758501407033519
Train: epoch: 1, loss = 1.875946479678154
Train: epoch: 1, loss = 1.8757145398855208
Train:  Epoch 1, Loss=1.8757385931832449, Cohen Kappa=-0.0037651691443421065, MAD=0.7216743640993458
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.160575398083391, Cohen Kappa=0.011676623449645818, MAD=0.7251257495672216
Eval task: 2
Eval:  Epoch 1, Loss=1.870474835921978, Cohen Kappa=-0.03355181968636023, MAD=0.716289901300533
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.1152386911984147, Cohen Kappa=0.005046734425497856, MAD=0.7205829990075442
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8822692755995125, Cohen Kappa=-0.014260470694534844, MAD=0.7177762552832586
{'0': {'precision': 0.2838018741633199, 'recall': 0.052024539877300616, 'f1-score': 0.08793031936955621, 'support': 4075}, '1': {'precision': 0.19783275112283452, 'recall': 0.9685863874345549, 'f1-score': 0.3285578972294577, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.6428571428571429, 'recall': 0.007401315789473684, 'f1-score': 0.014634146341463414, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.2017780172413793, 'macro avg': {'precision': 0.11244917681432973, 'recall': 0.10280122431013292, 'f1-score': 0.043112236294047736, 'support': 14848}, 'weighted avg': {'precision': 0.16870943931147195, 'recall': 0.2017780172413793, 'f1-score': 0.08872774440628754, 'support': 14848}}
{'0': {'precision': 0.2320675105485232, 'recall': 0.06658595641646489, 'f1-score': 0.10348071495766699, 'support': 2478}, '1': {'precision': 0.35875579482578135, 'recall': 0.9244701348747592, 'f1-score': 0.5169144580909287, 'support': 2595}, '2': {'precision': 0.07692307692307693, 'recall': 0.0018450184501845018, 'f1-score': 0.0036036036036036032, 'support': 1084}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 501}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 215}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 121}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 103}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 153}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102}, 'accuracy': 0.34563577586206895, 'macro avg': {'precision': 0.06677463822973814, 'recall': 0.09929011097414085, 'f1-score': 0.06239987766521993, 'support': 7424}, 'weighted avg': {'precision': 0.21409202506691255, 'recall': 0.34563577586206895, 'f1-score': 0.21574953350180023, 'support': 7424}}