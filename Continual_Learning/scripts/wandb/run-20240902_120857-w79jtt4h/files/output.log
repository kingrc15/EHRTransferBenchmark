
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south_baseline
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
south_val.csv
test_listfile.csv
south_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1813357681035996
Train: epoch: 1, loss = 2.1386272537708284
Train: epoch: 1, loss = 2.1161805442969004
Train: epoch: 1, loss = 2.1024779181182383
Train: epoch: 1, loss = 2.0931213978528977
Train: epoch: 1, loss = 2.085815414786339
Train: epoch: 1, loss = 2.081644053714616
Train: epoch: 1, loss = 2.079228821694851
Train: epoch: 1, loss = 2.0738815650012756
Train: epoch: 1, loss = 2.069878740251064
Train: epoch: 1, loss = 2.0672178423946552
Train: epoch: 1, loss = 2.0642897836863994
Train: epoch: 1, loss = 2.0627646706654477
Train: epoch: 1, loss = 2.061017832968916
Train: epoch: 1, loss = 2.060503450989723
Train: epoch: 1, loss = 2.059100270755589
Train: epoch: 1, loss = 2.0587857412941317
Train: epoch: 1, loss = 2.058365494377083
Train: epoch: 1, loss = 2.058283043848841
Train: epoch: 1, loss = 2.0578042430877685
Train: epoch: 1, loss = 2.057056951153846
Train: epoch: 1, loss = 2.05679347647862
Train: epoch: 1, loss = 2.0563591528457144
Train: epoch: 1, loss = 2.055802491158247
Train: epoch: 1, loss = 2.0548093340873717
Train: epoch: 1, loss = 2.0538090446820627
Train: epoch: 1, loss = 2.0526974724619476
Train: epoch: 1, loss = 2.052577778803451
Train: epoch: 1, loss = 2.05201962394961
Train: epoch: 1, loss = 2.051849750995636
Train: epoch: 1, loss = 2.0516821377508103
Train: epoch: 1, loss = 2.0509528648667037
Train: epoch: 1, loss = 2.0505907477032053
Train: epoch: 1, loss = 2.050565022002248
Train: epoch: 1, loss = 2.0501169144596374
Train: epoch: 1, loss = 2.0499856707784865
Train: epoch: 1, loss = 2.0496326265786147
Train: epoch: 1, loss = 2.048654372143118
Train: epoch: 1, loss = 2.048097875637886
Train: epoch: 1, loss = 2.0476514621376993
Train: epoch: 1, loss = 2.0473995356443453
Train: epoch: 1, loss = 2.0472639676502773
Train: epoch: 1, loss = 2.0463814989771953
Train:  Epoch 1, Loss=2.046056907899039, Cohen Kappa=0.3801640428242934, MAD=0.7167860805226582
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.033979054155021, Cohen Kappa=0.42893163719443805, MAD=0.7501074179894436
Eval task: 2
Eval:  Epoch 1, Loss=1.9258462560587917, Cohen Kappa=0.0025716933274980702, MAD=0.7527819937814171
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.058076564607949, Cohen Kappa=0.3404579204394492, MAD=0.7482845522568359
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9184423171240708, Cohen Kappa=0.004629330907629958, MAD=0.7530969844680087
south_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.92083504319191
Train: epoch: 1, loss = 1.9203222393989563
Train: epoch: 1, loss = 1.915812240242958
Train: epoch: 1, loss = 1.912354646474123
Train: epoch: 1, loss = 1.913277056336403
Train: epoch: 1, loss = 1.9128065745035807
Train: epoch: 1, loss = 1.9132269262416022
Train: epoch: 1, loss = 1.9125585088133812
Train: epoch: 1, loss = 1.9125477503405677
Train: epoch: 1, loss = 1.9121735653877259
Train: epoch: 1, loss = 1.9094623958522623
Train: epoch: 1, loss = 1.9106433486938477
Train: epoch: 1, loss = 1.9094626068610412
Train: epoch: 1, loss = 1.9100854156272753
Train: epoch: 1, loss = 1.9108123857180277
Train: epoch: 1, loss = 1.9117019346356392
Train: epoch: 1, loss = 1.9118434321529725
Train: epoch: 1, loss = 1.9125195443299081
Train: epoch: 1, loss = 1.9122030871165425
Train: epoch: 1, loss = 1.9115140280127525
Train: epoch: 1, loss = 1.9109398109004612
Train: epoch: 1, loss = 1.9112176085060293
Train: epoch: 1, loss = 1.911379204340603
Train: epoch: 1, loss = 1.9115986396372318
Train: epoch: 1, loss = 1.9106853819847107
Train: epoch: 1, loss = 1.9105996049596714
Train: epoch: 1, loss = 1.9102318804793887
Train: epoch: 1, loss = 1.9104575632938317
Train: epoch: 1, loss = 1.9102463142625217
Train: epoch: 1, loss = 1.9101337282657622
Train: epoch: 1, loss = 1.909920561371311
Train: epoch: 1, loss = 1.9096347541175782
Train: epoch: 1, loss = 1.9094076644471198
Train: epoch: 1, loss = 1.9097189227623097
Train: epoch: 1, loss = 1.909494019644601
Train: epoch: 1, loss = 1.9092007415824466
Train: epoch: 1, loss = 1.9090597541589995
Train: epoch: 1, loss = 1.9088842530470145
Train: epoch: 1, loss = 1.9086989902533018
Train: epoch: 1, loss = 1.908115429893136
Train: epoch: 1, loss = 1.9079706295089023
Train: epoch: 1, loss = 1.9078478195979482
Train: epoch: 1, loss = 1.907731266645498
Train:  Epoch 1, Loss=1.907535686479296, Cohen Kappa=0.06740453685599024, MAD=0.6979320331166569
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.1633180338760902, Cohen Kappa=0.02038253191101036, MAD=0.6859440689215173
Eval task: 2
Eval:  Epoch 1, Loss=1.908531982323219, Cohen Kappa=0.1022777200781354, MAD=0.6955434697057724
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.1097423906984, Cohen Kappa=0.014916858206092343, MAD=0.6960432545611719
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.895400988644567, Cohen Kappa=0.07592465524401937, MAD=0.6961816200241366
{'0': {'precision': 0.6475409836065574, 'recall': 0.019386503067484663, 'f1-score': 0.037645937574457944, 'support': 4075}, '1': {'precision': 0.1932277743505381, 'recall': 0.9839441535776614, 'f1-score': 0.32302051105763724, 'support': 2865}, '2': {'precision': 0.5, 'recall': 0.0011001100110011, 'f1-score': 0.0021953896816684962, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.23333333333333334, 'recall': 0.005756578947368421, 'f1-score': 0.011235955056179773, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.19578394396551724, 'macro avg': {'precision': 0.15741020912904288, 'recall': 0.10101873456035156, 'f1-score': 0.03740977933699434, 'support': 14848}, 'weighted avg': {'precision': 0.29533003872874103, 'recall': 0.19578394396551724, 'f1-score': 0.07384934668545491, 'support': 14848}}
{'0': {'precision': 0.3264490339773484, 'recall': 0.11031067086897794, 'f1-score': 0.16489988221436985, 'support': 4442}, '1': {'precision': 0.3466187270501836, 'recall': 0.8804897007384376, 'f1-score': 0.49742013393347234, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.16666666666666666, 'recall': 0.0007686395080707148, 'f1-score': 0.0015302218821729152, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.09696969696969697, 'recall': 0.09090909090909091, 'f1-score': 0.09384164222873902, 'support': 176}, '9': {'precision': 0.125, 'recall': 0.11607142857142858, 'f1-score': 0.12037037037037038, 'support': 112}, 'accuracy': 0.3401804956896552, 'macro avg': {'precision': 0.10617041246638954, 'recall': 0.11985495305960056, 'f1-score': 0.08780622506291244, 'support': 14848}, 'weighted avg': {'precision': 0.23448858959641883, 'recall': 0.3401804956896552, 'f1-score': 0.22388185043105646, 'support': 14848}}