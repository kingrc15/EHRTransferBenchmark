
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1615353375673294
Train: epoch: 1, loss = 2.1318672838807107
Train: epoch: 1, loss = 2.110394295454025
Train: epoch: 1, loss = 2.098609901815653
Train: epoch: 1, loss = 2.0865515382289885
Train: epoch: 1, loss = 2.078652472496033
Train: epoch: 1, loss = 2.073545685155051
Train: epoch: 1, loss = 2.071557754650712
Train: epoch: 1, loss = 2.068506322569317
Train: epoch: 1, loss = 2.066267371416092
Train: epoch: 1, loss = 2.065186436067928
Train: epoch: 1, loss = 2.06244085436066
Train: epoch: 1, loss = 2.0612868485083946
Train: epoch: 1, loss = 2.0600965648038048
Train: epoch: 1, loss = 2.0586168573697408
Train: epoch: 1, loss = 2.0571698369458318
Train: epoch: 1, loss = 2.0562295007705687
Train: epoch: 1, loss = 2.0551583370897504
Train: epoch: 1, loss = 2.054805301176874
Train: epoch: 1, loss = 2.0541278962790965
Train: epoch: 1, loss = 2.053917219042778
Train: epoch: 1, loss = 2.0540237401290375
Train: epoch: 1, loss = 2.0534398415295976
Train: epoch: 1, loss = 2.0531280294309058
Train: epoch: 1, loss = 2.052320517897606
Train: epoch: 1, loss = 2.051585886157476
Train: epoch: 1, loss = 2.0508450933076716
Train: epoch: 1, loss = 2.0504341853516443
Train: epoch: 1, loss = 2.050451309948132
Train: epoch: 1, loss = 2.04995504740874
Train: epoch: 1, loss = 2.0495047012452154
Train: epoch: 1, loss = 2.0490034391358494
Train: epoch: 1, loss = 2.048629532799576
Train: epoch: 1, loss = 2.0479680571836583
Train: epoch: 1, loss = 2.04746831042426
Train: epoch: 1, loss = 2.047492338269949
Train: epoch: 1, loss = 2.0473005745700887
Train: epoch: 1, loss = 2.0471177637890765
Train: epoch: 1, loss = 2.046907307857122
Train: epoch: 1, loss = 2.0465371364206075
Train: epoch: 1, loss = 2.0457937819201772
Train: epoch: 1, loss = 2.045382843670391
Train: epoch: 1, loss = 2.045152991843778
Train:  Epoch 1, Loss=2.0449217307499477, Cohen Kappa=0.38232817867668845, MAD=0.7217812824401417
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.029290427421701, Cohen Kappa=0.42673374868494185, MAD=0.7494177125057857
Eval task: 2
Eval:  Epoch 1, Loss=1.927401016498434, Cohen Kappa=0.0027498051997765227, MAD=0.7503404538994349
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.055390882080999, Cohen Kappa=0.32164073424855477, MAD=0.7488870861392342
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9204339241159374, Cohen Kappa=0.005248097855927614, MAD=0.7506361627471956
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.948136593103409
Train: epoch: 1, loss = 1.9475414028763771
Train: epoch: 1, loss = 1.9491065963109335
Train: epoch: 1, loss = 1.9499943923950196
Train: epoch: 1, loss = 1.9481160999536515
Train: epoch: 1, loss = 1.9476744412382443
Train: epoch: 1, loss = 1.9465875141961233
Train: epoch: 1, loss = 1.9441824092715978
Train: epoch: 1, loss = 1.9435376990503734
Train: epoch: 1, loss = 1.941954910814762
Train: epoch: 1, loss = 1.9416694907708603
Train: epoch: 1, loss = 1.9408906314273675
Train: epoch: 1, loss = 1.9411366134423476
Train: epoch: 1, loss = 1.9416748604178429
Train: epoch: 1, loss = 1.9411807935237884
Train: epoch: 1, loss = 1.9409763713926076
Train: epoch: 1, loss = 1.9407396479213939
Train: epoch: 1, loss = 1.9408635065952937
Train: epoch: 1, loss = 1.9400725000155599
Train: epoch: 1, loss = 1.9398426919579506
Train: epoch: 1, loss = 1.9394812174638112
Train: epoch: 1, loss = 1.9391150827299466
Train: epoch: 1, loss = 1.9390469354131947
Train: epoch: 1, loss = 1.9393446720888217
Train: epoch: 1, loss = 1.9394471190214158
Train: epoch: 1, loss = 1.9395768897579266
Train: epoch: 1, loss = 1.9398411207949673
Train: epoch: 1, loss = 1.9401163668504784
Train: epoch: 1, loss = 1.9403795406119577
Train: epoch: 1, loss = 1.9403875468770664
Train: epoch: 1, loss = 1.9403155952884306
Train: epoch: 1, loss = 1.9406372994557024
Train: epoch: 1, loss = 1.9406888682733883
Train: epoch: 1, loss = 1.9408817831207723
Train: epoch: 1, loss = 1.9411378638574055
Train: epoch: 1, loss = 1.9403131244414382
Train: epoch: 1, loss = 1.9391599177186554
Train: epoch: 1, loss = 1.938357124971716
Train: epoch: 1, loss = 1.9372543373169042
Train: epoch: 1, loss = 1.9366016246676445
Train: epoch: 1, loss = 1.9360245616843061
Train: epoch: 1, loss = 1.9353803262398357
Train: epoch: 1, loss = 1.9348552109058512
Train:  Epoch 1, Loss=1.9340676671845571, Cohen Kappa=0.06819928203697223, MAD=0.6939901047846366
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.023869183556787, Cohen Kappa=0.4165697105476046, MAD=0.7119490154887765
Eval task: 2
Eval:  Epoch 1, Loss=1.9388648107134063, Cohen Kappa=0.14414708697323664, MAD=0.6871138989765937
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.065840844450326, Cohen Kappa=0.32062516002100716, MAD=0.7051461286392943
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.89729695484556, Cohen Kappa=0.060036622779685245, MAD=0.6867023022515943
{'0': {'precision': 0.5535097813578826, 'recall': 0.11803680981595092, 'f1-score': 0.19457928802588997, 'support': 4075}, '1': {'precision': 0.23517988552739166, 'recall': 0.8031413612565445, 'f1-score': 0.36382322713257964, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.168579862249918, 'recall': 0.42269736842105265, 'f1-score': 0.24103165298944904, 'support': 1216}, '9': {'precision': 0.12303664921465969, 'recall': 0.13140726933830382, 'f1-score': 0.1270842721946823, 'support': 1073}, 'accuracy': 0.23147898706896552, 'macro avg': {'precision': 0.1080306178349852, 'recall': 0.14752828088318518, 'f1-score': 0.0926518440342601, 'support': 14848}, 'weighted avg': {'precision': 0.21998613740386444, 'recall': 0.23147898706896552, 'f1-score': 0.15252694359781832, 'support': 14848}}
{'0': {'precision': 0.363013698630137, 'recall': 0.023863124718595228, 'f1-score': 0.044782425010561885, 'support': 4442}, '1': {'precision': 0.35014005602240894, 'recall': 0.9716284492809949, 'f1-score': 0.5147740142077627, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 176}, '9': {'precision': 0.07971014492753623, 'recall': 0.19642857142857142, 'f1-score': 0.11340206185567009, 'support': 112}, 'accuracy': 0.3453663793103448, 'macro avg': {'precision': 0.07928638995800821, 'recall': 0.11919201454281617, 'f1-score': 0.06729585010739947, 'support': 14848}, 'weighted avg': {'precision': 0.2305532808350127, 'recall': 0.3453663793103448, 'f1-score': 0.19266242187081745, 'support': 14848}}