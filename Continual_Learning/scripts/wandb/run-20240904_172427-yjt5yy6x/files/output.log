
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_northeast
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.4337509848177433
Train: epoch: 1, loss = 0.42300545029342174
Train: epoch: 1, loss = 0.41805674279729527
Train: epoch: 1, loss = 0.4121574679389596
Train: epoch: 1, loss = 0.41109686115384103
Train: epoch: 1, loss = 0.4092510914554199
Train: epoch: 1, loss = 0.4078039545246533
Train: epoch: 1, loss = 0.40571927631273863
Train: epoch: 1, loss = 0.40541322130295965
Train: epoch: 1, loss = 0.40399982319772243
Train: epoch: 1, loss = 0.40184412210502407
Train: epoch: 1, loss = 0.4001271233893931
Train: epoch: 1, loss = 0.3993963548541069
Train: epoch: 1, loss = 0.3980894815975002
Train: epoch: 1, loss = 0.3970627722690503
Train: epoch: 1, loss = 0.3955126186879352
Train: epoch: 1, loss = 0.3947296035728034
Train: epoch: 1, loss = 0.39329309523933464
Train:  Epoch 1, Loss=0.39292228031973553, AUC-ROC Macro=0.6558221516009362, AUC-ROC Micro=0.7475801205381087
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.37069529046614963, AUC-ROC Macro=0.7164942462875352, AUC-ROC Micro=0.7828273971508009
Eval task: 2
Eval:  Epoch 1, Loss=0.39167143404483795, AUC-ROC Macro=0.4885450616434484, AUC-ROC Micro=0.6020149124284164
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.3772785989195108
Train: epoch: 2, loss = 0.37471789550036194
Train: epoch: 2, loss = 0.3766581496596336
Train: epoch: 2, loss = 0.3743439610488713
Train: epoch: 2, loss = 0.3738494811356068
Train: epoch: 2, loss = 0.37273485704014697
Train: epoch: 2, loss = 0.373318478135126
Train: epoch: 2, loss = 0.3734302917309105
Train: epoch: 2, loss = 0.3728573101013899
Train: epoch: 2, loss = 0.37188778575509784
Train: epoch: 2, loss = 0.3711597595363855
Train: epoch: 2, loss = 0.3708816824418803
Train: epoch: 2, loss = 0.3706155553803994
Train: epoch: 2, loss = 0.3704264131081956
Train: epoch: 2, loss = 0.3701003874838352
Train: epoch: 2, loss = 0.37022846231702716
Train: epoch: 2, loss = 0.3701745794362882
Train: epoch: 2, loss = 0.36965027975953285
Train:  Epoch 2, Loss=0.36973338585225946, AUC-ROC Macro=0.721289587655562, AUC-ROC Micro=0.7891633182780569
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.36243314916888875, AUC-ROC Macro=0.7376450476770067, AUC-ROC Micro=0.7971637439373407
Eval task: 2
Eval:  Epoch 2, Loss=0.41004276275634766, AUC-ROC Macro=0.47181485039429133, AUC-ROC Micro=0.5844214327104538
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3641589737683535
Train: epoch: 3, loss = 0.36424126394093037
Train: epoch: 3, loss = 0.3605784140030543
Train: epoch: 3, loss = 0.360834875702858
Train: epoch: 3, loss = 0.3606977002322674
Train: epoch: 3, loss = 0.3616861777628462
Train: epoch: 3, loss = 0.36216075418250904
Train: epoch: 3, loss = 0.36243876631371674
Train: epoch: 3, loss = 0.36354561382697687
Train: epoch: 3, loss = 0.3637322064042091
Train: epoch: 3, loss = 0.36368732507255946
Train: epoch: 3, loss = 0.3632456069688002
Train: epoch: 3, loss = 0.3626293683797121
Train: epoch: 3, loss = 0.36190370888582296
Train: epoch: 3, loss = 0.3617725778669119
Train: epoch: 3, loss = 0.3613463419303298
Train: epoch: 3, loss = 0.3613745185601361
Train: epoch: 3, loss = 0.3610060216858983
Train:  Epoch 3, Loss=0.36117361776237816, AUC-ROC Macro=0.7414932639300321, AUC-ROC Micro=0.8025491094881402
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3574935557941596, AUC-ROC Macro=0.7499360060268419, AUC-ROC Micro=0.8063570875170396
Eval task: 2
Eval:  Epoch 3, Loss=0.4193754643201828, AUC-ROC Macro=0.4750768403309041, AUC-ROC Micro=0.5766493201417506
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.3526481057703495
Train: epoch: 4, loss = 0.3524933821335435
Train: epoch: 4, loss = 0.3515203699717919
Train: epoch: 4, loss = 0.35277801267802716
Train: epoch: 4, loss = 0.3533363363146782
Train: epoch: 4, loss = 0.35346902708212535
Train: epoch: 4, loss = 0.35351346552371976
Train: epoch: 4, loss = 0.35374535331502555
Train: epoch: 4, loss = 0.35447806609173615
Train: epoch: 4, loss = 0.35461519756913185
Train: epoch: 4, loss = 0.35485059654170814
Train: epoch: 4, loss = 0.35496593079219263
Train: epoch: 4, loss = 0.3556255967571185
Train: epoch: 4, loss = 0.3557327598226922
Train: epoch: 4, loss = 0.355695660546422
Train: epoch: 4, loss = 0.35583732049446554
Train: epoch: 4, loss = 0.355404589548707
Train: epoch: 4, loss = 0.3552452060083548
Train:  Epoch 4, Loss=0.35514062489199844, AUC-ROC Macro=0.7549131291346821, AUC-ROC Micro=0.8114185402345753
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3521268852055073, AUC-ROC Macro=0.7570097796495099, AUC-ROC Micro=0.8126213787929348
Eval task: 2
Eval:  Epoch 4, Loss=0.4365386813879013, AUC-ROC Macro=0.47679828262281, AUC-ROC Micro=0.5784083003341788
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.34621631853282453
Train: epoch: 5, loss = 0.3489482186362147
Train: epoch: 5, loss = 0.3464050932228565
Train: epoch: 5, loss = 0.3472400558181107
Train: epoch: 5, loss = 0.3475449319779873
Train: epoch: 5, loss = 0.34947259930272895
Train: epoch: 5, loss = 0.3489719036327941
Train: epoch: 5, loss = 0.34971266536973417
Train: epoch: 5, loss = 0.3494873179909256
Train: epoch: 5, loss = 0.3498738406151533
Train: epoch: 5, loss = 0.3501517831534147
Train: epoch: 5, loss = 0.3499535613010327
Train: epoch: 5, loss = 0.34987817030686597
Train: epoch: 5, loss = 0.3498023323448641
Train: epoch: 5, loss = 0.3498850560883681
Train: epoch: 5, loss = 0.3498276736028492
Train: epoch: 5, loss = 0.35021670891081585
Train: epoch: 5, loss = 0.35056757593320476
Train:  Epoch 5, Loss=0.35051280897091597, AUC-ROC Macro=0.764621285080394, AUC-ROC Micro=0.818059383409137
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3527255641917388, AUC-ROC Macro=0.7600015890426622, AUC-ROC Micro=0.8130308849702079
Eval task: 2
Eval:  Epoch 5, Loss=0.43578876554965973, AUC-ROC Macro=0.48551403555943135, AUC-ROC Micro=0.5767832882984482
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3527350600808859
Train: epoch: 6, loss = 0.3482502415776253
Train: epoch: 6, loss = 0.34739031314849855
Train: epoch: 6, loss = 0.3463289512321353
Train: epoch: 6, loss = 0.34608609177172184
Train: epoch: 6, loss = 0.3468099110821883
Train: epoch: 6, loss = 0.3466416691669396
Train: epoch: 6, loss = 0.3462792373634875
Train: epoch: 6, loss = 0.34598695227669346
Train: epoch: 6, loss = 0.34630179377645254
Train: epoch: 6, loss = 0.34671754265373406
Train: epoch: 6, loss = 0.3477379527998467
Train: epoch: 6, loss = 0.3477895439129609
Train: epoch: 6, loss = 0.34732516259487184
Train: epoch: 6, loss = 0.34721494317551455
Train: epoch: 6, loss = 0.34756581044755874
Train: epoch: 6, loss = 0.34748617338345333
Train: epoch: 6, loss = 0.34718764570852123
Train:  Epoch 6, Loss=0.3471624322447002, AUC-ROC Macro=0.7714378560782612, AUC-ROC Micro=0.8227303775314181
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.34841731811563176, AUC-ROC Macro=0.7650244147627374, AUC-ROC Micro=0.8175542599526731
Eval task: 2
Eval:  Epoch 6, Loss=0.4345170706510544, AUC-ROC Macro=0.483813359177448, AUC-ROC Micro=0.5815195329129675
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.35153984526793164, AUC-ROC Macro=0.7644015640708198, AUC-ROC Micro=0.8162604616590887
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.44397570192813873, AUC-ROC Macro=0.48508426153358863, AUC-ROC Micro=0.5961361731005728
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.34058924168348315
Train:  Epoch 1, Loss=0.33706220302787954, AUC-ROC Macro=0.5544646540187238, AUC-ROC Micro=0.7260516214873166
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.33656618123253185, AUC-ROC Macro=0.7535399758888872, AUC-ROC Micro=0.8101868758943385
Eval task: 2
Eval:  Epoch 1, Loss=0.29460151493549347, AUC-ROC Macro=0.6073573030321334, AUC-ROC Micro=0.7653767800144592
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.3184733293950558
Train:  Epoch 2, Loss=0.31705338215894446, AUC-ROC Macro=0.6458157940770293, AUC-ROC Micro=0.7920922527575908
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.34563586364189786, AUC-ROC Macro=0.7559845399776165, AUC-ROC Micro=0.8116056323272687
Eval task: 2
Eval:  Epoch 2, Loss=0.33825117349624634, AUC-ROC Macro=0.6689150569317972, AUC-ROC Micro=0.7930465401879447
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.3087979825586081
Train:  Epoch 3, Loss=0.30985861576085644, AUC-ROC Macro=0.6898151516213049, AUC-ROC Micro=0.8149907988495688
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.35188495740294456, AUC-ROC Macro=0.7535402084405877, AUC-ROC Micro=0.8096490668529299
Eval task: 2
Eval:  Epoch 3, Loss=0.35624557733535767, AUC-ROC Macro=0.6957808403369357, AUC-ROC Micro=0.8089023829751676
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.3058740409463644
Train:  Epoch 4, Loss=0.3063264171614973, AUC-ROC Macro=0.7150059272436203, AUC-ROC Micro=0.8285102118182046
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.34790490691860515, AUC-ROC Macro=0.7508596068686945, AUC-ROC Micro=0.8058297109077049
Eval task: 2
Eval:  Epoch 4, Loss=0.31112468242645264, AUC-ROC Macro=0.7087372661298277, AUC-ROC Micro=0.8183734854951135
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.30345239251852035
Train:  Epoch 5, Loss=0.30446208300617117, AUC-ROC Macro=0.7373940608208995, AUC-ROC Micro=0.8397196837378502
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.33820027982195217, AUC-ROC Macro=0.7554707358052921, AUC-ROC Micro=0.8106590527248172
Eval task: 2
Eval:  Epoch 5, Loss=0.2817046791315079, AUC-ROC Macro=0.7172036070001749, AUC-ROC Micro=0.8207343275796362
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.29589492566883563
Train:  Epoch 6, Loss=0.29658803298051056, AUC-ROC Macro=0.7604704057466875, AUC-ROC Micro=0.8487254379264815
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.34222953269879025, AUC-ROC Macro=0.7528691236565966, AUC-ROC Micro=0.8089985675830541
Eval task: 2
Eval:  Epoch 6, Loss=0.30985528230667114, AUC-ROC Macro=0.7148756262130184, AUC-ROC Micro=0.822161492402854
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.35968028133114177, AUC-ROC Macro=0.7522779242768728, AUC-ROC Micro=0.8074281448997326
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.2931840270757675, AUC-ROC Macro=0.6881880430928632, AUC-ROC Micro=0.8132288223754855
{'0': {'precision': 0.563845050215208, 'recall': 0.30045871559633025, 'f1-score': 0.39201995012468827, 'support': 1308}, '1': {'precision': 0.6116838487972509, 'recall': 0.4427860696517413, 'f1-score': 0.5137085137085138, 'support': 402}, '2': {'precision': 0.4794520547945205, 'recall': 0.05319148936170213, 'f1-score': 0.09575923392612859, 'support': 658}, '3': {'precision': 0.512396694214876, 'recall': 0.2804020100502513, 'f1-score': 0.36245534264371554, 'support': 1990}, '4': {'precision': 0.46835443037974683, 'recall': 0.13771712158808933, 'f1-score': 0.21284755512943432, 'support': 806}, '5': {'precision': 0.35, 'recall': 0.008997429305912597, 'f1-score': 0.01754385964912281, 'support': 778}, '6': {'precision': 0.5354691075514875, 'recall': 0.17972350230414746, 'f1-score': 0.269120184013801, 'support': 1302}, '7': {'precision': 0.3333333333333333, 'recall': 0.0047169811320754715, 'f1-score': 0.009302325581395349, 'support': 424}, '8': {'precision': 0.5539956803455723, 'recall': 0.31204379562043794, 'f1-score': 0.3992217898832685, 'support': 1644}, '9': {'precision': 0.678853046594982, 'recall': 0.46627277203348105, 'f1-score': 0.5528312901342675, 'support': 2031}, '10': {'precision': 0.6536964980544747, 'recall': 0.2931937172774869, 'f1-score': 0.40481927710843374, 'support': 573}, '11': {'precision': 0.5214723926380368, 'recall': 0.21683673469387754, 'f1-score': 0.3063063063063063, 'support': 1176}, '12': {'precision': 0.5464716006884681, 'recall': 0.3587570621468927, 'f1-score': 0.43315143246930427, 'support': 1770}, '13': {'precision': 0.56689453125, 'recall': 0.44722650231124805, 'f1-score': 0.5, 'support': 2596}, '14': {'precision': 0.5702614379084967, 'recall': 0.21450522433927474, 'f1-score': 0.311746315319339, 'support': 1627}, '15': {'precision': 1.0, 'recall': 0.004132231404958678, 'f1-score': 0.008230452674897118, 'support': 484}, '16': {'precision': 0.3832599118942731, 'recall': 0.10943396226415095, 'f1-score': 0.17025440313111548, 'support': 795}, '17': {'precision': 0.45, 'recall': 0.03308823529411765, 'f1-score': 0.06164383561643836, 'support': 544}, '18': {'precision': 0.3333333333333333, 'recall': 0.002849002849002849, 'f1-score': 0.005649717514124295, 'support': 351}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 262}, '20': {'precision': 0.14285714285714285, 'recall': 0.0017761989342806395, 'f1-score': 0.003508771929824562, 'support': 563}, '21': {'precision': 0.5364806866952789, 'recall': 0.14934289127837516, 'f1-score': 0.23364485981308414, 'support': 837}, '22': {'precision': 0.7095115681233933, 'recall': 0.5082872928176796, 'f1-score': 0.5922746781115881, 'support': 1086}, '23': {'precision': 0.5889423076923077, 'recall': 0.2845528455284553, 'f1-score': 0.3837118245888802, 'support': 861}, '24': {'precision': 0.5962732919254659, 'recall': 0.1900990099009901, 'f1-score': 0.2882882882882883, 'support': 505}, 'micro avg': {'precision': 0.5748126453613576, 'recall': 0.2629960982146376, 'f1-score': 0.3608782651019415, 'support': 25373}, 'macro avg': {'precision': 0.507473517971506, 'recall': 0.20001563190739838, 'f1-score': 0.26112160830663833, 'support': 25373}, 'weighted avg': {'precision': 0.5403228505197859, 'recall': 0.2629960982146376, 'f1-score': 0.33412921249004934, 'support': 25373}, 'samples avg': {'precision': 0.3863417588271103, 'recall': 0.2388715271613939, 'f1-score': 0.2694226722381026, 'support': 25373}}
{'0': {'precision': 0.8918918918918919, 'recall': 0.25384615384615383, 'f1-score': 0.39520958083832336, 'support': 130}, '1': {'precision': 0.6, 'recall': 0.35294117647058826, 'f1-score': 0.4444444444444445, 'support': 136}, '2': {'precision': 0.42592592592592593, 'recall': 0.1678832116788321, 'f1-score': 0.24083769633507854, 'support': 137}, '3': {'precision': 0.6666666666666666, 'recall': 0.6009389671361502, 'f1-score': 0.6320987654320988, 'support': 213}, '4': {'precision': 0.6363636363636364, 'recall': 0.09333333333333334, 'f1-score': 0.1627906976744186, 'support': 75}, '5': {'precision': 0.2727272727272727, 'recall': 0.031914893617021274, 'f1-score': 0.057142857142857134, 'support': 94}, '6': {'precision': 0.6666666666666666, 'recall': 0.02702702702702703, 'f1-score': 0.051948051948051945, 'support': 74}, '7': {'precision': 0.5, 'recall': 0.05, 'f1-score': 0.09090909090909091, 'support': 40}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '9': {'precision': 1.0, 'recall': 0.015384615384615385, 'f1-score': 0.030303030303030307, 'support': 65}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 63}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 56}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 52}, '13': {'precision': 0.5, 'recall': 0.07272727272727272, 'f1-score': 0.12698412698412698, 'support': 55}, '14': {'precision': 0.5, 'recall': 0.031746031746031744, 'f1-score': 0.05970149253731343, 'support': 63}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 82}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, 'micro avg': {'precision': 0.6200980392156863, 'recall': 0.1646063760572544, 'f1-score': 0.26015424164524426, 'support': 1537}, 'macro avg': {'precision': 0.26640968240968244, 'recall': 0.06790970731868104, 'f1-score': 0.09169479338195337, 'support': 1537}, 'weighted avg': {'precision': 0.43239737637915904, 'recall': 0.1646063760572544, 'f1-score': 0.20639541948573417, 'support': 1537}, 'samples avg': {'precision': 0.28411458333333334, 'recall': 0.14045681423611112, 'f1-score': 0.17470518847471972, 'support': 1537}}