
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_west
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.4295112003386021
Train: epoch: 1, loss = 0.4178396897017956
Train: epoch: 1, loss = 0.4148023690780004
Train: epoch: 1, loss = 0.41156903689727187
Train: epoch: 1, loss = 0.40980128176510333
Train: epoch: 1, loss = 0.40767629455775023
Train: epoch: 1, loss = 0.4067591273039579
Train: epoch: 1, loss = 0.40479102186858656
Train: epoch: 1, loss = 0.4031053808000353
Train: epoch: 1, loss = 0.400631672129035
Train: epoch: 1, loss = 0.39910661418329585
Train: epoch: 1, loss = 0.39765667708590624
Train: epoch: 1, loss = 0.3963358798623085
Train: epoch: 1, loss = 0.3953880027468715
Train: epoch: 1, loss = 0.3941596226543188
Train: epoch: 1, loss = 0.39329590752720833
Train: epoch: 1, loss = 0.39258244814679905
Train: epoch: 1, loss = 0.3917874549453457
Train:  Epoch 1, Loss=0.3914247885422829, AUC-ROC Macro=0.6604231180208352, AUC-ROC Micro=0.7505597124816423
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3700292880336444, AUC-ROC Macro=0.7162482246965166, AUC-ROC Micro=0.783704994453806
Eval task: 2
Eval:  Epoch 1, Loss=0.3401281386613846, AUC-ROC Macro=0.4895003274772065, AUC-ROC Micro=0.5251143745829305
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.37112319089472295
Train: epoch: 2, loss = 0.37162925843149425
Train: epoch: 2, loss = 0.37338384680449965
Train: epoch: 2, loss = 0.37007772155106067
Train: epoch: 2, loss = 0.371177933678031
Train: epoch: 2, loss = 0.3704735905304551
Train: epoch: 2, loss = 0.3710703714724098
Train: epoch: 2, loss = 0.3705371960438788
Train: epoch: 2, loss = 0.3703751153498888
Train: epoch: 2, loss = 0.37023032565414904
Train: epoch: 2, loss = 0.3694499532539736
Train: epoch: 2, loss = 0.36968007085844873
Train: epoch: 2, loss = 0.36912411401478146
Train: epoch: 2, loss = 0.36911528230777807
Train: epoch: 2, loss = 0.3691266695211331
Train: epoch: 2, loss = 0.36906379283871504
Train: epoch: 2, loss = 0.3687842222259325
Train: epoch: 2, loss = 0.36891425101293457
Train:  Epoch 2, Loss=0.3689573683127379, AUC-ROC Macro=0.7231475467237715, AUC-ROC Micro=0.7903850888819357
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3623218449453513, AUC-ROC Macro=0.7371225687043431, AUC-ROC Micro=0.7971041882051924
Eval task: 2
Eval:  Epoch 2, Loss=0.3426913246512413, AUC-ROC Macro=0.4964650109940084, AUC-ROC Micro=0.5304357483414106
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.35762037642300126
Train: epoch: 3, loss = 0.35923036687076093
Train: epoch: 3, loss = 0.35994747397800286
Train: epoch: 3, loss = 0.36122595842927696
Train: epoch: 3, loss = 0.36105981494486333
Train: epoch: 3, loss = 0.3614675188312928
Train: epoch: 3, loss = 0.3614991965464183
Train: epoch: 3, loss = 0.36124495341442525
Train: epoch: 3, loss = 0.361187570657995
Train: epoch: 3, loss = 0.36100241328775884
Train: epoch: 3, loss = 0.36063499082895845
Train: epoch: 3, loss = 0.3608089867668847
Train: epoch: 3, loss = 0.36069284417308295
Train: epoch: 3, loss = 0.3609163571574858
Train: epoch: 3, loss = 0.36094020553429923
Train: epoch: 3, loss = 0.36105475027114153
Train: epoch: 3, loss = 0.36083371571319944
Train: epoch: 3, loss = 0.3610859824841221
Train:  Epoch 3, Loss=0.36102309503310764, AUC-ROC Macro=0.741764117105957, AUC-ROC Micro=0.8027820788340415
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.35838474954168004, AUC-ROC Macro=0.7466596893174888, AUC-ROC Micro=0.8036326175532222
Eval task: 2
Eval:  Epoch 3, Loss=0.37854567915201187, AUC-ROC Macro=0.4847836871544348, AUC-ROC Micro=0.5209055470703873
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.3589061001688242
Train: epoch: 4, loss = 0.3572838269919157
Train: epoch: 4, loss = 0.35604331860939664
Train: epoch: 4, loss = 0.3566692231222987
Train: epoch: 4, loss = 0.3563521672040224
Train: epoch: 4, loss = 0.3565573110928138
Train: epoch: 4, loss = 0.355340215159314
Train: epoch: 4, loss = 0.35577831788919867
Train: epoch: 4, loss = 0.354684275512894
Train: epoch: 4, loss = 0.3549159908294678
Train: epoch: 4, loss = 0.3552204821732911
Train: epoch: 4, loss = 0.3552852139435709
Train: epoch: 4, loss = 0.3552317205300698
Train: epoch: 4, loss = 0.3550766412009086
Train: epoch: 4, loss = 0.3548507482210795
Train: epoch: 4, loss = 0.3550856313249096
Train: epoch: 4, loss = 0.35522239753428625
Train: epoch: 4, loss = 0.35561666033748124
Train:  Epoch 4, Loss=0.35558990855094713, AUC-ROC Macro=0.7537938287691989, AUC-ROC Micro=0.8107316479073016
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.35354918986558914, AUC-ROC Macro=0.7558702650046226, AUC-ROC Micro=0.8105960570282721
Eval task: 2
Eval:  Epoch 4, Loss=0.37845005840063095, AUC-ROC Macro=0.48975642734424185, AUC-ROC Micro=0.5338957752355895
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.3517168786376715
Train: epoch: 5, loss = 0.3490605729818344
Train: epoch: 5, loss = 0.34896634278198085
Train: epoch: 5, loss = 0.3483550870604813
Train: epoch: 5, loss = 0.3487442811578512
Train: epoch: 5, loss = 0.34921091064810755
Train: epoch: 5, loss = 0.3492904647546155
Train: epoch: 5, loss = 0.3500149962492287
Train: epoch: 5, loss = 0.3508991655707359
Train: epoch: 5, loss = 0.35063789267838
Train: epoch: 5, loss = 0.3507227582484484
Train: epoch: 5, loss = 0.3507154344643156
Train: epoch: 5, loss = 0.35050728498743133
Train: epoch: 5, loss = 0.3505733903603894
Train: epoch: 5, loss = 0.3507822778522968
Train: epoch: 5, loss = 0.35109649116173386
Train: epoch: 5, loss = 0.3509893831303891
Train: epoch: 5, loss = 0.35103599180777867
Train:  Epoch 5, Loss=0.3509841722056397, AUC-ROC Macro=0.7633653038826596, AUC-ROC Micro=0.8174212985354842
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.35240811854600906, AUC-ROC Macro=0.758674149400381, AUC-ROC Micro=0.8123171028356027
Eval task: 2
Eval:  Epoch 5, Loss=0.391213022172451, AUC-ROC Macro=0.4909953818214825, AUC-ROC Micro=0.5298985124323199
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3488464477658272
Train: epoch: 6, loss = 0.34844700917601584
Train: epoch: 6, loss = 0.34794068699081737
Train: epoch: 6, loss = 0.3470740959607065
Train: epoch: 6, loss = 0.3467059048712254
Train: epoch: 6, loss = 0.3466875657935937
Train: epoch: 6, loss = 0.3460159928138767
Train: epoch: 6, loss = 0.34642619129270313
Train: epoch: 6, loss = 0.3462525972723961
Train: epoch: 6, loss = 0.3463664934709668
Train: epoch: 6, loss = 0.3468790550055829
Train: epoch: 6, loss = 0.34745890924086176
Train: epoch: 6, loss = 0.347510660130244
Train: epoch: 6, loss = 0.34753393747444666
Train: epoch: 6, loss = 0.34733263265589875
Train: epoch: 6, loss = 0.3476458991272375
Train: epoch: 6, loss = 0.3473892497271299
Train: epoch: 6, loss = 0.3474601763486862
Train:  Epoch 6, Loss=0.3474686212753638, AUC-ROC Macro=0.7703894332291387, AUC-ROC Micro=0.8223427332983839
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3509102153281371, AUC-ROC Macro=0.7619544739930394, AUC-ROC Micro=0.8150359368521559
Eval task: 2
Eval:  Epoch 6, Loss=0.38854148983955383, AUC-ROC Macro=0.4905440409614466, AUC-ROC Micro=0.5220787087396526
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3533404817183812, AUC-ROC Macro=0.7633905143163986, AUC-ROC Micro=0.8148315520987773
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.39019235223531723, AUC-ROC Macro=0.47754455209366337, AUC-ROC Micro=0.519225228426107
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.31263267517089843
Train: epoch: 1, loss = 0.3041795118525624
Train: epoch: 1, loss = 0.2919020814200242
Train:  Epoch 1, Loss=0.2846190121468899, AUC-ROC Macro=0.5423890138243364, AUC-ROC Micro=0.7242558170016298
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3626793585717678, AUC-ROC Macro=0.7430431985843998, AUC-ROC Micro=0.7918176234139321
Eval task: 2
Eval:  Epoch 1, Loss=0.31087576597929, AUC-ROC Macro=0.6307567964435451, AUC-ROC Micro=0.7816922203836216
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.2851174844056368
Train: epoch: 2, loss = 0.28486646600067617
Train: epoch: 2, loss = 0.27531702602903046
Train:  Epoch 2, Loss=0.268714106983223, AUC-ROC Macro=0.6519680762103286, AUC-ROC Micro=0.7966012870269068
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3488347778717677, AUC-ROC Macro=0.7536483939612437, AUC-ROC Micro=0.8068809948242548
Eval task: 2
Eval:  Epoch 2, Loss=0.29744135588407516, AUC-ROC Macro=0.6860248718299359, AUC-ROC Micro=0.7994348293950297
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.2782021876424551
Train: epoch: 3, loss = 0.2780145739018917
Train: epoch: 3, loss = 0.2687083519498507
Train:  Epoch 3, Loss=0.26372598715811235, AUC-ROC Macro=0.6922262981155646, AUC-ROC Micro=0.8138802389995659
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.35242826119065285, AUC-ROC Macro=0.7411781145558356, AUC-ROC Micro=0.7970394811414945
Eval task: 2
Eval:  Epoch 3, Loss=0.302421398460865, AUC-ROC Macro=0.695147150985107, AUC-ROC Micro=0.8063932655192313
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.2737971406430006
Train: epoch: 4, loss = 0.27355249866843223
Train: epoch: 4, loss = 0.26554278783500196
Train:  Epoch 4, Loss=0.26027527363111586, AUC-ROC Macro=0.7149324546674, AUC-ROC Micro=0.8239569817225276
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.34272264565030736, AUC-ROC Macro=0.7500057769302478, AUC-ROC Micro=0.8039343755888686
Eval task: 2
Eval:  Epoch 4, Loss=0.28805218636989594, AUC-ROC Macro=0.6955843943354628, AUC-ROC Micro=0.8120352140677897
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.2714003423601389
Train: epoch: 5, loss = 0.26954408645629885
Train: epoch: 5, loss = 0.261814274986585
Train:  Epoch 5, Loss=0.25620945102252995, AUC-ROC Macro=0.7359074063209238, AUC-ROC Micro=0.8321153017266093
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.33977383250991505, AUC-ROC Macro=0.7481209992887421, AUC-ROC Micro=0.804193178541815
Eval task: 2
Eval:  Epoch 5, Loss=0.28734391927719116, AUC-ROC Macro=0.6859017639119529, AUC-ROC Micro=0.8077622885852632
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.26594853326678275
Train: epoch: 6, loss = 0.26610429003834724
Train: epoch: 6, loss = 0.2583708331485589
Train:  Epoch 6, Loss=0.25271851201834084, AUC-ROC Macro=0.7481825796632878, AUC-ROC Micro=0.8378443795920716
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.34003793944915134, AUC-ROC Macro=0.7491342467772203, AUC-ROC Micro=0.8047215170869545
Eval task: 2
Eval:  Epoch 6, Loss=0.2860436365008354, AUC-ROC Macro=0.7052078566300695, AUC-ROC Micro=0.8156865155899705
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.36467713490128517, AUC-ROC Macro=0.7482592279540684, AUC-ROC Micro=0.8041728233845291
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.22223610430955887, AUC-ROC Macro=0.7095768356324322, AUC-ROC Micro=0.8132118332460739
{'0': {'precision': 0.5309941520467836, 'recall': 0.3470948012232416, 'f1-score': 0.41978733240869165, 'support': 1308}, '1': {'precision': 0.6703296703296703, 'recall': 0.3034825870646766, 'f1-score': 0.4178082191780822, 'support': 402}, '2': {'precision': 0.5256410256410257, 'recall': 0.06231003039513678, 'f1-score': 0.11141304347826085, 'support': 658}, '3': {'precision': 0.5436447166921899, 'recall': 0.17839195979899497, 'f1-score': 0.26863412788497915, 'support': 1990}, '4': {'precision': 0.5882352941176471, 'recall': 0.07444168734491315, 'f1-score': 0.13215859030837002, 'support': 806}, '5': {'precision': 0.2727272727272727, 'recall': 0.007712082262210797, 'f1-score': 0.015, 'support': 778}, '6': {'precision': 0.579136690647482, 'recall': 0.12365591397849462, 'f1-score': 0.20379746835443038, 'support': 1302}, '7': {'precision': 0.2, 'recall': 0.0047169811320754715, 'f1-score': 0.009216589861751152, 'support': 424}, '8': {'precision': 0.5492371705963939, 'recall': 0.24087591240875914, 'f1-score': 0.33488372093023255, 'support': 1644}, '9': {'precision': 0.6312981624184943, 'recall': 0.5243722304283605, 'f1-score': 0.5728886498117267, 'support': 2031}, '10': {'precision': 0.5511811023622047, 'recall': 0.36649214659685864, 'f1-score': 0.44025157232704404, 'support': 573}, '11': {'precision': 0.49105367793240556, 'recall': 0.2100340136054422, 'f1-score': 0.2942227516378797, 'support': 1176}, '12': {'precision': 0.5676905574516496, 'recall': 0.28192090395480224, 'f1-score': 0.3767459418648547, 'support': 1770}, '13': {'precision': 0.5805954825462012, 'recall': 0.43567026194144837, 'f1-score': 0.4977992957746478, 'support': 2596}, '14': {'precision': 0.5555555555555556, 'recall': 0.24892440073755379, 'f1-score': 0.3438030560271647, 'support': 1627}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 484}, '16': {'precision': 0.45, 'recall': 0.05660377358490566, 'f1-score': 0.10055865921787709, 'support': 795}, '17': {'precision': 0.6190476190476191, 'recall': 0.04779411764705882, 'f1-score': 0.0887372013651877, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.5, 'recall': 0.05725190839694656, 'f1-score': 0.10273972602739725, 'support': 262}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 563}, '21': {'precision': 0.5533596837944664, 'recall': 0.16726403823178015, 'f1-score': 0.25688073394495414, 'support': 837}, '22': {'precision': 0.6928471248246845, 'recall': 0.4548802946593002, 'f1-score': 0.5491939966648138, 'support': 1086}, '23': {'precision': 0.6101694915254238, 'recall': 0.2508710801393728, 'f1-score': 0.35555555555555557, 'support': 861}, '24': {'precision': 0.5321888412017167, 'recall': 0.24554455445544554, 'f1-score': 0.3360433604336043, 'support': 505}, 'micro avg': {'precision': 0.5778315045564442, 'recall': 0.24490600244354235, 'f1-score': 0.344008636200072, 'support': 25373}, 'macro avg': {'precision': 0.4717973316583554, 'recall': 0.18761222719951115, 'f1-score': 0.24912478372230024, 'support': 25373}, 'weighted avg': {'precision': 0.5220681729426203, 'recall': 0.24490600244354235, 'f1-score': 0.31472940178552267, 'support': 25373}, 'samples avg': {'precision': 0.3746292268386995, 'recall': 0.22008019089030695, 'f1-score': 0.25404470497705334, 'support': 25373}}
{'0': {'precision': 0.576271186440678, 'recall': 0.3469387755102041, 'f1-score': 0.43312101910828027, 'support': 196}, '1': {'precision': 0.47619047619047616, 'recall': 0.12448132780082988, 'f1-score': 0.19736842105263158, 'support': 241}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 145}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 118}, '4': {'precision': 0.6, 'recall': 0.12980769230769232, 'f1-score': 0.21343873517786563, 'support': 208}, '5': {'precision': 0.3333333333333333, 'recall': 0.01, 'f1-score': 0.019417475728155338, 'support': 100}, '6': {'precision': 1.0, 'recall': 0.00909090909090909, 'f1-score': 0.018018018018018018, 'support': 110}, '7': {'precision': 0.8125, 'recall': 0.19548872180451127, 'f1-score': 0.3151515151515151, 'support': 133}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 89}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87}, '13': {'precision': 0.3333333333333333, 'recall': 0.0136986301369863, 'f1-score': 0.02631578947368421, 'support': 73}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 45}, '15': {'precision': 0.75, 'recall': 0.7058823529411765, 'f1-score': 0.7272727272727272, 'support': 51}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'micro avg': {'precision': 0.5993690851735016, 'recall': 0.09528585757271815, 'f1-score': 0.16443098225876243, 'support': 1994}, 'macro avg': {'precision': 0.1952651331719128, 'recall': 0.061415536383692376, 'f1-score': 0.07800414803931509, 'support': 1994}, 'weighted avg': {'precision': 0.33424785555212855, 'recall': 0.09528585757271815, 'f1-score': 0.13124554108743242, 'support': 1994}, 'samples avg': {'precision': 0.171142578125, 'recall': 0.11833612351190476, 'f1-score': 0.13201962425595237, 'support': 1994}}