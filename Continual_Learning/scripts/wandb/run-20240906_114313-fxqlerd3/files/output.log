
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south_baseline
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.14679999768734
Train: epoch: 1, loss = 2.1265996265411378
Train: epoch: 1, loss = 2.112010586063067
Train: epoch: 1, loss = 2.1000934660434725
Train: epoch: 1, loss = 2.0887129640579225
Train: epoch: 1, loss = 2.084631969432036
Train: epoch: 1, loss = 2.0853086016859326
Train: epoch: 1, loss = 2.0769966880977155
Train: epoch: 1, loss = 2.07280050251219
Train: epoch: 1, loss = 2.0711787188649176
Train: epoch: 1, loss = 2.06806168355725
Train: epoch: 1, loss = 2.0663615392148493
Train: epoch: 1, loss = 2.0644629430770873
Train: epoch: 1, loss = 2.0613331122483527
Train: epoch: 1, loss = 2.0599133936564127
Train: epoch: 1, loss = 2.0582116597518323
Train: epoch: 1, loss = 2.057709796007942
Train: epoch: 1, loss = 2.057397913833459
Train: epoch: 1, loss = 2.056247387434307
Train: epoch: 1, loss = 2.0548446271419527
Train: epoch: 1, loss = 2.0539223927259447
Train: epoch: 1, loss = 2.052475699294697
Train: epoch: 1, loss = 2.0518453036443045
Train: epoch: 1, loss = 2.050778888637821
Train: epoch: 1, loss = 2.0504586140871046
Train: epoch: 1, loss = 2.049923316698808
Train: epoch: 1, loss = 2.0497467132409413
Train: epoch: 1, loss = 2.0496307184653624
Train: epoch: 1, loss = 2.0495333876075414
Train: epoch: 1, loss = 2.0494422926306726
Train: epoch: 1, loss = 2.0487941789819346
Train: epoch: 1, loss = 2.0483568075485525
Train: epoch: 1, loss = 2.047310494365114
Train: epoch: 1, loss = 2.0465306447884615
Train: epoch: 1, loss = 2.0459230712822505
Train: epoch: 1, loss = 2.0452156583136984
Train: epoch: 1, loss = 2.0451585471146814
Train: epoch: 1, loss = 2.0446069429893243
Train: epoch: 1, loss = 2.044395028199905
Train: epoch: 1, loss = 2.0440702554881574
Train: epoch: 1, loss = 2.0440832080492157
Train: epoch: 1, loss = 2.043673480451107
Train: epoch: 1, loss = 2.043431983784188
Train:  Epoch 1, Loss=2.0432731187003, Cohen Kappa=0.37989184401769205, MAD=0.7192428132827698
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0282453339675377, Cohen Kappa=0.42960019881802636, MAD=0.7290916160931389
Eval task: 2
Eval:  Epoch 1, Loss=1.915175775001789, Cohen Kappa=0.0016796355679691288, MAD=0.7122125225277502
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.055913976554213, Cohen Kappa=0.345175979164541, MAD=0.7268461651356972
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9062971164440285, Cohen Kappa=0.002786154518851669, MAD=0.7125873590992432
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9246747177839278
Train: epoch: 1, loss = 1.9097018164396287
Train: epoch: 1, loss = 1.9103580834468206
Train: epoch: 1, loss = 1.9124137488007547
Train: epoch: 1, loss = 1.9088977148532869
Train: epoch: 1, loss = 1.9101568605502446
Train: epoch: 1, loss = 1.9105575391224452
Train: epoch: 1, loss = 1.9103949590027332
Train: epoch: 1, loss = 1.9107295474741195
Train: epoch: 1, loss = 1.9105160103440284
Train: epoch: 1, loss = 1.9106654316186904
Train: epoch: 1, loss = 1.9108363036314646
Train: epoch: 1, loss = 1.9111316571785852
Train: epoch: 1, loss = 1.911541406895433
Train: epoch: 1, loss = 1.9119148879051209
Train: epoch: 1, loss = 1.9124345649033785
Train: epoch: 1, loss = 1.9117422436966616
Train: epoch: 1, loss = 1.9118688412507374
Train: epoch: 1, loss = 1.9118080393264167
Train: epoch: 1, loss = 1.9119595609903335
Train: epoch: 1, loss = 1.9115776227485566
Train: epoch: 1, loss = 1.9113601222634315
Train: epoch: 1, loss = 1.910353678646295
Train: epoch: 1, loss = 1.909913157224655
Train: epoch: 1, loss = 1.9101615159988403
Train: epoch: 1, loss = 1.9099368370725558
Train: epoch: 1, loss = 1.910047476998082
Train: epoch: 1, loss = 1.909648709339755
Train: epoch: 1, loss = 1.909840953720027
Train: epoch: 1, loss = 1.9099818014303842
Train: epoch: 1, loss = 1.9105498034146524
Train: epoch: 1, loss = 1.9100067011453212
Train: epoch: 1, loss = 1.9099521760507063
Train: epoch: 1, loss = 1.9096511339440065
Train: epoch: 1, loss = 1.9092238322666713
Train: epoch: 1, loss = 1.909039744221502
Train: epoch: 1, loss = 1.909051875745928
Train: epoch: 1, loss = 1.9089065202913786
Train: epoch: 1, loss = 1.9087633312971164
Train: epoch: 1, loss = 1.9088073656857014
Train: epoch: 1, loss = 1.90880749661748
Train: epoch: 1, loss = 1.9088859880112465
Train: epoch: 1, loss = 1.9086518858199897
Train:  Epoch 1, Loss=1.9085236253602165, Cohen Kappa=0.06929020304021416, MAD=0.6959898594937426
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.1745428463508345, Cohen Kappa=0.011145608384427907, MAD=0.6893400696697005
Eval task: 2
Eval:  Epoch 1, Loss=1.9062683294559348, Cohen Kappa=0.1539218907114438, MAD=0.6981786245283715
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.1142810274814736, Cohen Kappa=0.02677689366190772, MAD=0.7067345806670428
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.897489255872266, Cohen Kappa=0.09091664079433837, MAD=0.6974874851230143
{'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4075}, '1': {'precision': 0.1951860561626781, 'recall': 0.9849912739965097, 'f1-score': 0.3258096172718351, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.3333333333333333, 'recall': 0.0008006405124099279, 'f1-score': 0.001597444089456869, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.19012661637931033, 'macro avg': {'precision': 0.05285193894960114, 'recall': 0.09857919145089196, 'f1-score': 0.0327407061361292, 'support': 14848}, 'weighted avg': {'precision': 0.06570187124457207, 'recall': 0.19012661637931033, 'f1-score': 0.06300106149996897, 'support': 14848}}
{'0': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4442}, '1': {'precision': 0.3510660318774581, 'recall': 0.9887291099883404, 'f1-score': 0.5181526554305209, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.18, 'recall': 0.05113636363636364, 'f1-score': 0.07964601769911504, 'support': 176}, '9': {'precision': 0.047619047619047616, 'recall': 0.125, 'f1-score': 0.06896551724137931, 'support': 112}, 'accuracy': 0.34422144396551724, 'macro avg': {'precision': 0.05786850794965057, 'recall': 0.1164865473624704, 'f1-score': 0.06667641903710153, 'support': 14848}, 'weighted avg': {'precision': 0.12416481232319052, 'recall': 0.34422144396551724, 'f1-score': 0.18104494894204873, 'support': 14848}}