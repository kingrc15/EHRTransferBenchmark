
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_northeast
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
northeast_val.csv
test_listfile.csv
northeast_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.176561700105667
Train: epoch: 1, loss = 2.141032721400261
Train: epoch: 1, loss = 2.1222780005137127
Train: epoch: 1, loss = 2.110450877100229
Train: epoch: 1, loss = 2.100309680700302
Train: epoch: 1, loss = 2.092536471684774
Train: epoch: 1, loss = 2.086162829995155
Train: epoch: 1, loss = 2.079471637159586
Train: epoch: 1, loss = 2.0752799743413926
Train: epoch: 1, loss = 2.0702532271146774
Train: epoch: 1, loss = 2.066830202720382
Train: epoch: 1, loss = 2.063835252026717
Train: epoch: 1, loss = 2.0619664484720963
Train: epoch: 1, loss = 2.0608153621213776
Train: epoch: 1, loss = 2.0605648094813027
Train: epoch: 1, loss = 2.057863941155374
Train: epoch: 1, loss = 2.0574599353004905
Train: epoch: 1, loss = 2.05656095004744
Train: epoch: 1, loss = 2.055874078775707
Train: epoch: 1, loss = 2.0549743982553483
Train: epoch: 1, loss = 2.0531329850355786
Train: epoch: 1, loss = 2.052576357722282
Train: epoch: 1, loss = 2.0521036352541135
Train: epoch: 1, loss = 2.051872777764996
Train: epoch: 1, loss = 2.050826555395126
Train: epoch: 1, loss = 2.0497910148134597
Train: epoch: 1, loss = 2.0489170091019737
Train: epoch: 1, loss = 2.04791979140469
Train: epoch: 1, loss = 2.047449938696006
Train: epoch: 1, loss = 2.0471317121783894
Train: epoch: 1, loss = 2.046541835319611
Train: epoch: 1, loss = 2.0458496447466312
Train: epoch: 1, loss = 2.0458401329770233
Train: epoch: 1, loss = 2.0454403482114567
Train: epoch: 1, loss = 2.045031563247953
Train: epoch: 1, loss = 2.0447424711783726
Train: epoch: 1, loss = 2.044961080438382
Train: epoch: 1, loss = 2.04515078808132
Train: epoch: 1, loss = 2.044488026988812
Train: epoch: 1, loss = 2.0443057889640333
Train: epoch: 1, loss = 2.0440944887661354
Train: epoch: 1, loss = 2.044102055912926
Train: epoch: 1, loss = 2.0437891774122106
Train:  Epoch 1, Loss=2.0437833866391864, Cohen Kappa=0.3884339525313585, MAD=0.717836658343105
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0303697072226425, Cohen Kappa=0.4353216336356571, MAD=0.7224430292178646
Eval task: 2
Eval:  Epoch 1, Loss=1.8890705108642578, Cohen Kappa=0.012657427745208172, MAD=0.6484715051908495
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0488659801154303, Cohen Kappa=0.35851458805300673, MAD=0.7258826078015368
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9056201406887598, Cohen Kappa=0.01739868448970927, MAD=0.6466746097141705
northeast_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9391771638393402
Train: epoch: 1, loss = 1.9412256732583046
Train: epoch: 1, loss = 1.9435484212636949
Train: epoch: 1, loss = 1.9437578897178174
Train: epoch: 1, loss = 1.9428679727315903
Train: epoch: 1, loss = 1.9442004052797954
Train: epoch: 1, loss = 1.9444185092619488
Train: epoch: 1, loss = 1.94500861980021
Train: epoch: 1, loss = 1.9457890674802991
Train: epoch: 1, loss = 1.9451246055364608
Train:  Epoch 1, Loss=1.9448116224016463, Cohen Kappa=0.03558479736453701, MAD=0.5897936843183101
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0390690256809365, Cohen Kappa=0.4323447290967618, MAD=0.7206389011773219
Eval task: 2
Eval:  Epoch 1, Loss=1.8999884639467512, Cohen Kappa=0.019769085563441813, MAD=0.5911998410902358
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0528332262203612, Cohen Kappa=0.34900063589658403, MAD=0.70986969011022
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8813252534185136, Cohen Kappa=0.012909925502295083, MAD=0.5898124981477926
{'0': {'precision': 0.41358399029714976, 'recall': 0.5020858895705521, 'f1-score': 0.4535579694081135, 'support': 4075}, '1': {'precision': 0.26865401987353205, 'recall': 0.519022687609075, 'f1-score': 0.35404761904761906, 'support': 2865}, '2': {'precision': 0.5, 'recall': 0.0011001100110011, 'f1-score': 0.0021953896816684962, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.18154835518179568, 'recall': 0.6036184210526315, 'f1-score': 0.27914052101159914, 'support': 1216}, '9': {'precision': 0.22570532915360503, 'recall': 0.06710158434296365, 'f1-score': 0.10344827586206896, 'support': 1073}, 'accuracy': 0.29236260775862066, 'macro avg': {'precision': 0.15894916945060825, 'recall': 0.16929286925862236, 'f1-score': 0.1192389775011069, 'support': 14848}, 'weighted avg': {'precision': 0.25774468921615273, 'recall': 0.2923626077586206, 'f1-score': 0.22339852141034947, 'support': 14848}}
{'0': {'precision': 0.30957683741648107, 'recall': 0.27416173570019725, 'f1-score': 0.2907949790794979, 'support': 1014}, '1': {'precision': 0.3726731198808637, 'recall': 0.7777777777777778, 'f1-score': 0.5039013340045305, 'support': 1287}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 689}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 337}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 161}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'micro avg': {'precision': 0.3568638392857143, 'recall': 0.3568638392857143, 'f1-score': 0.3568638392857143, 'support': 3584}, 'macro avg': {'precision': 0.06822499572973448, 'recall': 0.10519395134779749, 'f1-score': 0.07946963130840284, 'support': 3584}, 'weighted avg': {'precision': 0.22141217032002886, 'recall': 0.3568638392857143, 'f1-score': 0.26322185425514555, 'support': 3584}}