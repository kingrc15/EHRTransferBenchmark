
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_west
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.4381221532821655
Train: epoch: 1, loss = 0.4252323668450117
Train: epoch: 1, loss = 0.41708757400512697
Train: epoch: 1, loss = 0.4140621954575181
Train: epoch: 1, loss = 0.4105517442822456
Train: epoch: 1, loss = 0.40861665971577166
Train: epoch: 1, loss = 0.4066333331806319
Train: epoch: 1, loss = 0.40432373298332097
Train: epoch: 1, loss = 0.4030141906026337
Train: epoch: 1, loss = 0.40143468327075243
Train: epoch: 1, loss = 0.40008584689010274
Train: epoch: 1, loss = 0.39821728624403474
Train: epoch: 1, loss = 0.39693365142895626
Train: epoch: 1, loss = 0.39585020067436355
Train: epoch: 1, loss = 0.39481719937920573
Train: epoch: 1, loss = 0.3937304568197578
Train: epoch: 1, loss = 0.39263144833638386
Train: epoch: 1, loss = 0.39159542844527295
Train:  Epoch 1, Loss=0.39128720028380043, AUC-ROC Macro=0.6607816692477713, AUC-ROC Micro=0.750842594865921
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3762899066011111, AUC-ROC Macro=0.713587165320688, AUC-ROC Micro=0.7790916163055708
Eval task: 2
Eval:  Epoch 1, Loss=0.368805967271328, AUC-ROC Macro=0.5006091170531178, AUC-ROC Micro=0.5513137110940877
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.3679328234493732
Train: epoch: 2, loss = 0.3693317627906799
Train: epoch: 2, loss = 0.36943544844786325
Train: epoch: 2, loss = 0.368421567864716
Train: epoch: 2, loss = 0.3693173054009676
Train: epoch: 2, loss = 0.370021375430127
Train: epoch: 2, loss = 0.3706837019962924
Train: epoch: 2, loss = 0.36990753198973836
Train: epoch: 2, loss = 0.37000531824926536
Train: epoch: 2, loss = 0.3700069828033447
Train: epoch: 2, loss = 0.370270773849704
Train: epoch: 2, loss = 0.37048400260508063
Train: epoch: 2, loss = 0.37029511517630176
Train: epoch: 2, loss = 0.37005691421883447
Train: epoch: 2, loss = 0.3695407525102297
Train: epoch: 2, loss = 0.36968234630301594
Train: epoch: 2, loss = 0.36909527940346915
Train: epoch: 2, loss = 0.3690295685662164
Train:  Epoch 2, Loss=0.36913550297826786, AUC-ROC Macro=0.7224566147164544, AUC-ROC Micro=0.7899740360574024
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3644458204507828, AUC-ROC Macro=0.7363813737063839, AUC-ROC Micro=0.7971661367468337
Eval task: 2
Eval:  Epoch 2, Loss=0.35231634229421616, AUC-ROC Macro=0.5019573636162851, AUC-ROC Micro=0.5408114970756694
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3646466053277254
Train: epoch: 3, loss = 0.36042093228548766
Train: epoch: 3, loss = 0.3580973333120346
Train: epoch: 3, loss = 0.3604395482502878
Train: epoch: 3, loss = 0.3604461075365543
Train: epoch: 3, loss = 0.3607880195975304
Train: epoch: 3, loss = 0.36098315170833045
Train: epoch: 3, loss = 0.36039790069684385
Train: epoch: 3, loss = 0.3603076514518923
Train: epoch: 3, loss = 0.3597451878711581
Train: epoch: 3, loss = 0.3598672862147743
Train: epoch: 3, loss = 0.3602696223494907
Train: epoch: 3, loss = 0.36007636264539683
Train: epoch: 3, loss = 0.36036720803273575
Train: epoch: 3, loss = 0.36098922447860243
Train: epoch: 3, loss = 0.36139802197925747
Train: epoch: 3, loss = 0.36077080497846886
Train: epoch: 3, loss = 0.3608287499431107
Train:  Epoch 3, Loss=0.3609448876340165, AUC-ROC Macro=0.7417985238561516, AUC-ROC Micro=0.8027393285500137
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3578161336481571, AUC-ROC Macro=0.7483676936134033, AUC-ROC Micro=0.8040769244785666
Eval task: 2
Eval:  Epoch 3, Loss=0.3610855042934418, AUC-ROC Macro=0.4769057813394562, AUC-ROC Micro=0.5194163018221257
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.3540377540886402
Train: epoch: 4, loss = 0.35536297485232354
Train: epoch: 4, loss = 0.3559735887746016
Train: epoch: 4, loss = 0.35531860584393143
Train: epoch: 4, loss = 0.35555700857937333
Train: epoch: 4, loss = 0.35494871098548175
Train: epoch: 4, loss = 0.35503093319279805
Train: epoch: 4, loss = 0.354239035975188
Train: epoch: 4, loss = 0.3550095963643657
Train: epoch: 4, loss = 0.35514383696019647
Train: epoch: 4, loss = 0.3549318672919815
Train: epoch: 4, loss = 0.354916154059271
Train: epoch: 4, loss = 0.3550724043181309
Train: epoch: 4, loss = 0.35467645678669213
Train: epoch: 4, loss = 0.3545969040244818
Train: epoch: 4, loss = 0.35432721901685
Train: epoch: 4, loss = 0.354916242356686
Train: epoch: 4, loss = 0.35507200045718085
Train:  Epoch 4, Loss=0.3553580673678308, AUC-ROC Macro=0.7548521323321471, AUC-ROC Micro=0.8111491429829322
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3546074690918128, AUC-ROC Macro=0.7536313579233949, AUC-ROC Micro=0.8084796419453211
Eval task: 2
Eval:  Epoch 4, Loss=0.37155260145664215, AUC-ROC Macro=0.4946949946769957, AUC-ROC Micro=0.538961903806328
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.3510092268139124
Train: epoch: 5, loss = 0.3538059435412288
Train: epoch: 5, loss = 0.35210778325796127
Train: epoch: 5, loss = 0.35035782208666205
Train: epoch: 5, loss = 0.35005915243923663
Train: epoch: 5, loss = 0.3513371792187293
Train: epoch: 5, loss = 0.35146733251001155
Train: epoch: 5, loss = 0.3507364303711802
Train: epoch: 5, loss = 0.35067736639744707
Train: epoch: 5, loss = 0.35123296031355855
Train: epoch: 5, loss = 0.3512057146836411
Train: epoch: 5, loss = 0.3515495682321489
Train: epoch: 5, loss = 0.3514683459355281
Train: epoch: 5, loss = 0.3511616947448679
Train: epoch: 5, loss = 0.351122264901797
Train: epoch: 5, loss = 0.3507983845053241
Train: epoch: 5, loss = 0.35114068896454925
Train: epoch: 5, loss = 0.3511257084459066
Train:  Epoch 5, Loss=0.35106581115926433, AUC-ROC Macro=0.7633065977415159, AUC-ROC Micro=0.817329825997533
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3522246020535628, AUC-ROC Macro=0.758810011050386, AUC-ROC Micro=0.8131255930374206
Eval task: 2
Eval:  Epoch 5, Loss=0.5105532929301262, AUC-ROC Macro=0.505697046647689, AUC-ROC Micro=0.5362069333469237
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.34767412036657336
Train: epoch: 6, loss = 0.3460639963671565
Train: epoch: 6, loss = 0.34632942751049994
Train: epoch: 6, loss = 0.3471812182478607
Train: epoch: 6, loss = 0.3468186645209789
Train: epoch: 6, loss = 0.3472180206452807
Train: epoch: 6, loss = 0.34810524694621564
Train: epoch: 6, loss = 0.3482578509394079
Train: epoch: 6, loss = 0.34797672318087686
Train: epoch: 6, loss = 0.3479306588023901
Train: epoch: 6, loss = 0.3477948449755257
Train: epoch: 6, loss = 0.3476040644633273
Train: epoch: 6, loss = 0.3472627735596437
Train: epoch: 6, loss = 0.34760088836508135
Train: epoch: 6, loss = 0.34757730617622534
Train: epoch: 6, loss = 0.3475784269347787
Train: epoch: 6, loss = 0.3476156082048136
Train: epoch: 6, loss = 0.34742105059739614
Train:  Epoch 6, Loss=0.34741535295584264, AUC-ROC Macro=0.7705759707678481, AUC-ROC Micro=0.8223270734504109
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.35108470792571705, AUC-ROC Macro=0.7620798449374324, AUC-ROC Micro=0.8149032947991413
Eval task: 2
Eval:  Epoch 6, Loss=0.45773568004369736, AUC-ROC Macro=0.5084298361080246, AUC-ROC Micro=0.5358975918933109
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.35347555453578633, AUC-ROC Macro=0.7632539792371886, AUC-ROC Micro=0.8143732888998483
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.45424044877290726, AUC-ROC Macro=0.49380322891912903, AUC-ROC Micro=0.5369391343563861
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.3144857779890299
Train: epoch: 1, loss = 0.3039081130921841
Train: epoch: 1, loss = 0.29937431481977306
Train:  Epoch 1, Loss=0.29777338783560936, AUC-ROC Macro=0.5431330142173372, AUC-ROC Micro=0.7301438303042065
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3505462010701497, AUC-ROC Macro=0.7560817252041703, AUC-ROC Micro=0.8107370406185263
Eval task: 2
Eval:  Epoch 1, Loss=0.26738524809479713, AUC-ROC Macro=0.6301517842607623, AUC-ROC Micro=0.7796122056889735
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.28705873258411885
Train: epoch: 2, loss = 0.28549212470650676
Train: epoch: 2, loss = 0.2839465982466936
Train:  Epoch 2, Loss=0.2844048413555659, AUC-ROC Macro=0.6352304407121706, AUC-ROC Micro=0.7925702716208967
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.35055457055568695, AUC-ROC Macro=0.7531793503660164, AUC-ROC Micro=0.8080273154215559
Eval task: 2
Eval:  Epoch 2, Loss=0.29188932478427887, AUC-ROC Macro=0.6790553455367601, AUC-ROC Micro=0.8003794489400794
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.2744231232255697
Train: epoch: 3, loss = 0.27567337308079004
Train: epoch: 3, loss = 0.2760761888076862
Train:  Epoch 3, Loss=0.2759420861267197, AUC-ROC Macro=0.6876654577252971, AUC-ROC Micro=0.8096358733340567
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3522261530160904, AUC-ROC Macro=0.7481970897265748, AUC-ROC Micro=0.8038093302985263
Eval task: 2
Eval:  Epoch 3, Loss=0.2683456763625145, AUC-ROC Macro=0.6850826892790427, AUC-ROC Micro=0.7994484092034789
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.27574943721294404
Train: epoch: 4, loss = 0.2735127582773566
Train: epoch: 4, loss = 0.2724279978126287
Train:  Epoch 4, Loss=0.27224182316777484, AUC-ROC Macro=0.7008616786737154, AUC-ROC Micro=0.8174339248888693
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3400159267087777, AUC-ROC Macro=0.7481129316815519, AUC-ROC Micro=0.8034672987101186
Eval task: 2
Eval:  Epoch 4, Loss=0.2697448059916496, AUC-ROC Macro=0.6816398614892516, AUC-ROC Micro=0.8035825424607909
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.2652707877755165
Train: epoch: 5, loss = 0.26556726660579444
Train: epoch: 5, loss = 0.26529369796315827
Train:  Epoch 5, Loss=0.2655003083902017, AUC-ROC Macro=0.7196024659916032, AUC-ROC Micro=0.8247785400939733
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.34134338920315105, AUC-ROC Macro=0.746011736143904, AUC-ROC Micro=0.8032743622042046
Eval task: 2
Eval:  Epoch 5, Loss=0.2549080289900303, AUC-ROC Macro=0.6905634103604974, AUC-ROC Micro=0.8098678702687666
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.2654049719870091
Train: epoch: 6, loss = 0.2636059840768576
Train: epoch: 6, loss = 0.26345134449501834
Train:  Epoch 6, Loss=0.26321429307619154, AUC-ROC Macro=0.7341804519133629, AUC-ROC Micro=0.8299609346243613
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.35142171010375023, AUC-ROC Macro=0.7455170943480778, AUC-ROC Micro=0.8012046877015275
Eval task: 2
Eval:  Epoch 6, Loss=0.2736532427370548, AUC-ROC Macro=0.6925316785733887, AUC-ROC Micro=0.8084171878541938
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3692349083721638, AUC-ROC Macro=0.7454114133079827, AUC-ROC Micro=0.8006806373755587
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.22231080755591393, AUC-ROC Macro=0.7080500620936176, AUC-ROC Micro=0.8125865353410056
{'0': {'precision': 0.5540334855403348, 'recall': 0.2782874617737003, 'f1-score': 0.37048346055979636, 'support': 1308}, '1': {'precision': 0.6313993174061433, 'recall': 0.4601990049751244, 'f1-score': 0.5323741007194244, 'support': 402}, '2': {'precision': 0.5280898876404494, 'recall': 0.07142857142857142, 'f1-score': 0.12583668005354753, 'support': 658}, '3': {'precision': 0.5195652173913043, 'recall': 0.24020100502512562, 'f1-score': 0.3285223367697594, 'support': 1990}, '4': {'precision': 0.48, 'recall': 0.13399503722084366, 'f1-score': 0.20950533462657614, 'support': 806}, '5': {'precision': 0.3023255813953488, 'recall': 0.033419023136246784, 'f1-score': 0.06018518518518518, 'support': 778}, '6': {'precision': 0.5358024691358024, 'recall': 0.16666666666666666, 'f1-score': 0.2542472173403632, 'support': 1302}, '7': {'precision': 0.25, 'recall': 0.0047169811320754715, 'f1-score': 0.009259259259259259, 'support': 424}, '8': {'precision': 0.5621734587251829, 'recall': 0.32725060827250607, 'f1-score': 0.4136870434448289, 'support': 1644}, '9': {'precision': 0.6587458745874587, 'recall': 0.4913835548990645, 'f1-score': 0.562887760857304, 'support': 2031}, '10': {'precision': 0.6390728476821192, 'recall': 0.3368237347294939, 'f1-score': 0.44114285714285717, 'support': 573}, '11': {'precision': 0.4859154929577465, 'recall': 0.29336734693877553, 'f1-score': 0.3658536585365854, 'support': 1176}, '12': {'precision': 0.5786864931846345, 'recall': 0.26384180790960454, 'f1-score': 0.36243694218083045, 'support': 1770}, '13': {'precision': 0.556550424128181, 'recall': 0.4549306625577812, 'f1-score': 0.5006358626536668, 'support': 2596}, '14': {'precision': 0.5334821428571429, 'recall': 0.29379225568531037, 'f1-score': 0.3789139912802219, 'support': 1627}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 484}, '16': {'precision': 0.43243243243243246, 'recall': 0.14088050314465408, 'f1-score': 0.2125237191650854, 'support': 795}, '17': {'precision': 0.4457831325301205, 'recall': 0.06801470588235294, 'f1-score': 0.11802232854864433, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.4166666666666667, 'recall': 0.05725190839694656, 'f1-score': 0.10067114093959732, 'support': 262}, '20': {'precision': 0.35294117647058826, 'recall': 0.010657193605683837, 'f1-score': 0.020689655172413796, 'support': 563}, '21': {'precision': 0.5245398773006135, 'recall': 0.20430107526881722, 'f1-score': 0.294067067927773, 'support': 837}, '22': {'precision': 0.6165556612749762, 'recall': 0.5966850828729282, 'f1-score': 0.606457650912494, 'support': 1086}, '23': {'precision': 0.5398633257403189, 'recall': 0.27526132404181186, 'f1-score': 0.3646153846153847, 'support': 861}, '24': {'precision': 0.48484848484848486, 'recall': 0.25346534653465347, 'f1-score': 0.3328998699609883, 'support': 505}, 'micro avg': {'precision': 0.5596440596440596, 'recall': 0.27513498600874947, 'f1-score': 0.3689063862393321, 'support': 25373}, 'macro avg': {'precision': 0.465178937995842, 'recall': 0.21827283448394955, 'f1-score': 0.27863674031410346, 'support': 25373}, 'weighted avg': {'precision': 0.513730331471646, 'recall': 0.27513498600874947, 'f1-score': 0.3431912037578739, 'support': 25373}, 'samples avg': {'precision': 0.39335402237013567, 'recall': 0.2483850913753832, 'f1-score': 0.2793611240632515, 'support': 25373}}
{'0': {'precision': 0.6341463414634146, 'recall': 0.2653061224489796, 'f1-score': 0.3741007194244605, 'support': 196}, '1': {'precision': 0.4782608695652174, 'recall': 0.13692946058091288, 'f1-score': 0.2129032258064516, 'support': 241}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 145}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 118}, '4': {'precision': 0.5079365079365079, 'recall': 0.15384615384615385, 'f1-score': 0.23616236162361623, 'support': 208}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 100}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '7': {'precision': 0.75, 'recall': 0.15789473684210525, 'f1-score': 0.2608695652173913, 'support': 133}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 89}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87}, '13': {'precision': 0.32142857142857145, 'recall': 0.1232876712328767, 'f1-score': 0.1782178217821782, 'support': 73}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 45}, '15': {'precision': 0.8048780487804879, 'recall': 0.6470588235294118, 'f1-score': 0.717391304347826, 'support': 51}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'micro avg': {'precision': 0.5625, 'recall': 0.09027081243731194, 'f1-score': 0.15557476231633535, 'support': 1994}, 'macro avg': {'precision': 0.13986601356696796, 'recall': 0.0593729187392176, 'f1-score': 0.07918579992807696, 'support': 1994}, 'weighted avg': {'precision': 0.25550020679284396, 'recall': 0.09027081243731194, 'f1-score': 0.12941208592277456, 'support': 1994}, 'samples avg': {'precision': 0.15771484375, 'recall': 0.10642206101190477, 'f1-score': 0.11815243675595238, 'support': 1994}}