
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.149050484895706
Train: epoch: 1, loss = 2.1293727099895476
Train: epoch: 1, loss = 2.1113248135646185
Train: epoch: 1, loss = 2.097413292378187
Train: epoch: 1, loss = 2.0903924450874327
Train: epoch: 1, loss = 2.084170426229636
Train: epoch: 1, loss = 2.079119840434619
Train: epoch: 1, loss = 2.0727143064141273
Train: epoch: 1, loss = 2.0751470975081125
Train: epoch: 1, loss = 2.0721965137124063
Train: epoch: 1, loss = 2.070549514781345
Train: epoch: 1, loss = 2.0680862497289976
Train: epoch: 1, loss = 2.067064259831722
Train: epoch: 1, loss = 2.064300473332405
Train: epoch: 1, loss = 2.0639159108400347
Train: epoch: 1, loss = 2.0632121505215766
Train: epoch: 1, loss = 2.0624530775056167
Train: epoch: 1, loss = 2.0619200699859195
Train: epoch: 1, loss = 2.0612696007678384
Train: epoch: 1, loss = 2.059974416553974
Train: epoch: 1, loss = 2.0585665959119797
Train: epoch: 1, loss = 2.0575045549056745
Train: epoch: 1, loss = 2.0567717287073966
Train: epoch: 1, loss = 2.0557313970973095
Train: epoch: 1, loss = 2.0549217257976533
Train: epoch: 1, loss = 2.0545206558704376
Train: epoch: 1, loss = 2.05371101655342
Train: epoch: 1, loss = 2.052759208168302
Train: epoch: 1, loss = 2.052527169461908
Train: epoch: 1, loss = 2.05194467596213
Train: epoch: 1, loss = 2.051088394388076
Train: epoch: 1, loss = 2.05083824954927
Train: epoch: 1, loss = 2.0507445632508308
Train: epoch: 1, loss = 2.0500989809982917
Train: epoch: 1, loss = 2.0497554918016707
Train: epoch: 1, loss = 2.049144562532504
Train: epoch: 1, loss = 2.0489102931763674
Train: epoch: 1, loss = 2.048141671968134
Train: epoch: 1, loss = 2.0477422528083506
Train: epoch: 1, loss = 2.047407534554601
Train: epoch: 1, loss = 2.047093390691571
Train: epoch: 1, loss = 2.0466575831742513
Train: epoch: 1, loss = 2.0466919356445934
Train:  Epoch 1, Loss=2.0461927579062325, Cohen Kappa=0.376296716312706, MAD=0.7191665859312061
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.030242948696531, Cohen Kappa=0.43735895474202835, MAD=0.7228134533750545
Eval task: 2
Eval:  Epoch 1, Loss=1.9815328244505257, Cohen Kappa=0.005442749706122574, MAD=0.7552996485479871
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.059118794983831, Cohen Kappa=0.3412768568135619, MAD=0.7255852682194222
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9461870378461377, Cohen Kappa=0.0018616927360860513, MAD=0.7541723455059988
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9604483938217163
Train: epoch: 1, loss = 1.9597887280583381
Train: epoch: 1, loss = 1.9632566060622534
Train: epoch: 1, loss = 1.9595363326370716
Train: epoch: 1, loss = 1.958449457168579
Train: epoch: 1, loss = 1.95435328433911
Train: epoch: 1, loss = 1.9544935292005539
Train: epoch: 1, loss = 1.9536788074672222
Train: epoch: 1, loss = 1.9536627069446775
Train: epoch: 1, loss = 1.9535275166034698
Train: epoch: 1, loss = 1.9528015859560532
Train: epoch: 1, loss = 1.9518566837410132
Train: epoch: 1, loss = 1.9514054326369212
Train: epoch: 1, loss = 1.950726819080966
Train: epoch: 1, loss = 1.95078420372804
Train: epoch: 1, loss = 1.9504221573472023
Train: epoch: 1, loss = 1.950741369934643
Train: epoch: 1, loss = 1.9510903479324446
Train: epoch: 1, loss = 1.9511903453500647
Train: epoch: 1, loss = 1.9514361979365349
Train: epoch: 1, loss = 1.951719080720629
Train: epoch: 1, loss = 1.9510881193659522
Train: epoch: 1, loss = 1.9509461245588635
Train: epoch: 1, loss = 1.9509115482866763
Train: epoch: 1, loss = 1.9508295075178146
Train: epoch: 1, loss = 1.9508640632721095
Train: epoch: 1, loss = 1.951168429939835
Train: epoch: 1, loss = 1.9506853883819921
Train: epoch: 1, loss = 1.9507782385472594
Train: epoch: 1, loss = 1.950218417565028
Train: epoch: 1, loss = 1.950346858732162
Train: epoch: 1, loss = 1.950497293639928
Train: epoch: 1, loss = 1.950226395834576
Train: epoch: 1, loss = 1.9499995261080125
Train: epoch: 1, loss = 1.9498700385774885
Train: epoch: 1, loss = 1.9498830355041556
Train: epoch: 1, loss = 1.9498309319728129
Train: epoch: 1, loss = 1.9499200866724316
Train: epoch: 1, loss = 1.9498263030021619
Train: epoch: 1, loss = 1.949412487268448
Train: epoch: 1, loss = 1.9492109774380195
Train: epoch: 1, loss = 1.9490686761197589
Train: epoch: 1, loss = 1.949117686762366
Train:  Epoch 1, Loss=1.9488876833506994, Cohen Kappa=0.0828031998987313, MAD=0.6856483742693553
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.034744885461084, Cohen Kappa=0.4303214427257197, MAD=0.7212865795864641
Eval task: 2
Eval:  Epoch 1, Loss=1.9543752403094852, Cohen Kappa=0.15011133165426127, MAD=0.6829797604108678
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0529123914652856, Cohen Kappa=0.3470402748853977, MAD=0.7194728583349929
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9249217284136806, Cohen Kappa=0.14665540760807183, MAD=0.6863645901683507
{'0': {'precision': 0.3928334439283344, 'recall': 0.8716564417177914, 'f1-score': 0.5415872531828924, 'support': 4075}, '1': {'precision': 0.24342928660826033, 'recall': 0.13577661431064572, 'f1-score': 0.17432220479498095, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.1853416149068323, 'recall': 0.6134868421052632, 'f1-score': 0.28467849647013926, 'support': 1216}, '9': {'precision': 0.14754098360655737, 'recall': 0.02516309412861137, 'f1-score': 0.042993630573248405, 'support': 1073}, 'accuracy': 0.3174838362068966, 'macro avg': {'precision': 0.09691453290499845, 'recall': 0.1646082992262312, 'f1-score': 0.10435815850212608, 'support': 14848}, 'weighted avg': {'precision': 0.18062419647610267, 'recall': 0.3174838362068966, 'f1-score': 0.20869493472324163, 'support': 14848}}
{'0': {'precision': 0.38338658146964855, 'recall': 0.538879697471047, 'f1-score': 0.4480251522892513, 'support': 4231}, '1': {'precision': 0.32247678018575854, 'recall': 0.5175909361955874, 'f1-score': 0.39737524797802537, 'support': 5031}, '2': {'precision': 0.18226600985221675, 'recall': 0.015314569536423841, 'f1-score': 0.028255059182894234, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.1187800963081862, 'recall': 0.24183006535947713, 'f1-score': 0.15931108719052745, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.33640894396551724, 'macro avg': {'precision': 0.100690946781581, 'recall': 0.13136152685625352, 'f1-score': 0.10329665466406986, 'support': 14848}, 'weighted avg': {'precision': 0.2506189854920457, 'recall': 0.33640894396551724, 'f1-score': 0.27019145390486543, 'support': 14848}}