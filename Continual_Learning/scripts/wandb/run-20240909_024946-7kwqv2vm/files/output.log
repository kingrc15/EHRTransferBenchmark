
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.158150802254677
Train: epoch: 1, loss = 2.11879109621048
Train: epoch: 1, loss = 2.096704305013021
Train: epoch: 1, loss = 2.0892108733952046
Train: epoch: 1, loss = 2.083810265779495
Train: epoch: 1, loss = 2.0808120088775954
Train: epoch: 1, loss = 2.0800261337416512
Train: epoch: 1, loss = 2.0754149290919304
Train: epoch: 1, loss = 2.0725105861822763
Train: epoch: 1, loss = 2.0720802308321
Train: epoch: 1, loss = 2.0707323519208214
Train: epoch: 1, loss = 2.0681219935417174
Train: epoch: 1, loss = 2.0665615446292436
Train: epoch: 1, loss = 2.065994819572994
Train: epoch: 1, loss = 2.0643215988874437
Train: epoch: 1, loss = 2.0631877183169127
Train: epoch: 1, loss = 2.0600192620824367
Train: epoch: 1, loss = 2.058241239918603
Train: epoch: 1, loss = 2.0572461821217285
Train: epoch: 1, loss = 2.056311358511448
Train: epoch: 1, loss = 2.0560981837624595
Train: epoch: 1, loss = 2.0557225371761754
Train: epoch: 1, loss = 2.054699483462002
Train: epoch: 1, loss = 2.054720362400015
Train: epoch: 1, loss = 2.053491264915466
Train: epoch: 1, loss = 2.0526667853502127
Train: epoch: 1, loss = 2.0518217463184287
Train: epoch: 1, loss = 2.0516714244868073
Train: epoch: 1, loss = 2.0512159063281685
Train: epoch: 1, loss = 2.0509081672231355
Train: epoch: 1, loss = 2.0504662732155094
Train: epoch: 1, loss = 2.0499707999639214
Train: epoch: 1, loss = 2.0494200709552475
Train: epoch: 1, loss = 2.0484930300186663
Train: epoch: 1, loss = 2.048553769860949
Train: epoch: 1, loss = 2.0480456779731644
Train: epoch: 1, loss = 2.0477000349276775
Train: epoch: 1, loss = 2.0473275767345176
Train: epoch: 1, loss = 2.0464384662952178
Train: epoch: 1, loss = 2.0463376963436604
Train: epoch: 1, loss = 2.046289195825414
Train: epoch: 1, loss = 2.045897817242713
Train: epoch: 1, loss = 2.045728379460268
Train:  Epoch 1, Loss=2.045778362097059, Cohen Kappa=0.3760888116407939, MAD=0.7134129979319599
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.032027741958355, Cohen Kappa=0.4240993091014613, MAD=0.7498955586578122
Eval task: 2
Eval:  Epoch 1, Loss=1.9302682013347232, Cohen Kappa=0.0011122250914014087, MAD=0.7571136048339178
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.055114053446671, Cohen Kappa=0.33800165715606745, MAD=0.7478326218034704
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.922930629088961, Cohen Kappa=0.0010295310310243222, MAD=0.7575912896576578
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9254037165641784
Train: epoch: 1, loss = 1.923601263165474
Train: epoch: 1, loss = 1.9194351887702943
Train: epoch: 1, loss = 1.9169633285701275
Train: epoch: 1, loss = 1.9143784272670745
Train: epoch: 1, loss = 1.913833729525407
Train: epoch: 1, loss = 1.911589664050511
Train: epoch: 1, loss = 1.9122739930450916
Train: epoch: 1, loss = 1.911687973274125
Train: epoch: 1, loss = 1.9104974890351296
Train: epoch: 1, loss = 1.9115245687961577
Train: epoch: 1, loss = 1.9119166276355584
Train: epoch: 1, loss = 1.9119376699282573
Train: epoch: 1, loss = 1.911484358395849
Train: epoch: 1, loss = 1.9114246468544007
Train: epoch: 1, loss = 1.9106606505811214
Train: epoch: 1, loss = 1.9109694639374228
Train: epoch: 1, loss = 1.9107641816801495
Train: epoch: 1, loss = 1.91046297716467
Train: epoch: 1, loss = 1.910678600758314
Train: epoch: 1, loss = 1.9102186765841076
Train: epoch: 1, loss = 1.909965945373882
Train: epoch: 1, loss = 1.9099132051934367
Train: epoch: 1, loss = 1.9101063934713602
Train: epoch: 1, loss = 1.9098820045232774
Train: epoch: 1, loss = 1.9096995000197337
Train: epoch: 1, loss = 1.9092665147560615
Train: epoch: 1, loss = 1.909284272321633
Train: epoch: 1, loss = 1.9090042219490841
Train: epoch: 1, loss = 1.9090879011154174
Train: epoch: 1, loss = 1.9085488934286179
Train: epoch: 1, loss = 1.9085124253295362
Train: epoch: 1, loss = 1.9085986889131141
Train: epoch: 1, loss = 1.9086254074818947
Train: epoch: 1, loss = 1.9087317863702773
Train: epoch: 1, loss = 1.9085447844862937
Train: epoch: 1, loss = 1.9083057564980275
Train: epoch: 1, loss = 1.9081446953980545
Train: epoch: 1, loss = 1.907887425972865
Train: epoch: 1, loss = 1.9079185830801726
Train: epoch: 1, loss = 1.908008095244082
Train: epoch: 1, loss = 1.9080890431574413
Train: epoch: 1, loss = 1.908146255321281
Train:  Epoch 1, Loss=1.9080457789284841, Cohen Kappa=0.1031331558995281, MAD=0.6938645749473247
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.086035498257341, Cohen Kappa=0.25150049595131996, MAD=0.7080435760389445
Eval task: 2
Eval:  Epoch 1, Loss=1.907600614531287, Cohen Kappa=0.0882465293795417, MAD=0.6870277675764738
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.082031046522075, Cohen Kappa=0.13713295980843399, MAD=0.7066117274922769
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8964723656917442, Cohen Kappa=0.043351491397999764, MAD=0.6876741020363621
{'0': {'precision': 0.4420401854714065, 'recall': 0.4912883435582822, 'f1-score': 0.4653649465364947, 'support': 4075}, '1': {'precision': 0.1864201606690877, 'recall': 0.5912739965095986, 'f1-score': 0.2834672021419009, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.2611683848797251, 'recall': 0.0625, 'f1-score': 0.10086264100862641, 'support': 1216}, '9': {'precision': 0.09158679446219382, 'recall': 0.08014911463187326, 'f1-score': 0.08548707753479125, 'support': 1073}, 'accuracy': 0.25983297413793105, 'macro avg': {'precision': 0.09812155254824131, 'recall': 0.12252114546997542, 'f1-score': 0.09351818672218132, 'support': 14848}, 'weighted avg': {'precision': 0.18529505001243246, 'recall': 0.25983297413793105, 'f1-score': 0.19685292948101313, 'support': 14848}}
{'0': {'precision': 0.3676914874711214, 'recall': 0.46578117964880683, 'f1-score': 0.4109643460125137, 'support': 4442}, '1': {'precision': 0.332680591818973, 'recall': 0.5942479595802566, 'f1-score': 0.4265587948109918, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 176}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.3452990301724138, 'macro avg': {'precision': 0.07003720792900944, 'recall': 0.10600291392290635, 'f1-score': 0.08375231408235055, 'support': 14848}, 'weighted avg': {'precision': 0.22530037128550354, 'recall': 0.3452990301724138, 'f1-score': 0.2707822725676825, 'support': 14848}}