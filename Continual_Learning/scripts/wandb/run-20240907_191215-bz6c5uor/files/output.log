
Experiment dir: ./exp/Test_los_south
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1566628301143647
Train: epoch: 1, loss = 2.1193054994940757
Train: epoch: 1, loss = 2.120333969593048
Train: epoch: 1, loss = 2.117662434279919
Train: epoch: 1, loss = 2.1135571646690368
Train: epoch: 1, loss = 2.107696638504664
Train: epoch: 1, loss = 2.0974468161378588
Train: epoch: 1, loss = 2.0910554552823304
Train: epoch: 1, loss = 2.0848813239071102
Train: epoch: 1, loss = 2.0815024178028105
Train: epoch: 1, loss = 2.0782966884699734
Train: epoch: 1, loss = 2.074900295933088
Train: epoch: 1, loss = 2.0738090373002565
Train: epoch: 1, loss = 2.0716996708512307
Train: epoch: 1, loss = 2.070039097905159
Train: epoch: 1, loss = 2.068249389305711
Train: epoch: 1, loss = 2.066839746271863
Train: epoch: 1, loss = 2.0655349730120767
Train: epoch: 1, loss = 2.064315224289894
Train: epoch: 1, loss = 2.0635190119743347
Train: epoch: 1, loss = 2.0630927358922504
Train: epoch: 1, loss = 2.0617421983588824
Train: epoch: 1, loss = 2.059826906271603
Train: epoch: 1, loss = 2.0600003639856976
Train: epoch: 1, loss = 2.059510423517227
Train: epoch: 1, loss = 2.058806673563444
Train: epoch: 1, loss = 2.058567806129102
Train: epoch: 1, loss = 2.057881642622607
Train: epoch: 1, loss = 2.05674406232505
Train: epoch: 1, loss = 2.056393474141757
Train: epoch: 1, loss = 2.0558384325619667
Train: epoch: 1, loss = 2.0550671037845314
Train: epoch: 1, loss = 2.053446111137217
Train: epoch: 1, loss = 2.052311637962566
Train: epoch: 1, loss = 2.0521399911642075
Train: epoch: 1, loss = 2.051708105785979
Train: epoch: 1, loss = 2.0511904976174637
Train: epoch: 1, loss = 2.0508715240735755
Train: epoch: 1, loss = 2.050459358631036
Train: epoch: 1, loss = 2.050036511361599
Train: epoch: 1, loss = 2.0492530528801245
Train: epoch: 1, loss = 2.0486262179272514
Train: epoch: 1, loss = 2.048416202456452
Train:  Epoch 1, Loss=2.0481802860941207, Cohen Kappa=0.3677697473176821, MAD=0.7215245217052334
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.02867650369118, Cohen Kappa=0.42508567135979447, MAD=0.7367362326453436
Eval task: 2
Eval:  Epoch 1, Loss=1.9220403638379326, Cohen Kappa=0.0008293866854938159, MAD=0.7396284716471493
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0522657077887962, Cohen Kappa=0.33846736349603257, MAD=0.7334513111793666
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9140930011354644, Cohen Kappa=0.0016828643384004804, MAD=0.7399802148635037
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.960343126654625
Train: epoch: 1, loss = 1.9513407742977142
Train: epoch: 1, loss = 1.9491009140014648
Train: epoch: 1, loss = 1.9474583461880683
Train: epoch: 1, loss = 1.9427865245342255
Train: epoch: 1, loss = 1.9405333844820658
Train: epoch: 1, loss = 1.9403990996735436
Train: epoch: 1, loss = 1.9410697720199823
Train: epoch: 1, loss = 1.9411876378456752
Train: epoch: 1, loss = 1.9419039160609246
Train: epoch: 1, loss = 1.9413270833817395
Train: epoch: 1, loss = 1.9400540888806184
Train: epoch: 1, loss = 1.9384697763277934
Train: epoch: 1, loss = 1.939279358599867
Train: epoch: 1, loss = 1.9402149146000545
Train: epoch: 1, loss = 1.9403495115414262
Train: epoch: 1, loss = 1.9406159383058548
Train: epoch: 1, loss = 1.9406009551882744
Train: epoch: 1, loss = 1.940185594966537
Train: epoch: 1, loss = 1.939443542599678
Train: epoch: 1, loss = 1.9395557135627384
Train: epoch: 1, loss = 1.939925353499976
Train: epoch: 1, loss = 1.9392556138919748
Train: epoch: 1, loss = 1.9393842263023058
Train: epoch: 1, loss = 1.9390009186267854
Train: epoch: 1, loss = 1.9388546881538171
Train: epoch: 1, loss = 1.9390194988913005
Train: epoch: 1, loss = 1.938868730302368
Train: epoch: 1, loss = 1.9391256471337943
Train: epoch: 1, loss = 1.9390694316824277
Train: epoch: 1, loss = 1.9394044874944996
Train: epoch: 1, loss = 1.939606281388551
Train: epoch: 1, loss = 1.9386833354198572
Train: epoch: 1, loss = 1.9385537510934998
Train: epoch: 1, loss = 1.9385542466129575
Train: epoch: 1, loss = 1.937328301899963
Train: epoch: 1, loss = 1.9361504045048274
Train: epoch: 1, loss = 1.935090264803485
Train: epoch: 1, loss = 1.934167708464158
Train: epoch: 1, loss = 1.933599971950054
Train: epoch: 1, loss = 1.9324200849271402
Train: epoch: 1, loss = 1.9313369572020713
Train: epoch: 1, loss = 1.9304046502778696
Train:  Epoch 1, Loss=1.9301490155356271, Cohen Kappa=0.122207141782807, MAD=0.6922786896261853
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.039676600489123, Cohen Kappa=0.3720724053519163, MAD=0.7471369884258234
Eval task: 2
Eval:  Epoch 1, Loss=1.9475256554011642, Cohen Kappa=0.1921396000587302, MAD=0.7073202301771255
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0584277510643005, Cohen Kappa=0.2602245242753207, MAD=0.7423520709306165
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8995956963506238, Cohen Kappa=0.08954607624117428, MAD=0.70866201283663
{'0': {'precision': 0.381201695337821, 'recall': 0.3752147239263804, 'f1-score': 0.3781845164481821, 'support': 4075}, '1': {'precision': 0.21050036973132857, 'recall': 0.5961605584642233, 'f1-score': 0.3111394480371618, 'support': 2865}, '2': {'precision': 0.125, 'recall': 0.00055005500550055, 'f1-score': 0.001095290251916758, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.25993555316863587, 'recall': 0.19901315789473684, 'f1-score': 0.22543083372147182, 'support': 1216}, '9': {'precision': 0.14798206278026907, 'recall': 0.24603914259086673, 'f1-score': 0.1848092404620231, 'support': 1073}, 'accuracy': 0.2521551724137931, 'macro avg': {'precision': 0.11246196810180545, 'recall': 0.14169776378817078, 'f1-score': 0.11006593289207559, 'support': 14848}, 'weighted avg': {'precision': 0.19252403379567398, 'recall': 0.2521551724137931, 'f1-score': 0.19577935544530278, 'support': 14848}}
{'0': {'precision': 0.35187303402916786, 'recall': 0.5540297163439892, 'f1-score': 0.4303952430919902, 'support': 4442}, '1': {'precision': 0.3335530652603823, 'recall': 0.49164399533618347, 'f1-score': 0.3974550310266279, 'support': 5146}, '2': {'precision': 1.0, 'recall': 0.0003937007874015748, 'f1-score': 0.0007870916961826053, 'support': 2540}, '3': {'precision': 0.2647058823529412, 'recall': 0.006917755572636433, 'f1-score': 0.01348314606741573, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 176}, '9': {'precision': 0.13270142180094788, 'recall': 0.25, 'f1-score': 0.17337461300309598, 'support': 112}, 'accuracy': 0.33869881465517243, 'macro avg': {'precision': 0.2082833403443439, 'recall': 0.13029851680402108, 'f1-score': 0.10154951248853124, 'support': 14848}, 'weighted avg': {'precision': 0.4161320718730047, 'recall': 0.33869881465517243, 'f1-score': 0.2691324085449896, 'support': 14848}}