Experiment dir: ./exp/Test_phen_west_baseline
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.43866683334112166
Train: epoch: 1, loss = 0.4229230608046055
Train: epoch: 1, loss = 0.41717583293716115
Train: epoch: 1, loss = 0.4143454344943166
Train: epoch: 1, loss = 0.41257080498337745
Train: epoch: 1, loss = 0.4097693464408318
Train: epoch: 1, loss = 0.40750454542892317
Train: epoch: 1, loss = 0.40601967603899536
Train: epoch: 1, loss = 0.40371041715972955
Train: epoch: 1, loss = 0.40158345326036216
Train: epoch: 1, loss = 0.39981065146625044
Train: epoch: 1, loss = 0.3983347143294911
Train: epoch: 1, loss = 0.3968876976233262
Train: epoch: 1, loss = 0.3954982246405312
Train: epoch: 1, loss = 0.3942236090948184
Train: epoch: 1, loss = 0.39315857651643454
Train: epoch: 1, loss = 0.39236185893416403
Train: epoch: 1, loss = 0.39103063857803744
Train:  Epoch 1, Loss=0.3909290596603328, AUC-ROC Macro=0.6626166598408443, AUC-ROC Micro=0.7514881097003828
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.37080033247669536, AUC-ROC Macro=0.715117605025541, AUC-ROC Micro=0.7824960482188525
Eval task: 2
Eval:  Epoch 1, Loss=0.32628854364156723, AUC-ROC Macro=0.511238092053302, AUC-ROC Micro=0.5449310737126656
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.37576003700494764
Train: epoch: 2, loss = 0.37584656655788423
Train: epoch: 2, loss = 0.3749040346344312
Train: epoch: 2, loss = 0.3744925131462514
Train: epoch: 2, loss = 0.3751653968691826
Train: epoch: 2, loss = 0.3741810105741024
Train: epoch: 2, loss = 0.3727592641647373
Train: epoch: 2, loss = 0.3727360452711582
Train: epoch: 2, loss = 0.37201764528950054
Train: epoch: 2, loss = 0.3713618197664619
Train: epoch: 2, loss = 0.3715726864812049
Train: epoch: 2, loss = 0.37170689428846043
Train: epoch: 2, loss = 0.3714890172504462
Train: epoch: 2, loss = 0.37101250070546354
Train: epoch: 2, loss = 0.37044772632420064
Train: epoch: 2, loss = 0.3699778314307332
Train: epoch: 2, loss = 0.3694772466228289
Train: epoch: 2, loss = 0.3689541371208098
Train:  Epoch 2, Loss=0.36883343615491165, AUC-ROC Macro=0.7233288028833615, AUC-ROC Micro=0.7906672096360431
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.36395656938354176, AUC-ROC Macro=0.7372600909143446, AUC-ROC Micro=0.7956402085265841
Eval task: 2
Eval:  Epoch 2, Loss=0.3525744751095772, AUC-ROC Macro=0.49779794367385644, AUC-ROC Micro=0.5436075361035505
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3609621677547693
Train: epoch: 3, loss = 0.3589430771023035
Train: epoch: 3, loss = 0.36091470914582413
Train: epoch: 3, loss = 0.3601439380645752
Train: epoch: 3, loss = 0.36048370152711867
Train: epoch: 3, loss = 0.3601934525370598
Train: epoch: 3, loss = 0.360488666508879
Train: epoch: 3, loss = 0.36095543308183553
Train: epoch: 3, loss = 0.3607968377901448
Train: epoch: 3, loss = 0.3607911687195301
Train: epoch: 3, loss = 0.3607079571485519
Train: epoch: 3, loss = 0.3608979309474428
Train: epoch: 3, loss = 0.3604466075335558
Train: epoch: 3, loss = 0.3608092714792916
Train: epoch: 3, loss = 0.3608623045533895
Train: epoch: 3, loss = 0.36076919940765945
Train: epoch: 3, loss = 0.3607863582889823
Train: epoch: 3, loss = 0.36068606432527306
Train:  Epoch 3, Loss=0.36071747917191593, AUC-ROC Macro=0.7420525780829056, AUC-ROC Micro=0.8032174805280488
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.35705143585801125, AUC-ROC Macro=0.7497317707697434, AUC-ROC Micro=0.8048727348856222
Eval task: 2
Eval:  Epoch 3, Loss=0.35800300538539886, AUC-ROC Macro=0.49180740122329014, AUC-ROC Micro=0.5276341988204997
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.35255715109407904
Train: epoch: 4, loss = 0.35456787373870613
Train: epoch: 4, loss = 0.3538533371935288
Train: epoch: 4, loss = 0.3541166270710528
Train: epoch: 4, loss = 0.3541529733091593
Train: epoch: 4, loss = 0.354675636763374
Train: epoch: 4, loss = 0.3549839929917029
Train: epoch: 4, loss = 0.3550437278300524
Train: epoch: 4, loss = 0.3550372367186679
Train: epoch: 4, loss = 0.35484214503318073
Train: epoch: 4, loss = 0.3548254735632376
Train: epoch: 4, loss = 0.35466438364237546
Train: epoch: 4, loss = 0.3549321092149386
Train: epoch: 4, loss = 0.35485860581908907
Train: epoch: 4, loss = 0.3546466550976038
Train: epoch: 4, loss = 0.35450994443614037
Train: epoch: 4, loss = 0.35476888312574695
Train: epoch: 4, loss = 0.35466691971653036
Train:  Epoch 4, Loss=0.3547112776581039, AUC-ROC Macro=0.7553114923708394, AUC-ROC Micro=0.8121178079652075
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.35322102159261703, AUC-ROC Macro=0.7554159892149067, AUC-ROC Micro=0.8109962508846165
Eval task: 2
Eval:  Epoch 4, Loss=0.3788033351302147, AUC-ROC Macro=0.4792326316131841, AUC-ROC Micro=0.5432259211893321
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.3471505831927061
Train: epoch: 5, loss = 0.3462806675955653
Train: epoch: 5, loss = 0.3464529294272264
Train: epoch: 5, loss = 0.3477936263009906
Train: epoch: 5, loss = 0.34869578056037426
Train: epoch: 5, loss = 0.34822594630221526
Train: epoch: 5, loss = 0.3481344584907804
Train: epoch: 5, loss = 0.3486563739553094
Train: epoch: 5, loss = 0.34889787137508393
Train: epoch: 5, loss = 0.34904704193770886
Train: epoch: 5, loss = 0.3494203887202523
Train: epoch: 5, loss = 0.3495565038174391
Train: epoch: 5, loss = 0.34939403862907337
Train: epoch: 5, loss = 0.3493612184801272
Train: epoch: 5, loss = 0.3491922588000695
Train: epoch: 5, loss = 0.34971045221202074
Train: epoch: 5, loss = 0.3498391682084869
Train: epoch: 5, loss = 0.35006889577127165
Train:  Epoch 5, Loss=0.35006328638089007, AUC-ROC Macro=0.7651385217795604, AUC-ROC Micro=0.8186757819631191
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.34993260850509006, AUC-ROC Macro=0.7611089522425429, AUC-ROC Micro=0.8153458150727004
Eval task: 2
Eval:  Epoch 5, Loss=0.3687872290611267, AUC-ROC Macro=0.4727455060003418, AUC-ROC Micro=0.5125443347831558
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3464040684700012
Train: epoch: 6, loss = 0.3479953359439969
Train: epoch: 6, loss = 0.3473261166115602
Train: epoch: 6, loss = 0.34735721310600637
Train: epoch: 6, loss = 0.346758043423295
Train: epoch: 6, loss = 0.34631098420669637
Train: epoch: 6, loss = 0.3468598809944732
Train: epoch: 6, loss = 0.346172207519412
Train: epoch: 6, loss = 0.34613875907328395
Train: epoch: 6, loss = 0.3464238825812936
Train: epoch: 6, loss = 0.3465884347124533
Train: epoch: 6, loss = 0.3469125912959377
Train: epoch: 6, loss = 0.3471273415421064
Train: epoch: 6, loss = 0.34643289878964423
Train: epoch: 6, loss = 0.34687179409960905
Train: epoch: 6, loss = 0.3467697730334476
Train: epoch: 6, loss = 0.3464170139940346
Train: epoch: 6, loss = 0.346584660605424
Train:  Epoch 6, Loss=0.34656013224878884, AUC-ROC Macro=0.7722454224505426, AUC-ROC Micro=0.8234340488085182
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3511046419541041, AUC-ROC Macro=0.7616082663035649, AUC-ROC Micro=0.8144304034631746
Eval task: 2
Eval:  Epoch 6, Loss=0.38871604204177856, AUC-ROC Macro=0.4789518478326802, AUC-ROC Micro=0.5387522396331859
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.35333645219604176, AUC-ROC Macro=0.7629069784872513, AUC-ROC Micro=0.8143532014782227
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.39784474670886993, AUC-ROC Macro=0.488645852269788, AUC-ROC Micro=0.5422304892309734
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.2672256152331829
Train: epoch: 1, loss = 0.253203262090683
Train: epoch: 1, loss = 0.2453756154080232
Train:  Epoch 1, Loss=0.2443139634070557, AUC-ROC Macro=0.5803084951247951, AUC-ROC Micro=0.7545463737878885
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.47276616220672923, AUC-ROC Macro=0.6807715884450293, AUC-ROC Micro=0.6765554218441503
Eval task: 2
Eval:  Epoch 1, Loss=0.22930537536740303, AUC-ROC Macro=0.6522708340838078, AUC-ROC Micro=0.7943113980672928
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.2274537631869316
Train: epoch: 2, loss = 0.2260323028638959
Train: epoch: 2, loss = 0.22432813437034688
Train:  Epoch 2, Loss=0.2239299910083698, AUC-ROC Macro=0.6904809280232379, AUC-ROC Micro=0.8107030855941509
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.4922068516413371, AUC-ROC Macro=0.6380947402228273, AUC-ROC Micro=0.6487111341297677
Eval task: 2
Eval:  Epoch 2, Loss=0.2232428379356861, AUC-ROC Macro=0.6888985751590464, AUC-ROC Micro=0.8081104901631329
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.21608963433653117
Train: epoch: 3, loss = 0.21524122124537826
Train: epoch: 3, loss = 0.2167493642990788
Train:  Epoch 3, Loss=0.21736454767894484, AUC-ROC Macro=0.7289844757827408, AUC-ROC Micro=0.8258734983482484
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.4853111406167348, AUC-ROC Macro=0.6323774752427215, AUC-ROC Micro=0.6537571372016061
Eval task: 2
Eval:  Epoch 3, Loss=0.22288291528820992, AUC-ROC Macro=0.6959077541882904, AUC-ROC Micro=0.8093080933641028
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.21991902716457845
Train: epoch: 4, loss = 0.21545464830473066
Train: epoch: 4, loss = 0.21411409279952445
Train:  Epoch 4, Loss=0.21311452525165323, AUC-ROC Macro=0.7524437958276496, AUC-ROC Micro=0.835446485473085
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.5127974773446718, AUC-ROC Macro=0.6161421860773907, AUC-ROC Micro=0.6382528817554709
Eval task: 2
Eval:  Epoch 4, Loss=0.22163774818181992, AUC-ROC Macro=0.696480184339, AUC-ROC Micro=0.8129606371361576
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.21115701422095298
Train: epoch: 5, loss = 0.21068335441872477
Train: epoch: 5, loss = 0.21010721037785213
Train:  Epoch 5, Loss=0.20966153479468508, AUC-ROC Macro=0.7691780558171384, AUC-ROC Micro=0.8426252453100889
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.5203868262469769, AUC-ROC Macro=0.5936781650860468, AUC-ROC Micro=0.6301905814256633
Eval task: 2
Eval:  Epoch 5, Loss=0.2200000248849392, AUC-ROC Macro=0.7018771507706806, AUC-ROC Micro=0.8179136466457396
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.20593326065689324
Train: epoch: 6, loss = 0.20621123569086194
Train: epoch: 6, loss = 0.2050672191257278
Train:  Epoch 6, Loss=0.20577013660984977, AUC-ROC Macro=0.780221765527451, AUC-ROC Micro=0.8510162320667354
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.5171329416334629, AUC-ROC Macro=0.5915157770381593, AUC-ROC Micro=0.6292731863377266
Eval task: 2
Eval:  Epoch 6, Loss=0.22018104046583176, AUC-ROC Macro=0.7070640490929496, AUC-ROC Micro=0.8197440646734395
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.5207693700989088, AUC-ROC Macro=0.5949826057569121, AUC-ROC Micro=0.6297628299187494
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.21893242746591568, AUC-ROC Macro=0.7237016240229415, AUC-ROC Micro=0.8215577427869478
{'0': {'precision': 0.3643031784841076, 'recall': 0.34174311926605505, 'f1-score': 0.3526627218934911, 'support': 1308}, '1': {'precision': 0.3383458646616541, 'recall': 0.11194029850746269, 'f1-score': 0.16822429906542058, 'support': 402}, '2': {'precision': 0.14285714285714285, 'recall': 0.001519756838905775, 'f1-score': 0.0030075187969924814, 'support': 658}, '3': {'precision': 0.42857142857142855, 'recall': 0.003015075376884422, 'f1-score': 0.005988023952095808, 'support': 1990}, '4': {'precision': 0.24425887265135698, 'recall': 0.14516129032258066, 'f1-score': 0.1821011673151751, 'support': 806}, '5': {'precision': 0.1794871794871795, 'recall': 0.008997429305912597, 'f1-score': 0.017135862913096694, 'support': 778}, '6': {'precision': 0.5945945945945946, 'recall': 0.05069124423963134, 'f1-score': 0.09341825902335457, 'support': 1302}, '7': {'precision': 0.06060606060606061, 'recall': 0.0047169811320754715, 'f1-score': 0.0087527352297593, 'support': 424}, '8': {'precision': 0.75, 'recall': 0.0036496350364963502, 'f1-score': 0.007263922518159806, 'support': 1644}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2031}, '10': {'precision': 0.5, 'recall': 0.006980802792321117, 'f1-score': 0.013769363166953527, 'support': 573}, '11': {'precision': 0.37209302325581395, 'recall': 0.027210884353741496, 'f1-score': 0.05071315372424723, 'support': 1176}, '12': {'precision': 0.4146341463414634, 'recall': 0.0288135593220339, 'f1-score': 0.05388272583201268, 'support': 1770}, '13': {'precision': 0.35826771653543305, 'recall': 0.03505392912172573, 'f1-score': 0.06385964912280702, 'support': 2596}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1627}, '15': {'precision': 0.0967741935483871, 'recall': 0.012396694214876033, 'f1-score': 0.021978021978021976, 'support': 484}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 795}, '17': {'precision': 1.0, 'recall': 0.001838235294117647, 'f1-score': 0.0036697247706422016, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 262}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 563}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 837}, '22': {'precision': 0.9047619047619048, 'recall': 0.017495395948434623, 'f1-score': 0.03432700993676604, 'support': 1086}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 861}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 505}, 'micro avg': {'precision': 0.34468247895944915, 'recall': 0.035510187995112914, 'f1-score': 0.06438703683853218, 'support': 25373}, 'macro avg': {'precision': 0.26998221225426106, 'recall': 0.03204897324293019, 'f1-score': 0.04323016636955985, 'support': 25373}, 'weighted avg': {'precision': 0.3109687664648859, 'recall': 0.035510187995112914, 'f1-score': 0.04803477715390164, 'support': 25373}, 'samples avg': {'precision': 0.09527277870783729, 'recall': 0.024639668009813917, 'f1-score': 0.036655649864035605, 'support': 25373}}
{'0': {'precision': 0.5766423357664233, 'recall': 0.4030612244897959, 'f1-score': 0.4744744744744745, 'support': 196}, '1': {'precision': 0.504424778761062, 'recall': 0.23651452282157676, 'f1-score': 0.3220338983050848, 'support': 241}, '2': {'precision': 0.2222222222222222, 'recall': 0.013793103448275862, 'f1-score': 0.025974025974025972, 'support': 145}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 118}, '4': {'precision': 0.5769230769230769, 'recall': 0.21634615384615385, 'f1-score': 0.3146853146853147, 'support': 208}, '5': {'precision': 0.3333333333333333, 'recall': 0.03, 'f1-score': 0.055045871559633024, 'support': 100}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '7': {'precision': 0.9642857142857143, 'recall': 0.20300751879699247, 'f1-score': 0.3354037267080745, 'support': 133}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 89}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87}, '13': {'precision': 0.2962962962962963, 'recall': 0.1095890410958904, 'f1-score': 0.16, 'support': 73}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 45}, '15': {'precision': 0.8157894736842105, 'recall': 0.6078431372549019, 'f1-score': 0.6966292134831461, 'support': 51}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'micro avg': {'precision': 0.5688487584650113, 'recall': 0.12637913741223672, 'f1-score': 0.20681165367254822, 'support': 1994}, 'macro avg': {'precision': 0.17159668925089355, 'recall': 0.0728061880701435, 'f1-score': 0.09536986100759014, 'support': 1994}, 'weighted avg': {'precision': 0.3067345626051729, 'recall': 0.12637913741223672, 'f1-score': 0.1690819049172915, 'support': 1994}, 'samples avg': {'precision': 0.22137044270833334, 'recall': 0.15034412202380953, 'f1-score': 0.1672295640557359, 'support': 1994}}