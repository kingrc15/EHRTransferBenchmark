
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
midwest_val.csv
test_listfile.csv
midwest_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1890028887987136
Train: epoch: 1, loss = 2.149419692456722
Train: epoch: 1, loss = 2.125095600684484
Train: epoch: 1, loss = 2.109518467783928
Train: epoch: 1, loss = 2.0982359948158265
Train: epoch: 1, loss = 2.0879073493679363
Train: epoch: 1, loss = 2.083781218273299
Train: epoch: 1, loss = 2.079777955785394
Train: epoch: 1, loss = 2.0765463052193325
Train: epoch: 1, loss = 2.0735424650907515
Train: epoch: 1, loss = 2.072476572502743
Train: epoch: 1, loss = 2.0695007416109243
Train: epoch: 1, loss = 2.0691321813601715
Train: epoch: 1, loss = 2.0675110372475216
Train: epoch: 1, loss = 2.065282662431399
Train: epoch: 1, loss = 2.064029521457851
Train: epoch: 1, loss = 2.0619744937560136
Train: epoch: 1, loss = 2.061860678328408
Train: epoch: 1, loss = 2.061666524441619
Train: epoch: 1, loss = 2.0616848991811274
Train: epoch: 1, loss = 2.060692752883548
Train: epoch: 1, loss = 2.0590461177175694
Train: epoch: 1, loss = 2.057890028461166
Train: epoch: 1, loss = 2.056663503025969
Train: epoch: 1, loss = 2.0560057310819624
Train: epoch: 1, loss = 2.054854643230255
Train: epoch: 1, loss = 2.0542214012366755
Train: epoch: 1, loss = 2.0539519500306676
Train: epoch: 1, loss = 2.0534229887559494
Train: epoch: 1, loss = 2.0527347601652144
Train: epoch: 1, loss = 2.0524558130771884
Train: epoch: 1, loss = 2.0520303974673153
Train: epoch: 1, loss = 2.051298956094366
Train: epoch: 1, loss = 2.0508408174444646
Train: epoch: 1, loss = 2.0503301929576057
Train: epoch: 1, loss = 2.0496520091427697
Train: epoch: 1, loss = 2.0487710473988505
Train: epoch: 1, loss = 2.0481121004255196
Train: epoch: 1, loss = 2.047548526204549
Train: epoch: 1, loss = 2.0469244458377363
Train: epoch: 1, loss = 2.0466363117898383
Train: epoch: 1, loss = 2.045944051572255
Train: epoch: 1, loss = 2.045702117847842
Train:  Epoch 1, Loss=2.0452038641793386, Cohen Kappa=0.38054573521616475, MAD=0.7200717645138208
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0298417333898873, Cohen Kappa=0.4294754638176058, MAD=0.7402883723630354
Eval task: 2
Eval:  Epoch 1, Loss=1.9777789013139133, Cohen Kappa=0.009838003509685889, MAD=0.7452021931727832
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0553877292008234, Cohen Kappa=0.33777232981689476, MAD=0.7352940970317473
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9431545939938775, Cohen Kappa=0.002185839455256633, MAD=0.7440810356372729
midwest_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.965540668964386
Train: epoch: 1, loss = 1.973209820985794
Train: epoch: 1, loss = 1.9740571508804956
Train: epoch: 1, loss = 1.9772049793601036
Train: epoch: 1, loss = 1.9775790461301803
Train: epoch: 1, loss = 1.9750699082016945
Train: epoch: 1, loss = 1.974419047151293
Train: epoch: 1, loss = 1.975514690876007
Train: epoch: 1, loss = 1.97389275987943
Train: epoch: 1, loss = 1.9734680123329162
Train: epoch: 1, loss = 1.9734235113859178
Train: epoch: 1, loss = 1.9734992694358031
Train: epoch: 1, loss = 1.9742646436049387
Train: epoch: 1, loss = 1.973829236967223
Train: epoch: 1, loss = 1.9736039990584056
Train: epoch: 1, loss = 1.975015982873738
Train: epoch: 1, loss = 1.9749892811564838
Train: epoch: 1, loss = 1.9748404731353124
Train: epoch: 1, loss = 1.9746270244686228
Train: epoch: 1, loss = 1.974872669696808
Train: epoch: 1, loss = 1.97404164206414
Train: epoch: 1, loss = 1.9734605080973018
Train: epoch: 1, loss = 1.9731403818856115
Train: epoch: 1, loss = 1.9725894689559937
Train: epoch: 1, loss = 1.9723458931207656
Train: epoch: 1, loss = 1.9719224751683382
Train: epoch: 1, loss = 1.9718006202247407
Train: epoch: 1, loss = 1.9716333985754422
Train: epoch: 1, loss = 1.9714639626289236
Train: epoch: 1, loss = 1.9720634384155273
Train: epoch: 1, loss = 1.9720247055061402
Train: epoch: 1, loss = 1.9714839636348187
Train: epoch: 1, loss = 1.9717100139820214
Train: epoch: 1, loss = 1.9712791673926746
Train: epoch: 1, loss = 1.9712118940523693
Train: epoch: 1, loss = 1.9705436985194682
Train: epoch: 1, loss = 1.9698577396450816
Train: epoch: 1, loss = 1.9696744739852454
Train: epoch: 1, loss = 1.9691288577287624
Train: epoch: 1, loss = 1.9684269980192184
Train: epoch: 1, loss = 1.9679133657856684
Train: epoch: 1, loss = 1.9672592628002166
Train: epoch: 1, loss = 1.9669800374258397
Train:  Epoch 1, Loss=1.9668545610972814, Cohen Kappa=0.061275449122518144, MAD=0.6912701249505918
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0252096776304573, Cohen Kappa=0.4217979050249141, MAD=0.7197510102200976
Eval task: 2
Eval:  Epoch 1, Loss=1.9617240346711258, Cohen Kappa=0.06082364924671024, MAD=0.6609344084879946
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0581840831657936, Cohen Kappa=0.3293484010344496, MAD=0.7113780504399715
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9259901252286187, Cohen Kappa=0.06339501873271436, MAD=0.6647518743550412
{'0': {'precision': 0.40136986301369865, 'recall': 0.3595092024539877, 'f1-score': 0.3792880258899677, 'support': 4075}, '1': {'precision': 0.24730242053076698, 'recall': 0.5919720767888307, 'f1-score': 0.3488635194898693, 'support': 2865}, '2': {'precision': 0.5384615384615384, 'recall': 0.02695269526952695, 'f1-score': 0.05133577789418543, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.1611789697291556, 'recall': 0.49917763157894735, 'f1-score': 0.2436772380570052, 'support': 1216}, '9': {'precision': 0.11180124223602485, 'recall': 0.05032618825722274, 'f1-score': 0.06940874035989718, 'support': 1073}, 'accuracy': 0.2607085129310345, 'macro avg': {'precision': 0.14601140339711843, 'recall': 0.15279377943485156, 'f1-score': 0.10925733016909248, 'support': 14848}, 'weighted avg': {'precision': 0.24508237228141524, 'recall': 0.2607085129310345, 'f1-score': 0.20266758034315804, 'support': 14848}}
{'0': {'precision': 0.40992167101827676, 'recall': 0.037107066887260697, 'f1-score': 0.06805374945817079, 'support': 4231}, '1': {'precision': 0.3456727640806883, 'recall': 0.9503080898429735, 'f1-score': 0.5069451807867671, 'support': 5031}, '2': {'precision': 0.15079365079365079, 'recall': 0.02359271523178808, 'f1-score': 0.0408017179670723, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.11328125, 'recall': 0.09477124183006536, 'f1-score': 0.10320284697508897, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.33836206896551724, 'macro avg': {'precision': 0.1019669335892616, 'recall': 0.11057791137920878, 'f1-score': 0.07190034951870991, 'support': 14848}, 'weighted avg': {'precision': 0.2608054814780261, 'recall': 0.33836206896551724, 'f1-score': 0.1999281815920373, 'support': 14848}}