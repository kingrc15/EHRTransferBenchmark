
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_west_baseline
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
west_val.csv
test_listfile.csv
west_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1936385399103164
Train: epoch: 1, loss = 2.147477224469185
Train: epoch: 1, loss = 2.12677394370238
Train: epoch: 1, loss = 2.107422297149897
Train: epoch: 1, loss = 2.1009003196954725
Train: epoch: 1, loss = 2.091406436661879
Train: epoch: 1, loss = 2.0844434653861184
Train: epoch: 1, loss = 2.0806749529391526
Train: epoch: 1, loss = 2.075430764026112
Train: epoch: 1, loss = 2.0733516675829886
Train: epoch: 1, loss = 2.069686732021245
Train: epoch: 1, loss = 2.067756674985091
Train: epoch: 1, loss = 2.067612529763809
Train: epoch: 1, loss = 2.0657795681272235
Train: epoch: 1, loss = 2.063393044710159
Train: epoch: 1, loss = 2.061528461538255
Train: epoch: 1, loss = 2.0611785177623525
Train: epoch: 1, loss = 2.0602425805396503
Train: epoch: 1, loss = 2.059489832740081
Train: epoch: 1, loss = 2.058673972547054
Train: epoch: 1, loss = 2.0581639784290675
Train: epoch: 1, loss = 2.0562683875723318
Train: epoch: 1, loss = 2.0549948435762655
Train: epoch: 1, loss = 2.0541631935785216
Train: epoch: 1, loss = 2.0544258577346803
Train: epoch: 1, loss = 2.0542150016931386
Train: epoch: 1, loss = 2.0534273197474304
Train: epoch: 1, loss = 2.052574684023857
Train: epoch: 1, loss = 2.0525641553771905
Train: epoch: 1, loss = 2.0516938662727675
Train: epoch: 1, loss = 2.051388062238693
Train: epoch: 1, loss = 2.0510732154361904
Train: epoch: 1, loss = 2.050473352110747
Train: epoch: 1, loss = 2.050052106801201
Train: epoch: 1, loss = 2.050028638635363
Train: epoch: 1, loss = 2.049548794925213
Train: epoch: 1, loss = 2.0497541048558983
Train: epoch: 1, loss = 2.0490403570783764
Train: epoch: 1, loss = 2.0481632517087154
Train: epoch: 1, loss = 2.0480205963402986
Train: epoch: 1, loss = 2.0474376456185084
Train: epoch: 1, loss = 2.046725648755119
Train: epoch: 1, loss = 2.0460470675590425
Train:  Epoch 1, Loss=2.0457999461582728, Cohen Kappa=0.3813772316568923, MAD=0.7163563788823349
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0353001890511346, Cohen Kappa=0.4061816712981612, MAD=0.7217068196347105
Eval task: 2
Eval:  Epoch 1, Loss=1.878950969926242, Cohen Kappa=0.0006380665705455479, MAD=0.7418767314553689
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.060020245354751, Cohen Kappa=0.32834928766470584, MAD=0.7214408190312829
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.892023805914254, Cohen Kappa=0.002127627269252419, MAD=0.7429465789988113
west_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.8854556173086165
Train: epoch: 1, loss = 1.8838755318522453
Train: epoch: 1, loss = 1.8783954441547395
Train: epoch: 1, loss = 1.8758317393064499
Train: epoch: 1, loss = 1.8789296144247054
Train: epoch: 1, loss = 1.8775249493122101
Train: epoch: 1, loss = 1.8746855014562607
Train: epoch: 1, loss = 1.8738667049258948
Train: epoch: 1, loss = 1.874176288512018
Train: epoch: 1, loss = 1.875475235104561
Train: epoch: 1, loss = 1.87496271583167
Train: epoch: 1, loss = 1.8749254668752353
Train: epoch: 1, loss = 1.8737346094846725
Train: epoch: 1, loss = 1.873863433599472
Train: epoch: 1, loss = 1.8747724211613337
Train: epoch: 1, loss = 1.8750927760079503
Train: epoch: 1, loss = 1.8754281604991239
Train: epoch: 1, loss = 1.875292139980528
Train: epoch: 1, loss = 1.8757763033791592
Train: epoch: 1, loss = 1.875074915856123
Train: epoch: 1, loss = 1.874683177471161
Train:  Epoch 1, Loss=1.875528875868661, Cohen Kappa=0.0014530621157954338, MAD=0.7218774807425354
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.1454015970230103, Cohen Kappa=0.06100907620842322, MAD=0.7297375670231315
Eval task: 2
Eval:  Epoch 1, Loss=1.8711800780789605, Cohen Kappa=0.001752061339338029, MAD=0.710987091223829
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0916504428304474, Cohen Kappa=0.08713461924306887, MAD=0.7279425056865806
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8792265776930184, Cohen Kappa=0.006496032564774601, MAD=0.7104467150859456
{'0': {'precision': 0.29868819374369326, 'recall': 0.07263803680981595, 'f1-score': 0.11685748124753258, 'support': 4075}, '1': {'precision': 0.2025972076264825, 'recall': 0.9420593368237348, 'f1-score': 0.3334774819299438, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.5625, 'recall': 0.007205764611689352, 'f1-score': 0.01422924901185771, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.427734375, 'recall': 0.18009868421052633, 'f1-score': 0.25347222222222227, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.21706627155172414, 'macro avg': {'precision': 0.14915197763701757, 'recall': 0.12020018224557664, 'f1-score': 0.07180364344115564, 'support': 14848}, 'weighted avg': {'precision': 0.2034134489059417, 'recall': 0.21706627155172414, 'f1-score': 0.1183729644430911, 'support': 14848}}
{'0': {'precision': 0.13793103448275862, 'recall': 0.00645682001614205, 'f1-score': 0.012336160370084809, 'support': 2478}, '1': {'precision': 0.35179599670962436, 'recall': 0.9888246628131021, 'f1-score': 0.5189604611184144, 'support': 2595}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1084}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 501}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 215}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 121}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 103}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, '8': {'precision': 0.35714285714285715, 'recall': 0.032679738562091505, 'f1-score': 0.059880239520958084, 'support': 153}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102}, 'accuracy': 0.34846443965517243, 'macro avg': {'precision': 0.08468698883352402, 'recall': 0.10279612213913356, 'f1-score': 0.059117686100945734, 'support': 7424}, 'weighted avg': {'precision': 0.1763667257613966, 'recall': 0.34846443965517243, 'f1-score': 0.18675014529176487, 'support': 7424}}