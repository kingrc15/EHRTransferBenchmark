
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_northeast
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.143700105547905
Train: epoch: 1, loss = 2.1295545759797094
Train: epoch: 1, loss = 2.1100972135861715
Train: epoch: 1, loss = 2.1083747270703315
Train: epoch: 1, loss = 2.0996076263189316
Train: epoch: 1, loss = 2.094195414483547
Train: epoch: 1, loss = 2.089861578685897
Train: epoch: 1, loss = 2.084259258583188
Train: epoch: 1, loss = 2.080805107686255
Train: epoch: 1, loss = 2.076727074086666
Train: epoch: 1, loss = 2.0741626355322924
Train: epoch: 1, loss = 2.071385268966357
Train: epoch: 1, loss = 2.0693313519771284
Train: epoch: 1, loss = 2.066868307037013
Train: epoch: 1, loss = 2.0644606035550437
Train: epoch: 1, loss = 2.0620983570069074
Train: epoch: 1, loss = 2.0603031811293433
Train: epoch: 1, loss = 2.0587134205301605
Train: epoch: 1, loss = 2.0582828565647726
Train: epoch: 1, loss = 2.0576845971643927
Train: epoch: 1, loss = 2.0571336630980173
Train: epoch: 1, loss = 2.056041016063907
Train: epoch: 1, loss = 2.055213559218075
Train: epoch: 1, loss = 2.054376245588064
Train: epoch: 1, loss = 2.0533910499811174
Train: epoch: 1, loss = 2.0518278758800945
Train: epoch: 1, loss = 2.051121741776113
Train: epoch: 1, loss = 2.0505625059987818
Train: epoch: 1, loss = 2.050020784591806
Train: epoch: 1, loss = 2.049399144987265
Train: epoch: 1, loss = 2.048789344314606
Train: epoch: 1, loss = 2.0484222463332116
Train: epoch: 1, loss = 2.047637598803549
Train: epoch: 1, loss = 2.0475502544641495
Train: epoch: 1, loss = 2.0473516097749984
Train: epoch: 1, loss = 2.046706217378378
Train: epoch: 1, loss = 2.0463372386790613
Train: epoch: 1, loss = 2.0463140958233885
Train: epoch: 1, loss = 2.0459165928608334
Train: epoch: 1, loss = 2.0454864833056927
Train: epoch: 1, loss = 2.045067754940289
Train: epoch: 1, loss = 2.0442583230279743
Train: epoch: 1, loss = 2.043923131449278
Train:  Epoch 1, Loss=2.0437067527907233, Cohen Kappa=0.380463613939624, MAD=0.7167938665641356
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0291716189220033, Cohen Kappa=0.4321259430958255, MAD=0.7025304295054366
Eval task: 2
Eval:  Epoch 1, Loss=1.8828528608594621, Cohen Kappa=0.015513378537096001, MAD=0.6267824673780342
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.05478513857414, Cohen Kappa=0.3316683431673778, MAD=0.6977926741215923
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.899661089692797, Cohen Kappa=0.013704292817761088, MAD=0.6261208830371132
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.8617458367347717
Train: epoch: 1, loss = 1.855985826253891
Train: epoch: 1, loss = 1.8535644541184106
Train: epoch: 1, loss = 1.8559484486281872
Train: epoch: 1, loss = 1.8547601799964906
Train: epoch: 1, loss = 1.8579702877998352
Train: epoch: 1, loss = 1.8556781344754356
Train: epoch: 1, loss = 1.854907231554389
Train: epoch: 1, loss = 1.856238409943051
Train: epoch: 1, loss = 1.8571131610870362
Train:  Epoch 1, Loss=1.8577238651003156, Cohen Kappa=0.03685095388213122, MAD=0.5843381660716065
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0474195048726838, Cohen Kappa=0.3703638125434141, MAD=0.6993912929230314
Eval task: 2
Eval:  Epoch 1, Loss=1.8740907396589006, Cohen Kappa=0.009115281501340444, MAD=0.5590441358465121
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0613625337337624, Cohen Kappa=0.2610813161029135, MAD=0.69883936878812
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8835684146199907, Cohen Kappa=0.01509372807034548, MAD=0.5627727976247601
{'0': {'precision': 0.38809034907597534, 'recall': 0.5101840490797546, 'f1-score': 0.4408396946564885, 'support': 4075}, '1': {'precision': 0.2410739387123981, 'recall': 0.5986038394415357, 'f1-score': 0.3437218158132077, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.27060133630289535, 'recall': 0.3996710526315789, 'f1-score': 0.32270916334661354, 'support': 1216}, '9': {'precision': 0.11187607573149742, 'recall': 0.06057781919850885, 'f1-score': 0.07859733978234583, 'support': 1073}, 'accuracy': 0.2926320043103448, 'macro avg': {'precision': 0.10116416998227662, 'recall': 0.15690367603513783, 'f1-score': 0.11858680135986555, 'support': 14848}, 'weighted avg': {'precision': 0.18327311833915932, 'recall': 0.2926320043103448, 'f1-score': 0.2194190494508331, 'support': 14848}}
{'0': {'precision': 0.32558139534883723, 'recall': 0.20710059171597633, 'f1-score': 0.2531645569620253, 'support': 1014}, '1': {'precision': 0.3655547991831178, 'recall': 0.8344988344988346, 'f1-score': 0.5084023668639054, 'support': 1287}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 689}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 337}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 161}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'micro avg': {'precision': 0.35825892857142855, 'recall': 0.35825892857142855, 'f1-score': 0.35825892857142855, 'support': 3584}, 'macro avg': {'precision': 0.0691136194531955, 'recall': 0.1041599426214811, 'f1-score': 0.07615669238259307, 'support': 3584}, 'weighted avg': {'precision': 0.22338408522109196, 'recall': 0.35825892857142855, 'f1-score': 0.25419160349144526, 'support': 3584}}