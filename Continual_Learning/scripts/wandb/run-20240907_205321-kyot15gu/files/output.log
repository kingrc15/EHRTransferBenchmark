
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1367265796661377
Train: epoch: 1, loss = 2.1113116565346717
Train: epoch: 1, loss = 2.10282284617424
Train: epoch: 1, loss = 2.0927796599268915
Train: epoch: 1, loss = 2.0851087654829024
Train: epoch: 1, loss = 2.0861326307058334
Train: epoch: 1, loss = 2.0812308502197268
Train: epoch: 1, loss = 2.0752746288478376
Train: epoch: 1, loss = 2.0728542913993198
Train: epoch: 1, loss = 2.070081878185272
Train: epoch: 1, loss = 2.068502025550062
Train: epoch: 1, loss = 2.066329463620981
Train: epoch: 1, loss = 2.0648740276465047
Train: epoch: 1, loss = 2.0628584411314557
Train: epoch: 1, loss = 2.061928067803383
Train: epoch: 1, loss = 2.0613675248622894
Train: epoch: 1, loss = 2.0603287868640003
Train: epoch: 1, loss = 2.059376289215353
Train: epoch: 1, loss = 2.0586218557546014
Train: epoch: 1, loss = 2.057882346481085
Train: epoch: 1, loss = 2.0577866592009864
Train: epoch: 1, loss = 2.056583871137012
Train: epoch: 1, loss = 2.056002822207368
Train: epoch: 1, loss = 2.0547159694631896
Train: epoch: 1, loss = 2.0546283735513686
Train: epoch: 1, loss = 2.054853649254029
Train: epoch: 1, loss = 2.054012346356003
Train: epoch: 1, loss = 2.052806557587215
Train: epoch: 1, loss = 2.0516345676882515
Train: epoch: 1, loss = 2.050939030488332
Train: epoch: 1, loss = 2.050537244831362
Train: epoch: 1, loss = 2.0506246068328617
Train: epoch: 1, loss = 2.050444279836886
Train: epoch: 1, loss = 2.049670059347854
Train: epoch: 1, loss = 2.048892380850656
Train: epoch: 1, loss = 2.0486333176328078
Train: epoch: 1, loss = 2.048445101106489
Train: epoch: 1, loss = 2.047936400990737
Train: epoch: 1, loss = 2.0474370290071535
Train: epoch: 1, loss = 2.046847812950611
Train: epoch: 1, loss = 2.0463834260295077
Train: epoch: 1, loss = 2.046496651243596
Train: epoch: 1, loss = 2.0460788921838584
Train:  Epoch 1, Loss=2.0455320707321167, Cohen Kappa=0.37651800800445023, MAD=0.7181707177555474
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0308971857202462, Cohen Kappa=0.4234390097177557, MAD=0.7476404127056944
Eval task: 2
Eval:  Epoch 1, Loss=1.9270536632373416, Cohen Kappa=0.0006616361339394361, MAD=0.7547526854002037
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0569944546140473, Cohen Kappa=0.34525523616642784, MAD=0.7463092072645344
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.919853403650481, Cohen Kappa=0.0017074333986301093, MAD=0.7551931021685132
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.931125894188881
Train: epoch: 1, loss = 1.9410779264569282
Train: epoch: 1, loss = 1.9380792566140492
Train: epoch: 1, loss = 1.9388362063467504
Train: epoch: 1, loss = 1.9397862504720689
Train: epoch: 1, loss = 1.941547249952952
Train: epoch: 1, loss = 1.9420697441271373
Train: epoch: 1, loss = 1.9427716449648142
Train: epoch: 1, loss = 1.942038560244772
Train: epoch: 1, loss = 1.9414850566387176
Train: epoch: 1, loss = 1.9421665540066633
Train: epoch: 1, loss = 1.9419113340973855
Train: epoch: 1, loss = 1.9422256356936234
Train: epoch: 1, loss = 1.9414871536408151
Train: epoch: 1, loss = 1.940357206106186
Train: epoch: 1, loss = 1.9393872429057957
Train: epoch: 1, loss = 1.9389818994788564
Train: epoch: 1, loss = 1.9391882335808541
Train: epoch: 1, loss = 1.9389292663963218
Train: epoch: 1, loss = 1.939061252564192
Train: epoch: 1, loss = 1.9391758752720696
Train: epoch: 1, loss = 1.9389025169881908
Train: epoch: 1, loss = 1.9390373942903851
Train: epoch: 1, loss = 1.9395336112131676
Train: epoch: 1, loss = 1.9397787682771683
Train: epoch: 1, loss = 1.9397028717398643
Train: epoch: 1, loss = 1.940165251603833
Train: epoch: 1, loss = 1.9396024602438722
Train: epoch: 1, loss = 1.9400095387779432
Train: epoch: 1, loss = 1.9399655041694641
Train: epoch: 1, loss = 1.939855377616421
Train: epoch: 1, loss = 1.9399261112324893
Train: epoch: 1, loss = 1.9397211114926771
Train: epoch: 1, loss = 1.9394748146218412
Train: epoch: 1, loss = 1.938984531896455
Train: epoch: 1, loss = 1.9383068149619633
Train: epoch: 1, loss = 1.9370260751730688
Train: epoch: 1, loss = 1.9358798858366515
Train: epoch: 1, loss = 1.9348174271675256
Train: epoch: 1, loss = 1.9340104361176491
Train: epoch: 1, loss = 1.933446080263068
Train: epoch: 1, loss = 1.9332236933566276
Train: epoch: 1, loss = 1.9324927664357563
Train:  Epoch 1, Loss=1.9317698534693037, Cohen Kappa=0.11356238906462701, MAD=0.689253825634908
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0568728714153686, Cohen Kappa=0.36375775700718316, MAD=0.7367456317597894
Eval task: 2
Eval:  Epoch 1, Loss=1.9412283506886712, Cohen Kappa=0.1682136395693441, MAD=0.697251668819214
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0602443362104483, Cohen Kappa=0.3063960076507086, MAD=0.7355204822242843
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8980560405501004, Cohen Kappa=0.09380521311160894, MAD=0.6987082136900145
{'0': {'precision': 0.3707678689975658, 'recall': 0.8223312883435583, 'f1-score': 0.5110958590711507, 'support': 4075}, '1': {'precision': 0.2093487814622453, 'recall': 0.18289703315881325, 'f1-score': 0.19523099850968703, 'support': 2865}, '2': {'precision': 0.18181818181818182, 'recall': 0.0033003300330033004, 'f1-score': 0.006482982171799027, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.1790920449812578, 'recall': 0.3536184210526316, 'f1-score': 0.2377661045064971, 'support': 1216}, '9': {'precision': 0.1718213058419244, 'recall': 0.13979496738117428, 'f1-score': 0.1541623843782117, 'support': 1073}, 'accuracy': 0.3004445043103448, 'macro avg': {'precision': 0.11128481831011752, 'recall': 0.15019420399691807, 'f1-score': 0.11047383286373455, 'support': 14848}, 'weighted avg': {'precision': 0.1914971017958959, 'recall': 0.3004445043103448, 'f1-score': 0.2093466001852939, 'support': 14848}}
{'0': {'precision': 0.34843304843304845, 'recall': 0.5506528590724898, 'f1-score': 0.4268016053044844, 'support': 4442}, '1': {'precision': 0.3298708216806499, 'recall': 0.4813447337738049, 'f1-score': 0.3914658237850652, 'support': 5146}, '2': {'precision': 0.25, 'recall': 0.0003937007874015748, 'f1-score': 0.0007861635220125786, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.10743801652892562, 'recall': 0.07386363636363637, 'f1-score': 0.08754208754208753, 'support': 176}, '9': {'precision': 0.08762886597938144, 'recall': 0.15178571428571427, 'f1-score': 0.1111111111111111, 'support': 112}, 'accuracy': 0.3336476293103448, 'macro avg': {'precision': 0.11233707526220053, 'recall': 0.1258040644283047, 'f1-score': 0.10177067912647608, 'support': 14848}, 'weighted avg': {'precision': 0.26326632364001934, 'recall': 0.3336476293103448, 'f1-score': 0.265368033887273, 'support': 14848}}