
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_west_baseline
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.43578624099493024
Train: epoch: 1, loss = 0.42065365746617317
Train: epoch: 1, loss = 0.4157362365971009
Train: epoch: 1, loss = 0.4128401352278888
Train: epoch: 1, loss = 0.41144412286579607
Train: epoch: 1, loss = 0.41050994742661717
Train: epoch: 1, loss = 0.40955320698874337
Train: epoch: 1, loss = 0.40701469076797364
Train: epoch: 1, loss = 0.4056426410211457
Train: epoch: 1, loss = 0.4034829490184784
Train: epoch: 1, loss = 0.40281897758218377
Train: epoch: 1, loss = 0.40311536407098175
Train: epoch: 1, loss = 0.4028387442918924
Train: epoch: 1, loss = 0.4020180075296334
Train: epoch: 1, loss = 0.4012674556573232
Train: epoch: 1, loss = 0.40027169504668564
Train: epoch: 1, loss = 0.39884604511453825
Train: epoch: 1, loss = 0.3977520741191175
Train:  Epoch 1, Loss=0.39718844325522074, AUC-ROC Macro=0.641164100974263, AUC-ROC Micro=0.7394543229707446
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.37537306050459546, AUC-ROC Macro=0.7081134327288696, AUC-ROC Micro=0.7749358403487132
Eval task: 2
Eval:  Epoch 1, Loss=0.32725583016872406, AUC-ROC Macro=0.5071822513181308, AUC-ROC Micro=0.5605982335631495
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.38258043766021727
Train: epoch: 2, loss = 0.37637824460864067
Train: epoch: 2, loss = 0.37721572764217853
Train: epoch: 2, loss = 0.3757806137762964
Train: epoch: 2, loss = 0.37284787686169146
Train: epoch: 2, loss = 0.3731611876189709
Train: epoch: 2, loss = 0.37391628580433983
Train: epoch: 2, loss = 0.37349706546403466
Train: epoch: 2, loss = 0.37337266676955755
Train: epoch: 2, loss = 0.37361141142249105
Train: epoch: 2, loss = 0.3733583577925509
Train: epoch: 2, loss = 0.3724957829465469
Train: epoch: 2, loss = 0.3723732869556317
Train: epoch: 2, loss = 0.3718424398132733
Train: epoch: 2, loss = 0.37142785199483236
Train: epoch: 2, loss = 0.37129279936198145
Train: epoch: 2, loss = 0.3713173848609714
Train: epoch: 2, loss = 0.3709426867341002
Train:  Epoch 2, Loss=0.3710384859875736, AUC-ROC Macro=0.7182982113291442, AUC-ROC Micro=0.7870369935782613
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3644683373471101, AUC-ROC Macro=0.7335192626151396, AUC-ROC Micro=0.7936935782952951
Eval task: 2
Eval:  Epoch 2, Loss=0.3386417403817177, AUC-ROC Macro=0.4947208812671706, AUC-ROC Micro=0.5440959101842724
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3682318565249443
Train: epoch: 3, loss = 0.36603738870471714
Train: epoch: 3, loss = 0.3648620576163133
Train: epoch: 3, loss = 0.36478651117533445
Train: epoch: 3, loss = 0.36417865569889546
Train: epoch: 3, loss = 0.36324772259841365
Train: epoch: 3, loss = 0.363267373197845
Train: epoch: 3, loss = 0.3633177701570094
Train: epoch: 3, loss = 0.3636052657663822
Train: epoch: 3, loss = 0.3633272517621517
Train: epoch: 3, loss = 0.3627051996642893
Train: epoch: 3, loss = 0.362763168339928
Train: epoch: 3, loss = 0.36268121768075684
Train: epoch: 3, loss = 0.3627557427276458
Train: epoch: 3, loss = 0.36263121840854484
Train: epoch: 3, loss = 0.3622007990721613
Train: epoch: 3, loss = 0.3620322894436472
Train: epoch: 3, loss = 0.36215708828220766
Train:  Epoch 3, Loss=0.3621309430293548, AUC-ROC Macro=0.7398013190486359, AUC-ROC Micro=0.8011770260983897
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3589194839199384, AUC-ROC Macro=0.7455116371584036, AUC-ROC Micro=0.8021540539219499
Eval task: 2
Eval:  Epoch 3, Loss=0.3644637241959572, AUC-ROC Macro=0.48894836949637877, AUC-ROC Micro=0.5465326098555009
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.35765879034996034
Train: epoch: 4, loss = 0.35909192003309726
Train: epoch: 4, loss = 0.35893370635807514
Train: epoch: 4, loss = 0.3572486268915236
Train: epoch: 4, loss = 0.3580428229570389
Train: epoch: 4, loss = 0.3580733620499571
Train: epoch: 4, loss = 0.35836921191641263
Train: epoch: 4, loss = 0.35771955457516014
Train: epoch: 4, loss = 0.35749694558481376
Train: epoch: 4, loss = 0.35744735769182445
Train: epoch: 4, loss = 0.3573274289207025
Train: epoch: 4, loss = 0.3570575131103396
Train: epoch: 4, loss = 0.35711869125755935
Train: epoch: 4, loss = 0.3567740057249154
Train: epoch: 4, loss = 0.35632521002491313
Train: epoch: 4, loss = 0.3562520272471011
Train: epoch: 4, loss = 0.35620538266266094
Train: epoch: 4, loss = 0.35627047665003275
Train:  Epoch 4, Loss=0.3563545190615532, AUC-ROC Macro=0.7524088613334895, AUC-ROC Micro=0.8098163872954485
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.35690832634766895, AUC-ROC Macro=0.7533346528648016, AUC-ROC Micro=0.8082861168222422
Eval task: 2
Eval:  Epoch 4, Loss=0.40304747223854065, AUC-ROC Macro=0.48333282027445357, AUC-ROC Micro=0.5487432837548224
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.35113064497709273
Train: epoch: 5, loss = 0.35244157921522856
Train: epoch: 5, loss = 0.3500171881665786
Train: epoch: 5, loss = 0.3509942246973515
Train: epoch: 5, loss = 0.3502403547614813
Train: epoch: 5, loss = 0.35136225666850807
Train: epoch: 5, loss = 0.35166432406221115
Train: epoch: 5, loss = 0.3523582292813808
Train: epoch: 5, loss = 0.3523190139068498
Train: epoch: 5, loss = 0.35216913125663996
Train: epoch: 5, loss = 0.3520907829363238
Train: epoch: 5, loss = 0.3521149140223861
Train: epoch: 5, loss = 0.35211294236091467
Train: epoch: 5, loss = 0.3519419408749257
Train: epoch: 5, loss = 0.35187462201714514
Train: epoch: 5, loss = 0.35167888688854876
Train: epoch: 5, loss = 0.35157886336831484
Train: epoch: 5, loss = 0.35171496931049556
Train:  Epoch 5, Loss=0.35166617013857915, AUC-ROC Macro=0.7614476973840066, AUC-ROC Micro=0.8163659953819433
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.35275696218013763, AUC-ROC Macro=0.758185020507817, AUC-ROC Micro=0.811946985112179
Eval task: 2
Eval:  Epoch 5, Loss=0.39549002796411514, AUC-ROC Macro=0.48542642635704814, AUC-ROC Micro=0.536848613803095
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.34877790093421934
Train: epoch: 6, loss = 0.34673077907413247
Train: epoch: 6, loss = 0.3463811013102531
Train: epoch: 6, loss = 0.34740258313715455
Train: epoch: 6, loss = 0.3481868782490492
Train: epoch: 6, loss = 0.3493345771854122
Train: epoch: 6, loss = 0.34909298996840205
Train: epoch: 6, loss = 0.34934033613651994
Train: epoch: 6, loss = 0.34875035477181276
Train: epoch: 6, loss = 0.3488163747191429
Train: epoch: 6, loss = 0.34925554318184204
Train: epoch: 6, loss = 0.34929378286624946
Train: epoch: 6, loss = 0.34966280681009476
Train: epoch: 6, loss = 0.34974384318505014
Train: epoch: 6, loss = 0.3493233367751042
Train: epoch: 6, loss = 0.34907955762464554
Train: epoch: 6, loss = 0.3485070893782027
Train: epoch: 6, loss = 0.34812155604776407
Train:  Epoch 6, Loss=0.3482246932127537, AUC-ROC Macro=0.7693938625169584, AUC-ROC Micro=0.8212632500900943
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3512006103992462, AUC-ROC Macro=0.7626119330170884, AUC-ROC Micro=0.8142200855208026
Eval task: 2
Eval:  Epoch 6, Loss=0.3964122235774994, AUC-ROC Macro=0.4810867671835976, AUC-ROC Micro=0.5252420184118419
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3530021806557973, AUC-ROC Macro=0.763034054306887, AUC-ROC Micro=0.8143852100482232
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.39591460675001144, AUC-ROC Macro=0.5090522848373824, AUC-ROC Micro=0.5318482240757688
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.26448462173342707
Train: epoch: 1, loss = 0.25200698092579843
Train: epoch: 1, loss = 0.2466597771892945
Train:  Epoch 1, Loss=0.24488002837409314, AUC-ROC Macro=0.5796909849258415, AUC-ROC Micro=0.7509027525944769
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.49335989356040955, AUC-ROC Macro=0.6650146734837493, AUC-ROC Micro=0.6423622820684878
Eval task: 2
Eval:  Epoch 1, Loss=0.23378488421440125, AUC-ROC Macro=0.641406486532091, AUC-ROC Micro=0.7825376298190934
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.2327576031535864
Train: epoch: 2, loss = 0.22669670332223177
Train: epoch: 2, loss = 0.2258035083860159
Train:  Epoch 2, Loss=0.22586659562110467, AUC-ROC Macro=0.6828591178777832, AUC-ROC Micro=0.8063621539393406
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.514962013810873, AUC-ROC Macro=0.6473598906880835, AUC-ROC Micro=0.6389748168276702
Eval task: 2
Eval:  Epoch 2, Loss=0.22577842324972153, AUC-ROC Macro=0.6820178346085909, AUC-ROC Micro=0.8038831987828073
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.2209374738484621
Train: epoch: 3, loss = 0.21811051920056343
Train: epoch: 3, loss = 0.21884882455070814
Train:  Epoch 3, Loss=0.21850579959137859, AUC-ROC Macro=0.7232465000585164, AUC-ROC Micro=0.8238557709583862
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.5252950886885325, AUC-ROC Macro=0.6342106139388065, AUC-ROC Micro=0.6303928654888182
Eval task: 2
Eval:  Epoch 3, Loss=0.22210588306188583, AUC-ROC Macro=0.7015123928134757, AUC-ROC Micro=0.8129153427946056
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.21860433600842952
Train: epoch: 4, loss = 0.21391162469983102
Train: epoch: 4, loss = 0.21334560892234247
Train:  Epoch 4, Loss=0.214102919135341, AUC-ROC Macro=0.7445390266847752, AUC-ROC Micro=0.8335416437594984
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.5084992585082849, AUC-ROC Macro=0.6284112088852892, AUC-ROC Micro=0.6345341113564499
Eval task: 2
Eval:  Epoch 4, Loss=0.2212456911802292, AUC-ROC Macro=0.7037047000862549, AUC-ROC Micro=0.8158130658142922
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.2047796918451786
Train: epoch: 5, loss = 0.20811443326994777
Train: epoch: 5, loss = 0.20999897907177606
Train:  Epoch 5, Loss=0.20984065975515923, AUC-ROC Macro=0.7619385911873893, AUC-ROC Micro=0.8428059122595691
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.5337979843219122, AUC-ROC Macro=0.6173656973022282, AUC-ROC Micro=0.6252768841872248
Eval task: 2
Eval:  Epoch 5, Loss=0.21995611861348152, AUC-ROC Macro=0.7110382544188764, AUC-ROC Micro=0.8173440803873695
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.20712870728224517
Train: epoch: 6, loss = 0.20721417464315892
Train: epoch: 6, loss = 0.20680690832436086
Train:  Epoch 6, Loss=0.2066886955548461, AUC-ROC Macro=0.773794563513015, AUC-ROC Micro=0.8491359085107386
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.554742249349753, AUC-ROC Macro=0.6189495639359663, AUC-ROC Micro=0.6223186824499927
Eval task: 2
Eval:  Epoch 6, Loss=0.22157394140958786, AUC-ROC Macro=0.711032232568926, AUC-ROC Micro=0.8174649820908977
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.5576687902212143, AUC-ROC Macro=0.6205490492755054, AUC-ROC Micro=0.6239143109299414
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.2206554003059864, AUC-ROC Macro=0.7322197511444206, AUC-ROC Micro=0.8192294943799456
{'0': {'precision': 0.2623738587217684, 'recall': 0.41743119266055045, 'f1-score': 0.3222189436411921, 'support': 1308}, '1': {'precision': 0.5652173913043478, 'recall': 0.06467661691542288, 'f1-score': 0.11607142857142855, 'support': 402}, '2': {'precision': 0.2, 'recall': 0.001519756838905775, 'f1-score': 0.0030165912518853697, 'support': 658}, '3': {'precision': 1.0, 'recall': 0.001507537688442211, 'f1-score': 0.0030105368790767687, 'support': 1990}, '4': {'precision': 0.29484029484029484, 'recall': 0.1488833746898263, 'f1-score': 0.1978565539983512, 'support': 806}, '5': {'precision': 0.08333333333333333, 'recall': 0.0012853470437017994, 'f1-score': 0.002531645569620253, 'support': 778}, '6': {'precision': 0.5714285714285714, 'recall': 0.02457757296466974, 'f1-score': 0.0471281296023564, 'support': 1302}, '7': {'precision': 0.05327868852459016, 'recall': 0.030660377358490566, 'f1-score': 0.038922155688622756, 'support': 424}, '8': {'precision': 0.8235294117647058, 'recall': 0.00851581508515815, 'f1-score': 0.016857314870559904, 'support': 1644}, '9': {'precision': 0.5, 'recall': 0.0004923682914820286, 'f1-score': 0.0009837678307919333, 'support': 2031}, '10': {'precision': 0.6666666666666666, 'recall': 0.0034904013961605585, 'f1-score': 0.006944444444444445, 'support': 573}, '11': {'precision': 0.7142857142857143, 'recall': 0.008503401360544218, 'f1-score': 0.016806722689075633, 'support': 1176}, '12': {'precision': 0.6666666666666666, 'recall': 0.0022598870056497176, 'f1-score': 0.0045045045045045045, 'support': 1770}, '13': {'precision': 0.3881578947368421, 'recall': 0.022727272727272728, 'f1-score': 0.04294032023289665, 'support': 2596}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1627}, '15': {'precision': 0.1282051282051282, 'recall': 0.02066115702479339, 'f1-score': 0.03558718861209965, 'support': 484}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 795}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.5, 'recall': 0.011450381679389313, 'f1-score': 0.02238805970149254, 'support': 262}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 563}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 837}, '22': {'precision': 0.8333333333333334, 'recall': 0.009208103130755065, 'f1-score': 0.018214936247723135, 'support': 1086}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 861}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 505}, 'micro avg': {'precision': 0.27151476659256907, 'recall': 0.03369723722066764, 'f1-score': 0.059953719935488405, 'support': 25373}, 'macro avg': {'precision': 0.33005267815247846, 'recall': 0.031114022554448596, 'f1-score': 0.03583932977344487, 'support': 25373}, 'weighted avg': {'precision': 0.4192708273814984, 'recall': 0.03369723722066764, 'f1-score': 0.0366995414883846, 'support': 25373}, 'samples avg': {'precision': 0.10247562767094016, 'recall': 0.02286002855927603, 'f1-score': 0.03533079616742754, 'support': 25373}}
{'0': {'precision': 0.5833333333333334, 'recall': 0.35714285714285715, 'f1-score': 0.44303797468354433, 'support': 196}, '1': {'precision': 0.573170731707317, 'recall': 0.1950207468879668, 'f1-score': 0.29102167182662536, 'support': 241}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 145}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 118}, '4': {'precision': 0.5806451612903226, 'recall': 0.25961538461538464, 'f1-score': 0.3588039867109635, 'support': 208}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 100}, '6': {'precision': 1.0, 'recall': 0.01818181818181818, 'f1-score': 0.03571428571428572, 'support': 110}, '7': {'precision': 0.8, 'recall': 0.2706766917293233, 'f1-score': 0.4044943820224719, 'support': 133}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 89}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '11': {'precision': 0.5, 'recall': 0.011627906976744186, 'f1-score': 0.022727272727272724, 'support': 86}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87}, '13': {'precision': 0.4444444444444444, 'recall': 0.1095890410958904, 'f1-score': 0.17582417582417584, 'support': 73}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 45}, '15': {'precision': 0.65, 'recall': 0.7647058823529411, 'f1-score': 0.7027027027027027, 'support': 51}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'micro avg': {'precision': 0.6004672897196262, 'recall': 0.1288866599799398, 'f1-score': 0.2122213047068538, 'support': 1994}, 'macro avg': {'precision': 0.20526374683101672, 'recall': 0.07946241315931703, 'f1-score': 0.09737305808848169, 'support': 1994}, 'weighted avg': {'precision': 0.35016856452739636, 'recall': 0.1288866599799398, 'f1-score': 0.17048985333459382, 'support': 1994}, 'samples avg': {'precision': 0.22298177083333334, 'recall': 0.15052548363095236, 'f1-score': 0.16760137648809523, 'support': 1994}}