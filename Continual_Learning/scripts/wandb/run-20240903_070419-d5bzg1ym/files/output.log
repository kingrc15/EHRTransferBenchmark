
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
south_val.csv
test_listfile.csv
south_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1744927829504013
Train: epoch: 1, loss = 2.1293921875953674
Train: epoch: 1, loss = 2.110175471504529
Train: epoch: 1, loss = 2.095993418544531
Train: epoch: 1, loss = 2.08930404484272
Train: epoch: 1, loss = 2.0826787666479745
Train: epoch: 1, loss = 2.079208771075521
Train: epoch: 1, loss = 2.0747619222104547
Train: epoch: 1, loss = 2.0711018917295667
Train: epoch: 1, loss = 2.0689425577521323
Train: epoch: 1, loss = 2.067329004515301
Train: epoch: 1, loss = 2.0649854778746763
Train: epoch: 1, loss = 2.061833287706742
Train: epoch: 1, loss = 2.059633501938411
Train: epoch: 1, loss = 2.0587644816239674
Train: epoch: 1, loss = 2.0583448931202293
Train: epoch: 1, loss = 2.0572563027283723
Train: epoch: 1, loss = 2.055552971727318
Train: epoch: 1, loss = 2.054760217478401
Train: epoch: 1, loss = 2.0536326246261596
Train: epoch: 1, loss = 2.0541516920214606
Train: epoch: 1, loss = 2.0535118140415713
Train: epoch: 1, loss = 2.0527201760333518
Train: epoch: 1, loss = 2.052362746099631
Train: epoch: 1, loss = 2.051426414132118
Train: epoch: 1, loss = 2.0499597301162207
Train: epoch: 1, loss = 2.0492124611580813
Train: epoch: 1, loss = 2.0479189410379957
Train: epoch: 1, loss = 2.047801034964364
Train: epoch: 1, loss = 2.047918455302715
Train: epoch: 1, loss = 2.047755734882047
Train: epoch: 1, loss = 2.0471534705534578
Train: epoch: 1, loss = 2.0467251560724145
Train: epoch: 1, loss = 2.04668450562393
Train: epoch: 1, loss = 2.046653958048139
Train: epoch: 1, loss = 2.046245838056008
Train: epoch: 1, loss = 2.04592684481595
Train: epoch: 1, loss = 2.0458390942059066
Train: epoch: 1, loss = 2.045374186543318
Train: epoch: 1, loss = 2.0451846888363363
Train: epoch: 1, loss = 2.0450976590993926
Train: epoch: 1, loss = 2.0446603774031002
Train: epoch: 1, loss = 2.0442210448065468
Train:  Epoch 1, Loss=2.0440683649880547, Cohen Kappa=0.38837955869944585, MAD=0.7230481554903613
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0365089342511933, Cohen Kappa=0.4129560414455695, MAD=0.7509266459727291
Eval task: 2
Eval:  Epoch 1, Loss=1.925610178503497, Cohen Kappa=0.002811369299477451, MAD=0.7527712260663881
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.057299628339965, Cohen Kappa=0.33914269165622835, MAD=0.7503539657519596
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9181336267241116, Cohen Kappa=0.0055059430349054805, MAD=0.7526303058519072
south_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9453105241060258
Train: epoch: 1, loss = 1.9473058459162713
Train: epoch: 1, loss = 1.9451943973700205
Train: epoch: 1, loss = 1.9497662214934826
Train: epoch: 1, loss = 1.9507522341012955
Train: epoch: 1, loss = 1.9504597056905428
Train: epoch: 1, loss = 1.950164804628917
Train: epoch: 1, loss = 1.947581329420209
Train: epoch: 1, loss = 1.9473612140946919
Train: epoch: 1, loss = 1.947066168129444
Train: epoch: 1, loss = 1.9458163608746095
Train: epoch: 1, loss = 1.946411285797755
Train: epoch: 1, loss = 1.9458964401483536
Train: epoch: 1, loss = 1.9452508835707392
Train: epoch: 1, loss = 1.944757330973943
Train: epoch: 1, loss = 1.9447639916092156
Train: epoch: 1, loss = 1.9442294441952426
Train: epoch: 1, loss = 1.9450116577744483
Train: epoch: 1, loss = 1.9445331778965498
Train: epoch: 1, loss = 1.9444392910897732
Train: epoch: 1, loss = 1.9441140507232575
Train: epoch: 1, loss = 1.9440769636901942
Train: epoch: 1, loss = 1.943972103336583
Train: epoch: 1, loss = 1.943535161614418
Train: epoch: 1, loss = 1.9431163414478303
Train: epoch: 1, loss = 1.9425898099404115
Train: epoch: 1, loss = 1.9428727337828389
Train: epoch: 1, loss = 1.9426085293505873
Train: epoch: 1, loss = 1.9421376830339432
Train: epoch: 1, loss = 1.9424594698747
Train: epoch: 1, loss = 1.9425950301462604
Train: epoch: 1, loss = 1.9426767013594508
Train: epoch: 1, loss = 1.9430004725492362
Train: epoch: 1, loss = 1.9429140877723694
Train: epoch: 1, loss = 1.9429038365227835
Train: epoch: 1, loss = 1.9418818176454968
Train: epoch: 1, loss = 1.9414522540891492
Train: epoch: 1, loss = 1.940421668620486
Train: epoch: 1, loss = 1.9393856751918792
Train: epoch: 1, loss = 1.9385272580981254
Train: epoch: 1, loss = 1.9374563803033131
Train: epoch: 1, loss = 1.9365019885415122
Train: epoch: 1, loss = 1.9357133675037428
Train:  Epoch 1, Loss=1.93518927929742, Cohen Kappa=0.016744417123719768, MAD=0.6955427408192711
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.042228873433738, Cohen Kappa=0.4049662744746507, MAD=0.7337353877948536
Eval task: 2
Eval:  Epoch 1, Loss=1.9403255910708987, Cohen Kappa=0.12585185113547692, MAD=0.6893548897658024
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0814276974776695, Cohen Kappa=0.3291844013266474, MAD=0.7272582304438744
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8970851774873405, Cohen Kappa=0.08560303716248086, MAD=0.6908485479352849
{'0': {'precision': 0.45291026677445434, 'recall': 0.5499386503067485, 'f1-score': 0.49673057741327725, 'support': 4075}, '1': {'precision': 0.24827109266943292, 'recall': 0.37591623036649213, 'f1-score': 0.2990420658059142, 'support': 2865}, '2': {'precision': 0.275092936802974, 'recall': 0.0407040704070407, 'f1-score': 0.07091518926689026, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.158715162966462, 'recall': 0.27631578947368424, 'f1-score': 0.20162016201620164, 'support': 1216}, '9': {'precision': 0.13790931989924432, 'recall': 0.4082013047530289, 'f1-score': 0.206166156742763, 'support': 1073}, 'accuracy': 0.28057650862068967, 'macro avg': {'precision': 0.12728987791125673, 'recall': 0.16510760453069945, 'f1-score': 0.12744741512450464, 'support': 14848}, 'weighted avg': {'precision': 0.22885232456430094, 'recall': 0.28057650862068967, 'f1-score': 0.2341219584305591, 'support': 14848}}
{'0': {'precision': 0.33393029342884695, 'recall': 0.5457001350742908, 'f1-score': 0.41432356208871035, 'support': 4442}, '1': {'precision': 0.3572404371584699, 'recall': 0.5081616789739604, 'f1-score': 0.4195411519332584, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.1, 'recall': 0.0007686395080707148, 'f1-score': 0.0015255530129672007, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 176}, '9': {'precision': 0.10424710424710425, 'recall': 0.24107142857142858, 'f1-score': 0.14555256064690028, 'support': 112}, 'accuracy': 0.3412580818965517, 'macro avg': {'precision': 0.08954178348344212, 'recall': 0.12957018821277505, 'f1-score': 0.09809428276818363, 'support': 14848}, 'weighted avg': {'precision': 0.23326059595259294, 'recall': 0.3412580818965517, 'f1-score': 0.2705866555703746, 'support': 14848}}