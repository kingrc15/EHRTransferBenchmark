Experiment dir: ./exp/Test_decomp_midwest_baseline
['/data/datasets/mimic3-benchmarks/data/decompensation', '/data/datasets/eICU2MIMIC/decompensation_split']
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.14248502154368908
Train: epoch: 1, loss = 0.11849570731283166
Train: epoch: 1, loss = 0.10679981486095737
Train: epoch: 1, loss = 0.10301153959182557
Train: epoch: 1, loss = 0.09510765944491141
Train: epoch: 1, loss = 0.09394489968020935
Train: epoch: 1, loss = 0.08985885112064092
Train: epoch: 1, loss = 0.0885910570670967
Train: epoch: 1, loss = 0.08808522118902248
Train: epoch: 1, loss = 0.08676709634694271
Train: epoch: 1, loss = 0.08739991764887237
Train: epoch: 1, loss = 0.08641011508278704
Train: epoch: 1, loss = 0.08753741783179486
Train: epoch: 1, loss = 0.08791876188213271
Train: epoch: 1, loss = 0.08783670770159611
Train: epoch: 1, loss = 0.08775849956233288
Train: epoch: 1, loss = 0.08729175155249644
Train: epoch: 1, loss = 0.08665197458622667
Train: epoch: 1, loss = 0.0860938569938911
Train: epoch: 1, loss = 0.08655306929675863
Train: epoch: 1, loss = 0.08638395800355024
Train: epoch: 1, loss = 0.0858609185365706
Train: epoch: 1, loss = 0.08570489356051321
Train: epoch: 1, loss = 0.08572665567223642
Train: epoch: 1, loss = 0.08528373489291408
Train: epoch: 1, loss = 0.08561166410146352
Train: epoch: 1, loss = 0.08422379356830519
Train: epoch: 1, loss = 0.08416116575278075
Train: epoch: 1, loss = 0.08346799793147386
Train: epoch: 1, loss = 0.08369359934601622
Train: epoch: 1, loss = 0.08445497392642973
Train: epoch: 1, loss = 0.0842165388640933
Train: epoch: 1, loss = 0.08399564231019185
Train: epoch: 1, loss = 0.08410306312232826
Train: epoch: 1, loss = 0.08396748317212664
Train: epoch: 1, loss = 0.08379991559628656
Train: epoch: 1, loss = 0.08334306774887483
Train: epoch: 1, loss = 0.08294310587050858
Train: epoch: 1, loss = 0.08249736513581295
Train: epoch: 1, loss = 0.08209900335311249
Train: epoch: 1, loss = 0.08249841854150873
Train: epoch: 1, loss = 0.08249486006684102
Train: epoch: 1, loss = 0.0827280685285155
Train:  Epoch 1, Loss=0.08279618626552235, AUC-ROC=0.8240173427171107, AUC-PR=0.15918534361954498
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.08507513794405706, AUC-ROC=0.8669888015275504, AUC-PR=0.22199838745900552
Eval task: 2
Eval:  Epoch 1, Loss=0.13048396927529368, AUC-ROC=0.6129936018959061, AUC-PR=0.046068008714309744
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.08322872972950854, AUC-ROC=0.8776152997660699, AUC-PR=0.2452543304938435
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.11908728854152663, AUC-ROC=0.6224279627427666, AUC-PR=0.04185276913120568
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.11007616272429005
Train: epoch: 1, loss = 0.11721526951063424
Train: epoch: 1, loss = 0.11258618125226348
Train: epoch: 1, loss = 0.11608179892296903
Train: epoch: 1, loss = 0.10750419596582651
Train: epoch: 1, loss = 0.11051711232944703
Train: epoch: 1, loss = 0.1101069597447557
Train: epoch: 1, loss = 0.10973264216387178
Train: epoch: 1, loss = 0.10938722569029778
Train: epoch: 1, loss = 0.11044063654867932
Train: epoch: 1, loss = 0.11079369543543593
Train: epoch: 1, loss = 0.11105298232481194
Train: epoch: 1, loss = 0.10940737537144182
Train: epoch: 1, loss = 0.10943752772673698
Train: epoch: 1, loss = 0.11101226001325995
Train: epoch: 1, loss = 0.11157326952583389
Train: epoch: 1, loss = 0.11205854524063932
Train: epoch: 1, loss = 0.1131226611489223
Train: epoch: 1, loss = 0.11211990212200601
Train: epoch: 1, loss = 0.11227553456788883
Train: epoch: 1, loss = 0.11162635896975795
Train: epoch: 1, loss = 0.11098938175794584
Train: epoch: 1, loss = 0.11137880994249945
Train: epoch: 1, loss = 0.11097941595769953
Train: epoch: 1, loss = 0.11098818157687783
Train: epoch: 1, loss = 0.11069037291901902
Train: epoch: 1, loss = 0.11010215139188977
Train: epoch: 1, loss = 0.11006281981211422
Train: epoch: 1, loss = 0.10956700182551968
Train: epoch: 1, loss = 0.10925913994666189
Train: epoch: 1, loss = 0.1094559224679946
Train: epoch: 1, loss = 0.1094394633223419
Train: epoch: 1, loss = 0.10864516234251134
Train: epoch: 1, loss = 0.1094628871141878
Train: epoch: 1, loss = 0.10911038023605943
Train: epoch: 1, loss = 0.10943433228492117
Train: epoch: 1, loss = 0.10979956101311522
Train: epoch: 1, loss = 0.1096259858900387
Train: epoch: 1, loss = 0.1100412218645215
Train: epoch: 1, loss = 0.10997339311556426
Train: epoch: 1, loss = 0.11057916847966248
Train: epoch: 1, loss = 0.11063072470803967
Train: epoch: 1, loss = 0.11045320035738133
Train:  Epoch 1, Loss=0.11087933189528329, AUC-ROC=0.6629288210916757, AUC-PR=0.0855575319990084
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.12564872102490787, AUC-ROC=0.7567155758114266, AUC-PR=0.11415610833074456
Eval task: 2
Eval:  Epoch 1, Loss=0.11394912556841455, AUC-ROC=0.6855992169398111, AUC-PR=0.10889771143059164
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.09384296237137811, AUC-ROC=0.8274779791434645, AUC-PR=0.20723894330371576
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.10569861595486772, AUC-ROC=0.7350222948870393, AUC-PR=0.11247497990113753