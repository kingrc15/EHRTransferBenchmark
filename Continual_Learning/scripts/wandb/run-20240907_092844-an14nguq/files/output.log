
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1760825484991075
Train: epoch: 1, loss = 2.1460309356451033
Train: epoch: 1, loss = 2.1230737511316935
Train: epoch: 1, loss = 2.1066809307038783
Train: epoch: 1, loss = 2.09467297577858
Train: epoch: 1, loss = 2.089811277290185
Train: epoch: 1, loss = 2.082535860368184
Train: epoch: 1, loss = 2.07865915350616
Train: epoch: 1, loss = 2.07583706524637
Train: epoch: 1, loss = 2.072674697101116
Train: epoch: 1, loss = 2.069977378140796
Train: epoch: 1, loss = 2.0682518527905147
Train: epoch: 1, loss = 2.066050843137961
Train: epoch: 1, loss = 2.0651619879688536
Train: epoch: 1, loss = 2.0630815090735752
Train: epoch: 1, loss = 2.0613691349700094
Train: epoch: 1, loss = 2.060405917342971
Train: epoch: 1, loss = 2.058020209206475
Train: epoch: 1, loss = 2.057160105736632
Train: epoch: 1, loss = 2.0558672562241553
Train: epoch: 1, loss = 2.0557160495292575
Train: epoch: 1, loss = 2.0557942509380256
Train: epoch: 1, loss = 2.055242260383523
Train: epoch: 1, loss = 2.054594874928395
Train: epoch: 1, loss = 2.0537029146909713
Train: epoch: 1, loss = 2.052846908385937
Train: epoch: 1, loss = 2.0525192768043943
Train: epoch: 1, loss = 2.0524104765696185
Train: epoch: 1, loss = 2.051618300183066
Train: epoch: 1, loss = 2.051161376317342
Train: epoch: 1, loss = 2.0507636530937687
Train: epoch: 1, loss = 2.0499430820718407
Train: epoch: 1, loss = 2.04899587123683
Train: epoch: 1, loss = 2.049179121624021
Train: epoch: 1, loss = 2.0488948312997817
Train: epoch: 1, loss = 2.0485840673247973
Train: epoch: 1, loss = 2.04820773778735
Train: epoch: 1, loss = 2.0474669657726037
Train: epoch: 1, loss = 2.0477242137835576
Train: epoch: 1, loss = 2.0474576214700937
Train: epoch: 1, loss = 2.047226278462061
Train: epoch: 1, loss = 2.0463707069981667
Train: epoch: 1, loss = 2.0458024659406306
Train:  Epoch 1, Loss=2.045575624029977, Cohen Kappa=0.3753290352737908, MAD=0.7181608687669909
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0319137347155602, Cohen Kappa=0.41992535418589483, MAD=0.7507832477499794
Eval task: 2
Eval:  Epoch 1, Loss=1.9830957897778214, Cohen Kappa=0.002749436955338136, MAD=0.7554579294063356
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0590214462115846, Cohen Kappa=0.3164424589753826, MAD=0.7538197613194232
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9479412970871761, Cohen Kappa=0.0029878122173413457, MAD=0.7536029339227673
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9873165100812913
Train: epoch: 1, loss = 1.9845707297325135
Train: epoch: 1, loss = 1.9815311036507288
Train: epoch: 1, loss = 1.9811727999150752
Train: epoch: 1, loss = 1.9805772335529328
Train: epoch: 1, loss = 1.9787385466694831
Train: epoch: 1, loss = 1.9774727591446468
Train: epoch: 1, loss = 1.977691855877638
Train: epoch: 1, loss = 1.9774734972582924
Train: epoch: 1, loss = 1.9778949165344237
Train: epoch: 1, loss = 1.977164320024577
Train: epoch: 1, loss = 1.9767116313179334
Train: epoch: 1, loss = 1.9759104572351163
Train: epoch: 1, loss = 1.9759447362167495
Train: epoch: 1, loss = 1.9762476880550384
Train: epoch: 1, loss = 1.975985145866871
Train: epoch: 1, loss = 1.9755184706870248
Train: epoch: 1, loss = 1.9759669333696366
Train: epoch: 1, loss = 1.9750235708450017
Train: epoch: 1, loss = 1.9750061591863632
Train: epoch: 1, loss = 1.9742929536104201
Train: epoch: 1, loss = 1.9739863977648995
Train: epoch: 1, loss = 1.9736126790616824
Train: epoch: 1, loss = 1.9734892442574103
Train: epoch: 1, loss = 1.9736542498350143
Train: epoch: 1, loss = 1.9731556107218449
Train: epoch: 1, loss = 1.9725980713190856
Train: epoch: 1, loss = 1.9731417018600872
Train: epoch: 1, loss = 1.9726111091416458
Train: epoch: 1, loss = 1.9726921663482984
Train: epoch: 1, loss = 1.9725116394604405
Train: epoch: 1, loss = 1.9727335014753045
Train: epoch: 1, loss = 1.972564272609624
Train: epoch: 1, loss = 1.9720413648030337
Train: epoch: 1, loss = 1.9719423998934882
Train: epoch: 1, loss = 1.9705834011733532
Train: epoch: 1, loss = 1.9697084565420409
Train: epoch: 1, loss = 1.9688929547447906
Train: epoch: 1, loss = 1.968556693532528
Train: epoch: 1, loss = 1.9677195538729428
Train: epoch: 1, loss = 1.9674120444495504
Train: epoch: 1, loss = 1.966912269663243
Train: epoch: 1, loss = 1.9663756540209747
Train:  Epoch 1, Loss=1.9661401372909546, Cohen Kappa=0.08531658215935833, MAD=0.6861005416465743
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.038446773742807, Cohen Kappa=0.4103469356520366, MAD=0.7240817825175545
Eval task: 2
Eval:  Epoch 1, Loss=1.9757432362128948, Cohen Kappa=0.11727554334750279, MAD=0.6865135478766731
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.052981504078569, Cohen Kappa=0.3092064971561813, MAD=0.7243598892050184
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.923808397917912, Cohen Kappa=0.12351974188500903, MAD=0.6897040916041267
{'0': {'precision': 0.41226104152933424, 'recall': 0.767361963190184, 'f1-score': 0.5363636363636364, 'support': 4075}, '1': {'precision': 0.230369085954917, 'recall': 0.32460732984293195, 'f1-score': 0.26948710518690233, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.20774505849132716, 'recall': 0.42351973684210525, 'f1-score': 0.2787550744248985, 'support': 1216}, '9': {'precision': 0.16331994645247658, 'recall': 0.11369990680335508, 'f1-score': 0.13406593406593406, 'support': 1073}, 'accuracy': 0.31613685344827586, 'macro avg': {'precision': 0.10136951324280549, 'recall': 0.16291889366785764, 'f1-score': 0.12186717500413713, 'support': 14848}, 'weighted avg': {'precision': 0.18641106338643829, 'recall': 0.31613685344827586, 'f1-score': 0.23172018401776112, 'support': 14848}}
{'0': {'precision': 0.417944609750515, 'recall': 0.43157645946584733, 'f1-score': 0.42465116279069764, 'support': 4231}, '1': {'precision': 0.3270905041506378, 'recall': 0.6422182468694096, 'f1-score': 0.43342947213092764, 'support': 5031}, '2': {'precision': 0.14893617021276595, 'recall': 0.00869205298013245, 'f1-score': 0.016425498631208443, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.09782608695652174, 'recall': 0.14705882352941177, 'f1-score': 0.1174934725848564, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.34502963362068967, 'macro avg': {'precision': 0.09917973710704406, 'recall': 0.1229545582844801, 'f1-score': 0.09919996061376901, 'support': 14848}, 'weighted avg': {'precision': 0.25617460533937403, 'recall': 0.34502963362068967, 'f1-score': 0.2729606513579003, 'support': 14848}}