
Experiment dir: ./exp/Test_los_south
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1601592433452605
Train: epoch: 1, loss = 2.124458834528923
Train: epoch: 1, loss = 2.105479874809583
Train: epoch: 1, loss = 2.098246100395918
Train: epoch: 1, loss = 2.0867957640886305
Train: epoch: 1, loss = 2.082845596174399
Train: epoch: 1, loss = 2.078172774740628
Train: epoch: 1, loss = 2.076567695811391
Train: epoch: 1, loss = 2.0750263178348543
Train: epoch: 1, loss = 2.0739234939217566
Train: epoch: 1, loss = 2.072160690968687
Train: epoch: 1, loss = 2.0699191982547442
Train: epoch: 1, loss = 2.0668078129108136
Train: epoch: 1, loss = 2.0654309105021613
Train: epoch: 1, loss = 2.063181412021319
Train: epoch: 1, loss = 2.061488641835749
Train: epoch: 1, loss = 2.0608481681346893
Train: epoch: 1, loss = 2.060518194867505
Train: epoch: 1, loss = 2.0598741777633367
Train: epoch: 1, loss = 2.058699021786451
Train: epoch: 1, loss = 2.058062422275543
Train: epoch: 1, loss = 2.056696421937509
Train: epoch: 1, loss = 2.055824194032213
Train: epoch: 1, loss = 2.055251504331827
Train: epoch: 1, loss = 2.0547729207754135
Train: epoch: 1, loss = 2.0543852194455954
Train: epoch: 1, loss = 2.0542184087523707
Train: epoch: 1, loss = 2.0537850166005747
Train: epoch: 1, loss = 2.052674057606993
Train: epoch: 1, loss = 2.051822573085626
Train: epoch: 1, loss = 2.0508266129609076
Train: epoch: 1, loss = 2.0504874645732345
Train: epoch: 1, loss = 2.049889817255916
Train: epoch: 1, loss = 2.0481706759859533
Train: epoch: 1, loss = 2.048631412727492
Train: epoch: 1, loss = 2.0483907695611316
Train: epoch: 1, loss = 2.048173058129646
Train: epoch: 1, loss = 2.0479040288297754
Train: epoch: 1, loss = 2.0478907577808085
Train: epoch: 1, loss = 2.0476669598221777
Train: epoch: 1, loss = 2.047049503878849
Train: epoch: 1, loss = 2.0471047848604975
Train: epoch: 1, loss = 2.04649857555711
Train:  Epoch 1, Loss=2.046580608340672, Cohen Kappa=0.3736690579563581, MAD=0.7204687411357091
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.029872851125125, Cohen Kappa=0.4274177157033223, MAD=0.7314603615348478
Eval task: 2
Eval:  Epoch 1, Loss=1.921658182966298, Cohen Kappa=0.011973497394146548, MAD=0.7381604999529647
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0526435786280137, Cohen Kappa=0.3320593475689848, MAD=0.7352554995140197
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9127350141262185, Cohen Kappa=0.011039186779701615, MAD=0.7390967547627781
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9202418875694276
Train: epoch: 1, loss = 1.9133086630702019
Train: epoch: 1, loss = 1.9195293456315994
Train: epoch: 1, loss = 1.9163499945402145
Train: epoch: 1, loss = 1.918662043452263
Train: epoch: 1, loss = 1.9179076452056567
Train: epoch: 1, loss = 1.9177755227259228
Train: epoch: 1, loss = 1.915323762744665
Train: epoch: 1, loss = 1.9163220919503106
Train: epoch: 1, loss = 1.916901790678501
Train: epoch: 1, loss = 1.9166109651327132
Train: epoch: 1, loss = 1.9153690845270952
Train: epoch: 1, loss = 1.9138778937321443
Train: epoch: 1, loss = 1.9127064171859196
Train: epoch: 1, loss = 1.9122837289969126
Train: epoch: 1, loss = 1.911955042667687
Train: epoch: 1, loss = 1.9121435225360535
Train: epoch: 1, loss = 1.9118813852800263
Train: epoch: 1, loss = 1.9118790623075084
Train: epoch: 1, loss = 1.9120010403394698
Train: epoch: 1, loss = 1.9117525148675556
Train: epoch: 1, loss = 1.9118075594847852
Train: epoch: 1, loss = 1.912365145838779
Train: epoch: 1, loss = 1.913168845648567
Train: epoch: 1, loss = 1.9132267937898635
Train: epoch: 1, loss = 1.913385708309137
Train: epoch: 1, loss = 1.913049304617776
Train: epoch: 1, loss = 1.9126367286486285
Train: epoch: 1, loss = 1.9120308751073376
Train: epoch: 1, loss = 1.9115422054330509
Train: epoch: 1, loss = 1.9115705567790615
Train: epoch: 1, loss = 1.9114081380143761
Train: epoch: 1, loss = 1.911225574124943
Train: epoch: 1, loss = 1.9112113869716139
Train: epoch: 1, loss = 1.9108875555310931
Train: epoch: 1, loss = 1.9105921642316712
Train: epoch: 1, loss = 1.910152894516249
Train: epoch: 1, loss = 1.9103166317155487
Train: epoch: 1, loss = 1.9098011550842187
Train: epoch: 1, loss = 1.9096694579869509
Train: epoch: 1, loss = 1.9095199105652367
Train: epoch: 1, loss = 1.9094587119278454
Train: epoch: 1, loss = 1.9090707564215328
Train:  Epoch 1, Loss=1.9087500646999904, Cohen Kappa=0.09034609243648917, MAD=0.6919352428112938
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0587083573999077, Cohen Kappa=0.3704852702816419, MAD=0.71639208367377
Eval task: 2
Eval:  Epoch 1, Loss=1.907799990012728, Cohen Kappa=0.1401521504079859, MAD=0.7057428138226244
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0614216656520448, Cohen Kappa=0.32978945681843297, MAD=0.7294097357275018
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8992926663365857, Cohen Kappa=0.08080191536391601, MAD=0.705652396159754
{'0': {'precision': 0.44092689295039167, 'recall': 0.6630674846625767, 'f1-score': 0.5296481427031265, 'support': 4075}, '1': {'precision': 0.21212121212121213, 'recall': 0.34205933682373474, 'f1-score': 0.2618570474281897, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.049586776859504134, 'recall': 0.009868421052631578, 'f1-score': 0.016460905349794237, 'support': 1216}, '9': {'precision': 0.155561317085818, 'recall': 0.5591798695246971, 'f1-score': 0.2434077079107505, 'support': 1073}, 'accuracy': 0.28919719827586204, 'macro avg': {'precision': 0.0858196199016926, 'recall': 0.157417511206364, 'f1-score': 0.1051373803391861, 'support': 14848}, 'weighted avg': {'precision': 0.17724401773938298, 'recall': 0.28919719827586204, 'f1-score': 0.21482553568767437, 'support': 14848}}
{'0': {'precision': 0.33153811045184844, 'recall': 0.8176497073390365, 'f1-score': 0.4717802169253751, 'support': 4442}, '1': {'precision': 0.32773340677499313, 'recall': 0.2312475709288768, 'f1-score': 0.2711632676313091, 'support': 5146}, '2': {'precision': 0.5, 'recall': 0.0003937007874015748, 'f1-score': 0.0007867820613690009, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.09448818897637795, 'recall': 0.06818181818181818, 'f1-score': 0.07920792079207921, 'support': 176}, '9': {'precision': 0.08270676691729323, 'recall': 0.09821428571428571, 'f1-score': 0.08979591836734695, 'support': 112}, 'accuracy': 0.3263739224137931, 'macro avg': {'precision': 0.13364664731205128, 'recall': 0.12156870829514188, 'f1-score': 0.09127341057774793, 'support': 14848}, 'weighted avg': {'precision': 0.3000472438743133, 'recall': 0.3263739224137931, 'f1-score': 0.23687028974714835, 'support': 14848}}