Experiment dir: ./exp/Test_los_south
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
south_val.csv
test_listfile.csv
south_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1791378372907637
Train: epoch: 1, loss = 2.132547880411148
Train: epoch: 1, loss = 2.109613094329834
Train: epoch: 1, loss = 2.094013966917992
Train: epoch: 1, loss = 2.086013689041138
Train: epoch: 1, loss = 2.08052350461483
Train: epoch: 1, loss = 2.074693062731198
Train: epoch: 1, loss = 2.0701363725215196
Train: epoch: 1, loss = 2.0683133506774904
Train: epoch: 1, loss = 2.065714719057083
Train: epoch: 1, loss = 2.0625217031890695
Train: epoch: 1, loss = 2.0619070350130397
Train: epoch: 1, loss = 2.0600105063731853
Train: epoch: 1, loss = 2.058654512294701
Train: epoch: 1, loss = 2.05718888092041
Train: epoch: 1, loss = 2.0563032268732786
Train: epoch: 1, loss = 2.0562684877830395
Train: epoch: 1, loss = 2.0563506635692383
Train: epoch: 1, loss = 2.0554811478602257
Train: epoch: 1, loss = 2.0545531462430953
Train: epoch: 1, loss = 2.053889973901567
Train: epoch: 1, loss = 2.054091977775097
Train: epoch: 1, loss = 2.0531715134952377
Train: epoch: 1, loss = 2.053058001374205
Train: epoch: 1, loss = 2.052438982629776
Train: epoch: 1, loss = 2.052043744509037
Train: epoch: 1, loss = 2.0517379843526418
Train: epoch: 1, loss = 2.0510950662834304
Train: epoch: 1, loss = 2.0503457508004943
Train: epoch: 1, loss = 2.0499270571867627
Train: epoch: 1, loss = 2.0494661580747175
Train: epoch: 1, loss = 2.0478798131644727
Train: epoch: 1, loss = 2.047507138938615
Train: epoch: 1, loss = 2.046710387240438
Train: epoch: 1, loss = 2.0461402846063885
Train: epoch: 1, loss = 2.0457541332145532
Train: epoch: 1, loss = 2.045437688891952
Train: epoch: 1, loss = 2.044753567497981
Train: epoch: 1, loss = 2.0445427637222484
Train: epoch: 1, loss = 2.044056075364351
Train: epoch: 1, loss = 2.0439397448301317
Train: epoch: 1, loss = 2.0441072062935146
Train: epoch: 1, loss = 2.043625953086587
Train:  Epoch 1, Loss=2.0434258858135768, Cohen Kappa=0.38800779963049337, MAD=0.7197010565225285
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0435868460556557, Cohen Kappa=0.39962362375004534, MAD=0.714387653087395
Eval task: 2
Eval:  Epoch 1, Loss=1.927121795456985, Cohen Kappa=0.0014182471555511666, MAD=0.7568896940737353
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.057397957505851, Cohen Kappa=0.32140089137818895, MAD=0.7191786768961898
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.920029381225849, Cohen Kappa=0.0014625190811975441, MAD=0.7573254677544897
south_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9836446118354798
Train: epoch: 1, loss = 1.978051913380623
Train: epoch: 1, loss = 1.9764052846034368
Train: epoch: 1, loss = 1.973672034293413
Train: epoch: 1, loss = 1.9747730380296706
Train: epoch: 1, loss = 1.9746941948930423
Train: epoch: 1, loss = 1.9747555381059647
Train: epoch: 1, loss = 1.9748157169669867
Train: epoch: 1, loss = 1.973865229487419
Train: epoch: 1, loss = 1.972687928378582
Train: epoch: 1, loss = 1.9735759983279488
Train: epoch: 1, loss = 1.9740899141629538
Train: epoch: 1, loss = 1.9734578053767864
Train: epoch: 1, loss = 1.9732677728789194
Train: epoch: 1, loss = 1.9729054509003958
Train: epoch: 1, loss = 1.973262056298554
Train: epoch: 1, loss = 1.9735022539601605
Train: epoch: 1, loss = 1.9733263954851363
Train: epoch: 1, loss = 1.9733648132650476
Train: epoch: 1, loss = 1.9736065693795681
Train: epoch: 1, loss = 1.9729474201656523
Train: epoch: 1, loss = 1.9732520678910341
Train: epoch: 1, loss = 1.9725920685218727
Train: epoch: 1, loss = 1.9727562204251687
Train: epoch: 1, loss = 1.972357438826561
Train: epoch: 1, loss = 1.9724442050777948
Train: epoch: 1, loss = 1.9722942674380761
Train: epoch: 1, loss = 1.9716521817658628
Train: epoch: 1, loss = 1.9715866636202253
Train: epoch: 1, loss = 1.9715920339226722
Train: epoch: 1, loss = 1.971144208581217
Train: epoch: 1, loss = 1.971309854928404
Train: epoch: 1, loss = 1.9709962521177349
Train: epoch: 1, loss = 1.9707776679887492
Train: epoch: 1, loss = 1.9707125796420233
Train: epoch: 1, loss = 1.9709417081210348
Train: epoch: 1, loss = 1.9706642552807525
Train: epoch: 1, loss = 1.9707905061621416
Train: epoch: 1, loss = 1.9705687986123257
Train: epoch: 1, loss = 1.9704250762313604
Train: epoch: 1, loss = 1.9702417112705184
Train: epoch: 1, loss = 1.9700782287262735
Train: epoch: 1, loss = 1.969926550180413
Train:  Epoch 1, Loss=1.9696765482085092, Cohen Kappa=0.02521006304107165, MAD=0.6962149995953528
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.017577818755446, Cohen Kappa=0.426984727173477, MAD=0.7261649554330205
Eval task: 2
Eval:  Epoch 1, Loss=1.9646218850694854, Cohen Kappa=0.023625310889686113, MAD=0.7052292463616794
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0559656702238938, Cohen Kappa=0.347724459019521, MAD=0.7154483661829846
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8993222877897065, Cohen Kappa=0.02499418699931588, MAD=0.7069101004189068
{'0': {'precision': 0.42582247051520794, 'recall': 0.6733742331288344, 'f1-score': 0.5217225972050575, 'support': 4075}, '1': {'precision': 0.2656449553001277, 'recall': 0.36300174520069806, 'f1-score': 0.3067846607669616, 'support': 2865}, '2': {'precision': 0.17647058823529413, 'recall': 0.01155115511551155, 'f1-score': 0.021683014971605578, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.19942857142857143, 'recall': 0.2870065789473684, 'f1-score': 0.2353337828725556, 'support': 1216}, '9': {'precision': 0.1729667812142039, 'recall': 0.42218080149114634, 'f1-score': 0.24539544962080173, 'support': 1073}, 'accuracy': 0.31027747844827586, 'macro avg': {'precision': 0.12403333666934054, 'recall': 0.1757114513883559, 'f1-score': 0.1330919505436982, 'support': 14848}, 'weighted avg': {'precision': 0.2185628632001675, 'recall': 0.31027747844827586, 'f1-score': 0.2420428714535615, 'support': 14848}}
{'0': {'precision': 0.3220338983050847, 'recall': 0.8169743358847366, 'f1-score': 0.4619693208579976, 'support': 4442}, '1': {'precision': 0.32848755940732455, 'recall': 0.2283326855810338, 'f1-score': 0.26940272841912183, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 176}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.32354525862068967, 'macro avg': {'precision': 0.06505214577124092, 'recall': 0.10453070214657703, 'f1-score': 0.07313720492771195, 'support': 14848}, 'weighted avg': {'precision': 0.21018800895617445, 'recall': 0.32354525862068967, 'f1-score': 0.23157422977478626, 'support': 14848}}