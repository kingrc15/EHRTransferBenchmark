
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_decomp_south_baseline
['/data/datasets/mimic3-benchmarks/data/decompensation', '/data/datasets/eICU2MIMIC/decompensation_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.17274765475653112
Train: epoch: 1, loss = 0.1284661578119267
Train: epoch: 1, loss = 0.118123918021253
Train: epoch: 1, loss = 0.11554848615720402
Train: epoch: 1, loss = 0.11083705079741776
Train: epoch: 1, loss = 0.1049501513998257
Train: epoch: 1, loss = 0.10001494199852459
Train: epoch: 1, loss = 0.09624074472809298
Train: epoch: 1, loss = 0.09545371234090352
Train: epoch: 1, loss = 0.09300118582110736
Train: epoch: 1, loss = 0.09365967212623218
Train: epoch: 1, loss = 0.09250620273017073
Train: epoch: 1, loss = 0.09016342162141182
Train: epoch: 1, loss = 0.08987078326234561
Train: epoch: 1, loss = 0.08984582473877041
Train: epoch: 1, loss = 0.08840840548164124
Train: epoch: 1, loss = 0.08819271999127094
Train: epoch: 1, loss = 0.08628886433984412
Train: epoch: 1, loss = 0.08702511675484283
Train: epoch: 1, loss = 0.08658140528114745
Train: epoch: 1, loss = 0.0858347282743281
Train: epoch: 1, loss = 0.08588629271448801
Train: epoch: 1, loss = 0.08547027243164611
Train: epoch: 1, loss = 0.08522352549106775
Train: epoch: 1, loss = 0.08506742358054034
Train: epoch: 1, loss = 0.08457425606463892
Train: epoch: 1, loss = 0.0845952922205389
Train: epoch: 1, loss = 0.08461610354445709
Train: epoch: 1, loss = 0.08428155130076478
Train: epoch: 1, loss = 0.08430201954227717
Train: epoch: 1, loss = 0.08411332160223185
Train: epoch: 1, loss = 0.08384023709044414
Train: epoch: 1, loss = 0.08350770425845191
Train: epoch: 1, loss = 0.08279745233390713
Train: epoch: 1, loss = 0.08255920547820694
Train: epoch: 1, loss = 0.08277925441508867
Train: epoch: 1, loss = 0.08265999744251383
Train: epoch: 1, loss = 0.08295245147942823
Train: epoch: 1, loss = 0.08304332685753858
Train: epoch: 1, loss = 0.08342007786328032
Train: epoch: 1, loss = 0.0829993491706001
Train: epoch: 1, loss = 0.08297653195909724
Train: epoch: 1, loss = 0.08293125612034495
Train:  Epoch 1, Loss=0.08298454991740041, AUC-ROC=0.8233018508628586, AUC-PR=0.14759138095946636
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.0853110861418576, AUC-ROC=0.8637253875167509, AUC-PR=0.2183009332641976
Eval task: 2
Eval:  Epoch 1, Loss=0.16548367140108142, AUC-ROC=0.6671963107536362, AUC-PR=0.09007061574339303
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.08539404583581049, AUC-ROC=0.8659858363129651, AUC-PR=0.23037258558148999
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.14147405506208025, AUC-ROC=0.7264601072444894, AUC-PR=0.09679984043427994
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.12482985074748285
Train: epoch: 1, loss = 0.11923473948438186
Train: epoch: 1, loss = 0.12924056051803443
Train: epoch: 1, loss = 0.1273261370966793
Train: epoch: 1, loss = 0.12877396014821715
Train: epoch: 1, loss = 0.12751960653831096
Train: epoch: 1, loss = 0.12508495119616522
Train: epoch: 1, loss = 0.12232704766021925
Train: epoch: 1, loss = 0.1228094494910652
Train: epoch: 1, loss = 0.12134551555814688
Train: epoch: 1, loss = 0.12134128574588844
Train: epoch: 1, loss = 0.1211677357229443
Train: epoch: 1, loss = 0.12006891745312784
Train: epoch: 1, loss = 0.11912090230658318
Train: epoch: 1, loss = 0.11961368134485868
Train: epoch: 1, loss = 0.11896615879777528
Train: epoch: 1, loss = 0.11943796024897464
Train: epoch: 1, loss = 0.11878073102878665
Train: epoch: 1, loss = 0.117830084387985
Train: epoch: 1, loss = 0.11699300099600805
Train: epoch: 1, loss = 0.11700838872481005
Train: epoch: 1, loss = 0.11665571194697721
Train: epoch: 1, loss = 0.11612046462519135
Train: epoch: 1, loss = 0.11668654462919222
Train: epoch: 1, loss = 0.11651744674690999
Train: epoch: 1, loss = 0.11567337908249241
Train: epoch: 1, loss = 0.11590242777067168
Train: epoch: 1, loss = 0.11585828761965136
Train: epoch: 1, loss = 0.1159228212636462
Train: epoch: 1, loss = 0.1152410027809674
Train: epoch: 1, loss = 0.1148474165018753
Train: epoch: 1, loss = 0.11479561215968716
Train: epoch: 1, loss = 0.11444291229349222
Train: epoch: 1, loss = 0.11456260217316037
Train: epoch: 1, loss = 0.11484235477570577
Train: epoch: 1, loss = 0.11486008552449574
Train: epoch: 1, loss = 0.11442227593966055
Train: epoch: 1, loss = 0.11443747365231455
Train: epoch: 1, loss = 0.1145970412706419
Train: epoch: 1, loss = 0.11461719267067383
Train: epoch: 1, loss = 0.11478433555398114
Train: epoch: 1, loss = 0.1148639961851794
Train: epoch: 1, loss = 0.1141651113698703
Train:  Epoch 1, Loss=0.11420264964468245, AUC-ROC=0.7569407225022865, AUC-PR=0.14377369408554222
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.1439136035483459, AUC-ROC=0.7863021272308162, AUC-PR=0.10933259797930016
Eval task: 2
Eval:  Epoch 1, Loss=0.13562304115500942, AUC-ROC=0.725381489918539, AUC-PR=0.11227797845827775
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.09406450708749993, AUC-ROC=0.8658596526752743, AUC-PR=0.2596461483664389
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.11352059707559388, AUC-ROC=0.8244270646141151, AUC-PR=0.1960037579231082