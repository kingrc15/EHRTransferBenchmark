
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_west
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.4322792921960354
Train: epoch: 1, loss = 0.42059696160256865
Train: epoch: 1, loss = 0.4172023732463519
Train: epoch: 1, loss = 0.4136530965194106
Train: epoch: 1, loss = 0.41170359206199647
Train: epoch: 1, loss = 0.40954564735293386
Train: epoch: 1, loss = 0.40832091569900514
Train: epoch: 1, loss = 0.4071225689910352
Train: epoch: 1, loss = 0.4057556757165326
Train: epoch: 1, loss = 0.4041485013961792
Train: epoch: 1, loss = 0.40306219706481156
Train: epoch: 1, loss = 0.4024921189931532
Train: epoch: 1, loss = 0.4014287128012914
Train: epoch: 1, loss = 0.40026135935315066
Train: epoch: 1, loss = 0.39909800912936527
Train: epoch: 1, loss = 0.39781634726561604
Train: epoch: 1, loss = 0.3966581826394095
Train: epoch: 1, loss = 0.3954378745373752
Train:  Epoch 1, Loss=0.3950741583363623, AUC-ROC Macro=0.6485225347095507, AUC-ROC Micro=0.7434597238977979
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.371339812874794, AUC-ROC Macro=0.715831662022891, AUC-ROC Micro=0.7830077322511055
Eval task: 2
Eval:  Epoch 1, Loss=0.3233054503798485, AUC-ROC Macro=0.5100420892894605, AUC-ROC Micro=0.5434566080526458
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.37329611629247667
Train: epoch: 2, loss = 0.3733445167168975
Train: epoch: 2, loss = 0.373270705267787
Train: epoch: 2, loss = 0.37405759055167437
Train: epoch: 2, loss = 0.372188942655921
Train: epoch: 2, loss = 0.371204079700013
Train: epoch: 2, loss = 0.37143788743231976
Train: epoch: 2, loss = 0.3707606693729758
Train: epoch: 2, loss = 0.370683380605446
Train: epoch: 2, loss = 0.37087586722522975
Train: epoch: 2, loss = 0.3706538075005466
Train: epoch: 2, loss = 0.36999899946774045
Train: epoch: 2, loss = 0.36920119997973627
Train: epoch: 2, loss = 0.3685645759584648
Train: epoch: 2, loss = 0.36866323617100716
Train: epoch: 2, loss = 0.36876915670465676
Train: epoch: 2, loss = 0.36827893589787625
Train: epoch: 2, loss = 0.3679921865214904
Train:  Epoch 2, Loss=0.3682730764649872, AUC-ROC Macro=0.7255680471085567, AUC-ROC Micro=0.7917574968309982
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3621262423694134, AUC-ROC Macro=0.7395494730201445, AUC-ROC Micro=0.798390670005158
Eval task: 2
Eval:  Epoch 2, Loss=0.3513976186513901, AUC-ROC Macro=0.4834267419305849, AUC-ROC Micro=0.5392907071746301
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.36445486031472685
Train: epoch: 3, loss = 0.3595248169451952
Train: epoch: 3, loss = 0.3613053490718206
Train: epoch: 3, loss = 0.3625499261729419
Train: epoch: 3, loss = 0.36050406327843665
Train: epoch: 3, loss = 0.3607403798773885
Train: epoch: 3, loss = 0.36053016139992644
Train: epoch: 3, loss = 0.36068971338681877
Train: epoch: 3, loss = 0.3602604254914655
Train: epoch: 3, loss = 0.36030807084590194
Train: epoch: 3, loss = 0.36007144958458165
Train: epoch: 3, loss = 0.36022498504569134
Train: epoch: 3, loss = 0.359825092410812
Train: epoch: 3, loss = 0.35985373584287506
Train: epoch: 3, loss = 0.35966243580480417
Train: epoch: 3, loss = 0.35960871836636216
Train: epoch: 3, loss = 0.3595418054347529
Train: epoch: 3, loss = 0.3596751623393761
Train:  Epoch 3, Loss=0.35959942391998745, AUC-ROC Macro=0.7451261361630582, AUC-ROC Micro=0.8050276648798962
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3554685066143672, AUC-ROC Macro=0.7517871267535764, AUC-ROC Micro=0.8075102666219404
Eval task: 2
Eval:  Epoch 3, Loss=0.35746578872203827, AUC-ROC Macro=0.49292231824364435, AUC-ROC Micro=0.5325989937776022
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.356093108355999
Train: epoch: 4, loss = 0.3548648193478584
Train: epoch: 4, loss = 0.3522040629883607
Train: epoch: 4, loss = 0.3518332875147462
Train: epoch: 4, loss = 0.35260362753272056
Train: epoch: 4, loss = 0.3521611002087593
Train: epoch: 4, loss = 0.3534650718314307
Train: epoch: 4, loss = 0.35371606529690325
Train: epoch: 4, loss = 0.35440070430437726
Train: epoch: 4, loss = 0.354840096950531
Train: epoch: 4, loss = 0.35438154701482166
Train: epoch: 4, loss = 0.3544670582314332
Train: epoch: 4, loss = 0.35503754302286183
Train: epoch: 4, loss = 0.3551036284384983
Train: epoch: 4, loss = 0.35490352641542755
Train: epoch: 4, loss = 0.35490717317443343
Train: epoch: 4, loss = 0.3544930852379869
Train: epoch: 4, loss = 0.3541386695371734
Train:  Epoch 4, Loss=0.3541744684276418, AUC-ROC Macro=0.7567509067384053, AUC-ROC Micro=0.8129442816749766
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3533468308548133, AUC-ROC Macro=0.7558601124102513, AUC-ROC Micro=0.8108769053394435
Eval task: 2
Eval:  Epoch 4, Loss=0.38215716928243637, AUC-ROC Macro=0.4845699748281839, AUC-ROC Micro=0.5412610216496547
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.35090249836444853
Train: epoch: 5, loss = 0.3502141637355089
Train: epoch: 5, loss = 0.34756599788864456
Train: epoch: 5, loss = 0.3500095175951719
Train: epoch: 5, loss = 0.35132868605852124
Train: epoch: 5, loss = 0.3515928071737289
Train: epoch: 5, loss = 0.35203912400773596
Train: epoch: 5, loss = 0.3514727724343538
Train: epoch: 5, loss = 0.3510873594052262
Train: epoch: 5, loss = 0.35045754996687173
Train: epoch: 5, loss = 0.349950738271529
Train: epoch: 5, loss = 0.3499872478221854
Train: epoch: 5, loss = 0.34979038988741545
Train: epoch: 5, loss = 0.3500255598127842
Train: epoch: 5, loss = 0.3499892741491397
Train: epoch: 5, loss = 0.35013151973951606
Train: epoch: 5, loss = 0.35008408618323944
Train: epoch: 5, loss = 0.35011222361276545
Train:  Epoch 5, Loss=0.3500444930435246, AUC-ROC Macro=0.7652877705080602, AUC-ROC Micro=0.8187467276178366
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.35088663051525754, AUC-ROC Macro=0.761942389428915, AUC-ROC Micro=0.8142178738601046
Eval task: 2
Eval:  Epoch 5, Loss=0.3604549989104271, AUC-ROC Macro=0.4890888691641643, AUC-ROC Micro=0.5139677620231473
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.34179575815796853
Train: epoch: 6, loss = 0.3500129079073668
Train: epoch: 6, loss = 0.3511851383994023
Train: epoch: 6, loss = 0.35131048945710064
Train: epoch: 6, loss = 0.3492522905170917
Train: epoch: 6, loss = 0.3479951784635584
Train: epoch: 6, loss = 0.34773120569331306
Train: epoch: 6, loss = 0.34775125067681073
Train: epoch: 6, loss = 0.347455959841609
Train: epoch: 6, loss = 0.34718890974670646
Train: epoch: 6, loss = 0.34656257375397465
Train: epoch: 6, loss = 0.34693462764223415
Train: epoch: 6, loss = 0.3471297685859295
Train: epoch: 6, loss = 0.34706570010632276
Train: epoch: 6, loss = 0.34669523196915786
Train: epoch: 6, loss = 0.3471003868523985
Train: epoch: 6, loss = 0.3470622754842043
Train: epoch: 6, loss = 0.3469727350316114
Train:  Epoch 6, Loss=0.346895037781479, AUC-ROC Macro=0.7710259318501594, AUC-ROC Micro=0.8229013135335413
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.350091843555371, AUC-ROC Macro=0.7635739381249737, AUC-ROC Micro=0.8158991973223617
Eval task: 2
Eval:  Epoch 6, Loss=0.37686699628829956, AUC-ROC Macro=0.48834651950984304, AUC-ROC Micro=0.5290578808809782
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3529489648838838, AUC-ROC Macro=0.7628258180567589, AUC-ROC Micro=0.814959602054188
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.37615857273340225, AUC-ROC Macro=0.5034884467222812, AUC-ROC Micro=0.5313470382340786
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.256902581602335
Train: epoch: 1, loss = 0.24952999036759138
Train: epoch: 1, loss = 0.24714925043284894
Train:  Epoch 1, Loss=0.24531648912898402, AUC-ROC Macro=0.5569589658777949, AUC-ROC Micro=0.7511462770482784
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.44398802146315575, AUC-ROC Macro=0.6860768068598856, AUC-ROC Micro=0.693779716146258
Eval task: 2
Eval:  Epoch 1, Loss=0.2329888865351677, AUC-ROC Macro=0.6227418203382551, AUC-ROC Micro=0.7865254536468262
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.2289365655183792
Train: epoch: 2, loss = 0.22786840703338385
Train: epoch: 2, loss = 0.22611478362232446
Train:  Epoch 2, Loss=0.22649627299716626, AUC-ROC Macro=0.6669001330200363, AUC-ROC Micro=0.804996774667765
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.4583974704146385, AUC-ROC Macro=0.6748192494183154, AUC-ROC Micro=0.6877375536520938
Eval task: 2
Eval:  Epoch 2, Loss=0.22588586062192917, AUC-ROC Macro=0.6720252935175094, AUC-ROC Micro=0.8022288298590152
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.22145012713968754
Train: epoch: 3, loss = 0.22030231047421694
Train: epoch: 3, loss = 0.22111601067086062
Train:  Epoch 3, Loss=0.22063621924181653, AUC-ROC Macro=0.7105342048337513, AUC-ROC Micro=0.81913820137312
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.4638530860344569, AUC-ROC Macro=0.6672416178904825, AUC-ROC Micro=0.6830297789753195
Eval task: 2
Eval:  Epoch 3, Loss=0.2217891775071621, AUC-ROC Macro=0.6996839457543854, AUC-ROC Micro=0.8134018588092768
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.211428055241704
Train: epoch: 4, loss = 0.21402258401736618
Train: epoch: 4, loss = 0.21585456653187673
Train:  Epoch 4, Loss=0.215593488635097, AUC-ROC Macro=0.7382190113633481, AUC-ROC Micro=0.8297987076433552
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.4539567319055398, AUC-ROC Macro=0.6613562807886086, AUC-ROC Micro=0.6871843818889504
Eval task: 2
Eval:  Epoch 4, Loss=0.22085653245449066, AUC-ROC Macro=0.7010565149753885, AUC-ROC Micro=0.8147118803150645
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.20867508720606565
Train: epoch: 5, loss = 0.21127665335312484
Train: epoch: 5, loss = 0.21216047986100117
Train:  Epoch 5, Loss=0.21135349463234174, AUC-ROC Macro=0.7564866936445506, AUC-ROC Micro=0.8396400852068018
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.49978123729427654, AUC-ROC Macro=0.6292694872796492, AUC-ROC Micro=0.6604411199669836
Eval task: 2
Eval:  Epoch 5, Loss=0.22014030441641808, AUC-ROC Macro=0.7147996500470832, AUC-ROC Micro=0.8198403868174992
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.20613929677754642
Train: epoch: 6, loss = 0.20806669557467103
Train: epoch: 6, loss = 0.20893380797157685
Train:  Epoch 6, Loss=0.20807357708143037, AUC-ROC Macro=0.7699357593060179, AUC-ROC Micro=0.8470874174509717
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.49184466650088626, AUC-ROC Macro=0.6403761589266014, AUC-ROC Micro=0.6732852589080673
Eval task: 2
Eval:  Epoch 6, Loss=0.2188609316945076, AUC-ROC Macro=0.7180327935596621, AUC-ROC Micro=0.82302728861977
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.49431407699982327, AUC-ROC Macro=0.6404338370107812, AUC-ROC Micro=0.6733047025659864
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.21706000715494156, AUC-ROC Macro=0.742232159532886, AUC-ROC Micro=0.8241684831670305
{'0': {'precision': 0.2915896487985213, 'recall': 0.48241590214067276, 'f1-score': 0.36347926267281105, 'support': 1308}, '1': {'precision': 0.6052631578947368, 'recall': 0.05721393034825871, 'f1-score': 0.10454545454545455, 'support': 402}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 658}, '3': {'precision': 0.5588235294117647, 'recall': 0.009547738693467337, 'f1-score': 0.018774703557312252, 'support': 1990}, '4': {'precision': 0.3008130081300813, 'recall': 0.04590570719602978, 'f1-score': 0.07965554359526374, 'support': 806}, '5': {'precision': 0.1506849315068493, 'recall': 0.014138817480719794, 'f1-score': 0.025851938895417155, 'support': 778}, '6': {'precision': 0.5737704918032787, 'recall': 0.026881720430107527, 'f1-score': 0.05135730007336758, 'support': 1302}, '7': {'precision': 0.05161290322580645, 'recall': 0.03773584905660377, 'f1-score': 0.043596730245231606, 'support': 424}, '8': {'precision': 0.6666666666666666, 'recall': 0.0024330900243309003, 'f1-score': 0.0048484848484848485, 'support': 1644}, '9': {'precision': 1.0, 'recall': 0.0019694731659281144, 'f1-score': 0.003931203931203931, 'support': 2031}, '10': {'precision': 0.2916666666666667, 'recall': 0.012216404886561954, 'f1-score': 0.02345058626465662, 'support': 573}, '11': {'precision': 0.35185185185185186, 'recall': 0.03231292517006803, 'f1-score': 0.05919003115264798, 'support': 1176}, '12': {'precision': 0.441340782122905, 'recall': 0.04463276836158192, 'f1-score': 0.0810672139558748, 'support': 1770}, '13': {'precision': 0.39776951672862454, 'recall': 0.04121725731895223, 'f1-score': 0.07469458987783593, 'support': 2596}, '14': {'precision': 0.6666666666666666, 'recall': 0.0036877688998156115, 'f1-score': 0.007334963325183374, 'support': 1627}, '15': {'precision': 0.06578947368421052, 'recall': 0.02066115702479339, 'f1-score': 0.031446540880503145, 'support': 484}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 795}, '17': {'precision': 1.0, 'recall': 0.003676470588235294, 'f1-score': 0.007326007326007326, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.40625, 'recall': 0.04961832061068702, 'f1-score': 0.08843537414965986, 'support': 262}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 563}, '21': {'precision': 0.45454545454545453, 'recall': 0.011947431302270013, 'f1-score': 0.023282887077997673, 'support': 837}, '22': {'precision': 0.7727272727272727, 'recall': 0.06261510128913444, 'f1-score': 0.11584327086882454, 'support': 1086}, '23': {'precision': 0.2857142857142857, 'recall': 0.0023228803716608595, 'f1-score': 0.004608294930875577, 'support': 861}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 505}, 'micro avg': {'precision': 0.3026706231454006, 'recall': 0.044220234107121746, 'f1-score': 0.07716643741403027, 'support': 25373}, 'macro avg': {'precision': 0.3733418523258258, 'recall': 0.038526028574395174, 'f1-score': 0.04850881528698453, 'support': 25373}, 'weighted avg': {'precision': 0.4579538623466426, 'recall': 0.044220234107121746, 'f1-score': 0.05377582516365802, 'support': 25373}, 'samples avg': {'precision': 0.1283170185391865, 'recall': 0.030763844689913156, 'f1-score': 0.04663598872511441, 'support': 25373}}
{'0': {'precision': 0.6178861788617886, 'recall': 0.3877551020408163, 'f1-score': 0.4764890282131662, 'support': 196}, '1': {'precision': 0.5037037037037037, 'recall': 0.2821576763485477, 'f1-score': 0.36170212765957444, 'support': 241}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 145}, '3': {'precision': 1.0, 'recall': 0.00847457627118644, 'f1-score': 0.01680672268907563, 'support': 118}, '4': {'precision': 0.4838709677419355, 'recall': 0.21634615384615385, 'f1-score': 0.29900332225913623, 'support': 208}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 100}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '7': {'precision': 0.9411764705882353, 'recall': 0.24060150375939848, 'f1-score': 0.3832335329341317, 'support': 133}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 89}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '11': {'precision': 1.0, 'recall': 0.05813953488372093, 'f1-score': 0.10989010989010987, 'support': 86}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87}, '13': {'precision': 0.3333333333333333, 'recall': 0.0684931506849315, 'f1-score': 0.11363636363636363, 'support': 73}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 45}, '15': {'precision': 0.7777777777777778, 'recall': 0.6862745098039216, 'f1-score': 0.7291666666666667, 'support': 51}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'micro avg': {'precision': 0.579175704989154, 'recall': 0.13390170511534605, 'f1-score': 0.21751527494908351, 'support': 1994}, 'macro avg': {'precision': 0.226309937280271, 'recall': 0.07792968830554707, 'f1-score': 0.09959711495792899, 'support': 1994}, 'weighted avg': {'precision': 0.36926776104717207, 'recall': 0.13390170511534605, 'f1-score': 0.17584830014001646, 'support': 1994}, 'samples avg': {'precision': 0.23852539062499997, 'recall': 0.1586937313988095, 'f1-score': 0.1782381572420635, 'support': 1994}}