
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_northeast
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.4330112548172474
Train: epoch: 1, loss = 0.42537425756454467
Train: epoch: 1, loss = 0.4201914080480735
Train: epoch: 1, loss = 0.41351712863892315
Train: epoch: 1, loss = 0.412634202376008
Train: epoch: 1, loss = 0.4120171096051733
Train: epoch: 1, loss = 0.40999469372842995
Train: epoch: 1, loss = 0.4080514453072101
Train: epoch: 1, loss = 0.4060248270051347
Train: epoch: 1, loss = 0.40435485592484477
Train: epoch: 1, loss = 0.40226610739122737
Train: epoch: 1, loss = 0.40003277100622653
Train: epoch: 1, loss = 0.3986010899165502
Train: epoch: 1, loss = 0.3973513859297548
Train: epoch: 1, loss = 0.39596470176676907
Train: epoch: 1, loss = 0.394762115245685
Train: epoch: 1, loss = 0.39370911148102844
Train: epoch: 1, loss = 0.3927975990002354
Train:  Epoch 1, Loss=0.39253584967311633, AUC-ROC Macro=0.6570743715150003, AUC-ROC Micro=0.7482378055882939
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3726445659995079, AUC-ROC Macro=0.7155630014962523, AUC-ROC Micro=0.7795648084696138
Eval task: 2
Eval:  Epoch 1, Loss=0.3826512396335602, AUC-ROC Macro=0.48309802719830963, AUC-ROC Micro=0.5824836273367631
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.36555350802838804
Train: epoch: 2, loss = 0.36752567943185566
Train: epoch: 2, loss = 0.3689345341424147
Train: epoch: 2, loss = 0.36910415910184385
Train: epoch: 2, loss = 0.36867384776473044
Train: epoch: 2, loss = 0.368866589255631
Train: epoch: 2, loss = 0.3690310608169862
Train: epoch: 2, loss = 0.3695271592307836
Train: epoch: 2, loss = 0.37056314398845036
Train: epoch: 2, loss = 0.3707553772926331
Train: epoch: 2, loss = 0.37038039438426495
Train: epoch: 2, loss = 0.3699850373218457
Train: epoch: 2, loss = 0.3699771592937983
Train: epoch: 2, loss = 0.3691889647713729
Train: epoch: 2, loss = 0.3690427176405986
Train: epoch: 2, loss = 0.36881889241281895
Train: epoch: 2, loss = 0.36840770653065513
Train: epoch: 2, loss = 0.3686592328755392
Train:  Epoch 2, Loss=0.3687565668485103, AUC-ROC Macro=0.7233052428784014, AUC-ROC Micro=0.7905433726172373
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.36050281549493474, AUC-ROC Macro=0.7390380990749912, AUC-ROC Micro=0.7992721004601335
Eval task: 2
Eval:  Epoch 2, Loss=0.40801574289798737, AUC-ROC Macro=0.4903728318050908, AUC-ROC Micro=0.5861994047882824
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.36234242752194407
Train: epoch: 3, loss = 0.3628347337245941
Train: epoch: 3, loss = 0.36014917939901353
Train: epoch: 3, loss = 0.36236935440450907
Train: epoch: 3, loss = 0.36198992471396924
Train: epoch: 3, loss = 0.3624089372282227
Train: epoch: 3, loss = 0.3624448039702007
Train: epoch: 3, loss = 0.36111115149222317
Train: epoch: 3, loss = 0.3603635653025574
Train: epoch: 3, loss = 0.3609869147092104
Train: epoch: 3, loss = 0.36095398938113993
Train: epoch: 3, loss = 0.3617357665983339
Train: epoch: 3, loss = 0.361388359064093
Train: epoch: 3, loss = 0.3607613707280585
Train: epoch: 3, loss = 0.3602497143795093
Train: epoch: 3, loss = 0.3597987986542284
Train: epoch: 3, loss = 0.35980345954351567
Train: epoch: 3, loss = 0.3599389243291484
Train:  Epoch 3, Loss=0.3599185024122907, AUC-ROC Macro=0.7443951138360544, AUC-ROC Micro=0.8045248674553622
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3564679150780042, AUC-ROC Macro=0.7508088154004839, AUC-ROC Micro=0.8056261443669612
Eval task: 2
Eval:  Epoch 3, Loss=0.3947935104370117, AUC-ROC Macro=0.47950879802861274, AUC-ROC Micro=0.5965488669350733
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.3589861689507961
Train: epoch: 4, loss = 0.35759025368839503
Train: epoch: 4, loss = 0.35664258114993574
Train: epoch: 4, loss = 0.3565728438459337
Train: epoch: 4, loss = 0.3568106377720833
Train: epoch: 4, loss = 0.3558157211045424
Train: epoch: 4, loss = 0.35574891305395534
Train: epoch: 4, loss = 0.35604979971423745
Train: epoch: 4, loss = 0.35599056468241747
Train: epoch: 4, loss = 0.35639441704005004
Train: epoch: 4, loss = 0.35608253854919564
Train: epoch: 4, loss = 0.355545445010066
Train: epoch: 4, loss = 0.3553483954587808
Train: epoch: 4, loss = 0.35513332330754827
Train: epoch: 4, loss = 0.35509400120377543
Train: epoch: 4, loss = 0.35497247957624495
Train: epoch: 4, loss = 0.3546512034403927
Train: epoch: 4, loss = 0.3544235960849457
Train:  Epoch 4, Loss=0.3543061173960694, AUC-ROC Macro=0.756734617370963, AUC-ROC Micro=0.8127048961640788
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3530611644188563, AUC-ROC Macro=0.7571360169135914, AUC-ROC Micro=0.8110450342396509
Eval task: 2
Eval:  Epoch 4, Loss=0.4390503168106079, AUC-ROC Macro=0.47788829333340144, AUC-ROC Micro=0.5741489027724596
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.3484383722394705
Train: epoch: 5, loss = 0.35107570838183166
Train: epoch: 5, loss = 0.35329502863188583
Train: epoch: 5, loss = 0.3520492458157241
Train: epoch: 5, loss = 0.35118534725904466
Train: epoch: 5, loss = 0.3513944518814484
Train: epoch: 5, loss = 0.35164858433817114
Train: epoch: 5, loss = 0.35100960929878056
Train: epoch: 5, loss = 0.35035537771880626
Train: epoch: 5, loss = 0.35051596319675443
Train: epoch: 5, loss = 0.35010337200354447
Train: epoch: 5, loss = 0.3503088029784461
Train: epoch: 5, loss = 0.35043832917052964
Train: epoch: 5, loss = 0.35078622076660393
Train: epoch: 5, loss = 0.350705192938447
Train: epoch: 5, loss = 0.3502319558849558
Train: epoch: 5, loss = 0.3501198558334042
Train: epoch: 5, loss = 0.35024174981233147
Train:  Epoch 5, Loss=0.34999491453374554, AUC-ROC Macro=0.7655639752443706, AUC-ROC Micro=0.8188929176620617
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.35033968836069107, AUC-ROC Macro=0.7628770368881342, AUC-ROC Micro=0.8151132811786796
Eval task: 2
Eval:  Epoch 5, Loss=0.4346946030855179, AUC-ROC Macro=0.49607584826931483, AUC-ROC Micro=0.5874388212586845
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3431127215176821
Train: epoch: 6, loss = 0.34175920594483616
Train: epoch: 6, loss = 0.3433063036203384
Train: epoch: 6, loss = 0.34327715788036584
Train: epoch: 6, loss = 0.3439147782176733
Train: epoch: 6, loss = 0.34431717031945785
Train: epoch: 6, loss = 0.34544459935809885
Train: epoch: 6, loss = 0.34605790114961565
Train: epoch: 6, loss = 0.34675484820372526
Train: epoch: 6, loss = 0.34687485598027706
Train: epoch: 6, loss = 0.3461100398004055
Train: epoch: 6, loss = 0.34656339125086866
Train: epoch: 6, loss = 0.346271085108702
Train: epoch: 6, loss = 0.34696473026382074
Train: epoch: 6, loss = 0.3470978223135074
Train: epoch: 6, loss = 0.3469079634919763
Train: epoch: 6, loss = 0.3467320314531817
Train: epoch: 6, loss = 0.34663267641845674
Train:  Epoch 6, Loss=0.3468606721702804, AUC-ROC Macro=0.7718075610839003, AUC-ROC Micro=0.823055394257582
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.34938153127829236, AUC-ROC Macro=0.7644534123834102, AUC-ROC Micro=0.8169026775154511
Eval task: 2
Eval:  Epoch 6, Loss=0.442294180393219, AUC-ROC Macro=0.4888928952798393, AUC-ROC Micro=0.5776730129106837
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3523072923223178, AUC-ROC Macro=0.763665748254173, AUC-ROC Micro=0.8158824305810964
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.44696615636348724, AUC-ROC Macro=0.48724242905075377, AUC-ROC Micro=0.5892738650417177
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.3453491434454918
Train:  Epoch 1, Loss=0.33810240790933743, AUC-ROC Macro=0.557152942550772, AUC-ROC Micro=0.724136188658741
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.353133462369442, AUC-ROC Macro=0.7592840003120297, AUC-ROC Micro=0.8125169323092982
Eval task: 2
Eval:  Epoch 1, Loss=0.297470286488533, AUC-ROC Macro=0.6191793913057857, AUC-ROC Micro=0.7667383474684208
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.32190859541296957
Train:  Epoch 2, Loss=0.318494608295845, AUC-ROC Macro=0.6453488089644126, AUC-ROC Micro=0.7911834485307501
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.34749699632326764, AUC-ROC Macro=0.7587490840109689, AUC-ROC Micro=0.8125937439000336
Eval task: 2
Eval:  Epoch 2, Loss=0.28846047818660736, AUC-ROC Macro=0.6708280393504096, AUC-ROC Micro=0.7935846134617739
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.3097455605119467
Train:  Epoch 3, Loss=0.3098558123682001, AUC-ROC Macro=0.6909650910390923, AUC-ROC Micro=0.8127860086715943
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3443138649066289, AUC-ROC Macro=0.7585541851218249, AUC-ROC Micro=0.8122624021084833
Eval task: 2
Eval:  Epoch 3, Loss=0.2870248556137085, AUC-ROC Macro=0.6857407923519908, AUC-ROC Micro=0.8020943648302599
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.3047093327343464
Train:  Epoch 4, Loss=0.3038357097234686, AUC-ROC Macro=0.7180280541083757, AUC-ROC Micro=0.8270394973987722
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.34114497279127437, AUC-ROC Macro=0.756128481210884, AUC-ROC Micro=0.8103478910953275
Eval task: 2
Eval:  Epoch 4, Loss=0.275296688079834, AUC-ROC Macro=0.7006973296573892, AUC-ROC Micro=0.8142574615952424
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.2986078494042158
Train:  Epoch 5, Loss=0.2981227258508674, AUC-ROC Macro=0.7427995015766266, AUC-ROC Micro=0.8389932976320721
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.33962533871332806, AUC-ROC Macro=0.7546642094959136, AUC-ROC Micro=0.8090729921076599
Eval task: 2
Eval:  Epoch 5, Loss=0.27007313072681427, AUC-ROC Macro=0.7039106744145301, AUC-ROC Micro=0.8186102208539223
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.2937614579498768
Train:  Epoch 6, Loss=0.29283736806201804, AUC-ROC Macro=0.7553248306100367, AUC-ROC Micro=0.8462182574259505
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.338321216404438, AUC-ROC Macro=0.7526766223896737, AUC-ROC Micro=0.807288370679278
Eval task: 2
Eval:  Epoch 6, Loss=0.2690785527229309, AUC-ROC Macro=0.7162344748867591, AUC-ROC Micro=0.8195873684306991
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.36248552550872165, AUC-ROC Macro=0.7510774394170816, AUC-ROC Micro=0.8063362862884564
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.2971115708351135, AUC-ROC Macro=0.6875565749685575, AUC-ROC Micro=0.8088065487659428
{'0': {'precision': 0.5387994143484627, 'recall': 0.28134556574923547, 'f1-score': 0.36966348568558516, 'support': 1308}, '1': {'precision': 0.6268656716417911, 'recall': 0.417910447761194, 'f1-score': 0.5014925373134329, 'support': 402}, '2': {'precision': 0.5132743362831859, 'recall': 0.08814589665653495, 'f1-score': 0.1504539559014267, 'support': 658}, '3': {'precision': 0.544924154025671, 'recall': 0.23467336683417087, 'f1-score': 0.3280646294344925, 'support': 1990}, '4': {'precision': 0.5372340425531915, 'recall': 0.12531017369727046, 'f1-score': 0.2032193158953722, 'support': 806}, '5': {'precision': 0.37142857142857144, 'recall': 0.016709511568123392, 'f1-score': 0.03198031980319803, 'support': 778}, '6': {'precision': 0.5720720720720721, 'recall': 0.09754224270353302, 'f1-score': 0.16666666666666666, 'support': 1302}, '7': {'precision': 0.14285714285714285, 'recall': 0.0023584905660377358, 'f1-score': 0.004640371229698376, 'support': 424}, '8': {'precision': 0.5724381625441696, 'recall': 0.2956204379562044, 'f1-score': 0.3898916967509025, 'support': 1644}, '9': {'precision': 0.6780045351473923, 'recall': 0.44165435745937964, 'f1-score': 0.5348837209302326, 'support': 2031}, '10': {'precision': 0.7078189300411523, 'recall': 0.30017452006980805, 'f1-score': 0.4215686274509804, 'support': 573}, '11': {'precision': 0.5076586433260394, 'recall': 0.19727891156462585, 'f1-score': 0.28413962033067974, 'support': 1176}, '12': {'precision': 0.60727969348659, 'recall': 0.1790960451977401, 'f1-score': 0.2766143106457242, 'support': 1770}, '13': {'precision': 0.5509400961958898, 'recall': 0.48536209553158705, 'f1-score': 0.5160761826745853, 'support': 2596}, '14': {'precision': 0.541025641025641, 'recall': 0.25937307928703135, 'f1-score': 0.3506439551308683, 'support': 1627}, '15': {'precision': 0.75, 'recall': 0.012396694214876033, 'f1-score': 0.024390243902439025, 'support': 484}, '16': {'precision': 0.4818181818181818, 'recall': 0.13333333333333333, 'f1-score': 0.20886699507389164, 'support': 795}, '17': {'precision': 0.4444444444444444, 'recall': 0.022058823529411766, 'f1-score': 0.04203152364273205, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.2727272727272727, 'recall': 0.011450381679389313, 'f1-score': 0.021978021978021976, 'support': 262}, '20': {'precision': 0.42857142857142855, 'recall': 0.0053285968028419185, 'f1-score': 0.010526315789473684, 'support': 563}, '21': {'precision': 0.5859872611464968, 'recall': 0.10991636798088411, 'f1-score': 0.18511066398390344, 'support': 837}, '22': {'precision': 0.6596218020022246, 'recall': 0.5460405156537753, 'f1-score': 0.5974811083123425, 'support': 1086}, '23': {'precision': 0.605080831408776, 'recall': 0.3042973286875726, 'f1-score': 0.4049459041731066, 'support': 861}, '24': {'precision': 0.5384615384615384, 'recall': 0.22178217821782178, 'f1-score': 0.3141654978962132, 'support': 505}, 'micro avg': {'precision': 0.581027302174919, 'recall': 0.24742836873842272, 'f1-score': 0.34706175023494945, 'support': 25373}, 'macro avg': {'precision': 0.511173354702293, 'recall': 0.1915663745080953, 'f1-score': 0.2535798268238388, 'support': 25373}, 'weighted avg': {'precision': 0.5483243192815915, 'recall': 0.24742836873842272, 'f1-score': 0.3180942223339329, 'support': 25373}, 'samples avg': {'precision': 0.3887291469200648, 'recall': 0.2223861423173521, 'f1-score': 0.25961916909499994, 'support': 25373}}
{'0': {'precision': 0.7142857142857143, 'recall': 0.2692307692307692, 'f1-score': 0.3910614525139664, 'support': 130}, '1': {'precision': 0.6052631578947368, 'recall': 0.16911764705882354, 'f1-score': 0.26436781609195403, 'support': 136}, '2': {'precision': 0.40350877192982454, 'recall': 0.1678832116788321, 'f1-score': 0.23711340206185563, 'support': 137}, '3': {'precision': 0.6534090909090909, 'recall': 0.539906103286385, 'f1-score': 0.5912596401028278, 'support': 213}, '4': {'precision': 0.4, 'recall': 0.05333333333333334, 'f1-score': 0.09411764705882353, 'support': 75}, '5': {'precision': 0.3333333333333333, 'recall': 0.010638297872340425, 'f1-score': 0.020618556701030927, 'support': 94}, '6': {'precision': 0.6, 'recall': 0.04054054054054054, 'f1-score': 0.0759493670886076, 'support': 74}, '7': {'precision': 0.3333333333333333, 'recall': 0.075, 'f1-score': 0.12244897959183673, 'support': 40}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 65}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 63}, '11': {'precision': 0.5, 'recall': 0.017857142857142856, 'f1-score': 0.03448275862068965, 'support': 56}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 52}, '13': {'precision': 0.42857142857142855, 'recall': 0.05454545454545454, 'f1-score': 0.09677419354838708, 'support': 55}, '14': {'precision': 0.7272727272727273, 'recall': 0.12698412698412698, 'f1-score': 0.2162162162162162, 'support': 63}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}, '17': {'precision': 1.0, 'recall': 0.012195121951219513, 'f1-score': 0.024096385542168676, 'support': 82}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, 'micro avg': {'precision': 0.5978260869565217, 'recall': 0.14313597918022122, 'f1-score': 0.23097112860892388, 'support': 1537}, 'macro avg': {'precision': 0.26795910230120756, 'recall': 0.06148926997355872, 'f1-score': 0.08674025660553458, 'support': 1537}, 'weighted avg': {'precision': 0.43466886630131846, 'recall': 0.14313597918022122, 'f1-score': 0.18710551191362157, 'support': 1537}, 'samples avg': {'precision': 0.2837239583333333, 'recall': 0.1262757316468254, 'f1-score': 0.16041355562839937, 'support': 1537}}