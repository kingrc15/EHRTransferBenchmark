
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
south_val.csv
test_listfile.csv
south_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1732576954364777
Train: epoch: 1, loss = 2.139738511443138
Train: epoch: 1, loss = 2.1252825073401134
Train: epoch: 1, loss = 2.1076429571211337
Train: epoch: 1, loss = 2.094952710390091
Train: epoch: 1, loss = 2.0845502916971843
Train: epoch: 1, loss = 2.079938023175512
Train: epoch: 1, loss = 2.0751205026358366
Train: epoch: 1, loss = 2.073594115111563
Train: epoch: 1, loss = 2.072311427950859
Train: epoch: 1, loss = 2.0677749391577462
Train: epoch: 1, loss = 2.067109331091245
Train: epoch: 1, loss = 2.0653498107653396
Train: epoch: 1, loss = 2.0633902583377703
Train: epoch: 1, loss = 2.0626294986804328
Train: epoch: 1, loss = 2.0618818140774966
Train: epoch: 1, loss = 2.060654152912252
Train: epoch: 1, loss = 2.060211096538438
Train: epoch: 1, loss = 2.0588709440356805
Train: epoch: 1, loss = 2.058702573001385
Train: epoch: 1, loss = 2.0575396890583493
Train: epoch: 1, loss = 2.0566371317614207
Train: epoch: 1, loss = 2.0559597980976103
Train: epoch: 1, loss = 2.0547557283441225
Train: epoch: 1, loss = 2.0551158268928527
Train: epoch: 1, loss = 2.0540863918111874
Train: epoch: 1, loss = 2.0529902881604656
Train: epoch: 1, loss = 2.0525585719730173
Train: epoch: 1, loss = 2.0519212789987695
Train: epoch: 1, loss = 2.051429241637389
Train: epoch: 1, loss = 2.0512142537486167
Train: epoch: 1, loss = 2.0503898039646447
Train: epoch: 1, loss = 2.0499921970295185
Train: epoch: 1, loss = 2.0493788591553184
Train: epoch: 1, loss = 2.049135073406356
Train: epoch: 1, loss = 2.048778767850664
Train: epoch: 1, loss = 2.0483534973215414
Train: epoch: 1, loss = 2.0481683031038234
Train: epoch: 1, loss = 2.047530190470891
Train: epoch: 1, loss = 2.0473772636055947
Train: epoch: 1, loss = 2.047162093432938
Train: epoch: 1, loss = 2.0471432550606274
Train: epoch: 1, loss = 2.0469783588204273
Train:  Epoch 1, Loss=2.046899780505044, Cohen Kappa=0.37562577553023846, MAD=0.716945135761574
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.040783000403437, Cohen Kappa=0.4139576413449948, MAD=0.7286465777110306
Eval task: 2
Eval:  Epoch 1, Loss=1.9356511851836895, Cohen Kappa=0.004712766500040266, MAD=0.7634189397890063
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.057776631980107, Cohen Kappa=0.32906362193439964, MAD=0.728998864538726
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.929555779901044, Cohen Kappa=0.007016238238471084, MAD=0.7634115900931273
south_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.972265088558197
Train: epoch: 1, loss = 1.9722505500912666
Train: epoch: 1, loss = 1.9722738361358643
Train: epoch: 1, loss = 1.974715397953987
Train: epoch: 1, loss = 1.9749080229997635
Train: epoch: 1, loss = 1.9759502730766931
Train: epoch: 1, loss = 1.9759795367717743
Train: epoch: 1, loss = 1.9758428080379964
Train: epoch: 1, loss = 1.9773882942729526
Train: epoch: 1, loss = 1.9780555517673493
Train: epoch: 1, loss = 1.9758643542094665
Train: epoch: 1, loss = 1.975252116372188
Train: epoch: 1, loss = 1.973461212836779
Train: epoch: 1, loss = 1.9731064243827547
Train: epoch: 1, loss = 1.972782796462377
Train: epoch: 1, loss = 1.9719194221869112
Train: epoch: 1, loss = 1.9714139208022285
Train: epoch: 1, loss = 1.9713854968878959
Train: epoch: 1, loss = 1.9711785118203413
Train: epoch: 1, loss = 1.9711578337550164
Train: epoch: 1, loss = 1.9712323027565366
Train: epoch: 1, loss = 1.971133585951545
Train: epoch: 1, loss = 1.9710803451227106
Train: epoch: 1, loss = 1.9712371707707643
Train: epoch: 1, loss = 1.9714408385038376
Train: epoch: 1, loss = 1.971622692827995
Train: epoch: 1, loss = 1.9714474769654098
Train: epoch: 1, loss = 1.9708289892120021
Train: epoch: 1, loss = 1.9703172913090936
Train: epoch: 1, loss = 1.9700480249524117
Train: epoch: 1, loss = 1.9699997026112772
Train: epoch: 1, loss = 1.9700233336351811
Train: epoch: 1, loss = 1.9699899726925474
Train: epoch: 1, loss = 1.9700589550768628
Train: epoch: 1, loss = 1.9699958558423178
Train: epoch: 1, loss = 1.9698519246776898
Train: epoch: 1, loss = 1.9697822542126113
Train: epoch: 1, loss = 1.9694594116430533
Train: epoch: 1, loss = 1.9690868032284272
Train: epoch: 1, loss = 1.9689867696017027
Train: epoch: 1, loss = 1.968771592335003
Train: epoch: 1, loss = 1.9685976697575478
Train: epoch: 1, loss = 1.9686092901368475
Train:  Epoch 1, Loss=1.968446621118273, Cohen Kappa=0.011965172517775513, MAD=0.6981888828632149
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0319324156333662, Cohen Kappa=0.43113122583097263, MAD=0.728553612045263
Eval task: 2
Eval:  Epoch 1, Loss=1.9865017512748981, Cohen Kappa=0.010725141855240539, MAD=0.692695442248999
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.056492996626887, Cohen Kappa=0.3376756226678348, MAD=0.7163088472394461
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8967405516525795, Cohen Kappa=0.012239366868017187, MAD=0.694950414897485
{'0': {'precision': 0.40625392440035163, 'recall': 0.7938650306748466, 'f1-score': 0.5374646951320816, 'support': 4075}, '1': {'precision': 0.2560228664761127, 'recall': 0.218848167539267, 'f1-score': 0.23598042905532554, 'support': 2865}, '2': {'precision': 0.21428571428571427, 'recall': 0.0033003300330033004, 'f1-score': 0.006500541711809317, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.09720534629404617, 'recall': 0.06578947368421052, 'f1-score': 0.07846983815595879, 'support': 1216}, '9': {'precision': 0.15704323570432357, 'recall': 0.5246971109040075, 'f1-score': 0.24173465006440534, 'support': 1073}, 'accuracy': 0.3038119612068966, 'macro avg': {'precision': 0.11308110871605485, 'recall': 0.16065001128353348, 'f1-score': 0.11001501541195806, 'support': 14848}, 'weighted avg': {'precision': 0.20644334428618155, 'recall': 0.3038119612068966, 'f1-score': 0.21773108495794466, 'support': 14848}}
{'0': {'precision': 0.30924161437756603, 'recall': 0.8986942818550203, 'f1-score': 0.46014638925710327, 'support': 4442}, '1': {'precision': 0.35312338668043364, 'recall': 0.1329187718616401, 'f1-score': 0.193138500635324, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 176}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.31492456896551724, 'macro avg': {'precision': 0.06623650010579997, 'recall': 0.10316130537166604, 'f1-score': 0.06532848898924273, 'support': 14848}, 'weighted avg': {'precision': 0.21489925908692484, 'recall': 0.31492456896551724, 'f1-score': 0.20459731851760707, 'support': 14848}}