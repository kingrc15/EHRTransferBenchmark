
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_decomp_midwest
['/data/datasets/mimic3-benchmarks/data/decompensation', '/data/datasets/eICU2MIMIC/decompensation_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.14816912453621625
Train: epoch: 1, loss = 0.12097681440645829
Train: epoch: 1, loss = 0.11231588573098028
Train: epoch: 1, loss = 0.09696567778133612
Train: epoch: 1, loss = 0.09371077787928515
Train: epoch: 1, loss = 0.0868706899259026
Train: epoch: 1, loss = 0.0839510878179239
Train: epoch: 1, loss = 0.08348306152172881
Train: epoch: 1, loss = 0.08307586984285283
Train: epoch: 1, loss = 0.0833485894270998
Train: epoch: 1, loss = 0.08293633729158584
Train: epoch: 1, loss = 0.08322491392534478
Train: epoch: 1, loss = 0.08335241008802909
Train: epoch: 1, loss = 0.08354179857699949
Train: epoch: 1, loss = 0.08443166827971194
Train: epoch: 1, loss = 0.08350857717925464
Train: epoch: 1, loss = 0.08326530063156765
Train: epoch: 1, loss = 0.08326371224534038
Train: epoch: 1, loss = 0.08280080590263855
Train: epoch: 1, loss = 0.08249433079345908
Train: epoch: 1, loss = 0.08176171149075907
Train: epoch: 1, loss = 0.08186819092332205
Train: epoch: 1, loss = 0.08193073897773107
Train: epoch: 1, loss = 0.08206259582530037
Train: epoch: 1, loss = 0.08195261258546961
Train: epoch: 1, loss = 0.08221121019619974
Train: epoch: 1, loss = 0.08232101231570899
Train: epoch: 1, loss = 0.08242919223199091
Train: epoch: 1, loss = 0.08247274804690749
Train: epoch: 1, loss = 0.08284118426217658
Train: epoch: 1, loss = 0.08257503805313102
Train: epoch: 1, loss = 0.08253330556041874
Train: epoch: 1, loss = 0.08253863436620591
Train: epoch: 1, loss = 0.08214933596386212
Train: epoch: 1, loss = 0.08203641415679262
Train: epoch: 1, loss = 0.08196571210307917
Train: epoch: 1, loss = 0.08224564406686506
Train: epoch: 1, loss = 0.08234195935655551
Train: epoch: 1, loss = 0.0824768147648548
Train: epoch: 1, loss = 0.08281696698621818
Train: epoch: 1, loss = 0.08282484397302785
Train: epoch: 1, loss = 0.08302242475508441
Train: epoch: 1, loss = 0.08285948874130385
Train:  Epoch 1, Loss=0.0827758381357084, AUC-ROC=0.8239784860771776, AUC-PR=0.15785666576147067
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.08816994810155754, AUC-ROC=0.8553881904596861, AUC-PR=0.20135641727421932
Eval task: 2
Eval:  Epoch 1, Loss=0.123207184646664, AUC-ROC=0.6347549552914471, AUC-PR=0.0503153032461726
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.08635330253184356, AUC-ROC=0.8502941975775724, AUC-PR=0.2184408043824298
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.11443257293310659, AUC-ROC=0.6009487713040031, AUC-PR=0.041836092366756145
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.13341872247867287
Train: epoch: 1, loss = 0.12625709386542439
Train: epoch: 1, loss = 0.12190808492557456
Train: epoch: 1, loss = 0.11637758218101225
Train: epoch: 1, loss = 0.11159803592739627
Train: epoch: 1, loss = 0.10933850165495339
Train: epoch: 1, loss = 0.11027660522443641
Train: epoch: 1, loss = 0.10826618722028797
Train: epoch: 1, loss = 0.10716217754745028
Train: epoch: 1, loss = 0.10816565356520004
Train: epoch: 1, loss = 0.10780026894591918
Train: epoch: 1, loss = 0.10874646173964721
Train: epoch: 1, loss = 0.10921910303143355
Train: epoch: 1, loss = 0.1087950072660377
Train: epoch: 1, loss = 0.10987131887394935
Train: epoch: 1, loss = 0.11033725003129803
Train: epoch: 1, loss = 0.11065797877717105
Train: epoch: 1, loss = 0.11016226295123084
Train: epoch: 1, loss = 0.1110841730741882
Train: epoch: 1, loss = 0.11144992846087552
Train: epoch: 1, loss = 0.11143374257610135
Train: epoch: 1, loss = 0.11304042444500903
Train: epoch: 1, loss = 0.11329165426265124
Train: epoch: 1, loss = 0.1130153662453328
Train: epoch: 1, loss = 0.1118656491825357
Train: epoch: 1, loss = 0.1114654065319337
Train: epoch: 1, loss = 0.11189439842158376
Train: epoch: 1, loss = 0.1120788088822571
Train: epoch: 1, loss = 0.1117070265341518
Train: epoch: 1, loss = 0.11126780656515621
Train: epoch: 1, loss = 0.11191792028753328
Train: epoch: 1, loss = 0.11225586300010036
Train: epoch: 1, loss = 0.11233969203775016
Train: epoch: 1, loss = 0.11236535593305769
Train: epoch: 1, loss = 0.11239142079278827
Train: epoch: 1, loss = 0.11251482527483152
Train: epoch: 1, loss = 0.11258535324986017
Train: epoch: 1, loss = 0.11206571979858716
Train: epoch: 1, loss = 0.11209811454776149
Train: epoch: 1, loss = 0.112286971481808
Train: epoch: 1, loss = 0.11203930386790734
Train: epoch: 1, loss = 0.11173757700033353
Train: epoch: 1, loss = 0.11110444401688657
Train:  Epoch 1, Loss=0.11100978772539113, AUC-ROC=0.6694147863801009, AUC-PR=0.09286992013445217
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.09975680888726793, AUC-ROC=0.7755558744135106, AUC-PR=0.11318462281824308
Eval task: 2
Eval:  Epoch 1, Loss=0.11288150078777609, AUC-ROC=0.6782765763085568, AUC-PR=0.11796826989318335
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.0889585991871768, AUC-ROC=0.8404077521940927, AUC-PR=0.24476342379485666
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.10369317342752013, AUC-ROC=0.6870159532302814, AUC-PR=0.11128760321739994