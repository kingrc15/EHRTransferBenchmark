
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
midwest_val.csv
test_listfile.csv
midwest_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1713685804605483
Train: epoch: 1, loss = 2.1336576837301253
Train: epoch: 1, loss = 2.112489289244016
Train: epoch: 1, loss = 2.097712053358555
Train: epoch: 1, loss = 2.0863042442798614
Train: epoch: 1, loss = 2.081664523382982
Train: epoch: 1, loss = 2.0772812159572327
Train: epoch: 1, loss = 2.074649985805154
Train: epoch: 1, loss = 2.07134457634555
Train: epoch: 1, loss = 2.068988739490509
Train: epoch: 1, loss = 2.06613838206638
Train: epoch: 1, loss = 2.066171265145143
Train: epoch: 1, loss = 2.064073189451144
Train: epoch: 1, loss = 2.062364103581224
Train: epoch: 1, loss = 2.059864299058914
Train: epoch: 1, loss = 2.0585928517207503
Train: epoch: 1, loss = 2.0588076000704483
Train: epoch: 1, loss = 2.0581839778025945
Train: epoch: 1, loss = 2.056773263404244
Train: epoch: 1, loss = 2.056213128268719
Train: epoch: 1, loss = 2.055309292560532
Train: epoch: 1, loss = 2.054072620082985
Train: epoch: 1, loss = 2.053674572084261
Train: epoch: 1, loss = 2.052345078488191
Train: epoch: 1, loss = 2.052543344926834
Train: epoch: 1, loss = 2.051780076898061
Train: epoch: 1, loss = 2.0516868829727173
Train: epoch: 1, loss = 2.050631801996912
Train: epoch: 1, loss = 2.05022287650355
Train: epoch: 1, loss = 2.048923570851485
Train: epoch: 1, loss = 2.0489600306364797
Train: epoch: 1, loss = 2.049003304373473
Train: epoch: 1, loss = 2.0484884943564734
Train: epoch: 1, loss = 2.048346458428046
Train: epoch: 1, loss = 2.048167010154043
Train: epoch: 1, loss = 2.0475806271864307
Train: epoch: 1, loss = 2.0476677515700055
Train: epoch: 1, loss = 2.047854892266424
Train: epoch: 1, loss = 2.0471566972212916
Train: epoch: 1, loss = 2.046574417948723
Train: epoch: 1, loss = 2.0460381120879476
Train: epoch: 1, loss = 2.0451793513411567
Train: epoch: 1, loss = 2.0451687971104024
Train:  Epoch 1, Loss=2.0450249811853682, Cohen Kappa=0.3828708646743493, MAD=0.7182713688437226
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0311434268951416, Cohen Kappa=0.4291325235885183, MAD=0.729506447164106
Eval task: 2
Eval:  Epoch 1, Loss=1.978512992118967, Cohen Kappa=0.005277788326495947, MAD=0.7530139661364996
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0510089233003814, Cohen Kappa=0.34562141770022126, MAD=0.7312764234958145
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9446617508756703, Cohen Kappa=0.0034768019354318724, MAD=0.7517530976775271
midwest_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9683617371320725
Train: epoch: 1, loss = 1.9683021232485771
Train: epoch: 1, loss = 1.9626111062367757
Train: epoch: 1, loss = 1.9638688255846501
Train: epoch: 1, loss = 1.9641189678907394
Train: epoch: 1, loss = 1.9655297334988913
Train: epoch: 1, loss = 1.961944060070174
Train: epoch: 1, loss = 1.960044024810195
Train: epoch: 1, loss = 1.9580850712458293
Train: epoch: 1, loss = 1.9576088089346886
Train: epoch: 1, loss = 1.956405093182217
Train: epoch: 1, loss = 1.9556998731195927
Train: epoch: 1, loss = 1.9549735768941732
Train: epoch: 1, loss = 1.95469163111278
Train: epoch: 1, loss = 1.9540399410327276
Train: epoch: 1, loss = 1.9526467686519027
Train: epoch: 1, loss = 1.9518672850202112
Train: epoch: 1, loss = 1.951468155450291
Train: epoch: 1, loss = 1.9517418260323374
Train: epoch: 1, loss = 1.9513642657995225
Train: epoch: 1, loss = 1.9515007885013307
Train: epoch: 1, loss = 1.951325574327599
Train: epoch: 1, loss = 1.9513018474371537
Train: epoch: 1, loss = 1.9511099365601936
Train: epoch: 1, loss = 1.9506846637964248
Train: epoch: 1, loss = 1.9502575048575035
Train: epoch: 1, loss = 1.950396406253179
Train: epoch: 1, loss = 1.9504376124058451
Train: epoch: 1, loss = 1.9501313448363338
Train: epoch: 1, loss = 1.949701442182064
Train: epoch: 1, loss = 1.9491846400691617
Train: epoch: 1, loss = 1.949144874792546
Train: epoch: 1, loss = 1.9490881875789527
Train: epoch: 1, loss = 1.949144750307588
Train: epoch: 1, loss = 1.948846395952361
Train: epoch: 1, loss = 1.9485087799694802
Train: epoch: 1, loss = 1.9483717828827936
Train: epoch: 1, loss = 1.9482341554447224
Train: epoch: 1, loss = 1.9481610965881593
Train: epoch: 1, loss = 1.9477055243104697
Train: epoch: 1, loss = 1.9478147917549784
Train: epoch: 1, loss = 1.9479998689889908
Train: epoch: 1, loss = 1.9481069165468217
Train:  Epoch 1, Loss=1.9480649678911481, Cohen Kappa=0.09318398132522554, MAD=0.6855672013997323
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.112948282011624, Cohen Kappa=0.1078267263186542, MAD=0.7132628556385348
Eval task: 2
Eval:  Epoch 1, Loss=1.954311572272202, Cohen Kappa=0.07405826348321809, MAD=0.667256422335772
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.084494845620517, Cohen Kappa=0.04996976534615882, MAD=0.7112349726657489
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9245291948318481, Cohen Kappa=0.08344894964721117, MAD=0.6708761112529581
{'0': {'precision': 0.434863523573201, 'recall': 0.34404907975460125, 'f1-score': 0.38416221400191813, 'support': 4075}, '1': {'precision': 0.18875641806631277, 'recall': 0.7570680628272252, 'f1-score': 0.30217330732794656, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.48484848484848486, 'recall': 0.05263157894736842, 'f1-score': 0.09495548961424333, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.24481411637931033, 'macro avg': {'precision': 0.11084684264879988, 'recall': 0.11537487215291949, 'f1-score': 0.0781291010944108, 'support': 14848}, 'weighted avg': {'precision': 0.19547627652859223, 'recall': 0.24481411637931033, 'f1-score': 0.17151491264300261, 'support': 14848}}
{'0': {'precision': 0.46385193753614806, 'recall': 0.18955329709288585, 'f1-score': 0.26912751677852353, 'support': 4231}, '1': {'precision': 0.3416381437554724, 'recall': 0.8531107135758299, 'f1-score': 0.4878936000909401, 'support': 5031}, '2': {'precision': 0.1569767441860465, 'recall': 0.022350993377483443, 'f1-score': 0.03913043478260869, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.1179245283018868, 'recall': 0.08169934640522876, 'f1-score': 0.09652509652509653, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3483970905172414, 'macro avg': {'precision': 0.10803913537795537, 'recall': 0.1146714350451428, 'f1-score': 0.08926766481771689, 'support': 14848}, 'weighted avg': {'precision': 0.27590785079223396, 'recall': 0.3483970905172414, 'f1-score': 0.25036011823268556, 'support': 14848}}