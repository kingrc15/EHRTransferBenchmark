
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1614313662052154
Train: epoch: 1, loss = 2.1345535695552824
Train: epoch: 1, loss = 2.11470249692599
Train: epoch: 1, loss = 2.1005843971669673
Train: epoch: 1, loss = 2.089058718085289
Train: epoch: 1, loss = 2.085385289589564
Train: epoch: 1, loss = 2.0797002663782664
Train: epoch: 1, loss = 2.075507814064622
Train: epoch: 1, loss = 2.070963999165429
Train: epoch: 1, loss = 2.0746369738578796
Train: epoch: 1, loss = 2.0728491461818868
Train: epoch: 1, loss = 2.0706272046267986
Train: epoch: 1, loss = 2.0685918273375585
Train: epoch: 1, loss = 2.0674069477404866
Train: epoch: 1, loss = 2.065834967136383
Train: epoch: 1, loss = 2.064442406706512
Train: epoch: 1, loss = 2.063286481955472
Train: epoch: 1, loss = 2.0617313847608036
Train: epoch: 1, loss = 2.0604420862072392
Train: epoch: 1, loss = 2.0584665974378584
Train: epoch: 1, loss = 2.0579853721175874
Train: epoch: 1, loss = 2.0567982149936936
Train: epoch: 1, loss = 2.0560248887020607
Train: epoch: 1, loss = 2.0551723384608827
Train: epoch: 1, loss = 2.05391644077301
Train: epoch: 1, loss = 2.054204270564593
Train: epoch: 1, loss = 2.0535251326251913
Train: epoch: 1, loss = 2.052898453984942
Train: epoch: 1, loss = 2.052192034104775
Train: epoch: 1, loss = 2.052145796954632
Train: epoch: 1, loss = 2.0506427556468596
Train: epoch: 1, loss = 2.050220652166754
Train: epoch: 1, loss = 2.0496390346505424
Train: epoch: 1, loss = 2.048876811002984
Train: epoch: 1, loss = 2.0484639746121
Train: epoch: 1, loss = 2.0480905578037105
Train: epoch: 1, loss = 2.047867957981857
Train: epoch: 1, loss = 2.047245719542629
Train: epoch: 1, loss = 2.0470025945321106
Train: epoch: 1, loss = 2.047050420448184
Train: epoch: 1, loss = 2.0463143525327125
Train: epoch: 1, loss = 2.045973732272784
Train: epoch: 1, loss = 2.0454134159725768
Train:  Epoch 1, Loss=2.045518491431645, Cohen Kappa=0.3805838882839726, MAD=0.7199763743166915
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.042826066757071, Cohen Kappa=0.38319971667547004, MAD=0.6855472790561852
Eval task: 2
Eval:  Epoch 1, Loss=1.9782502897854508, Cohen Kappa=0.005283163060331497, MAD=0.7241361600107997
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0553912931475145, Cohen Kappa=0.30603438199139055, MAD=0.6828051527876875
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9417110229360646, Cohen Kappa=0.0045381302240385946, MAD=0.7203246570514715
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.99298113822937
Train: epoch: 1, loss = 1.9948717001080514
Train: epoch: 1, loss = 1.9954290509223938
Train: epoch: 1, loss = 1.994520329684019
Train: epoch: 1, loss = 1.9961879904270172
Train: epoch: 1, loss = 1.9938633638620376
Train: epoch: 1, loss = 1.9954698174340384
Train: epoch: 1, loss = 1.9943884359300137
Train: epoch: 1, loss = 1.9957910079426235
Train: epoch: 1, loss = 1.9949564126133918
Train: epoch: 1, loss = 1.9936028772050685
Train: epoch: 1, loss = 1.9928907124201456
Train: epoch: 1, loss = 1.9931278894956295
Train: epoch: 1, loss = 1.992069787979126
Train: epoch: 1, loss = 1.991228315472603
Train: epoch: 1, loss = 1.991218557693064
Train: epoch: 1, loss = 1.9914606754569446
Train: epoch: 1, loss = 1.9919782280259661
Train: epoch: 1, loss = 1.9914994845578544
Train: epoch: 1, loss = 1.9916046535670757
Train: epoch: 1, loss = 1.9909965047098341
Train: epoch: 1, loss = 1.9908167545091022
Train: epoch: 1, loss = 1.9906783435137376
Train: epoch: 1, loss = 1.9905024335533381
Train: epoch: 1, loss = 1.9900361222028733
Train: epoch: 1, loss = 1.9894468364578026
Train: epoch: 1, loss = 1.9892170166307026
Train: epoch: 1, loss = 1.9889342924952507
Train: epoch: 1, loss = 1.9888152471287497
Train: epoch: 1, loss = 1.9890465581218402
Train: epoch: 1, loss = 1.9889884990069173
Train: epoch: 1, loss = 1.9884556163288654
Train: epoch: 1, loss = 1.9880479177561674
Train: epoch: 1, loss = 1.9874462935328483
Train: epoch: 1, loss = 1.986832584466253
Train: epoch: 1, loss = 1.98687573214372
Train: epoch: 1, loss = 1.9868569905371278
Train: epoch: 1, loss = 1.9869917871136413
Train: epoch: 1, loss = 1.9868035205510945
Train: epoch: 1, loss = 1.9868497357219457
Train: epoch: 1, loss = 1.986726198051034
Train: epoch: 1, loss = 1.9869355736743837
Train: epoch: 1, loss = 1.9866733926811884
Train:  Epoch 1, Loss=1.9863453535352436, Cohen Kappa=0.08054449939343444, MAD=0.6866108879663546
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0208068921648223, Cohen Kappa=0.4366627155212225, MAD=0.7272452379935971
Eval task: 2
Eval:  Epoch 1, Loss=1.9819079925274026, Cohen Kappa=0.08131852173049325, MAD=0.6910890530036639
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0478493180768242, Cohen Kappa=0.3752071071444977, MAD=0.7198839488766586
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.923064571002434, Cohen Kappa=0.08170480373708988, MAD=0.6920742168403301
{'0': {'precision': 0.4191302223308087, 'recall': 0.8419631901840491, 'f1-score': 0.5596607128292961, 'support': 4075}, '1': {'precision': 0.28229974160206717, 'recall': 0.15253054101221641, 'f1-score': 0.19805121232721504, 'support': 2865}, '2': {'precision': 0.17857142857142858, 'recall': 0.0027502750275027505, 'f1-score': 0.005417118093174431, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.16253694021368492, 'recall': 0.5879934210526315, 'f1-score': 0.25467497773820125, 'support': 1216}, '9': {'precision': 0.1572052401746725, 'recall': 0.10065237651444547, 'f1-score': 0.12272727272727273, 'support': 1073}, 'accuracy': 0.31627155172413796, 'macro avg': {'precision': 0.11997435728926617, 'recall': 0.16858898037908454, 'f1-score': 0.11405312937151597, 'support': 14848}, 'weighted avg': {'precision': 0.21603673321916017, 'recall': 0.31627155172413796, 'f1-score': 0.22220188478961883, 'support': 14848}}
{'0': {'precision': 0.3400395778364116, 'recall': 0.7310328527534862, 'f1-score': 0.46417048097846475, 'support': 4231}, '1': {'precision': 0.3245944926442852, 'recall': 0.34207910952097, 'f1-score': 0.33310751959740637, 'support': 5031}, '2': {'precision': 0.1885245901639344, 'recall': 0.01903973509933775, 'f1-score': 0.03458646616541353, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.0970873786407767, 'recall': 0.06535947712418301, 'f1-score': 0.078125, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3286637931034483, 'macro avg': {'precision': 0.09502460392854079, 'recall': 0.11575111744979767, 'f1-score': 0.09099894667412846, 'support': 14848}, 'weighted avg': {'precision': 0.23955593305626344, 'recall': 0.3286637931034483, 'f1-score': 0.25237314038052766, 'support': 14848}}