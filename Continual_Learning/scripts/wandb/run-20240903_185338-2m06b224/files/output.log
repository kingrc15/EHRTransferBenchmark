
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_west
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.43646125808358194
Train: epoch: 1, loss = 0.4226495857536793
Train: epoch: 1, loss = 0.41755856446921824
Train: epoch: 1, loss = 0.41298362547531725
Train: epoch: 1, loss = 0.41130347387492655
Train: epoch: 1, loss = 0.409087546877563
Train: epoch: 1, loss = 0.40761865902159894
Train: epoch: 1, loss = 0.4063420651387423
Train: epoch: 1, loss = 0.4046603846467204
Train: epoch: 1, loss = 0.4032184099778533
Train: epoch: 1, loss = 0.4009538246826692
Train: epoch: 1, loss = 0.39938781725242734
Train: epoch: 1, loss = 0.3979977505826033
Train: epoch: 1, loss = 0.39689387943063464
Train: epoch: 1, loss = 0.3957316830853621
Train: epoch: 1, loss = 0.394577331636101
Train: epoch: 1, loss = 0.3939454015037593
Train: epoch: 1, loss = 0.39308831633792984
Train:  Epoch 1, Loss=0.3929073357826624, AUC-ROC Macro=0.6552135971726636, AUC-ROC Micro=0.747506780332382
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.37325020755330723, AUC-ROC Macro=0.7151358913505864, AUC-ROC Micro=0.7814416531066704
Eval task: 2
Eval:  Epoch 1, Loss=0.3355414792895317, AUC-ROC Macro=0.5035211659096632, AUC-ROC Micro=0.5243264696373426
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.3710534504801035
Train: epoch: 2, loss = 0.37213352501392366
Train: epoch: 2, loss = 0.37140807921687763
Train: epoch: 2, loss = 0.37229359306395055
Train: epoch: 2, loss = 0.3716375725120306
Train: epoch: 2, loss = 0.37124642719825107
Train: epoch: 2, loss = 0.3709616962500981
Train: epoch: 2, loss = 0.3712374070286751
Train: epoch: 2, loss = 0.371154184896085
Train: epoch: 2, loss = 0.37085007299482825
Train: epoch: 2, loss = 0.37054845440116796
Train: epoch: 2, loss = 0.37016714612642926
Train: epoch: 2, loss = 0.37022866142483857
Train: epoch: 2, loss = 0.3706078022399119
Train: epoch: 2, loss = 0.3700816307415565
Train: epoch: 2, loss = 0.36989398672245444
Train: epoch: 2, loss = 0.3693347139437409
Train: epoch: 2, loss = 0.3688488817546103
Train:  Epoch 2, Loss=0.368838266578495, AUC-ROC Macro=0.7233972742898057, AUC-ROC Micro=0.7906580655096005
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3624839000403881, AUC-ROC Macro=0.7379959694958861, AUC-ROC Micro=0.7968999518640618
Eval task: 2
Eval:  Epoch 2, Loss=0.3456708714365959, AUC-ROC Macro=0.4779859105019986, AUC-ROC Micro=0.5321500744022734
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3646593591570854
Train: epoch: 3, loss = 0.36336664043366906
Train: epoch: 3, loss = 0.36259242504835126
Train: epoch: 3, loss = 0.3634393966011703
Train: epoch: 3, loss = 0.36129339261353016
Train: epoch: 3, loss = 0.36251272511978944
Train: epoch: 3, loss = 0.36214037586535724
Train: epoch: 3, loss = 0.3622139534074813
Train: epoch: 3, loss = 0.36157249350514675
Train: epoch: 3, loss = 0.36127526021003725
Train: epoch: 3, loss = 0.3610077913511883
Train: epoch: 3, loss = 0.3612048306999107
Train: epoch: 3, loss = 0.36120354044322783
Train: epoch: 3, loss = 0.3607603492108839
Train: epoch: 3, loss = 0.3605515739868085
Train: epoch: 3, loss = 0.36069595043547453
Train: epoch: 3, loss = 0.3611251256790231
Train: epoch: 3, loss = 0.3610074126637644
Train:  Epoch 3, Loss=0.36091496520572236, AUC-ROC Macro=0.7417158947005514, AUC-ROC Micro=0.8029883419382479
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.35727466891209286, AUC-ROC Macro=0.7480088192527851, AUC-ROC Micro=0.8047356359823856
Eval task: 2
Eval:  Epoch 3, Loss=0.3595251515507698, AUC-ROC Macro=0.4894540377324805, AUC-ROC Micro=0.5296328408396548
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.35246260188519957
Train: epoch: 4, loss = 0.3521485773846507
Train: epoch: 4, loss = 0.3508439162870248
Train: epoch: 4, loss = 0.35196383368223905
Train: epoch: 4, loss = 0.35251822049915793
Train: epoch: 4, loss = 0.35421423841267824
Train: epoch: 4, loss = 0.35408675790897437
Train: epoch: 4, loss = 0.353833991587162
Train: epoch: 4, loss = 0.3543640292270316
Train: epoch: 4, loss = 0.3545738462358713
Train: epoch: 4, loss = 0.35518502498214893
Train: epoch: 4, loss = 0.3555398522193233
Train: epoch: 4, loss = 0.3554407615386523
Train: epoch: 4, loss = 0.35562417842979943
Train: epoch: 4, loss = 0.3555721738884846
Train: epoch: 4, loss = 0.35543167335912584
Train: epoch: 4, loss = 0.35514983771916697
Train: epoch: 4, loss = 0.3548024005442858
Train:  Epoch 4, Loss=0.3549623408317566, AUC-ROC Macro=0.7551641766321247, AUC-ROC Micro=0.8118251643136838
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.35435977826515835, AUC-ROC Macro=0.7561962764491416, AUC-ROC Micro=0.8095416238857088
Eval task: 2
Eval:  Epoch 4, Loss=0.36901793628931046, AUC-ROC Macro=0.4983060581315527, AUC-ROC Micro=0.5334461763389622
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.35100996769964693
Train: epoch: 5, loss = 0.34941831152886155
Train: epoch: 5, loss = 0.34991669535636905
Train: epoch: 5, loss = 0.3497198208607733
Train: epoch: 5, loss = 0.3495335200726986
Train: epoch: 5, loss = 0.3509571300571164
Train: epoch: 5, loss = 0.35094782976167543
Train: epoch: 5, loss = 0.350043723443523
Train: epoch: 5, loss = 0.35006891806092527
Train: epoch: 5, loss = 0.35035828774422406
Train: epoch: 5, loss = 0.35084036779674616
Train: epoch: 5, loss = 0.35104385474696753
Train: epoch: 5, loss = 0.3513375248072239
Train: epoch: 5, loss = 0.350988852253982
Train: epoch: 5, loss = 0.3509882982770602
Train: epoch: 5, loss = 0.35091552866157144
Train: epoch: 5, loss = 0.35073832008330263
Train: epoch: 5, loss = 0.3507359388263689
Train:  Epoch 5, Loss=0.3507556960073292, AUC-ROC Macro=0.7638943222246162, AUC-ROC Micro=0.8178020543516414
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.35274675488471985, AUC-ROC Macro=0.7594793364472143, AUC-ROC Micro=0.8131904596734936
Eval task: 2
Eval:  Epoch 5, Loss=0.39297599345445633, AUC-ROC Macro=0.49614222340731523, AUC-ROC Micro=0.5602187103004279
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3405796065181494
Train: epoch: 6, loss = 0.3420888901129365
Train: epoch: 6, loss = 0.3450934232274691
Train: epoch: 6, loss = 0.3459708714298904
Train: epoch: 6, loss = 0.347117402240634
Train: epoch: 6, loss = 0.34572014403839907
Train: epoch: 6, loss = 0.34641876508082664
Train: epoch: 6, loss = 0.3471883703581989
Train: epoch: 6, loss = 0.3478614732871453
Train: epoch: 6, loss = 0.3476206733584404
Train: epoch: 6, loss = 0.34758603717115794
Train: epoch: 6, loss = 0.34748111374055346
Train: epoch: 6, loss = 0.34758437301103884
Train: epoch: 6, loss = 0.34744491659637006
Train: epoch: 6, loss = 0.3472529289225737
Train: epoch: 6, loss = 0.34734834168571976
Train: epoch: 6, loss = 0.34710407298715673
Train: epoch: 6, loss = 0.34752455446869135
Train:  Epoch 6, Loss=0.3474073795090374, AUC-ROC Macro=0.7708389894704041, AUC-ROC Micro=0.8223907367420783
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3510541481276353, AUC-ROC Macro=0.7628694800998713, AUC-ROC Micro=0.8148916596756659
Eval task: 2
Eval:  Epoch 6, Loss=0.4163569360971451, AUC-ROC Macro=0.5197297937982792, AUC-ROC Micro=0.5592716699607523
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.35337133953968686, AUC-ROC Macro=0.7636343693586243, AUC-ROC Micro=0.8146833355762948
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.4222821220755577, AUC-ROC Macro=0.4903348412419731, AUC-ROC Micro=0.5521106337737265
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.31100436054170133
Train: epoch: 1, loss = 0.3036295149847865
Train: epoch: 1, loss = 0.2915590137491624
Train:  Epoch 1, Loss=0.2843283666384231, AUC-ROC Macro=0.5441535407087347, AUC-ROC Micro=0.7350729571911921
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.36265137667457265, AUC-ROC Macro=0.7500197893867857, AUC-ROC Micro=0.8019963807377232
Eval task: 2
Eval:  Epoch 1, Loss=0.30655278265476227, AUC-ROC Macro=0.6206252495797336, AUC-ROC Micro=0.7818440615412712
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.28858834743499756
Train: epoch: 2, loss = 0.28791966557502746
Train: epoch: 2, loss = 0.27736749773224195
Train:  Epoch 2, Loss=0.27012380339320513, AUC-ROC Macro=0.6428683681717652, AUC-ROC Micro=0.7942451471856726
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3587419167160988, AUC-ROC Macro=0.7508261575164519, AUC-ROC Micro=0.8043530714584941
Eval task: 2
Eval:  Epoch 2, Loss=0.2965429574251175, AUC-ROC Macro=0.6535070372332202, AUC-ROC Micro=0.7915951921744628
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.28254018642008305
Train: epoch: 3, loss = 0.28098173189908265
Train: epoch: 3, loss = 0.27110413211087386
Train:  Epoch 3, Loss=0.26530245090203464, AUC-ROC Macro=0.6854127322268027, AUC-ROC Micro=0.8094119765871479
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3533271600802739, AUC-ROC Macro=0.7533094901242273, AUC-ROC Micro=0.8071959473842306
Eval task: 2
Eval:  Epoch 3, Loss=0.29211169481277466, AUC-ROC Macro=0.6826682509012031, AUC-ROC Micro=0.8016696475354876
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.27923260889947416
Train: epoch: 4, loss = 0.27646900713443756
Train: epoch: 4, loss = 0.26712983681509894
Train:  Epoch 4, Loss=0.26146680492504387, AUC-ROC Macro=0.709875687272328, AUC-ROC Micro=0.8194205092940913
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.35253308713436127, AUC-ROC Macro=0.7530642235317357, AUC-ROC Micro=0.8058488662674124
Eval task: 2
Eval:  Epoch 4, Loss=0.28788215667009354, AUC-ROC Macro=0.6960096104947547, AUC-ROC Micro=0.8085102822720858
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.27111728526651857
Train: epoch: 5, loss = 0.27264202702790497
Train: epoch: 5, loss = 0.2629095478604237
Train:  Epoch 5, Loss=0.2574184221826541, AUC-ROC Macro=0.7316156200796418, AUC-ROC Micro=0.8287082272068552
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3491402454674244, AUC-ROC Macro=0.7512736520319391, AUC-ROC Micro=0.8050185432118261
Eval task: 2
Eval:  Epoch 5, Loss=0.28542618453502655, AUC-ROC Macro=0.6943388923237183, AUC-ROC Micro=0.8103656727075047
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.26998908817768097
Train: epoch: 6, loss = 0.2691967548802495
Train: epoch: 6, loss = 0.2595566946764787
Train:  Epoch 6, Loss=0.25402085928075196, AUC-ROC Macro=0.7419627303323204, AUC-ROC Micro=0.8335091442487046
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3462980588277181, AUC-ROC Macro=0.7490089764527812, AUC-ROC Micro=0.8023437007222791
Eval task: 2
Eval:  Epoch 6, Loss=0.2845887094736099, AUC-ROC Macro=0.7049041580404648, AUC-ROC Micro=0.8152979249649223
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.36639246096213657, AUC-ROC Macro=0.7479829527354974, AUC-ROC Micro=0.8008867138296829
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.2203008159995079, AUC-ROC Macro=0.7210712927738747, AUC-ROC Micro=0.8177548722589016
{'0': {'precision': 0.4880677444187837, 'recall': 0.4847094801223242, 'f1-score': 0.4863828154967395, 'support': 1308}, '1': {'precision': 0.5384615384615384, 'recall': 0.4701492537313433, 'f1-score': 0.50199203187251, 'support': 402}, '2': {'precision': 0.5113636363636364, 'recall': 0.06838905775075987, 'f1-score': 0.12064343163538874, 'support': 658}, '3': {'precision': 0.5233480176211454, 'recall': 0.2984924623115578, 'f1-score': 0.38016000000000005, 'support': 1990}, '4': {'precision': 0.4424778761061947, 'recall': 0.18610421836228289, 'f1-score': 0.2620087336244542, 'support': 806}, '5': {'precision': 0.5294117647058824, 'recall': 0.02313624678663239, 'f1-score': 0.04433497536945812, 'support': 778}, '6': {'precision': 0.5240384615384616, 'recall': 0.1674347158218126, 'f1-score': 0.25378346915017463, 'support': 1302}, '7': {'precision': 0.75, 'recall': 0.007075471698113208, 'f1-score': 0.014018691588785048, 'support': 424}, '8': {'precision': 0.5392857142857143, 'recall': 0.36739659367396593, 'f1-score': 0.4370477568740955, 'support': 1644}, '9': {'precision': 0.6755805770584096, 'recall': 0.4726735598227474, 'f1-score': 0.5561993047508691, 'support': 2031}, '10': {'precision': 0.6081871345029239, 'recall': 0.36300174520069806, 'f1-score': 0.45464480874316937, 'support': 573}, '11': {'precision': 0.49382716049382713, 'recall': 0.20408163265306123, 'f1-score': 0.2888086642599278, 'support': 1176}, '12': {'precision': 0.5888252148997135, 'recall': 0.23220338983050848, 'f1-score': 0.33306320907617504, 'support': 1770}, '13': {'precision': 0.602555003548616, 'recall': 0.32704160246533126, 'f1-score': 0.4239700374531835, 'support': 2596}, '14': {'precision': 0.5170863309352518, 'recall': 0.3534111862323294, 'f1-score': 0.4198612632347572, 'support': 1627}, '15': {'precision': 0.1111111111111111, 'recall': 0.002066115702479339, 'f1-score': 0.004056795131845843, 'support': 484}, '16': {'precision': 0.45149253731343286, 'recall': 0.15220125786163521, 'f1-score': 0.22765757290686736, 'support': 795}, '17': {'precision': 0.3865546218487395, 'recall': 0.08455882352941177, 'f1-score': 0.138763197586727, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.5833333333333334, 'recall': 0.026717557251908396, 'f1-score': 0.051094890510948905, 'support': 262}, '20': {'precision': 0.27586206896551724, 'recall': 0.014209591474245116, 'f1-score': 0.027027027027027025, 'support': 563}, '21': {'precision': 0.4605543710021322, 'recall': 0.25806451612903225, 'f1-score': 0.33078101071975496, 'support': 837}, '22': {'precision': 0.6662958843159066, 'recall': 0.5515653775322283, 'f1-score': 0.6035264483627205, 'support': 1086}, '23': {'precision': 0.528052805280528, 'recall': 0.3716608594657375, 'f1-score': 0.43626448534423995, 'support': 861}, '24': {'precision': 0.49, 'recall': 0.29108910891089107, 'f1-score': 0.36521739130434777, 'support': 505}, 'micro avg': {'precision': 0.5524448557766466, 'recall': 0.28230796515981554, 'f1-score': 0.3736665014736952, 'support': 25373}, 'macro avg': {'precision': 0.49143091632443203, 'recall': 0.2310973529728415, 'f1-score': 0.2864523204809667, 'support': 25373}, 'weighted avg': {'precision': 0.527317023241639, 'recall': 0.28230796515981554, 'f1-score': 0.34906737621947537, 'support': 25373}, 'samples avg': {'precision': 0.3799859117119859, 'recall': 0.2492357335812931, 'f1-score': 0.27624658687946946, 'support': 25373}}
{'0': {'precision': 0.5930232558139535, 'recall': 0.2602040816326531, 'f1-score': 0.3617021276595745, 'support': 196}, '1': {'precision': 0.6470588235294118, 'recall': 0.0912863070539419, 'f1-score': 0.15999999999999998, 'support': 241}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 145}, '3': {'precision': 1.0, 'recall': 0.00847457627118644, 'f1-score': 0.01680672268907563, 'support': 118}, '4': {'precision': 0.4266666666666667, 'recall': 0.15384615384615385, 'f1-score': 0.22614840989399299, 'support': 208}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 100}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '7': {'precision': 0.9130434782608695, 'recall': 0.15789473684210525, 'f1-score': 0.2692307692307692, 'support': 133}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 89}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87}, '13': {'precision': 0.5, 'recall': 0.0958904109589041, 'f1-score': 0.16091954022988506, 'support': 73}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 45}, '15': {'precision': 0.7708333333333334, 'recall': 0.7254901960784313, 'f1-score': 0.7474747474747475, 'support': 51}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'micro avg': {'precision': 0.59375, 'recall': 0.08575727181544635, 'f1-score': 0.14986853637160388, 'support': 1994}, 'macro avg': {'precision': 0.19402502230416943, 'recall': 0.05972345850733504, 'f1-score': 0.0776912926871218, 'support': 1994}, 'weighted avg': {'precision': 0.33910114537887937, 'recall': 0.08575727181544635, 'f1-score': 0.12244318476540826, 'support': 1994}, 'samples avg': {'precision': 0.15120442708333331, 'recall': 0.10628255208333334, 'f1-score': 0.11763547867063491, 'support': 1994}}