
Experiment dir: ./exp/Test_los_midwest
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.166063304543495
Train: epoch: 1, loss = 2.1389712649583816
Train: epoch: 1, loss = 2.1157920720179875
Train: epoch: 1, loss = 2.100720234066248
Train: epoch: 1, loss = 2.0933509505987167
Train: epoch: 1, loss = 2.0847330781817437
Train: epoch: 1, loss = 2.079634022116661
Train: epoch: 1, loss = 2.075452092140913
Train: epoch: 1, loss = 2.0732188752624725
Train: epoch: 1, loss = 2.0700953006744385
Train: epoch: 1, loss = 2.066843195503408
Train: epoch: 1, loss = 2.0643981109559535
Train: epoch: 1, loss = 2.0621174644506897
Train: epoch: 1, loss = 2.0601158996565
Train: epoch: 1, loss = 2.0592207861741385
Train: epoch: 1, loss = 2.0584833393245936
Train: epoch: 1, loss = 2.057174300270922
Train: epoch: 1, loss = 2.05627877920866
Train: epoch: 1, loss = 2.056612195247098
Train: epoch: 1, loss = 2.0561384396851063
Train: epoch: 1, loss = 2.05477044573852
Train: epoch: 1, loss = 2.0537233822995966
Train: epoch: 1, loss = 2.052848604943441
Train: epoch: 1, loss = 2.0522563383976618
Train: epoch: 1, loss = 2.051962326478958
Train: epoch: 1, loss = 2.051034151888811
Train: epoch: 1, loss = 2.051080133959099
Train: epoch: 1, loss = 2.0504095707833767
Train: epoch: 1, loss = 2.0499637233388834
Train: epoch: 1, loss = 2.049769076625506
Train: epoch: 1, loss = 2.04897655961975
Train: epoch: 1, loss = 2.0487158088572324
Train: epoch: 1, loss = 2.0483600449200834
Train: epoch: 1, loss = 2.047776358600925
Train: epoch: 1, loss = 2.0465477254731312
Train: epoch: 1, loss = 2.0457198655605318
Train: epoch: 1, loss = 2.045317699941429
Train: epoch: 1, loss = 2.044496883498995
Train: epoch: 1, loss = 2.0442156592546366
Train: epoch: 1, loss = 2.0438431867808102
Train: epoch: 1, loss = 2.0440230901793734
Train: epoch: 1, loss = 2.0437665331647508
Train: epoch: 1, loss = 2.0434425514104753
Train:  Epoch 1, Loss=2.043339586162567, Cohen Kappa=0.3846551439503383, MAD=0.7169014164385931
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.027460217475891, Cohen Kappa=0.43328245702261226, MAD=0.7194836002552815
Eval task: 2
Eval:  Epoch 1, Loss=1.990976734408017, Cohen Kappa=0.011353157793265622, MAD=0.7283561870149897
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0523802350307334, Cohen Kappa=0.35598637941868283, MAD=0.7175321990046293
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9569860018532852, Cohen Kappa=0.03146465009074595, MAD=0.7277647387281676
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.956907639503479
Train: epoch: 1, loss = 1.9581875041127206
Train: epoch: 1, loss = 1.9570288729667664
Train: epoch: 1, loss = 1.9544530296325684
Train: epoch: 1, loss = 1.958695965886116
Train: epoch: 1, loss = 1.956315708756447
Train: epoch: 1, loss = 1.957472628695624
Train: epoch: 1, loss = 1.9577212493866682
Train: epoch: 1, loss = 1.9565175204806857
Train: epoch: 1, loss = 1.9547538065314294
Train: epoch: 1, loss = 1.9537004678899592
Train: epoch: 1, loss = 1.9544361822803815
Train: epoch: 1, loss = 1.954839761027923
Train: epoch: 1, loss = 1.9544286719390325
Train: epoch: 1, loss = 1.954128560066223
Train: epoch: 1, loss = 1.9541846695914864
Train: epoch: 1, loss = 1.9535073299267713
Train: epoch: 1, loss = 1.9538467769821486
Train: epoch: 1, loss = 1.9533400219365171
Train: epoch: 1, loss = 1.9526691226959227
Train: epoch: 1, loss = 1.9524647939772832
Train: epoch: 1, loss = 1.951800708906217
Train: epoch: 1, loss = 1.9514643806737402
Train: epoch: 1, loss = 1.9508288624882697
Train: epoch: 1, loss = 1.9506729020118714
Train: epoch: 1, loss = 1.950984082038586
Train: epoch: 1, loss = 1.951031371752421
Train: epoch: 1, loss = 1.9511902013421059
Train: epoch: 1, loss = 1.9511487496310267
Train: epoch: 1, loss = 1.9512222804029782
Train: epoch: 1, loss = 1.9510780322551726
Train: epoch: 1, loss = 1.950851378440857
Train: epoch: 1, loss = 1.950636954054688
Train: epoch: 1, loss = 1.9505249047454665
Train: epoch: 1, loss = 1.9507636545215334
Train: epoch: 1, loss = 1.950619294014242
Train: epoch: 1, loss = 1.9504693117012848
Train: epoch: 1, loss = 1.950419680193851
Train: epoch: 1, loss = 1.9508491438474411
Train: epoch: 1, loss = 1.9505529278516769
Train: epoch: 1, loss = 1.9504490925771434
Train: epoch: 1, loss = 1.9506154427641913
Train: epoch: 1, loss = 1.9502863545889078
Train:  Epoch 1, Loss=1.9505438004357474, Cohen Kappa=0.08882950092252684, MAD=0.687810983532953
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0905617804362855, Cohen Kappa=0.2690366799462205, MAD=0.7195925072878301
Eval task: 2
Eval:  Epoch 1, Loss=1.9544153645120819, Cohen Kappa=0.09446034423775818, MAD=0.6672748994309113
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0811703287321945, Cohen Kappa=0.16933709342891023, MAD=0.7199159636150714
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9218493432834232, Cohen Kappa=0.10761726921217596, MAD=0.6711143825344111
{'0': {'precision': 0.4033740400352512, 'recall': 0.7862576687116565, 'f1-score': 0.5332001997004493, 'support': 4075}, '1': {'precision': 0.1609764726693791, 'recall': 0.31762652705061084, 'f1-score': 0.21366517961962903, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.28023352793994993, 'recall': 0.27631578947368424, 'f1-score': 0.27826086956521734, 'support': 1216}, '9': {'precision': 0.14, 'recall': 0.0065237651444548, 'f1-score': 0.012466607301869992, 'support': 1073}, 'accuracy': 0.30017510775862066, 'macro avg': {'precision': 0.09845840406445802, 'recall': 0.13867237503804064, 'f1-score': 0.10375928561871657, 'support': 14848}, 'weighted avg': {'precision': 0.17483369998089973, 'recall': 0.30017510775862066, 'f1-score': 0.2112529256745541, 'support': 14848}}
{'0': {'precision': 0.4750639386189258, 'recall': 0.17560860316709997, 'f1-score': 0.256427955133736, 'support': 4231}, '1': {'precision': 0.3393849283981532, 'recall': 0.8620552574040946, 'f1-score': 0.4870297585626052, 'support': 5031}, '2': {'precision': 0.15463917525773196, 'recall': 0.006208609271523178, 'f1-score': 0.01193792280143255, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.14215686274509803, 'recall': 0.1895424836601307, 'f1-score': 0.16246498599439776, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.34705010775862066, 'macro avg': {'precision': 0.11112449050199091, 'recall': 0.12334149535028485, 'f1-score': 0.09178606224921715, 'support': 14848}, 'weighted avg': {'precision': 0.2784583342194548, 'recall': 0.34705010775862066, 'f1-score': 0.24338292704080355, 'support': 14848}}