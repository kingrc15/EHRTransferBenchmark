
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_west
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
west_val.csv
test_listfile.csv
west_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1822241443395614
Train: epoch: 1, loss = 2.135331290066242
Train: epoch: 1, loss = 2.1149652926127116
Train: epoch: 1, loss = 2.100261747688055
Train: epoch: 1, loss = 2.0917771816253663
Train: epoch: 1, loss = 2.0856391925613087
Train: epoch: 1, loss = 2.0800232753583363
Train: epoch: 1, loss = 2.073858755454421
Train: epoch: 1, loss = 2.0716984133587943
Train: epoch: 1, loss = 2.0684220574498178
Train: epoch: 1, loss = 2.067115993879058
Train: epoch: 1, loss = 2.0648294471204283
Train: epoch: 1, loss = 2.0641354621832186
Train: epoch: 1, loss = 2.0618348113128118
Train: epoch: 1, loss = 2.0611950620412824
Train: epoch: 1, loss = 2.0600908299162985
Train: epoch: 1, loss = 2.0584081854890375
Train: epoch: 1, loss = 2.058245040078958
Train: epoch: 1, loss = 2.057548146655685
Train: epoch: 1, loss = 2.0576611795127393
Train: epoch: 1, loss = 2.0572205835296993
Train: epoch: 1, loss = 2.0570821793241936
Train: epoch: 1, loss = 2.055990742833718
Train: epoch: 1, loss = 2.0550603634119033
Train: epoch: 1, loss = 2.053943861722946
Train: epoch: 1, loss = 2.0533001418755603
Train: epoch: 1, loss = 2.05190304517746
Train: epoch: 1, loss = 2.0510198139292855
Train: epoch: 1, loss = 2.0500297507540934
Train: epoch: 1, loss = 2.049894445935885
Train: epoch: 1, loss = 2.050004936514362
Train: epoch: 1, loss = 2.050023438055068
Train: epoch: 1, loss = 2.0497989217259667
Train: epoch: 1, loss = 2.049385972899549
Train: epoch: 1, loss = 2.048722062894276
Train: epoch: 1, loss = 2.0484237782491577
Train: epoch: 1, loss = 2.0481778286115544
Train: epoch: 1, loss = 2.047602306259306
Train: epoch: 1, loss = 2.047509481647076
Train: epoch: 1, loss = 2.047369931668043
Train: epoch: 1, loss = 2.0472581982757987
Train: epoch: 1, loss = 2.047087744346687
Train: epoch: 1, loss = 2.046900239503661
Train:  Epoch 1, Loss=2.046925489807129, Cohen Kappa=0.3750730624545495, MAD=0.7192836863104117
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0401616034836603, Cohen Kappa=0.4098828654830319, MAD=0.7370636970190712
Eval task: 2
Eval:  Epoch 1, Loss=1.8859821969065174, Cohen Kappa=-0.0004893345339884725, MAD=0.7571642687863287
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.069405656436394, Cohen Kappa=0.31782665506873486, MAD=0.7369616690628212
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8974272547097042, Cohen Kappa=-0.0028689144215767737, MAD=0.757831118943774
west_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9682264763116837
Train: epoch: 1, loss = 1.9607355323433877
Train: epoch: 1, loss = 1.9607051368554433
Train: epoch: 1, loss = 1.9593166019022465
Train: epoch: 1, loss = 1.9572222934961319
Train: epoch: 1, loss = 1.9556504068771998
Train: epoch: 1, loss = 1.9562542385714394
Train: epoch: 1, loss = 1.9566025834530592
Train: epoch: 1, loss = 1.9580652321709526
Train: epoch: 1, loss = 1.9573988786935805
Train: epoch: 1, loss = 1.95747041285038
Train: epoch: 1, loss = 1.9571035532156627
Train: epoch: 1, loss = 1.9570299454377247
Train: epoch: 1, loss = 1.9573329538532667
Train: epoch: 1, loss = 1.957309781273206
Train: epoch: 1, loss = 1.9575828668102622
Train: epoch: 1, loss = 1.9582708463949317
Train: epoch: 1, loss = 1.9554759697450532
Train: epoch: 1, loss = 1.9519368905142733
Train: epoch: 1, loss = 1.9479380845427514
Train: epoch: 1, loss = 1.9445881938082832
Train:  Epoch 1, Loss=1.9417159892490932, Cohen Kappa=0.0008088645948041151, MAD=0.728107334474376
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0446114416780143, Cohen Kappa=0.3973223919518599, MAD=0.7150748342242398
Eval task: 2
Eval:  Epoch 1, Loss=1.9547907525095447, Cohen Kappa=0.0011135925743589459, MAD=0.711892673513024
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0714105737620385, Cohen Kappa=0.2759769750527531, MAD=0.7108569541570507
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8853025806361232, Cohen Kappa=0.0008789636511513654, MAD=0.7120864860355238
{'0': {'precision': 0.39504337050805455, 'recall': 0.7823312883435583, 'f1-score': 0.5249897076986414, 'support': 4075}, '1': {'precision': 0.22068463219227968, 'recall': 0.21151832460732983, 'f1-score': 0.21600427731242203, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.07246376811594203, 'recall': 0.01644736842105263, 'f1-score': 0.02680965147453083, 'support': 1216}, '9': {'precision': 0.13391906283280086, 'recall': 0.46877912395153776, 'f1-score': 0.2083247049078484, 'support': 1073}, 'accuracy': 0.29074622844827586, 'macro avg': {'precision': 0.0822110833649077, 'recall': 0.14790761053234786, 'f1-score': 0.09761283413934427, 'support': 14848}, 'weighted avg': {'precision': 0.1666133016230997, 'recall': 0.29074622844827586, 'f1-score': 0.20301173612144421, 'support': 14848}}
{'0': {'precision': 0.33445284075007, 'recall': 0.9644874899112187, 'f1-score': 0.4966749792186202, 'support': 2478}, '1': {'precision': 0.4460431654676259, 'recall': 0.047784200385356454, 'f1-score': 0.08632091890010442, 'support': 2595}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1084}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 501}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 215}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 121}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 103}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 153}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102}, 'accuracy': 0.3386314655172414, 'macro avg': {'precision': 0.07804960062176959, 'recall': 0.10122716902965752, 'f1-score': 0.058299589811872464, 'support': 7424}, 'weighted avg': {'precision': 0.2675452793328614, 'recall': 0.3386314655172414, 'f1-score': 0.19595411948403985, 'support': 7424}}