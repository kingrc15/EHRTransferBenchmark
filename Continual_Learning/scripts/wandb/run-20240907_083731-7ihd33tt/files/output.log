
Experiment dir: ./exp/Test_los_midwest
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.172815870642662
Train: epoch: 1, loss = 2.124032577574253
Train: epoch: 1, loss = 2.1079498785734176
Train: epoch: 1, loss = 2.10166486248374
Train: epoch: 1, loss = 2.0971050078868867
Train: epoch: 1, loss = 2.0871157256762185
Train: epoch: 1, loss = 2.0801680201292037
Train: epoch: 1, loss = 2.0768355068564417
Train: epoch: 1, loss = 2.075225133034918
Train: epoch: 1, loss = 2.0734920221567155
Train: epoch: 1, loss = 2.0719714904915203
Train: epoch: 1, loss = 2.0706054121255875
Train: epoch: 1, loss = 2.0681867401416487
Train: epoch: 1, loss = 2.0667719218560627
Train: epoch: 1, loss = 2.063878539323807
Train: epoch: 1, loss = 2.0624254020303487
Train: epoch: 1, loss = 2.060675202502924
Train: epoch: 1, loss = 2.0600892824265693
Train: epoch: 1, loss = 2.0596724869075573
Train: epoch: 1, loss = 2.0577872996628286
Train: epoch: 1, loss = 2.0561238159735997
Train: epoch: 1, loss = 2.0553346125104213
Train: epoch: 1, loss = 2.054967752176782
Train: epoch: 1, loss = 2.054556846593817
Train: epoch: 1, loss = 2.053513657951355
Train: epoch: 1, loss = 2.0525851078216846
Train: epoch: 1, loss = 2.0524534329882376
Train: epoch: 1, loss = 2.0513831243344716
Train: epoch: 1, loss = 2.051550458176383
Train: epoch: 1, loss = 2.0507500995000205
Train: epoch: 1, loss = 2.050259657367583
Train: epoch: 1, loss = 2.049303261525929
Train: epoch: 1, loss = 2.048736464886954
Train: epoch: 1, loss = 2.0484534649989183
Train: epoch: 1, loss = 2.048297493832452
Train: epoch: 1, loss = 2.047965665029155
Train: epoch: 1, loss = 2.0479913315418603
Train: epoch: 1, loss = 2.0480591502158267
Train: epoch: 1, loss = 2.047122594225101
Train: epoch: 1, loss = 2.0469201966375112
Train: epoch: 1, loss = 2.0460712536224506
Train: epoch: 1, loss = 2.0456494000696
Train: epoch: 1, loss = 2.045788720527361
Train:  Epoch 1, Loss=2.0455191328321183, Cohen Kappa=0.37569691255955473, MAD=0.7180903772138629
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0348623004452935, Cohen Kappa=0.42403374286456574, MAD=0.7512554858424548
Eval task: 2
Eval:  Epoch 1, Loss=1.9915989514054924, Cohen Kappa=0.0034324914850824007, MAD=0.7752438541890081
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0576078871200822, Cohen Kappa=0.3441928177367265, MAD=0.7477951292484385
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9598124294445431, Cohen Kappa=0.0019841901403564455, MAD=0.774149300489311
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9782864624261856
Train: epoch: 1, loss = 1.975037454366684
Train: epoch: 1, loss = 1.9751825322707495
Train: epoch: 1, loss = 1.9734291371703148
Train: epoch: 1, loss = 1.974503108382225
Train: epoch: 1, loss = 1.9762405257423719
Train: epoch: 1, loss = 1.9760425353901727
Train: epoch: 1, loss = 1.9756101056933404
Train: epoch: 1, loss = 1.9758507893482844
Train: epoch: 1, loss = 1.974422104179859
Train: epoch: 1, loss = 1.9740237978913566
Train: epoch: 1, loss = 1.9732994773983956
Train: epoch: 1, loss = 1.9726887375574846
Train: epoch: 1, loss = 1.9729176296080861
Train: epoch: 1, loss = 1.9717998774846395
Train: epoch: 1, loss = 1.971916497014463
Train: epoch: 1, loss = 1.9719240747479831
Train: epoch: 1, loss = 1.9726201913091872
Train: epoch: 1, loss = 1.9723552331798955
Train: epoch: 1, loss = 1.9720433817207814
Train: epoch: 1, loss = 1.972320797954287
Train: epoch: 1, loss = 1.9721264037218962
Train: epoch: 1, loss = 1.9722785330855328
Train: epoch: 1, loss = 1.9719910953938962
Train: epoch: 1, loss = 1.9718309235572815
Train: epoch: 1, loss = 1.9721111210951439
Train: epoch: 1, loss = 1.9719038183600814
Train: epoch: 1, loss = 1.9720203194873673
Train: epoch: 1, loss = 1.9721199564687137
Train: epoch: 1, loss = 1.972011000573635
Train: epoch: 1, loss = 1.9714996772043167
Train: epoch: 1, loss = 1.9714341199584304
Train: epoch: 1, loss = 1.971382777275461
Train: epoch: 1, loss = 1.9712957512981752
Train: epoch: 1, loss = 1.971203184042658
Train: epoch: 1, loss = 1.9708434935741954
Train: epoch: 1, loss = 1.9702578509820474
Train: epoch: 1, loss = 1.9702065942318816
Train: epoch: 1, loss = 1.9695769933248177
Train: epoch: 1, loss = 1.9690718584358693
Train: epoch: 1, loss = 1.9682599678126778
Train: epoch: 1, loss = 1.9676597352113043
Train: epoch: 1, loss = 1.9672513654481534
Train:  Epoch 1, Loss=1.9670897536141532, Cohen Kappa=0.10031333442486068, MAD=0.6918436513866324
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0366742878124633, Cohen Kappa=0.43357114053596435, MAD=0.7213181689091894
Eval task: 2
Eval:  Epoch 1, Loss=1.9661529804098195, Cohen Kappa=0.13139000447820837, MAD=0.677571052031578
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0525245625397255, Cohen Kappa=0.3451899254121037, MAD=0.7189267223114875
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9262803792953491, Cohen Kappa=0.11090057899355343, MAD=0.6810909137060848
{'0': {'precision': 0.425026162356107, 'recall': 0.6976687116564417, 'f1-score': 0.5282422891118543, 'support': 4075}, '1': {'precision': 0.2562674094707521, 'recall': 0.32111692844677137, 'f1-score': 0.28505034856700234, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.16690042075736325, 'recall': 0.587171052631579, 'f1-score': 0.2599199126319621, 'support': 1216}, '9': {'precision': 0.15120274914089346, 'recall': 0.04100652376514446, 'f1-score': 0.06451612903225806, 'support': 1073}, 'accuracy': 0.3044854525862069, 'macro avg': {'precision': 0.09993967417251158, 'recall': 0.16469632164999365, 'f1-score': 0.1137728679343077, 'support': 14848}, 'weighted avg': {'precision': 0.1906909483569486, 'recall': 0.3044854525862069, 'f1-score': 0.22592571369796247, 'support': 14848}}
{'0': {'precision': 0.40096214181133655, 'recall': 0.4530843772157882, 'f1-score': 0.42543275632490013, 'support': 4231}, '1': {'precision': 0.3289940828402367, 'recall': 0.6078314450407474, 'f1-score': 0.4269160966075667, 'support': 5031}, '2': {'precision': 0.14285714285714285, 'recall': 0.02359271523178808, 'f1-score': 0.04049733570159858, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.06702412868632708, 'recall': 0.08169934640522876, 'f1-score': 0.07363770250368189, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3405845905172414, 'macro avg': {'precision': 0.09398374961950431, 'recall': 0.11662078838935523, 'f1-score': 0.09664838911377471, 'support': 14848}, 'weighted avg': {'precision': 0.25035643139102026, 'recall': 0.3405845905172414, 'f1-score': 0.2739894648480946, 'support': 14848}}