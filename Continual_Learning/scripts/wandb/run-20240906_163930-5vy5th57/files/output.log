
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest_baseline
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1544160199165345
Train: epoch: 1, loss = 2.124739054143429
Train: epoch: 1, loss = 2.103165294130643
Train: epoch: 1, loss = 2.102954536229372
Train: epoch: 1, loss = 2.094839515566826
Train: epoch: 1, loss = 2.088863974114259
Train: epoch: 1, loss = 2.085378170439175
Train: epoch: 1, loss = 2.082019792050123
Train: epoch: 1, loss = 2.0775519924693637
Train: epoch: 1, loss = 2.07485379076004
Train: epoch: 1, loss = 2.072011310133067
Train: epoch: 1, loss = 2.070086609671513
Train: epoch: 1, loss = 2.0702654938514415
Train: epoch: 1, loss = 2.0680885423507007
Train: epoch: 1, loss = 2.066190133253733
Train: epoch: 1, loss = 2.0641313109174373
Train: epoch: 1, loss = 2.061763235611074
Train: epoch: 1, loss = 2.060752296215958
Train: epoch: 1, loss = 2.0598082418190806
Train: epoch: 1, loss = 2.0595466464161873
Train: epoch: 1, loss = 2.058816006779671
Train: epoch: 1, loss = 2.0573413116552612
Train: epoch: 1, loss = 2.0560594314336775
Train: epoch: 1, loss = 2.054605933104952
Train: epoch: 1, loss = 2.0537045397520064
Train: epoch: 1, loss = 2.052393983900547
Train: epoch: 1, loss = 2.0521134956898512
Train: epoch: 1, loss = 2.0518259806292396
Train: epoch: 1, loss = 2.0519680567445424
Train: epoch: 1, loss = 2.0513136532107987
Train: epoch: 1, loss = 2.0512952094501067
Train: epoch: 1, loss = 2.050519212707877
Train: epoch: 1, loss = 2.0499414174303863
Train: epoch: 1, loss = 2.048885313044576
Train: epoch: 1, loss = 2.0480877100058965
Train: epoch: 1, loss = 2.047661176688141
Train: epoch: 1, loss = 2.047288921330426
Train: epoch: 1, loss = 2.0473791257801808
Train: epoch: 1, loss = 2.0472683440874784
Train: epoch: 1, loss = 2.046663477867842
Train: epoch: 1, loss = 2.046395550442905
Train: epoch: 1, loss = 2.0461375652324585
Train: epoch: 1, loss = 2.04553883352945
Train:  Epoch 1, Loss=2.045151533085959, Cohen Kappa=0.3752631651708527, MAD=0.7169857001051709
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0364518391674964, Cohen Kappa=0.41120934060262604, MAD=0.7185139024345021
Eval task: 2
Eval:  Epoch 1, Loss=1.977194621645171, Cohen Kappa=9.452847381186125e-05, MAD=0.742401325622031
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0511599368062514, Cohen Kappa=0.3142298755817171, MAD=0.7186073567968075
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9406600697287197, Cohen Kappa=0.0032575359645016233, MAD=0.7404579348198344
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9486892372369766
Train: epoch: 1, loss = 1.9502567940950393
Train: epoch: 1, loss = 1.9480497415860494
Train: epoch: 1, loss = 1.9503994485735894
Train: epoch: 1, loss = 1.9542149235010147
Train: epoch: 1, loss = 1.9548427642385164
Train: epoch: 1, loss = 1.9513399562665394
Train: epoch: 1, loss = 1.9530959787964821
Train: epoch: 1, loss = 1.9544702910052405
Train: epoch: 1, loss = 1.9521062561273574
Train: epoch: 1, loss = 1.951885903640227
Train: epoch: 1, loss = 1.9505585116644701
Train: epoch: 1, loss = 1.9496499719986549
Train: epoch: 1, loss = 1.9494794070720673
Train: epoch: 1, loss = 1.94966943581899
Train: epoch: 1, loss = 1.9493146236613392
Train: epoch: 1, loss = 1.949580489011372
Train: epoch: 1, loss = 1.9477587545249198
Train: epoch: 1, loss = 1.9481573531815881
Train: epoch: 1, loss = 1.9484747970700265
Train: epoch: 1, loss = 1.948267437957582
Train: epoch: 1, loss = 1.9480931081826036
Train: epoch: 1, loss = 1.9483663898188135
Train: epoch: 1, loss = 1.948284243469437
Train: epoch: 1, loss = 1.9484465433597564
Train: epoch: 1, loss = 1.947946000786928
Train: epoch: 1, loss = 1.947803043745182
Train: epoch: 1, loss = 1.9476680609796728
Train: epoch: 1, loss = 1.947649212767338
Train: epoch: 1, loss = 1.9480285452802977
Train: epoch: 1, loss = 1.9476805714061183
Train: epoch: 1, loss = 1.9474752667732538
Train: epoch: 1, loss = 1.947235364155336
Train: epoch: 1, loss = 1.9471167509345448
Train: epoch: 1, loss = 1.9469181909220559
Train: epoch: 1, loss = 1.947062349634038
Train: epoch: 1, loss = 1.9470850871382532
Train: epoch: 1, loss = 1.9467953144719725
Train: epoch: 1, loss = 1.9468852775524823
Train: epoch: 1, loss = 1.946635034814477
Train: epoch: 1, loss = 1.9467682037120912
Train: epoch: 1, loss = 1.9468111340488707
Train: epoch: 1, loss = 1.9467702598211378
Train:  Epoch 1, Loss=1.9467299021584648, Cohen Kappa=0.08158838959838222, MAD=0.6821140008075208
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.167586351263112, Cohen Kappa=0.03704560311889504, MAD=0.7103965617707694
Eval task: 2
Eval:  Epoch 1, Loss=1.9514055046541938, Cohen Kappa=0.12858123398219434, MAD=0.6628459037261694
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.1106867954648774, Cohen Kappa=0.036292257826973096, MAD=0.7090934443884596
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.925874416170449, Cohen Kappa=0.10096872913086896, MAD=0.6666582584086215
{'0': {'precision': 0.4104615384615385, 'recall': 0.49104294478527605, 'f1-score': 0.4471508379888268, 'support': 4075}, '1': {'precision': 0.176216324889425, 'recall': 0.6118673647469459, 'f1-score': 0.27362834621087956, 'support': 2865}, '2': {'precision': 0.125, 'recall': 0.00055005500550055, 'f1-score': 0.001095290251916758, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.2528960129310345, 'macro avg': {'precision': 0.07116778633509635, 'recall': 0.11034603645377225, 'f1-score': 0.07218744744516233, 'support': 14848}, 'weighted avg': {'precision': 0.16195720231943508, 'recall': 0.2528960129310345, 'f1-score': 0.1756516779617877, 'support': 14848}}
{'0': {'precision': 0.4837310195227766, 'recall': 0.10541243204916095, 'f1-score': 0.17310304676887248, 'support': 4231}, '1': {'precision': 0.34511563152602676, 'recall': 0.8869012124826078, 'f1-score': 0.49688195991091316, 'support': 5031}, '2': {'precision': 0.1540041067761807, 'recall': 0.031043046357615893, 'f1-score': 0.05167068549776094, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.032467532467532464, 'recall': 0.016778523489932886, 'f1-score': 0.022123893805309734, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.08022922636103152, 'recall': 0.0915032679738562, 'f1-score': 0.08549618320610686, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.33782327586206895, 'macro avg': {'precision': 0.1095547516653548, 'recall': 0.11316384823531736, 'f1-score': 0.08292757691889632, 'support': 14848}, 'weighted avg': {'precision': 0.28214184238425116, 'recall': 0.33782327586206895, 'f1-score': 0.22830032730122204, 'support': 14848}}