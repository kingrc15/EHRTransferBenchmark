
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
south_val.csv
test_listfile.csv
south_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1765405517816543
Train: epoch: 1, loss = 2.135419565439224
Train: epoch: 1, loss = 2.1069744527339935
Train: epoch: 1, loss = 2.094661448150873
Train: epoch: 1, loss = 2.0835291051864626
Train: epoch: 1, loss = 2.077736458182335
Train: epoch: 1, loss = 2.074469363774572
Train: epoch: 1, loss = 2.072143346965313
Train: epoch: 1, loss = 2.0689377579424115
Train: epoch: 1, loss = 2.066603476524353
Train: epoch: 1, loss = 2.064431479464878
Train: epoch: 1, loss = 2.0635430973768236
Train: epoch: 1, loss = 2.062497638418124
Train: epoch: 1, loss = 2.0615345206856728
Train: epoch: 1, loss = 2.0605791368484496
Train: epoch: 1, loss = 2.0601346787065267
Train: epoch: 1, loss = 2.059052488418186
Train: epoch: 1, loss = 2.0576095120443236
Train: epoch: 1, loss = 2.0569209685451106
Train: epoch: 1, loss = 2.0557826547920706
Train: epoch: 1, loss = 2.0559224249635424
Train: epoch: 1, loss = 2.055932818190618
Train: epoch: 1, loss = 2.055718367255252
Train: epoch: 1, loss = 2.0548257821798326
Train: epoch: 1, loss = 2.053767299628258
Train: epoch: 1, loss = 2.0528619736662277
Train: epoch: 1, loss = 2.0527455972742152
Train: epoch: 1, loss = 2.052945593276194
Train: epoch: 1, loss = 2.052384566623589
Train: epoch: 1, loss = 2.0519864075779917
Train: epoch: 1, loss = 2.051185029437465
Train: epoch: 1, loss = 2.050716063939035
Train: epoch: 1, loss = 2.0498613664959415
Train: epoch: 1, loss = 2.0494830918312075
Train: epoch: 1, loss = 2.0493454181126185
Train: epoch: 1, loss = 2.04880421905054
Train: epoch: 1, loss = 2.048256516456604
Train: epoch: 1, loss = 2.0477606322263417
Train: epoch: 1, loss = 2.0477364980104644
Train: epoch: 1, loss = 2.047662226572633
Train: epoch: 1, loss = 2.046715322238643
Train: epoch: 1, loss = 2.046464033580962
Train: epoch: 1, loss = 2.046453856146613
Train:  Epoch 1, Loss=2.0464281631061008, Cohen Kappa=0.38202235435502097, MAD=0.7189387562590117
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0338431576202654, Cohen Kappa=0.4221994646210995, MAD=0.7317484497947573
Eval task: 2
Eval:  Epoch 1, Loss=1.920837168035836, Cohen Kappa=0.006167970648056631, MAD=0.7360169583302685
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0599058907607506, Cohen Kappa=0.33860292756491794, MAD=0.7278807034264332
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9126657638056526, Cohen Kappa=0.008853922621761101, MAD=0.7362378866640299
south_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.92096582531929
Train: epoch: 1, loss = 1.9165884044766426
Train: epoch: 1, loss = 1.921353992819786
Train: epoch: 1, loss = 1.9149462200701237
Train: epoch: 1, loss = 1.9164073914289474
Train: epoch: 1, loss = 1.9138274066646894
Train: epoch: 1, loss = 1.9160301463093077
Train: epoch: 1, loss = 1.9177535554766656
Train: epoch: 1, loss = 1.9163160577085283
Train: epoch: 1, loss = 1.916043073296547
Train: epoch: 1, loss = 1.916842320453037
Train: epoch: 1, loss = 1.9154384963214397
Train: epoch: 1, loss = 1.9160088675297224
Train: epoch: 1, loss = 1.9146530814681735
Train: epoch: 1, loss = 1.9144981640179952
Train: epoch: 1, loss = 1.914381766989827
Train: epoch: 1, loss = 1.9141208086995518
Train: epoch: 1, loss = 1.913921926120917
Train: epoch: 1, loss = 1.9136978455280003
Train: epoch: 1, loss = 1.9138726542294024
Train: epoch: 1, loss = 1.9133529724109741
Train: epoch: 1, loss = 1.9136598920009353
Train: epoch: 1, loss = 1.9139118360954783
Train: epoch: 1, loss = 1.9138499170790115
Train: epoch: 1, loss = 1.9138229806661606
Train: epoch: 1, loss = 1.9141247230309706
Train: epoch: 1, loss = 1.9139822354140106
Train: epoch: 1, loss = 1.9134877131666457
Train: epoch: 1, loss = 1.9133219438174676
Train: epoch: 1, loss = 1.9131654512087504
Train: epoch: 1, loss = 1.9127222160946937
Train: epoch: 1, loss = 1.912993473559618
Train: epoch: 1, loss = 1.9133948972911545
Train: epoch: 1, loss = 1.913425569919979
Train: epoch: 1, loss = 1.9131943814584187
Train: epoch: 1, loss = 1.913034304479758
Train: epoch: 1, loss = 1.9133917787429449
Train: epoch: 1, loss = 1.9132406232074688
Train: epoch: 1, loss = 1.9130976570263887
Train: epoch: 1, loss = 1.913001556441188
Train: epoch: 1, loss = 1.9128022468235435
Train: epoch: 1, loss = 1.9128037257279669
Train: epoch: 1, loss = 1.912928320349649
Train:  Epoch 1, Loss=1.9127015243530274, Cohen Kappa=0.0142451786100537, MAD=0.6931611558972569
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.048400075271212, Cohen Kappa=0.3772099815817861, MAD=0.7154054331908442
Eval task: 2
Eval:  Epoch 1, Loss=1.9110345038874397, Cohen Kappa=0.01346263611382248, MAD=0.6852101282962246
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.066524224034671, Cohen Kappa=0.27904706477942665, MAD=0.7119834788238313
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8962642344935188, Cohen Kappa=0.016924249870323482, MAD=0.6863463813915234
{'0': {'precision': 0.4158269116775341, 'recall': 0.6885889570552147, 'f1-score': 0.5185253626536082, 'support': 4075}, '1': {'precision': 0.21266521996449003, 'recall': 0.3762652705061082, 'f1-score': 0.27174187043105624, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.19266741488963712, 'recall': 0.42351973684210525, 'f1-score': 0.2648495757264079, 'support': 1216}, '9': {'precision': 0.08659217877094973, 'recall': 0.028890959925442685, 'f1-score': 0.04332634521313767, 'support': 1073}, 'accuracy': 0.29835668103448276, 'macro avg': {'precision': 0.0907751725302611, 'recall': 0.1517264924328871, 'f1-score': 0.10984431540242098, 'support': 14848}, 'weighted avg': {'precision': 0.17719406685151157, 'recall': 0.29835668103448276, 'f1-score': 0.2195634135301346, 'support': 14848}}
{'0': {'precision': 0.31470274118903524, 'recall': 0.7960378208014408, 'f1-score': 0.45107794361525705, 'support': 4442}, '1': {'precision': 0.36600221483942413, 'recall': 0.2568985619898951, 'f1-score': 0.30189540991093855, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 176}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.3271821120689655, 'macro avg': {'precision': 0.06807049560284593, 'recall': 0.10529363827913359, 'f1-score': 0.07529733535261955, 'support': 14848}, 'weighted avg': {'precision': 0.22099656343786173, 'recall': 0.3271821120689655, 'f1-score': 0.2395771824448183, 'support': 14848}}