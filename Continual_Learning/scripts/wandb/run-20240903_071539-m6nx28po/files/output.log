
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_west_baseline
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.4352282273769379
Train: epoch: 1, loss = 0.4223593981564045
Train: epoch: 1, loss = 0.41588666970531146
Train: epoch: 1, loss = 0.41130686186254023
Train: epoch: 1, loss = 0.40921163341403005
Train: epoch: 1, loss = 0.407466419065992
Train: epoch: 1, loss = 0.4059904292864459
Train: epoch: 1, loss = 0.40458909085951744
Train: epoch: 1, loss = 0.40251249997980065
Train: epoch: 1, loss = 0.40146174067258833
Train: epoch: 1, loss = 0.3996017157354138
Train: epoch: 1, loss = 0.3981176611408591
Train: epoch: 1, loss = 0.3965415523946285
Train: epoch: 1, loss = 0.39529565288552215
Train: epoch: 1, loss = 0.3940074961185455
Train: epoch: 1, loss = 0.39280442815274
Train: epoch: 1, loss = 0.39174766302108766
Train: epoch: 1, loss = 0.390854513094657
Train:  Epoch 1, Loss=0.3909621273758065, AUC-ROC Macro=0.6628021100894469, AUC-ROC Micro=0.7514021031960584
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3706466356913249, AUC-ROC Macro=0.7188288500314891, AUC-ROC Micro=0.7831906096435852
Eval task: 2
Eval:  Epoch 1, Loss=0.3466636463999748, AUC-ROC Macro=0.5011284428902101, AUC-ROC Micro=0.5310014285873549
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.3771067260950804
Train: epoch: 2, loss = 0.37402274925261736
Train: epoch: 2, loss = 0.3744265052676201
Train: epoch: 2, loss = 0.37270620146766303
Train: epoch: 2, loss = 0.3716751662939787
Train: epoch: 2, loss = 0.3721734863271316
Train: epoch: 2, loss = 0.3710263584873506
Train: epoch: 2, loss = 0.37055984456092117
Train: epoch: 2, loss = 0.36965811861885917
Train: epoch: 2, loss = 0.3694710962846875
Train: epoch: 2, loss = 0.3698137482662093
Train: epoch: 2, loss = 0.3698846971367796
Train: epoch: 2, loss = 0.3697484824921076
Train: epoch: 2, loss = 0.3696065855824522
Train: epoch: 2, loss = 0.3690244973997275
Train: epoch: 2, loss = 0.3685491513647139
Train: epoch: 2, loss = 0.3682382934496683
Train: epoch: 2, loss = 0.3677247997456127
Train:  Epoch 2, Loss=0.36777382875915265, AUC-ROC Macro=0.7261869725687113, AUC-ROC Micro=0.792296462918796
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3605300262570381, AUC-ROC Macro=0.7396634844024408, AUC-ROC Micro=0.799517904318342
Eval task: 2
Eval:  Epoch 2, Loss=0.3480665907263756, AUC-ROC Macro=0.5033221614676018, AUC-ROC Micro=0.543180690552902
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3573388808965683
Train: epoch: 3, loss = 0.3582134226709604
Train: epoch: 3, loss = 0.35995280742645264
Train: epoch: 3, loss = 0.35935594633221624
Train: epoch: 3, loss = 0.36026263029873373
Train: epoch: 3, loss = 0.3601122416431705
Train: epoch: 3, loss = 0.359413955020053
Train: epoch: 3, loss = 0.3596264168713242
Train: epoch: 3, loss = 0.3596480509721571
Train: epoch: 3, loss = 0.35969781877845525
Train: epoch: 3, loss = 0.359994617626071
Train: epoch: 3, loss = 0.3598782637901604
Train: epoch: 3, loss = 0.3601310684130742
Train: epoch: 3, loss = 0.36000563137233255
Train: epoch: 3, loss = 0.3599179042875767
Train: epoch: 3, loss = 0.36019941229838875
Train: epoch: 3, loss = 0.36028673747444856
Train: epoch: 3, loss = 0.35986440891193017
Train:  Epoch 3, Loss=0.3596717075527224, AUC-ROC Macro=0.7448451716425001, AUC-ROC Micro=0.8049125111534009
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3559219402571519, AUC-ROC Macro=0.7506409570839512, AUC-ROC Micro=0.8072027276579032
Eval task: 2
Eval:  Epoch 3, Loss=0.35926534980535507, AUC-ROC Macro=0.4871337541227443, AUC-ROC Micro=0.5271588949072533
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.3519150179624557
Train: epoch: 4, loss = 0.3529193000122905
Train: epoch: 4, loss = 0.35371218209465344
Train: epoch: 4, loss = 0.35498547412455084
Train: epoch: 4, loss = 0.3553003360182047
Train: epoch: 4, loss = 0.3553633097310861
Train: epoch: 4, loss = 0.35520650403840204
Train: epoch: 4, loss = 0.35510777273215355
Train: epoch: 4, loss = 0.35517859988742406
Train: epoch: 4, loss = 0.35523844286054373
Train: epoch: 4, loss = 0.3550374665179036
Train: epoch: 4, loss = 0.3551229729130864
Train: epoch: 4, loss = 0.354919444213693
Train: epoch: 4, loss = 0.35474398226610254
Train: epoch: 4, loss = 0.35461084632078804
Train: epoch: 4, loss = 0.35484077168628575
Train: epoch: 4, loss = 0.3546489968326162
Train: epoch: 4, loss = 0.3543011601062285
Train:  Epoch 4, Loss=0.35435752953830946, AUC-ROC Macro=0.7566572296122481, AUC-ROC Micro=0.8127117041014067
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.35262709731856984, AUC-ROC Macro=0.7587338465367393, AUC-ROC Micro=0.8119938747094568
Eval task: 2
Eval:  Epoch 4, Loss=0.37201613932847977, AUC-ROC Macro=0.49203277217566105, AUC-ROC Micro=0.5285444494523749
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.3443582452833652
Train: epoch: 5, loss = 0.3478664103895426
Train: epoch: 5, loss = 0.34946209418276947
Train: epoch: 5, loss = 0.35011021507903933
Train: epoch: 5, loss = 0.3489174861907959
Train: epoch: 5, loss = 0.35031157661229373
Train: epoch: 5, loss = 0.35036266889955314
Train: epoch: 5, loss = 0.3497254320140928
Train: epoch: 5, loss = 0.34946551845305496
Train: epoch: 5, loss = 0.34925181756913665
Train: epoch: 5, loss = 0.34924008207565005
Train: epoch: 5, loss = 0.3487713158068558
Train: epoch: 5, loss = 0.3491418897245939
Train: epoch: 5, loss = 0.3496225421343531
Train: epoch: 5, loss = 0.3493937923014164
Train: epoch: 5, loss = 0.3496168249845505
Train: epoch: 5, loss = 0.34965756032396766
Train: epoch: 5, loss = 0.3497352681764298
Train:  Epoch 5, Loss=0.3499234155508188, AUC-ROC Macro=0.7652605352748474, AUC-ROC Micro=0.8188957352453817
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.35126685723662376, AUC-ROC Macro=0.7603407400314065, AUC-ROC Micro=0.8141976814351864
Eval task: 2
Eval:  Epoch 5, Loss=0.3926890939474106, AUC-ROC Macro=0.5087337336243225, AUC-ROC Micro=0.5539271712430833
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3467966487258673
Train: epoch: 6, loss = 0.3449978455156088
Train: epoch: 6, loss = 0.3464108555515607
Train: epoch: 6, loss = 0.34641978207975627
Train: epoch: 6, loss = 0.3445530499815941
Train: epoch: 6, loss = 0.3460004978006085
Train: epoch: 6, loss = 0.34657879331282204
Train: epoch: 6, loss = 0.3465163760818541
Train: epoch: 6, loss = 0.3460865892469883
Train: epoch: 6, loss = 0.345898603014648
Train: epoch: 6, loss = 0.34541461043059823
Train: epoch: 6, loss = 0.3455059571191669
Train: epoch: 6, loss = 0.34515449008689475
Train: epoch: 6, loss = 0.34524613460791964
Train: epoch: 6, loss = 0.3454465414782365
Train: epoch: 6, loss = 0.3459726627962664
Train: epoch: 6, loss = 0.3462168841414592
Train: epoch: 6, loss = 0.346370897649063
Train:  Epoch 6, Loss=0.3465091435990782, AUC-ROC Macro=0.7725221123944508, AUC-ROC Micro=0.8234973086392223
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.34902407974004745, AUC-ROC Macro=0.7634765160200523, AUC-ROC Micro=0.8167691424469958
Eval task: 2
Eval:  Epoch 6, Loss=0.5168289914727211, AUC-ROC Macro=0.4965639843592118, AUC-ROC Micro=0.5461804585600837
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3509310844043891, AUC-ROC Macro=0.7654660019657021, AUC-ROC Micro=0.8169203565653514
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.5245911329984665, AUC-ROC Macro=0.5045670870598901, AUC-ROC Micro=0.5448542845345322
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.28030554205179214
Train: epoch: 1, loss = 0.25977804146707056
Train: epoch: 1, loss = 0.25081543969611325
Train:  Epoch 1, Loss=0.24809945899318628, AUC-ROC Macro=0.5703506156863601, AUC-ROC Micro=0.7451103207471051
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.47933947791655857, AUC-ROC Macro=0.6679014538037401, AUC-ROC Micro=0.6466248200159046
Eval task: 2
Eval:  Epoch 1, Loss=0.2304488979279995, AUC-ROC Macro=0.6369651664254039, AUC-ROC Micro=0.7917086828488293
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.22705614753067493
Train: epoch: 2, loss = 0.22538594007492066
Train: epoch: 2, loss = 0.22463674592475097
Train:  Epoch 2, Loss=0.22393504329927408, AUC-ROC Macro=0.6787052386844761, AUC-ROC Micro=0.8110351181620614
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.5227929192284743, AUC-ROC Macro=0.6200998364808517, AUC-ROC Micro=0.6128746104657878
Eval task: 2
Eval:  Epoch 2, Loss=0.22171741351485252, AUC-ROC Macro=0.691003469657876, AUC-ROC Micro=0.8134159801112609
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.21541171886026858
Train: epoch: 3, loss = 0.21414701376110315
Train: epoch: 3, loss = 0.21663576622804007
Train:  Epoch 3, Loss=0.2167559256978855, AUC-ROC Macro=0.7279204298580708, AUC-ROC Micro=0.8274623119395985
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.5423116063078245, AUC-ROC Macro=0.6067561220901682, AUC-ROC Micro=0.6121312917639964
Eval task: 2
Eval:  Epoch 3, Loss=0.21983177587389946, AUC-ROC Macro=0.7156823217844073, AUC-ROC Micro=0.8188178877611312
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.21212310910224916
Train: epoch: 4, loss = 0.21044312726706266
Train: epoch: 4, loss = 0.2121656630933285
Train:  Epoch 4, Loss=0.21224460411440577, AUC-ROC Macro=0.7501551958750574, AUC-ROC Micro=0.8374598265786504
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.5440043297906717, AUC-ROC Macro=0.5915525995134537, AUC-ROC Micro=0.6080767067349206
Eval task: 2
Eval:  Epoch 4, Loss=0.22054465860128403, AUC-ROC Macro=0.713064616258371, AUC-ROC Micro=0.8175687683517203
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.20790312349796294
Train: epoch: 5, loss = 0.2094597660563886
Train: epoch: 5, loss = 0.20790697219471135
Train:  Epoch 5, Loss=0.20895066414777533, AUC-ROC Macro=0.7675702693493771, AUC-ROC Micro=0.8445403449975603
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.5551370779673258, AUC-ROC Macro=0.5844366960881642, AUC-ROC Micro=0.5996411999938336
Eval task: 2
Eval:  Epoch 5, Loss=0.2192266248166561, AUC-ROC Macro=0.7212040705514662, AUC-ROC Micro=0.8212844757519727
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.2032358591631055
Train: epoch: 6, loss = 0.20615678453817965
Train: epoch: 6, loss = 0.20560148214300475
Train:  Epoch 6, Loss=0.2052351801096037, AUC-ROC Macro=0.7794172544135465, AUC-ROC Micro=0.8520198618773573
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.5789690191547076, AUC-ROC Macro=0.5871220777555329, AUC-ROC Micro=0.6072489827842421
Eval task: 2
Eval:  Epoch 6, Loss=0.21879897266626358, AUC-ROC Macro=0.7166010077241708, AUC-ROC Micro=0.822499523538777
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.581434428691864, AUC-ROC Macro=0.5873069297616613, AUC-ROC Micro=0.6071958461607649
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.2166432850062847, AUC-ROC Macro=0.7423132848717989, AUC-ROC Micro=0.826455144897541
{'0': {'precision': 0.29659725749111227, 'recall': 0.44648318042813456, 'f1-score': 0.35642355813243826, 'support': 1308}, '1': {'precision': 0.14788732394366197, 'recall': 0.05223880597014925, 'f1-score': 0.07720588235294117, 'support': 402}, '2': {'precision': 0.23529411764705882, 'recall': 0.0060790273556231, 'f1-score': 0.011851851851851851, 'support': 658}, '3': {'precision': 0.5, 'recall': 0.003015075376884422, 'f1-score': 0.005994005994005994, 'support': 1990}, '4': {'precision': 0.21689059500959693, 'recall': 0.1401985111662531, 'f1-score': 0.17030896759608138, 'support': 806}, '5': {'precision': 0.15053763440860216, 'recall': 0.017994858611825194, 'f1-score': 0.03214695752009185, 'support': 778}, '6': {'precision': 0.5166666666666667, 'recall': 0.047619047619047616, 'f1-score': 0.08720112517580873, 'support': 1302}, '7': {'precision': 0.053452115812917596, 'recall': 0.05660377358490566, 'f1-score': 0.0549828178694158, 'support': 424}, '8': {'precision': 0.8, 'recall': 0.004866180048661801, 'f1-score': 0.009673518742442563, 'support': 1644}, '9': {'precision': 0.5333333333333333, 'recall': 0.003938946331856229, 'f1-score': 0.007820136852394919, 'support': 2031}, '10': {'precision': 0.5, 'recall': 0.0017452006980802793, 'f1-score': 0.0034782608695652175, 'support': 573}, '11': {'precision': 0.45714285714285713, 'recall': 0.013605442176870748, 'f1-score': 0.026424442609413706, 'support': 1176}, '12': {'precision': 0.4117647058823529, 'recall': 0.0039548022598870055, 'f1-score': 0.00783435926133184, 'support': 1770}, '13': {'precision': 0.3102189781021898, 'recall': 0.032742681047765794, 'f1-score': 0.059233449477351915, 'support': 2596}, '14': {'precision': 1.0, 'recall': 0.001229256299938537, 'f1-score': 0.0024554941682013503, 'support': 1627}, '15': {'precision': 0.056818181818181816, 'recall': 0.010330578512396695, 'f1-score': 0.01748251748251748, 'support': 484}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 795}, '17': {'precision': 0.75, 'recall': 0.0055147058823529415, 'f1-score': 0.010948905109489052, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.14285714285714285, 'recall': 0.007633587786259542, 'f1-score': 0.014492753623188403, 'support': 262}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 563}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 837}, '22': {'precision': 1.0, 'recall': 0.0027624309392265192, 'f1-score': 0.005509641873278237, 'support': 1086}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 861}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 505}, 'micro avg': {'precision': 0.2554763789918184, 'recall': 0.038150790210065816, 'f1-score': 0.06638776489952677, 'support': 25373}, 'macro avg': {'precision': 0.32317843640462696, 'recall': 0.03434224368384476, 'f1-score': 0.03845874586247239, 'support': 25373}, 'weighted avg': {'precision': 0.41489377727038257, 'recall': 0.038150790210065816, 'f1-score': 0.04243793464065006, 'support': 25373}, 'samples avg': {'precision': 0.10320444258432539, 'recall': 0.02555415337254147, 'f1-score': 0.038592308607531496, 'support': 25373}}
{'0': {'precision': 0.6296296296296297, 'recall': 0.3469387755102041, 'f1-score': 0.4473684210526315, 'support': 196}, '1': {'precision': 0.5266666666666666, 'recall': 0.3278008298755187, 'f1-score': 0.4040920716112532, 'support': 241}, '2': {'precision': 0.3333333333333333, 'recall': 0.006896551724137931, 'f1-score': 0.013513513513513514, 'support': 145}, '3': {'precision': 1.0, 'recall': 0.01694915254237288, 'f1-score': 0.03333333333333333, 'support': 118}, '4': {'precision': 0.5294117647058824, 'recall': 0.21634615384615385, 'f1-score': 0.30716723549488056, 'support': 208}, '5': {'precision': 0.2, 'recall': 0.01, 'f1-score': 0.019047619047619046, 'support': 100}, '6': {'precision': 1.0, 'recall': 0.00909090909090909, 'f1-score': 0.018018018018018018, 'support': 110}, '7': {'precision': 0.8157894736842105, 'recall': 0.23308270676691728, 'f1-score': 0.36257309941520466, 'support': 133}, '8': {'precision': 1.0, 'recall': 0.011235955056179775, 'f1-score': 0.02222222222222222, 'support': 89}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87}, '13': {'precision': 0.3684210526315789, 'recall': 0.0958904109589041, 'f1-score': 0.15217391304347827, 'support': 73}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 45}, '15': {'precision': 0.7727272727272727, 'recall': 0.6666666666666666, 'f1-score': 0.7157894736842105, 'support': 51}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'micro avg': {'precision': 0.5895196506550219, 'recall': 0.1354062186559679, 'f1-score': 0.2202283849918434, 'support': 1994}, 'macro avg': {'precision': 0.28703916773514293, 'recall': 0.07763592448151857, 'f1-score': 0.0998119568174546, 'support': 1994}, 'weighted avg': {'precision': 0.46167947954735555, 'recall': 0.1354062186559679, 'f1-score': 0.17881378147300314, 'support': 1994}, 'samples avg': {'precision': 0.23811848958333331, 'recall': 0.15791480654761902, 'f1-score': 0.1781670640557359, 'support': 1994}}