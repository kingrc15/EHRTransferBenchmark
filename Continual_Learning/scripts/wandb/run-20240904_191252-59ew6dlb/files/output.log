
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_northeast
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.42524579748511315
Train: epoch: 1, loss = 0.41888084053993224
Train: epoch: 1, loss = 0.41539803355932237
Train: epoch: 1, loss = 0.4114347557350993
Train: epoch: 1, loss = 0.40962354764342307
Train: epoch: 1, loss = 0.40766139249006905
Train: epoch: 1, loss = 0.40581298603543214
Train: epoch: 1, loss = 0.4040606682468206
Train: epoch: 1, loss = 0.4029175949427817
Train: epoch: 1, loss = 0.40111503618210553
Train: epoch: 1, loss = 0.4006032282384959
Train: epoch: 1, loss = 0.3990221041503052
Train: epoch: 1, loss = 0.3979906931806069
Train: epoch: 1, loss = 0.39639926875808407
Train: epoch: 1, loss = 0.395190960218509
Train: epoch: 1, loss = 0.39404764474835247
Train: epoch: 1, loss = 0.3931870726057712
Train: epoch: 1, loss = 0.3922133335098624
Train:  Epoch 1, Loss=0.391779081705289, AUC-ROC Macro=0.6598533773327508, AUC-ROC Micro=0.7498180188637643
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3703429227073987, AUC-ROC Macro=0.7218493772181711, AUC-ROC Micro=0.7848498107554991
Eval task: 2
Eval:  Epoch 1, Loss=0.3984576612710953, AUC-ROC Macro=0.47788457415319363, AUC-ROC Micro=0.5786680369764171
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.37448237657546996
Train: epoch: 2, loss = 0.3731587614864111
Train: epoch: 2, loss = 0.371897242218256
Train: epoch: 2, loss = 0.3714892824366689
Train: epoch: 2, loss = 0.372225412145257
Train: epoch: 2, loss = 0.37236704539507626
Train: epoch: 2, loss = 0.3712979888490268
Train: epoch: 2, loss = 0.3707291148882359
Train: epoch: 2, loss = 0.3703375127332078
Train: epoch: 2, loss = 0.3702895734682679
Train: epoch: 2, loss = 0.3701374946602366
Train: epoch: 2, loss = 0.3698411965246002
Train: epoch: 2, loss = 0.36972619560475534
Train: epoch: 2, loss = 0.3691321153300149
Train: epoch: 2, loss = 0.3684754920055469
Train: epoch: 2, loss = 0.36794101090636105
Train: epoch: 2, loss = 0.3680052598259028
Train: epoch: 2, loss = 0.36814467784017324
Train:  Epoch 2, Loss=0.3681567800788798, AUC-ROC Macro=0.7248268804627866, AUC-ROC Micro=0.7917665781395096
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.36189163103699684, AUC-ROC Macro=0.7383495552649394, AUC-ROC Micro=0.797410108472026
Eval task: 2
Eval:  Epoch 2, Loss=0.40621039271354675, AUC-ROC Macro=0.4808293210560047, AUC-ROC Micro=0.5887638820884876
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.36258476600050926
Train: epoch: 3, loss = 0.3618859654664993
Train: epoch: 3, loss = 0.35862627409398556
Train: epoch: 3, loss = 0.35796431435272097
Train: epoch: 3, loss = 0.36060188856720926
Train: epoch: 3, loss = 0.3610395091896256
Train: epoch: 3, loss = 0.3613438917696476
Train: epoch: 3, loss = 0.36198979515582325
Train: epoch: 3, loss = 0.36248161986470223
Train: epoch: 3, loss = 0.36176694856584074
Train: epoch: 3, loss = 0.361304300644181
Train: epoch: 3, loss = 0.3614030477590859
Train: epoch: 3, loss = 0.3610867647310862
Train: epoch: 3, loss = 0.36125645577375376
Train: epoch: 3, loss = 0.3612221613774697
Train: epoch: 3, loss = 0.3609916864708066
Train: epoch: 3, loss = 0.360887864924529
Train: epoch: 3, loss = 0.360615201820102
Train:  Epoch 3, Loss=0.3604087837700151, AUC-ROC Macro=0.7430187345088776, AUC-ROC Micro=0.8037785126670679
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.35730522871017456, AUC-ROC Macro=0.7492984186338534, AUC-ROC Micro=0.8050228546152431
Eval task: 2
Eval:  Epoch 3, Loss=0.4093977212905884, AUC-ROC Macro=0.4878720824461347, AUC-ROC Micro=0.5950339475429656
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.35763927944004537
Train: epoch: 4, loss = 0.3599383537843823
Train: epoch: 4, loss = 0.3584795270860195
Train: epoch: 4, loss = 0.3571157507039607
Train: epoch: 4, loss = 0.3573140642940998
Train: epoch: 4, loss = 0.35743730643143257
Train: epoch: 4, loss = 0.3558944020633187
Train: epoch: 4, loss = 0.3564072441123426
Train: epoch: 4, loss = 0.3561115879731046
Train: epoch: 4, loss = 0.35567405092716214
Train: epoch: 4, loss = 0.35558405011214994
Train: epoch: 4, loss = 0.35575075042123594
Train: epoch: 4, loss = 0.35574679242303736
Train: epoch: 4, loss = 0.35497078270252264
Train: epoch: 4, loss = 0.35488519713282585
Train: epoch: 4, loss = 0.3551685294508934
Train: epoch: 4, loss = 0.3555213550302912
Train: epoch: 4, loss = 0.3555273720829023
Train:  Epoch 4, Loss=0.35546837321305885, AUC-ROC Macro=0.753806212460701, AUC-ROC Micro=0.8110182489018262
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3555211238563061, AUC-ROC Macro=0.7528594468169183, AUC-ROC Micro=0.808525269710074
Eval task: 2
Eval:  Epoch 4, Loss=0.43997980654239655, AUC-ROC Macro=0.486915996156866, AUC-ROC Micro=0.5898704457986362
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.35205460362136365
Train: epoch: 5, loss = 0.3487244099751115
Train: epoch: 5, loss = 0.34977535319825015
Train: epoch: 5, loss = 0.3491687531769276
Train: epoch: 5, loss = 0.3492294016480446
Train: epoch: 5, loss = 0.3498073193927606
Train: epoch: 5, loss = 0.35063414391662395
Train: epoch: 5, loss = 0.35029397304169835
Train: epoch: 5, loss = 0.35054690829581686
Train: epoch: 5, loss = 0.3506825813576579
Train: epoch: 5, loss = 0.3503523196076805
Train: epoch: 5, loss = 0.35017642566313345
Train: epoch: 5, loss = 0.35054154984652997
Train: epoch: 5, loss = 0.3507347657425063
Train: epoch: 5, loss = 0.3506096626470486
Train: epoch: 5, loss = 0.3506469081249088
Train: epoch: 5, loss = 0.35058661736109675
Train: epoch: 5, loss = 0.3510835347945491
Train:  Epoch 5, Loss=0.351003034685412, AUC-ROC Macro=0.7631418817111298, AUC-ROC Micro=0.8172878220658356
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3514890670776367, AUC-ROC Macro=0.7601176346664852, AUC-ROC Micro=0.8136782187153355
Eval task: 2
Eval:  Epoch 5, Loss=0.4479580223560333, AUC-ROC Macro=0.4860575992399088, AUC-ROC Micro=0.5847447770958586
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3481396697461605
Train: epoch: 6, loss = 0.3437838665023446
Train: epoch: 6, loss = 0.3439209962636232
Train: epoch: 6, loss = 0.34429746612906453
Train: epoch: 6, loss = 0.3445923319607973
Train: epoch: 6, loss = 0.34434500087052583
Train: epoch: 6, loss = 0.3452472791501454
Train: epoch: 6, loss = 0.34665277066640554
Train: epoch: 6, loss = 0.34672542163895237
Train: epoch: 6, loss = 0.3466760583892465
Train: epoch: 6, loss = 0.34703796570273965
Train: epoch: 6, loss = 0.34723998941481116
Train: epoch: 6, loss = 0.34786621674322166
Train: epoch: 6, loss = 0.3478079847938248
Train: epoch: 6, loss = 0.3479845732599497
Train: epoch: 6, loss = 0.3482324830116704
Train: epoch: 6, loss = 0.34805927732849823
Train: epoch: 6, loss = 0.3478318154770467
Train:  Epoch 6, Loss=0.34770947924230855, AUC-ROC Macro=0.7700155201344249, AUC-ROC Micro=0.8218388956126992
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3498288703461488, AUC-ROC Macro=0.7630790458173078, AUC-ROC Micro=0.8160689637021243
Eval task: 2
Eval:  Epoch 6, Loss=0.4378345012664795, AUC-ROC Macro=0.4878321855422672, AUC-ROC Micro=0.5879207629601078
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.35243090863029164, AUC-ROC Macro=0.763035889648372, AUC-ROC Micro=0.815303194720139
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.4521529972553253, AUC-ROC Macro=0.47319817615062887, AUC-ROC Micro=0.591347836557666
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.3460717289149761
Train:  Epoch 1, Loss=0.3374822394950952, AUC-ROC Macro=0.5553533395375697, AUC-ROC Micro=0.7218124117199538
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3493504573901494, AUC-ROC Macro=0.7521172651908036, AUC-ROC Micro=0.8072788044085386
Eval task: 2
Eval:  Epoch 1, Loss=0.3080691546201706, AUC-ROC Macro=0.6336046466627132, AUC-ROC Micro=0.7723529818556351
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.31920557968318464
Train:  Epoch 2, Loss=0.3178873304459507, AUC-ROC Macro=0.6552526076529045, AUC-ROC Micro=0.7959384580000121
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.34982723121841747, AUC-ROC Macro=0.7567065408113827, AUC-ROC Micro=0.8112131476172539
Eval task: 2
Eval:  Epoch 2, Loss=0.32566386461257935, AUC-ROC Macro=0.6754410122108476, AUC-ROC Micro=0.7959309855383726
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.3115911157429218
Train:  Epoch 3, Loss=0.3106364456097617, AUC-ROC Macro=0.6988976232652313, AUC-ROC Micro=0.8189003134543059
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.34252336621284485, AUC-ROC Macro=0.755981962653312, AUC-ROC Micro=0.8095386286439326
Eval task: 2
Eval:  Epoch 3, Loss=0.322562113404274, AUC-ROC Macro=0.6931138669973314, AUC-ROC Micro=0.8094444656470253
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.30393099814653396
Train:  Epoch 4, Loss=0.30488821702023433, AUC-ROC Macro=0.7255432642533086, AUC-ROC Micro=0.8343134492934736
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.34553369755546254, AUC-ROC Macro=0.7527718795731145, AUC-ROC Micro=0.807176855822428
Eval task: 2
Eval:  Epoch 4, Loss=0.3469657897949219, AUC-ROC Macro=0.7001638528847519, AUC-ROC Micro=0.8122170096028399
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.2950193280726671
Train:  Epoch 5, Loss=0.2972521928646907, AUC-ROC Macro=0.744445759732371, AUC-ROC Micro=0.8436654279462938
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3554003561536471, AUC-ROC Macro=0.7518208347190332, AUC-ROC Micro=0.8060156437696666
Eval task: 2
Eval:  Epoch 5, Loss=0.3145468682050705, AUC-ROC Macro=0.7141359380783914, AUC-ROC Micro=0.8203370957162688
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.2944971650838852
Train:  Epoch 6, Loss=0.29350094349647, AUC-ROC Macro=0.7654382739692265, AUC-ROC Micro=0.8517276851000659
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.34071282173196477, AUC-ROC Macro=0.7507432310098656, AUC-ROC Micro=0.8060071737052614
Eval task: 2
Eval:  Epoch 6, Loss=0.2711613178253174, AUC-ROC Macro=0.7166632647813646, AUC-ROC Micro=0.8242576539257644
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3643544365962346, AUC-ROC Macro=0.7477706049179254, AUC-ROC Micro=0.803562510871991
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.29357559978961945, AUC-ROC Macro=0.6833783378869078, AUC-ROC Micro=0.8131068495360034
{'0': {'precision': 0.5588235294117647, 'recall': 0.26146788990825687, 'f1-score': 0.35625, 'support': 1308}, '1': {'precision': 0.610909090909091, 'recall': 0.417910447761194, 'f1-score': 0.49630723781388475, 'support': 402}, '2': {'precision': 0.48717948717948717, 'recall': 0.057750759878419454, 'f1-score': 0.1032608695652174, 'support': 658}, '3': {'precision': 0.5609756097560976, 'recall': 0.1849246231155779, 'f1-score': 0.2781557067271353, 'support': 1990}, '4': {'precision': 0.46846846846846846, 'recall': 0.06451612903225806, 'f1-score': 0.11341330425299889, 'support': 806}, '5': {'precision': 0.3333333333333333, 'recall': 0.006426735218508998, 'f1-score': 0.012610340479192938, 'support': 778}, '6': {'precision': 0.5945017182130584, 'recall': 0.13287250384024576, 'f1-score': 0.21720025109855617, 'support': 1302}, '7': {'precision': 1.0, 'recall': 0.0023584905660377358, 'f1-score': 0.004705882352941177, 'support': 424}, '8': {'precision': 0.5403225806451613, 'recall': 0.3260340632603406, 'f1-score': 0.40667678300455234, 'support': 1644}, '9': {'precision': 0.6664460622104567, 'recall': 0.4958148695224028, 'f1-score': 0.5686053077357426, 'support': 2031}, '10': {'precision': 0.5518134715025906, 'recall': 0.3717277486910995, 'f1-score': 0.4442127215849843, 'support': 573}, '11': {'precision': 0.5114155251141552, 'recall': 0.19047619047619047, 'f1-score': 0.27757125154894674, 'support': 1176}, '12': {'precision': 0.5591054313099042, 'recall': 0.2966101694915254, 'f1-score': 0.38759689922480617, 'support': 1770}, '13': {'precision': 0.5666199158485273, 'recall': 0.46687211093990755, 'f1-score': 0.5119324181626188, 'support': 2596}, '14': {'precision': 0.5537065052950075, 'recall': 0.2249539028887523, 'f1-score': 0.31993006993006995, 'support': 1627}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 484}, '16': {'precision': 0.5338983050847458, 'recall': 0.07924528301886792, 'f1-score': 0.13800657174151149, 'support': 795}, '17': {'precision': 0.6, 'recall': 0.016544117647058824, 'f1-score': 0.032200357781753126, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.391304347826087, 'recall': 0.03435114503816794, 'f1-score': 0.06315789473684211, 'support': 262}, '20': {'precision': 0.14285714285714285, 'recall': 0.0017761989342806395, 'f1-score': 0.003508771929824562, 'support': 563}, '21': {'precision': 0.5488958990536278, 'recall': 0.2078853046594982, 'f1-score': 0.30155979202772965, 'support': 837}, '22': {'precision': 0.6808266360505166, 'recall': 0.5460405156537753, 'f1-score': 0.6060296371997956, 'support': 1086}, '23': {'precision': 0.5971896955503513, 'recall': 0.2961672473867596, 'f1-score': 0.39596273291925466, 'support': 861}, '24': {'precision': 0.5787037037037037, 'recall': 0.24752475247524752, 'f1-score': 0.34674063800277394, 'support': 505}, 'micro avg': {'precision': 0.5819443193080458, 'recall': 0.2545619359161313, 'f1-score': 0.35418951524457115, 'support': 25373}, 'macro avg': {'precision': 0.5054918583729312, 'recall': 0.19721004797617492, 'f1-score': 0.25542381759284527, 'support': 25373}, 'weighted avg': {'precision': 0.5402719252488097, 'recall': 0.2545619359161313, 'f1-score': 0.32259629078910657, 'support': 25373}, 'samples avg': {'precision': 0.38436211773614115, 'recall': 0.2301031850434424, 'f1-score': 0.26348731422380456, 'support': 25373}}
{'0': {'precision': 0.5789473684210527, 'recall': 0.3384615384615385, 'f1-score': 0.4271844660194175, 'support': 130}, '1': {'precision': 0.5873015873015873, 'recall': 0.5441176470588235, 'f1-score': 0.564885496183206, 'support': 136}, '2': {'precision': 0.4444444444444444, 'recall': 0.20437956204379562, 'f1-score': 0.28, 'support': 137}, '3': {'precision': 0.6259259259259259, 'recall': 0.7934272300469484, 'f1-score': 0.6997929606625258, 'support': 213}, '4': {'precision': 0.5, 'recall': 0.08, 'f1-score': 0.13793103448275865, 'support': 75}, '5': {'precision': 0.42857142857142855, 'recall': 0.031914893617021274, 'f1-score': 0.0594059405940594, 'support': 94}, '6': {'precision': 0.5714285714285714, 'recall': 0.05405405405405406, 'f1-score': 0.09876543209876544, 'support': 74}, '7': {'precision': 0.6428571428571429, 'recall': 0.225, 'f1-score': 0.33333333333333337, 'support': 40}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '9': {'precision': 1.0, 'recall': 0.015384615384615385, 'f1-score': 0.030303030303030307, 'support': 65}, '10': {'precision': 0.5, 'recall': 0.015873015873015872, 'f1-score': 0.03076923076923077, 'support': 63}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 56}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 52}, '13': {'precision': 0.5, 'recall': 0.07272727272727272, 'f1-score': 0.12698412698412698, 'support': 55}, '14': {'precision': 0.4, 'recall': 0.031746031746031744, 'f1-score': 0.058823529411764705, 'support': 63}, '15': {'precision': 0.7142857142857143, 'recall': 0.2631578947368421, 'f1-score': 0.3846153846153846, 'support': 19}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}, '17': {'precision': 0.46153846153846156, 'recall': 0.07317073170731707, 'f1-score': 0.12631578947368421, 'support': 82}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, 'micro avg': {'precision': 0.5807504078303426, 'recall': 0.23162003903708522, 'f1-score': 0.3311627906976744, 'support': 1537}, 'macro avg': {'precision': 0.3182120257909732, 'recall': 0.10973657949829105, 'f1-score': 0.13436439019725152, 'support': 1537}, 'weighted avg': {'precision': 0.4526679125453224, 'recall': 0.23162003903708522, 'f1-score': 0.25283606043266743, 'support': 1537}, 'samples avg': {'precision': 0.3687825520833333, 'recall': 0.21299680679563493, 'f1-score': 0.24898609420093798, 'support': 1537}}