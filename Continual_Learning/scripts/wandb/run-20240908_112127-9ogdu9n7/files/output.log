
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.154611345529556
Train: epoch: 1, loss = 2.126785731911659
Train: epoch: 1, loss = 2.107173763712247
Train: epoch: 1, loss = 2.098853954076767
Train: epoch: 1, loss = 2.0937490578889846
Train: epoch: 1, loss = 2.086453984777133
Train: epoch: 1, loss = 2.0822180507012775
Train: epoch: 1, loss = 2.0777338490635158
Train: epoch: 1, loss = 2.076479666233063
Train: epoch: 1, loss = 2.073026042103767
Train: epoch: 1, loss = 2.070587017156861
Train: epoch: 1, loss = 2.0681974929074447
Train: epoch: 1, loss = 2.0664210424973413
Train: epoch: 1, loss = 2.0654553990704674
Train: epoch: 1, loss = 2.063765900015831
Train: epoch: 1, loss = 2.063835699558258
Train: epoch: 1, loss = 2.0628288862985724
Train: epoch: 1, loss = 2.0612579932808877
Train: epoch: 1, loss = 2.0592352010388124
Train: epoch: 1, loss = 2.058509597539902
Train: epoch: 1, loss = 2.057913961552438
Train: epoch: 1, loss = 2.057598258121447
Train: epoch: 1, loss = 2.0564440920301106
Train: epoch: 1, loss = 2.054720858857036
Train: epoch: 1, loss = 2.0541866657733916
Train: epoch: 1, loss = 2.053490096147244
Train: epoch: 1, loss = 2.0528747683984263
Train: epoch: 1, loss = 2.0520198032898564
Train: epoch: 1, loss = 2.0516406169636494
Train: epoch: 1, loss = 2.050952227493127
Train: epoch: 1, loss = 2.0503914346618037
Train: epoch: 1, loss = 2.0499178930372
Train: epoch: 1, loss = 2.0495292965751704
Train: epoch: 1, loss = 2.048867022780811
Train: epoch: 1, loss = 2.048618345669338
Train: epoch: 1, loss = 2.047683022568623
Train: epoch: 1, loss = 2.0473069385419023
Train: epoch: 1, loss = 2.046935807497878
Train: epoch: 1, loss = 2.0469102359735047
Train: epoch: 1, loss = 2.0465176314860583
Train: epoch: 1, loss = 2.0464620074557094
Train: epoch: 1, loss = 2.0466043719365485
Train: epoch: 1, loss = 2.046160683784374
Train:  Epoch 1, Loss=2.0457470844268797, Cohen Kappa=0.3770006110621933, MAD=0.7198479340720481
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0324818265849145, Cohen Kappa=0.42463868376732905, MAD=0.73082409077552
Eval task: 2
Eval:  Epoch 1, Loss=1.9163889473882214, Cohen Kappa=0.00579564031882851, MAD=0.7232026155757819
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.060613414336895, Cohen Kappa=0.326193230164309, MAD=0.7271099448923097
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9062508344650269, Cohen Kappa=0.005644020969470587, MAD=0.7234268634871948
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9830218786001206
Train: epoch: 1, loss = 1.973930335342884
Train: epoch: 1, loss = 1.9725821143388749
Train: epoch: 1, loss = 1.9718830151855946
Train: epoch: 1, loss = 1.9702827109098435
Train: epoch: 1, loss = 1.970973118742307
Train: epoch: 1, loss = 1.9713939034087318
Train: epoch: 1, loss = 1.973402003645897
Train: epoch: 1, loss = 1.9723842560582692
Train: epoch: 1, loss = 1.97205124938488
Train: epoch: 1, loss = 1.9721277739243075
Train: epoch: 1, loss = 1.9720719694097837
Train: epoch: 1, loss = 1.9721378053610141
Train: epoch: 1, loss = 1.9719200751185417
Train: epoch: 1, loss = 1.972004445830981
Train: epoch: 1, loss = 1.9716136556863786
Train: epoch: 1, loss = 1.9714468217246672
Train: epoch: 1, loss = 1.971372843914562
Train: epoch: 1, loss = 1.9713540205202604
Train: epoch: 1, loss = 1.9709104652106761
Train: epoch: 1, loss = 1.9702262627226965
Train: epoch: 1, loss = 1.9704472111300988
Train: epoch: 1, loss = 1.9706409064842307
Train: epoch: 1, loss = 1.970776287764311
Train: epoch: 1, loss = 1.9707204810619354
Train: epoch: 1, loss = 1.9704345212532923
Train: epoch: 1, loss = 1.970407467727308
Train: epoch: 1, loss = 1.969841808698007
Train: epoch: 1, loss = 1.9699380671772464
Train: epoch: 1, loss = 1.9695440942049027
Train: epoch: 1, loss = 1.9692378703048152
Train: epoch: 1, loss = 1.9692696776613594
Train: epoch: 1, loss = 1.9691034814083215
Train: epoch: 1, loss = 1.9689714414757842
Train: epoch: 1, loss = 1.9690263111080442
Train: epoch: 1, loss = 1.9687973891364203
Train: epoch: 1, loss = 1.9685048078524099
Train: epoch: 1, loss = 1.9685531269719727
Train: epoch: 1, loss = 1.9684257995929473
Train: epoch: 1, loss = 1.9684915955364704
Train: epoch: 1, loss = 1.9683351336165171
Train: epoch: 1, loss = 1.9685402488708497
Train: epoch: 1, loss = 1.9683461375430573
Train:  Epoch 1, Loss=1.968111392715999, Cohen Kappa=0.02691003482348786, MAD=0.6968921195011537
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0296255329559587, Cohen Kappa=0.440751046595913, MAD=0.7224603679791752
Eval task: 2
Eval:  Epoch 1, Loss=1.96404610009029, Cohen Kappa=0.11376834964138893, MAD=0.6954316276438792
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0575013900625296, Cohen Kappa=0.35202130391606634, MAD=0.7163968607533245
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.899855862403738, Cohen Kappa=0.04195037611164332, MAD=0.6963558555580112
{'0': {'precision': 0.40329265484688004, 'recall': 0.8596319018404908, 'f1-score': 0.5490165347543295, 'support': 4075}, '1': {'precision': 0.3183890577507599, 'recall': 0.1462478184991274, 'f1-score': 0.20043051901458983, 'support': 2865}, '2': {'precision': 0.08771929824561403, 'recall': 0.0027502750275027505, 'f1-score': 0.005333333333333334, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.14889657006115395, 'recall': 0.4605263157894737, 'f1-score': 0.2250351617440225, 'support': 1216}, '9': {'precision': 0.12840466926070038, 'recall': 0.12301957129543337, 'f1-score': 0.1256544502617801, 'support': 1073}, 'accuracy': 0.3110856681034483, 'macro avg': {'precision': 0.10867022501651083, 'recall': 0.1592175882452028, 'f1-score': 0.11054699991080552, 'support': 14848}, 'weighted avg': {'precision': 0.20433138082425809, 'recall': 0.3110856681034483, 'f1-score': 0.21751359091543065, 'support': 14848}}
{'0': {'precision': 0.34717039800995025, 'recall': 0.5027014858171994, 'f1-score': 0.41070443259150263, 'support': 4442}, '1': {'precision': 0.3452209414024976, 'recall': 0.5586863583365721, 'f1-score': 0.42674781059818906, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 176}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.34401939655172414, 'macro avg': {'precision': 0.06923913394124478, 'recall': 0.10613878441537716, 'f1-score': 0.08374522431896916, 'support': 14848}, 'weighted avg': {'precision': 0.2235073998125978, 'recall': 0.34401939655172414, 'f1-score': 0.2707700244416578, 'support': 14848}}