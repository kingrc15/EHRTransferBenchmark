
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.146547008752823
Train: epoch: 1, loss = 2.1220516270399092
Train: epoch: 1, loss = 2.1177902932961783
Train: epoch: 1, loss = 2.1078835536539553
Train: epoch: 1, loss = 2.099845077514648
Train: epoch: 1, loss = 2.093799339036147
Train: epoch: 1, loss = 2.0899572455883026
Train: epoch: 1, loss = 2.0886794494837524
Train: epoch: 1, loss = 2.085131916867362
Train: epoch: 1, loss = 2.0827329417467118
Train: epoch: 1, loss = 2.07841842380437
Train: epoch: 1, loss = 2.0763279891014097
Train: epoch: 1, loss = 2.073978062272072
Train: epoch: 1, loss = 2.071823282156672
Train: epoch: 1, loss = 2.069760216196378
Train: epoch: 1, loss = 2.068209566138685
Train: epoch: 1, loss = 2.067814762802685
Train: epoch: 1, loss = 2.066275169716941
Train: epoch: 1, loss = 2.0657371100312787
Train: epoch: 1, loss = 2.065012138545513
Train: epoch: 1, loss = 2.0639118487494335
Train: epoch: 1, loss = 2.0630125010826372
Train: epoch: 1, loss = 2.0609940594434737
Train: epoch: 1, loss = 2.059776362950603
Train: epoch: 1, loss = 2.059086052250862
Train: epoch: 1, loss = 2.057553274562726
Train: epoch: 1, loss = 2.056733516344318
Train: epoch: 1, loss = 2.0559482323059015
Train: epoch: 1, loss = 2.0554983314563486
Train: epoch: 1, loss = 2.0547717121839524
Train: epoch: 1, loss = 2.0540511615814703
Train: epoch: 1, loss = 2.0533866401389242
Train: epoch: 1, loss = 2.0527964984286915
Train: epoch: 1, loss = 2.052018123339204
Train: epoch: 1, loss = 2.051822053398405
Train: epoch: 1, loss = 2.051166021161609
Train: epoch: 1, loss = 2.050486893847182
Train: epoch: 1, loss = 2.049533609763572
Train: epoch: 1, loss = 2.0487047312504205
Train: epoch: 1, loss = 2.048210787221789
Train: epoch: 1, loss = 2.047677507400513
Train: epoch: 1, loss = 2.0476526281805265
Train: epoch: 1, loss = 2.0473153376302053
Train:  Epoch 1, Loss=2.047266598715101, Cohen Kappa=0.369488023929459, MAD=0.7174736447245935
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.028748401280107, Cohen Kappa=0.4379703810923513, MAD=0.7193344755709817
Eval task: 2
Eval:  Epoch 1, Loss=1.9748468296281223, Cohen Kappa=0.009672423925132123, MAD=0.7375085927496485
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.056229967495491, Cohen Kappa=0.34133742002917944, MAD=0.7127753760894764
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9406279531018487, Cohen Kappa=0.005517314404410278, MAD=0.7358569506641862
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9748376923799515
Train: epoch: 1, loss = 1.974308295249939
Train: epoch: 1, loss = 1.9775444181760151
Train: epoch: 1, loss = 1.9767824345827103
Train: epoch: 1, loss = 1.9747429537773131
Train: epoch: 1, loss = 1.9721213034788767
Train: epoch: 1, loss = 1.9737507230043412
Train: epoch: 1, loss = 1.9730982748419046
Train: epoch: 1, loss = 1.973061793645223
Train: epoch: 1, loss = 1.9723973785638809
Train: epoch: 1, loss = 1.9731502053954384
Train: epoch: 1, loss = 1.9732442636787892
Train: epoch: 1, loss = 1.9716593217391234
Train: epoch: 1, loss = 1.97150278874806
Train: epoch: 1, loss = 1.9716895219882329
Train: epoch: 1, loss = 1.972557187564671
Train: epoch: 1, loss = 1.9722809687782736
Train: epoch: 1, loss = 1.9721446640955078
Train: epoch: 1, loss = 1.9720417599615299
Train: epoch: 1, loss = 1.9717647494971753
Train: epoch: 1, loss = 1.9723210424752462
Train: epoch: 1, loss = 1.9713776716318998
Train: epoch: 1, loss = 1.971661355987839
Train: epoch: 1, loss = 1.971625747208794
Train: epoch: 1, loss = 1.9719994489669799
Train: epoch: 1, loss = 1.9714738305944663
Train: epoch: 1, loss = 1.9715553377513533
Train: epoch: 1, loss = 1.9712283035899911
Train: epoch: 1, loss = 1.9717415335466122
Train: epoch: 1, loss = 1.9715400162935257
Train: epoch: 1, loss = 1.971303670367887
Train: epoch: 1, loss = 1.9710662808455526
Train: epoch: 1, loss = 1.9713628284317075
Train: epoch: 1, loss = 1.9709276632876958
Train: epoch: 1, loss = 1.9705864105394908
Train: epoch: 1, loss = 1.9696777934498257
Train: epoch: 1, loss = 1.969033548090909
Train: epoch: 1, loss = 1.9682155293696806
Train: epoch: 1, loss = 1.9681028061035353
Train: epoch: 1, loss = 1.9675541743338107
Train: epoch: 1, loss = 1.9670620215956758
Train: epoch: 1, loss = 1.9666558133136658
Train: epoch: 1, loss = 1.965919511831084
Train:  Epoch 1, Loss=1.9657029403414046, Cohen Kappa=0.09716517104514444, MAD=0.6859622577746869
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.030204766783221, Cohen Kappa=0.4063502885180278, MAD=0.7314007734646838
Eval task: 2
Eval:  Epoch 1, Loss=1.985500239092728, Cohen Kappa=0.12834986792474, MAD=0.702584813710712
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0533195507937463, Cohen Kappa=0.33965943069191695, MAD=0.7319135666019342
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9256512892657314, Cohen Kappa=0.09097599298751746, MAD=0.7050295084131616
{'0': {'precision': 0.38595006347862887, 'recall': 0.8952147239263804, 'f1-score': 0.5393657130184077, 'support': 4075}, '1': {'precision': 0.24147339699863574, 'recall': 0.12356020942408377, 'f1-score': 0.16347263911336873, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.17878395860284604, 'recall': 0.5682565789473685, 'f1-score': 0.27199370202716, 'support': 1216}, '9': {'precision': 0.09230769230769231, 'recall': 0.005591798695246971, 'f1-score': 0.010544815465729352, 'support': 1073}, 'accuracy': 0.31647359913793105, 'macro avg': {'precision': 0.08985151113878029, 'recall': 0.15926233109930796, 'f1-score': 0.09853768696246659, 'support': 14848}, 'weighted avg': {'precision': 0.17382915130547671, 'recall': 0.31647359913793105, 'f1-score': 0.2026079822379827, 'support': 14848}}
{'0': {'precision': 0.34643949322848405, 'recall': 0.7497045615693689, 'f1-score': 0.47389258235601706, 'support': 4231}, '1': {'precision': 0.30475108839674425, 'recall': 0.32001590141125025, 'f1-score': 0.3121970137676944, 'support': 5031}, '2': {'precision': 0.13924050632911392, 'recall': 0.004552980132450331, 'f1-score': 0.008817635270541082, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.07430340557275542, 'recall': 0.0784313725490196, 'f1-score': 0.07631160572337042, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3244207974137931, 'macro avg': {'precision': 0.08647344935270976, 'recall': 0.11527048156620892, 'f1-score': 0.0871218837117623, 'support': 14848}, 'weighted avg': {'precision': 0.22616716911167423, 'recall': 0.3244207974137931, 'f1-score': 0.24382795328519374, 'support': 14848}}