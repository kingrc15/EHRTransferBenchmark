
Experiment dir: ./exp/Test_los_midwest
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1538225412368774
Train: epoch: 1, loss = 2.1276148599386215
Train: epoch: 1, loss = 2.114025505979856
Train: epoch: 1, loss = 2.101871054768562
Train: epoch: 1, loss = 2.0948992772102355
Train: epoch: 1, loss = 2.08877082357804
Train: epoch: 1, loss = 2.0851364188534873
Train: epoch: 1, loss = 2.079144788682461
Train: epoch: 1, loss = 2.0759589571423
Train: epoch: 1, loss = 2.0748162700533865
Train: epoch: 1, loss = 2.0732767832279206
Train: epoch: 1, loss = 2.0703784299393493
Train: epoch: 1, loss = 2.0688237438293604
Train: epoch: 1, loss = 2.0661101688657486
Train: epoch: 1, loss = 2.065075018644333
Train: epoch: 1, loss = 2.063343780748546
Train: epoch: 1, loss = 2.0615982619804494
Train: epoch: 1, loss = 2.060539369483789
Train: epoch: 1, loss = 2.059680983079107
Train: epoch: 1, loss = 2.05801515892148
Train: epoch: 1, loss = 2.0571417901629494
Train: epoch: 1, loss = 2.0557478670098566
Train: epoch: 1, loss = 2.0559910455993986
Train: epoch: 1, loss = 2.055115526591738
Train: epoch: 1, loss = 2.05434466612339
Train: epoch: 1, loss = 2.0537247799451537
Train: epoch: 1, loss = 2.053367680178748
Train: epoch: 1, loss = 2.052039471907275
Train: epoch: 1, loss = 2.0514900613242184
Train: epoch: 1, loss = 2.0508972546458244
Train: epoch: 1, loss = 2.0498570014584447
Train: epoch: 1, loss = 2.049522118642926
Train: epoch: 1, loss = 2.0490538992484413
Train: epoch: 1, loss = 2.0484969353675844
Train: epoch: 1, loss = 2.0476512672219958
Train: epoch: 1, loss = 2.0477419385645126
Train: epoch: 1, loss = 2.047341824641099
Train: epoch: 1, loss = 2.0469082389850364
Train: epoch: 1, loss = 2.0464236815006305
Train: epoch: 1, loss = 2.045604170680046
Train: epoch: 1, loss = 2.045002899824119
Train: epoch: 1, loss = 2.0447194876557306
Train: epoch: 1, loss = 2.044167063374852
Train:  Epoch 1, Loss=2.0439426275117056, Cohen Kappa=0.3817982009476959, MAD=0.7203182974749341
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0357702127818404, Cohen Kappa=0.40775952996883924, MAD=0.7330605798484864
Eval task: 2
Eval:  Epoch 1, Loss=1.9788448995557324, Cohen Kappa=0.008385163997382206, MAD=0.7380559383660522
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0519841395575424, Cohen Kappa=0.32608186158624763, MAD=0.7333645467379665
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9439215886181798, Cohen Kappa=0.005505908600474174, MAD=0.7354658842061672
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9790719258785248
Train: epoch: 1, loss = 1.98601746737957
Train: epoch: 1, loss = 1.9900448264678319
Train: epoch: 1, loss = 1.9916743764281273
Train: epoch: 1, loss = 1.9910331896543503
Train: epoch: 1, loss = 1.987331740061442
Train: epoch: 1, loss = 1.9863543731825692
Train: epoch: 1, loss = 1.9872684710472823
Train: epoch: 1, loss = 1.9872390171554353
Train: epoch: 1, loss = 1.986445018708706
Train: epoch: 1, loss = 1.9865661252086813
Train: epoch: 1, loss = 1.9871821103990077
Train: epoch: 1, loss = 1.986428221143209
Train: epoch: 1, loss = 1.9863673678466252
Train: epoch: 1, loss = 1.9872616796096165
Train: epoch: 1, loss = 1.987062350027263
Train: epoch: 1, loss = 1.9868033471528221
Train: epoch: 1, loss = 1.9868491168485747
Train: epoch: 1, loss = 1.9868823579424306
Train: epoch: 1, loss = 1.9870781214237214
Train: epoch: 1, loss = 1.987088141923859
Train: epoch: 1, loss = 1.9872156798568639
Train: epoch: 1, loss = 1.9866196715831757
Train: epoch: 1, loss = 1.9868961825221776
Train: epoch: 1, loss = 1.9868159985542297
Train: epoch: 1, loss = 1.9866497873342954
Train: epoch: 1, loss = 1.9864051414419104
Train: epoch: 1, loss = 1.9864516216090746
Train: epoch: 1, loss = 1.9864886489613303
Train: epoch: 1, loss = 1.9867603658835093
Train: epoch: 1, loss = 1.986463325139015
Train: epoch: 1, loss = 1.9865848008729516
Train: epoch: 1, loss = 1.9863531249400341
Train: epoch: 1, loss = 1.9859493713168537
Train: epoch: 1, loss = 1.985946384208543
Train: epoch: 1, loss = 1.9856612069904804
Train: epoch: 1, loss = 1.9858737771253328
Train: epoch: 1, loss = 1.9856673710440333
Train: epoch: 1, loss = 1.9857318731760367
Train: epoch: 1, loss = 1.9854791548848152
Train: epoch: 1, loss = 1.9854953040146246
Train: epoch: 1, loss = 1.9858852805552027
Train: epoch: 1, loss = 1.9857470337318819
Train:  Epoch 1, Loss=1.9859891721452985, Cohen Kappa=0.08856679384101918, MAD=0.685477801768044
-------------
Eval task: 1
Eval:  Epoch 1, Loss=1.9965967679845875, Cohen Kappa=0.42372424871080505, MAD=0.7191193089760833
Eval task: 2
Eval:  Epoch 1, Loss=1.9887521040850673, Cohen Kappa=0.15713775392966423, MAD=0.6634862503008122
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0457831723936675, Cohen Kappa=0.34460875387806766, MAD=0.7223252999266463
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.930059907765224, Cohen Kappa=0.15263965769184717, MAD=0.6688751136775914
{'0': {'precision': 0.4100492362075496, 'recall': 0.7970552147239264, 'f1-score': 0.5415138379459821, 'support': 4075}, '1': {'precision': 0.2730340870739116, 'recall': 0.2823734729493892, 'f1-score': 0.27762525737817434, 'support': 2865}, '2': {'precision': 0.30526315789473685, 'recall': 0.01595159515951595, 'f1-score': 0.03031887088342917, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.12839598064756233, 'recall': 0.2837171052631579, 'f1-score': 0.17678708685626437, 'support': 1216}, '9': {'precision': 0.11759729272419628, 'recall': 0.12954333643988816, 'f1-score': 0.12328159645232817, 'support': 1073}, 'accuracy': 0.30778556034482757, 'macro avg': {'precision': 0.12343397545479565, 'recall': 0.15086407245358777, 'f1-score': 0.11495266495161782, 'support': 14848}, 'weighted avg': {'precision': 0.2216105283961241, 'recall': 0.30778556034482757, 'f1-score': 0.22928604592503954, 'support': 14848}}
{'0': {'precision': 0.4320950965824666, 'recall': 0.3436539825100449, 'f1-score': 0.38283307003686157, 'support': 4231}, '1': {'precision': 0.344568190699492, 'recall': 0.701053468495329, 'f1-score': 0.46204231348660507, 'support': 5031}, '2': {'precision': 0.2247557003257329, 'recall': 0.057119205298013245, 'f1-score': 0.0910891089108911, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.10268562401263823, 'recall': 0.21241830065359477, 'f1-score': 0.13844515441959532, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.34913793103448276, 'macro avg': {'precision': 0.11041046116203294, 'recall': 0.1314244956956982, 'f1-score': 0.1074409646853953, 'support': 14848}, 'weighted avg': {'precision': 0.2785660354245958, 'recall': 0.34913793103448276, 'f1-score': 0.28332011737999596, 'support': 14848}}