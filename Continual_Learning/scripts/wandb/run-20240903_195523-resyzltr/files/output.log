
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_northeast
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.43332351379096506
Train: epoch: 1, loss = 0.42325355295091865
Train: epoch: 1, loss = 0.41913386233150957
Train: epoch: 1, loss = 0.4145079261995852
Train: epoch: 1, loss = 0.4114314478188753
Train: epoch: 1, loss = 0.4088175442690651
Train: epoch: 1, loss = 0.407032020006861
Train: epoch: 1, loss = 0.4052512970287353
Train: epoch: 1, loss = 0.40335988255010713
Train: epoch: 1, loss = 0.40109585597366093
Train: epoch: 1, loss = 0.400216890769926
Train: epoch: 1, loss = 0.3987117764229576
Train: epoch: 1, loss = 0.3973363334227067
Train: epoch: 1, loss = 0.39575180272970883
Train: epoch: 1, loss = 0.3938278043369452
Train: epoch: 1, loss = 0.39293223049491643
Train: epoch: 1, loss = 0.3917424270028577
Train: epoch: 1, loss = 0.3905176072360741
Train:  Epoch 1, Loss=0.3903076811478688, AUC-ROC Macro=0.6648083039710009, AUC-ROC Micro=0.752749064465253
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.37131477023164433, AUC-ROC Macro=0.7189402882147432, AUC-ROC Micro=0.7825122895200055
Eval task: 2
Eval:  Epoch 1, Loss=0.4023442566394806, AUC-ROC Macro=0.48943819309214753, AUC-ROC Micro=0.5799329568357855
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.37490965954959393
Train: epoch: 2, loss = 0.3768824051693082
Train: epoch: 2, loss = 0.3768843380858501
Train: epoch: 2, loss = 0.3732804095372558
Train: epoch: 2, loss = 0.3727522419542074
Train: epoch: 2, loss = 0.37155605679998793
Train: epoch: 2, loss = 0.37114768324153763
Train: epoch: 2, loss = 0.3708983060903847
Train: epoch: 2, loss = 0.37059878495004445
Train: epoch: 2, loss = 0.370124592371285
Train: epoch: 2, loss = 0.3695515883917158
Train: epoch: 2, loss = 0.3689756477996707
Train: epoch: 2, loss = 0.3689821835206105
Train: epoch: 2, loss = 0.3686410187238029
Train: epoch: 2, loss = 0.36826644610365233
Train: epoch: 2, loss = 0.36834974425844846
Train: epoch: 2, loss = 0.3678911988305695
Train: epoch: 2, loss = 0.36796902555144495
Train:  Epoch 2, Loss=0.36797615899387587, AUC-ROC Macro=0.7252934441178421, AUC-ROC Micro=0.7917828011614789
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.36455925678213436, AUC-ROC Macro=0.7359134281553642, AUC-ROC Micro=0.7942543446479463
Eval task: 2
Eval:  Epoch 2, Loss=0.4146966487169266, AUC-ROC Macro=0.4823241888991254, AUC-ROC Micro=0.5990179326205286
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3572006775438786
Train: epoch: 3, loss = 0.3576087515801191
Train: epoch: 3, loss = 0.3610715007036924
Train: epoch: 3, loss = 0.3613146360404789
Train: epoch: 3, loss = 0.3616129236072302
Train: epoch: 3, loss = 0.3617766500388582
Train: epoch: 3, loss = 0.3622200660407543
Train: epoch: 3, loss = 0.360984045388177
Train: epoch: 3, loss = 0.360885497091545
Train: epoch: 3, loss = 0.36091629377752543
Train: epoch: 3, loss = 0.36066053181209345
Train: epoch: 3, loss = 0.36006895602370304
Train: epoch: 3, loss = 0.3606373022439388
Train: epoch: 3, loss = 0.36036477146936313
Train: epoch: 3, loss = 0.36050297115743163
Train: epoch: 3, loss = 0.36017729168292134
Train: epoch: 3, loss = 0.3597978698944344
Train: epoch: 3, loss = 0.3595412512496114
Train:  Epoch 3, Loss=0.3595224207466484, AUC-ROC Macro=0.7451638363021279, AUC-ROC Micro=0.8050348688288855
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.35794639711578685, AUC-ROC Macro=0.7492219272434818, AUC-ROC Micro=0.8042661309026042
Eval task: 2
Eval:  Epoch 3, Loss=0.42115263640880585, AUC-ROC Macro=0.4877325640614169, AUC-ROC Micro=0.5900441763312754
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.356265337690711
Train: epoch: 4, loss = 0.35515879310667514
Train: epoch: 4, loss = 0.3568202566355467
Train: epoch: 4, loss = 0.3562223488651216
Train: epoch: 4, loss = 0.3543531472682953
Train: epoch: 4, loss = 0.3552614170561234
Train: epoch: 4, loss = 0.35460414824741227
Train: epoch: 4, loss = 0.3542915714997798
Train: epoch: 4, loss = 0.35444403030806115
Train: epoch: 4, loss = 0.35430986285209654
Train: epoch: 4, loss = 0.3541218335452405
Train: epoch: 4, loss = 0.3541485428189238
Train: epoch: 4, loss = 0.35388450406491756
Train: epoch: 4, loss = 0.35324185137237823
Train: epoch: 4, loss = 0.35278297017514704
Train: epoch: 4, loss = 0.3532304325280711
Train: epoch: 4, loss = 0.35342420107739814
Train: epoch: 4, loss = 0.3538239953873886
Train:  Epoch 4, Loss=0.3537772332725362, AUC-ROC Macro=0.757906617932289, AUC-ROC Micro=0.81347295175755
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.35484521463513374, AUC-ROC Macro=0.7572699903118124, AUC-ROC Micro=0.8098964139684839
Eval task: 2
Eval:  Epoch 4, Loss=0.4344327598810196, AUC-ROC Macro=0.4876870993366838, AUC-ROC Micro=0.5638561148233715
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.3540885965526104
Train: epoch: 5, loss = 0.3531141483411193
Train: epoch: 5, loss = 0.3508883386602004
Train: epoch: 5, loss = 0.35058839969336986
Train: epoch: 5, loss = 0.3514324449300766
Train: epoch: 5, loss = 0.35151246229807537
Train: epoch: 5, loss = 0.3519647150167397
Train: epoch: 5, loss = 0.35148014224134383
Train: epoch: 5, loss = 0.3516033265988032
Train: epoch: 5, loss = 0.35139903166145087
Train: epoch: 5, loss = 0.35088942375372756
Train: epoch: 5, loss = 0.3506730965524912
Train: epoch: 5, loss = 0.35059849592928705
Train: epoch: 5, loss = 0.3505885446657028
Train: epoch: 5, loss = 0.35012854146957395
Train: epoch: 5, loss = 0.3499155578855425
Train: epoch: 5, loss = 0.34989492574158837
Train: epoch: 5, loss = 0.34961480279349616
Train:  Epoch 5, Loss=0.34970553670174037, AUC-ROC Macro=0.765919329199965, AUC-ROC Micro=0.8192743704619935
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.34968965003887814, AUC-ROC Macro=0.7629707074587028, AUC-ROC Micro=0.8161147009012396
Eval task: 2
Eval:  Epoch 5, Loss=0.44106264412403107, AUC-ROC Macro=0.4800134357266134, AUC-ROC Micro=0.5786939322614313
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.33878641836345197
Train: epoch: 6, loss = 0.3414535168558359
Train: epoch: 6, loss = 0.34382984737555183
Train: epoch: 6, loss = 0.34557083280757067
Train: epoch: 6, loss = 0.3459114971458912
Train: epoch: 6, loss = 0.3460489702721437
Train: epoch: 6, loss = 0.34538647198251315
Train: epoch: 6, loss = 0.3457424825523049
Train: epoch: 6, loss = 0.34589897241029477
Train: epoch: 6, loss = 0.3461372528746724
Train: epoch: 6, loss = 0.34625213201073085
Train: epoch: 6, loss = 0.3458863232471049
Train: epoch: 6, loss = 0.34617386182340293
Train: epoch: 6, loss = 0.34626246305448666
Train: epoch: 6, loss = 0.34641675656537213
Train: epoch: 6, loss = 0.34651086818426846
Train: epoch: 6, loss = 0.3463080882982296
Train: epoch: 6, loss = 0.34602443911135194
Train:  Epoch 6, Loss=0.3460679925456006, AUC-ROC Macro=0.7732405358582362, AUC-ROC Micro=0.824048029989539
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.34863822907209396, AUC-ROC Macro=0.7646320162907795, AUC-ROC Micro=0.8175125261885005
Eval task: 2
Eval:  Epoch 6, Loss=0.457280233502388, AUC-ROC Macro=0.4809164277999489, AUC-ROC Micro=0.5781213118436834
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3512255325913429, AUC-ROC Macro=0.7644493817140894, AUC-ROC Micro=0.8168382100466978
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.4680534154176712, AUC-ROC Macro=0.4816751043865631, AUC-ROC Micro=0.5881276727229854
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.3473606149852276
Train:  Epoch 1, Loss=0.3385461888885232, AUC-ROC Macro=0.5493035275678269, AUC-ROC Micro=0.7161269013058933
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.34740809351205826, AUC-ROC Macro=0.7593644582697513, AUC-ROC Micro=0.8127786975960994
Eval task: 2
Eval:  Epoch 1, Loss=0.33194322884082794, AUC-ROC Macro=0.6195196690374664, AUC-ROC Micro=0.7669105405627181
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.3196615541726351
Train:  Epoch 2, Loss=0.3158671194206887, AUC-ROC Macro=0.6547080659763652, AUC-ROC Micro=0.7934568828799494
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.34441956381003064, AUC-ROC Macro=0.7589210816317079, AUC-ROC Micro=0.8125196447292194
Eval task: 2
Eval:  Epoch 2, Loss=0.32338470220565796, AUC-ROC Macro=0.6719630705501065, AUC-ROC Micro=0.7934827807810078
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.30726913824677465
Train:  Epoch 3, Loss=0.30621456468121944, AUC-ROC Macro=0.7048179282879928, AUC-ROC Micro=0.8190170229203382
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3434024726351102, AUC-ROC Macro=0.7571595024368211, AUC-ROC Micro=0.8113716226992322
Eval task: 2
Eval:  Epoch 3, Loss=0.31328514218330383, AUC-ROC Macro=0.6991404695976737, AUC-ROC Micro=0.812210317224175
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.29954041972756384
Train:  Epoch 4, Loss=0.29958497097967723, AUC-ROC Macro=0.7293480348594997, AUC-ROC Micro=0.8327796184386921
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3404048482577006, AUC-ROC Macro=0.756121318475866, AUC-ROC Micro=0.8107875913773159
Eval task: 2
Eval:  Epoch 4, Loss=0.3089142292737961, AUC-ROC Macro=0.701538827475581, AUC-ROC Micro=0.8149752644258292
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.29410869903862474
Train:  Epoch 5, Loss=0.2940487608084951, AUC-ROC Macro=0.7482269283602662, AUC-ROC Micro=0.8426276000277853
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.33973002433776855, AUC-ROC Macro=0.7524178625222412, AUC-ROC Micro=0.8077570656343273
Eval task: 2
Eval:  Epoch 5, Loss=0.30611515045166016, AUC-ROC Macro=0.7092409547145426, AUC-ROC Micro=0.8224550828344649
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.28946022361516954
Train:  Epoch 6, Loss=0.2887615329135246, AUC-ROC Macro=0.7657209997065223, AUC-ROC Micro=0.8514537798766676
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.33893924951553345, AUC-ROC Macro=0.7518685990355413, AUC-ROC Micro=0.806599239837751
Eval task: 2
Eval:  Epoch 6, Loss=0.30155882239341736, AUC-ROC Macro=0.7118574489897523, AUC-ROC Micro=0.8220499527584387
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3641910043855508, AUC-ROC Macro=0.7510305172050792, AUC-ROC Micro=0.8046052204684911
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.2906518131494522, AUC-ROC Macro=0.6883372942416203, AUC-ROC Micro=0.8170293031154169
{'0': {'precision': 0.5289351851851852, 'recall': 0.34938837920489296, 'f1-score': 0.4208103130755065, 'support': 1308}, '1': {'precision': 0.7100591715976331, 'recall': 0.29850746268656714, 'f1-score': 0.4203152364273204, 'support': 402}, '2': {'precision': 0.5483870967741935, 'recall': 0.025835866261398176, 'f1-score': 0.049346879535558774, 'support': 658}, '3': {'precision': 0.5139949109414759, 'recall': 0.30452261306532663, 'f1-score': 0.38245503313348056, 'support': 1990}, '4': {'precision': 0.43410852713178294, 'recall': 0.13895781637717122, 'f1-score': 0.2105263157894737, 'support': 806}, '5': {'precision': 0.29411764705882354, 'recall': 0.012853470437017995, 'f1-score': 0.024630541871921183, 'support': 778}, '6': {'precision': 0.5098039215686274, 'recall': 0.2196620583717358, 'f1-score': 0.30703166935050996, 'support': 1302}, '7': {'precision': 0.2727272727272727, 'recall': 0.014150943396226415, 'f1-score': 0.026905829596412554, 'support': 424}, '8': {'precision': 0.5022801302931597, 'recall': 0.46897810218978103, 'f1-score': 0.485058194400755, 'support': 1644}, '9': {'precision': 0.66711140760507, 'recall': 0.49236829148202854, 'f1-score': 0.56657223796034, 'support': 2031}, '10': {'precision': 0.6510791366906474, 'recall': 0.3158813263525305, 'f1-score': 0.4253819036427732, 'support': 573}, '11': {'precision': 0.4978902953586498, 'recall': 0.20068027210884354, 'f1-score': 0.28606060606060607, 'support': 1176}, '12': {'precision': 0.6095890410958904, 'recall': 0.2514124293785311, 'f1-score': 0.356, 'support': 1770}, '13': {'precision': 0.56732223903177, 'recall': 0.43335901386748843, 'f1-score': 0.49137366237169683, 'support': 2596}, '14': {'precision': 0.5244922341696535, 'recall': 0.2698217578365089, 'f1-score': 0.35633116883116883, 'support': 1627}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 484}, '16': {'precision': 0.39826839826839827, 'recall': 0.11572327044025157, 'f1-score': 0.1793372319688109, 'support': 795}, '17': {'precision': 0.2982456140350877, 'recall': 0.03125, 'f1-score': 0.056572379367720464, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.3888888888888889, 'recall': 0.05343511450381679, 'f1-score': 0.09395973154362415, 'support': 262}, '20': {'precision': 0.26666666666666666, 'recall': 0.007104795737122558, 'f1-score': 0.013840830449826988, 'support': 563}, '21': {'precision': 0.4878048780487805, 'recall': 0.2867383512544803, 'f1-score': 0.3611738148984199, 'support': 837}, '22': {'precision': 0.6337099811676082, 'recall': 0.6197053406998159, 'f1-score': 0.6266294227188082, 'support': 1086}, '23': {'precision': 0.5851063829787234, 'recall': 0.25551684088269455, 'f1-score': 0.3556992724333064, 'support': 861}, '24': {'precision': 0.5180180180180181, 'recall': 0.22772277227722773, 'f1-score': 0.31636863823933975, 'support': 505}, 'micro avg': {'precision': 0.5549463279017685, 'recall': 0.2832144405470382, 'f1-score': 0.37503261833933516, 'support': 25373}, 'macro avg': {'precision': 0.4563442818120803, 'recall': 0.21574305155245832, 'f1-score': 0.27249523654669516, 'support': 25373}, 'weighted avg': {'precision': 0.5066879529274045, 'recall': 0.2832144405470382, 'f1-score': 0.34608945994529877, 'support': 25373}, 'samples avg': {'precision': 0.3917919663525133, 'recall': 0.24956729856344975, 'f1-score': 0.27953865718381227, 'support': 25373}}
{'0': {'precision': 0.6101694915254238, 'recall': 0.27692307692307694, 'f1-score': 0.380952380952381, 'support': 130}, '1': {'precision': 0.6176470588235294, 'recall': 0.3088235294117647, 'f1-score': 0.4117647058823529, 'support': 136}, '2': {'precision': 0.5306122448979592, 'recall': 0.1897810218978102, 'f1-score': 0.2795698924731183, 'support': 137}, '3': {'precision': 0.6544715447154471, 'recall': 0.755868544600939, 'f1-score': 0.7015250544662309, 'support': 213}, '4': {'precision': 0.35294117647058826, 'recall': 0.08, 'f1-score': 0.13043478260869565, 'support': 75}, '5': {'precision': 0.35714285714285715, 'recall': 0.05319148936170213, 'f1-score': 0.09259259259259259, 'support': 94}, '6': {'precision': 0.75, 'recall': 0.04054054054054054, 'f1-score': 0.07692307692307693, 'support': 74}, '7': {'precision': 0.5, 'recall': 0.075, 'f1-score': 0.13043478260869565, 'support': 40}, '8': {'precision': 0.5, 'recall': 0.04, 'f1-score': 0.07407407407407407, 'support': 75}, '9': {'precision': 1.0, 'recall': 0.015384615384615385, 'f1-score': 0.030303030303030307, 'support': 65}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 63}, '11': {'precision': 0.3333333333333333, 'recall': 0.017857142857142856, 'f1-score': 0.03389830508474576, 'support': 56}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 52}, '13': {'precision': 0.6666666666666666, 'recall': 0.10909090909090909, 'f1-score': 0.1875, 'support': 55}, '14': {'precision': 0.6875, 'recall': 0.1746031746031746, 'f1-score': 0.27848101265822783, 'support': 63}, '15': {'precision': 1.0, 'recall': 0.15789473684210525, 'f1-score': 0.2727272727272727, 'support': 19}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 19}, '17': {'precision': 0.5, 'recall': 0.012195121951219513, 'f1-score': 0.023809523809523808, 'support': 82}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}, 'micro avg': {'precision': 0.6123260437375746, 'recall': 0.2003903708523097, 'f1-score': 0.3019607843137255, 'support': 1537}, 'macro avg': {'precision': 0.3624193749430322, 'recall': 0.0922861561386, 'f1-score': 0.12419961948656073, 'support': 1537}, 'weighted avg': {'precision': 0.5023462593453297, 'recall': 0.2003903708523097, 'f1-score': 0.23881606592817897, 'support': 1537}, 'samples avg': {'precision': 0.36988932291666665, 'recall': 0.18185841393849206, 'f1-score': 0.22575418288308913, 'support': 1537}}