
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south_baseline
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.17022200524807
Train: epoch: 1, loss = 2.1437701272964476
Train: epoch: 1, loss = 2.1203839431206384
Train: epoch: 1, loss = 2.111027192771435
Train: epoch: 1, loss = 2.098574599981308
Train: epoch: 1, loss = 2.0905795632799467
Train: epoch: 1, loss = 2.0827763701336726
Train: epoch: 1, loss = 2.079746772199869
Train: epoch: 1, loss = 2.074342672427495
Train: epoch: 1, loss = 2.0709491360783576
Train: epoch: 1, loss = 2.0687805249474267
Train: epoch: 1, loss = 2.06609237541755
Train: epoch: 1, loss = 2.0653555223116506
Train: epoch: 1, loss = 2.0632790509717807
Train: epoch: 1, loss = 2.060345405737559
Train: epoch: 1, loss = 2.0591323426365853
Train: epoch: 1, loss = 2.05881220211001
Train: epoch: 1, loss = 2.058471167120669
Train: epoch: 1, loss = 2.057381670443635
Train: epoch: 1, loss = 2.0553152434527875
Train: epoch: 1, loss = 2.054974494406155
Train: epoch: 1, loss = 2.053767156167464
Train: epoch: 1, loss = 2.0529739848168
Train: epoch: 1, loss = 2.051735120018323
Train: epoch: 1, loss = 2.050919755148888
Train: epoch: 1, loss = 2.050463179923021
Train: epoch: 1, loss = 2.0502063502868015
Train: epoch: 1, loss = 2.0503845520317556
Train: epoch: 1, loss = 2.0498552584237064
Train: epoch: 1, loss = 2.0486085811456043
Train: epoch: 1, loss = 2.0481386126818197
Train: epoch: 1, loss = 2.0475782783143224
Train: epoch: 1, loss = 2.0472106060837256
Train: epoch: 1, loss = 2.0467149560591755
Train: epoch: 1, loss = 2.0460187452180043
Train: epoch: 1, loss = 2.0452431667844455
Train: epoch: 1, loss = 2.0450070893281214
Train: epoch: 1, loss = 2.044325757120785
Train: epoch: 1, loss = 2.044137524381662
Train: epoch: 1, loss = 2.0437330543249845
Train: epoch: 1, loss = 2.0432352568172827
Train: epoch: 1, loss = 2.0431524423900105
Train: epoch: 1, loss = 2.0421824101514594
Train:  Epoch 1, Loss=2.0419096798079353, Cohen Kappa=0.3830763487770754, MAD=0.7193721384291166
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0280095523801345, Cohen Kappa=0.4413456647825875, MAD=0.6969253579011976
Eval task: 2
Eval:  Epoch 1, Loss=1.9205848286891807, Cohen Kappa=-0.00023338893757229862, MAD=0.7269972761428968
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0565654779302665, Cohen Kappa=0.3456055935331157, MAD=0.6870230670286448
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9116116145561481, Cohen Kappa=0.0014358699843367573, MAD=0.7272891954379386
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.91150828063488
Train: epoch: 1, loss = 1.9085103112459183
Train: epoch: 1, loss = 1.9121511157353719
Train: epoch: 1, loss = 1.9100711171329021
Train: epoch: 1, loss = 1.9082269656658173
Train: epoch: 1, loss = 1.9096666638056436
Train: epoch: 1, loss = 1.9108318965775626
Train: epoch: 1, loss = 1.910273435562849
Train: epoch: 1, loss = 1.909207577639156
Train: epoch: 1, loss = 1.907337109208107
Train: epoch: 1, loss = 1.9074533612619746
Train: epoch: 1, loss = 1.9074816597998143
Train: epoch: 1, loss = 1.9078182858228683
Train: epoch: 1, loss = 1.9080192004782812
Train: epoch: 1, loss = 1.9079597183863322
Train: epoch: 1, loss = 1.9076882921159268
Train: epoch: 1, loss = 1.9072310086909463
Train: epoch: 1, loss = 1.9070329950253169
Train: epoch: 1, loss = 1.9069380252298556
Train: epoch: 1, loss = 1.9067556372284888
Train: epoch: 1, loss = 1.906650618485042
Train: epoch: 1, loss = 1.9070736235109242
Train: epoch: 1, loss = 1.9066916880400284
Train: epoch: 1, loss = 1.9061853243907292
Train: epoch: 1, loss = 1.9059139236450195
Train: epoch: 1, loss = 1.9059931524212543
Train: epoch: 1, loss = 1.9059779428773456
Train: epoch: 1, loss = 1.906016719618014
Train: epoch: 1, loss = 1.9059639263153076
Train: epoch: 1, loss = 1.9058723157842954
Train: epoch: 1, loss = 1.9055639392137527
Train: epoch: 1, loss = 1.9050134230963887
Train: epoch: 1, loss = 1.9046543857003704
Train: epoch: 1, loss = 1.904186293430188
Train: epoch: 1, loss = 1.9041886759996414
Train: epoch: 1, loss = 1.9042580196592542
Train: epoch: 1, loss = 1.9044291960387616
Train: epoch: 1, loss = 1.904325198907601
Train: epoch: 1, loss = 1.9042503136090743
Train: epoch: 1, loss = 1.904330473870039
Train: epoch: 1, loss = 1.904353214734938
Train: epoch: 1, loss = 1.9043354344793728
Train: epoch: 1, loss = 1.9040634243017018
Train:  Epoch 1, Loss=1.9041060135023935, Cohen Kappa=0.13765942609718795, MAD=0.6933577008979763
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.1741777082969405, Cohen Kappa=0.04016376323858939, MAD=0.6810907989287583
Eval task: 2
Eval:  Epoch 1, Loss=1.9062280696013878, Cohen Kappa=0.07451566905434148, MAD=0.6936058506110532
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.115333651674205, Cohen Kappa=0.05112225725263109, MAD=0.690552021591994
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.894996347098515, Cohen Kappa=0.07132237210362258, MAD=0.6927774277759837
{'0': {'precision': 0.4415139923495067, 'recall': 0.538159509202454, 'f1-score': 0.4850696748506968, 'support': 4075}, '1': {'precision': 0.16774979691307879, 'recall': 0.5766143106457242, 'f1-score': 0.2598914496971604, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.25895743534482757, 'macro avg': {'precision': 0.06092637892625855, 'recall': 0.11147738198481782, 'f1-score': 0.07449611245478571, 'support': 14848}, 'weighted avg': {'precision': 0.1535407251468353, 'recall': 0.25895743534482757, 'f1-score': 0.18327370207428298, 'support': 14848}}
{'0': {'precision': 0.3633440514469453, 'recall': 0.3815848716794237, 'f1-score': 0.3722411331942462, 'support': 4442}, '1': {'precision': 0.33984647592463363, 'recall': 0.6624562767197824, 'f1-score': 0.4492323911181393, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.3142857142857143, 'recall': 0.008455034588777863, 'f1-score': 0.01646706586826347, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 176}, '9': {'precision': 0.17094017094017094, 'recall': 0.17857142857142858, 'f1-score': 0.17467248908296945, 'support': 112}, 'accuracy': 0.34583782327586204, 'macro avg': {'precision': 0.11884164125974642, 'recall': 0.12310676115594126, 'f1-score': 0.10126130792636183, 'support': 14848}, 'weighted avg': {'precision': 0.2553108334500612, 'recall': 0.34583782327586204, 'f1-score': 0.26981626951876947, 'support': 14848}}