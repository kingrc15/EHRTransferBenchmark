
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_northeast_baseline
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
northeast_val.csv
test_listfile.csv
northeast_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1873204159736632
Train: epoch: 1, loss = 2.1411242428421975
Train: epoch: 1, loss = 2.120239315231641
Train: epoch: 1, loss = 2.103100129812956
Train: epoch: 1, loss = 2.0914290496110914
Train: epoch: 1, loss = 2.086158721148968
Train: epoch: 1, loss = 2.07994876742363
Train: epoch: 1, loss = 2.074628100916743
Train: epoch: 1, loss = 2.071270860301124
Train: epoch: 1, loss = 2.068791019320488
Train: epoch: 1, loss = 2.066941437125206
Train: epoch: 1, loss = 2.064759610891342
Train: epoch: 1, loss = 2.064442360309454
Train: epoch: 1, loss = 2.062535669037274
Train: epoch: 1, loss = 2.0595762132406237
Train: epoch: 1, loss = 2.0590793957188724
Train: epoch: 1, loss = 2.058165632451282
Train: epoch: 1, loss = 2.057495630019241
Train: epoch: 1, loss = 2.0581308497880633
Train: epoch: 1, loss = 2.0572327741980554
Train: epoch: 1, loss = 2.055358557956559
Train: epoch: 1, loss = 2.05471056423404
Train: epoch: 1, loss = 2.0548354392207187
Train: epoch: 1, loss = 2.0541803858677548
Train: epoch: 1, loss = 2.05301565823555
Train: epoch: 1, loss = 2.053079948471143
Train: epoch: 1, loss = 2.051867107969743
Train: epoch: 1, loss = 2.050865072671856
Train: epoch: 1, loss = 2.0501267088076163
Train: epoch: 1, loss = 2.049557285606861
Train: epoch: 1, loss = 2.049067673913894
Train: epoch: 1, loss = 2.04831506120041
Train: epoch: 1, loss = 2.047578072909153
Train: epoch: 1, loss = 2.047325902440969
Train: epoch: 1, loss = 2.046474552512169
Train: epoch: 1, loss = 2.046049064149459
Train: epoch: 1, loss = 2.0456633283157606
Train: epoch: 1, loss = 2.0456540544723207
Train: epoch: 1, loss = 2.0456330205996833
Train: epoch: 1, loss = 2.0456764290332794
Train: epoch: 1, loss = 2.045358135656613
Train: epoch: 1, loss = 2.045373698331061
Train: epoch: 1, loss = 2.0449549605125603
Train:  Epoch 1, Loss=2.045138339465005, Cohen Kappa=0.3808330947883003, MAD=0.7224800374912934
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0446581861068465, Cohen Kappa=0.39903345415432145, MAD=0.7064896494194467
Eval task: 2
Eval:  Epoch 1, Loss=1.888752179486411, Cohen Kappa=0.026821490086496036, MAD=0.624027395206887
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0573720582600297, Cohen Kappa=0.32343907014804196, MAD=0.7021898018146375
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.904849682535444, Cohen Kappa=0.027197062721398435, MAD=0.6227600306282001
northeast_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.8715125739574432
Train: epoch: 1, loss = 1.8670977744460107
Train: epoch: 1, loss = 1.8621335844198863
Train: epoch: 1, loss = 1.8605368861556053
Train: epoch: 1, loss = 1.8581842341423034
Train: epoch: 1, loss = 1.8574496591091156
Train: epoch: 1, loss = 1.8568163675921303
Train: epoch: 1, loss = 1.8561912374943494
Train: epoch: 1, loss = 1.8567584567599826
Train: epoch: 1, loss = 1.8565935910344125
Train:  Epoch 1, Loss=1.8568134991237095, Cohen Kappa=0.012316997250532702, MAD=0.5863761418352162
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0949357501391708, Cohen Kappa=0.16099929553925818, MAD=0.7210478649142786
Eval task: 2
Eval:  Epoch 1, Loss=1.8662317906107222, Cohen Kappa=0.0001728342903232205, MAD=0.5733478516844193
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0847147805937407, Cohen Kappa=0.06923933072356603, MAD=0.7152912738254547
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8775173340524947, Cohen Kappa=0.0003868534200992535, MAD=0.5745208003602674
{'0': {'precision': 0.2457831325301205, 'recall': 0.025030674846625765, 'f1-score': 0.04543429844097995, 'support': 4075}, '1': {'precision': 0.20181620050853613, 'recall': 0.9696335078534032, 'f1-score': 0.3340950090198437, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.3076923076923077, 'recall': 0.10526315789473684, 'f1-score': 0.1568627450980392, 'support': 1216}, '9': {'precision': 0.16334661354581673, 'recall': 0.03821062441752097, 'f1-score': 0.061933534743202415, 'support': 1073}, 'accuracy': 0.20534752155172414, 'macro avg': {'precision': 0.0918638254276781, 'recall': 0.11381379650122866, 'f1-score': 0.05983255873020652, 'support': 14848}, 'weighted avg': {'precision': 0.14339941015663418, 'recall': 0.20534752155172414, 'f1-score': 0.0942569199762606, 'support': 14848}}
{'0': {'precision': 0.3076923076923077, 'recall': 0.007889546351084813, 'f1-score': 0.015384615384615387, 'support': 1014}, '1': {'precision': 0.35975267003934797, 'recall': 0.9945609945609946, 'f1-score': 0.5283797729618163, 'support': 1287}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 689}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 337}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 161}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 54}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 22}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 8}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'micro avg': {'precision': 0.359375, 'recall': 0.359375, 'f1-score': 0.359375, 'support': 3584}, 'macro avg': {'precision': 0.06674449777316557, 'recall': 0.10024505409120794, 'f1-score': 0.05437643883464317, 'support': 3584}, 'weighted avg': {'precision': 0.2162393098048663, 'recall': 0.359375, 'f1-score': 0.19409173208757186, 'support': 3584}}