
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
south_val.csv
test_listfile.csv
south_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.151443145275116
Train: epoch: 1, loss = 2.1190415316820146
Train: epoch: 1, loss = 2.099815360705058
Train: epoch: 1, loss = 2.085942339301109
Train: epoch: 1, loss = 2.080234646677971
Train: epoch: 1, loss = 2.075871913830439
Train: epoch: 1, loss = 2.0690725380182267
Train: epoch: 1, loss = 2.067374246492982
Train: epoch: 1, loss = 2.065478227602111
Train: epoch: 1, loss = 2.065108640253544
Train: epoch: 1, loss = 2.064129100983793
Train: epoch: 1, loss = 2.0609972424805165
Train: epoch: 1, loss = 2.0581462968771276
Train: epoch: 1, loss = 2.056142854179655
Train: epoch: 1, loss = 2.055922549764315
Train: epoch: 1, loss = 2.0547701358050108
Train: epoch: 1, loss = 2.0543629215745365
Train: epoch: 1, loss = 2.0530080603228673
Train: epoch: 1, loss = 2.052766886290751
Train: epoch: 1, loss = 2.0514454950988292
Train: epoch: 1, loss = 2.050774954074905
Train: epoch: 1, loss = 2.0507358426668425
Train: epoch: 1, loss = 2.05066317534965
Train: epoch: 1, loss = 2.050419581805666
Train: epoch: 1, loss = 2.0499023448228835
Train: epoch: 1, loss = 2.04870418294118
Train: epoch: 1, loss = 2.048179930095319
Train: epoch: 1, loss = 2.047545615966831
Train: epoch: 1, loss = 2.04780178203665
Train: epoch: 1, loss = 2.046920502483845
Train: epoch: 1, loss = 2.046694074542292
Train: epoch: 1, loss = 2.0466903445124625
Train: epoch: 1, loss = 2.0462885107054856
Train: epoch: 1, loss = 2.046133120708606
Train: epoch: 1, loss = 2.0459365554366795
Train: epoch: 1, loss = 2.0459613550537163
Train: epoch: 1, loss = 2.045371979297818
Train: epoch: 1, loss = 2.0445711301031864
Train: epoch: 1, loss = 2.0445417686761953
Train: epoch: 1, loss = 2.044043875172734
Train: epoch: 1, loss = 2.043651300683254
Train: epoch: 1, loss = 2.043070158859094
Train: epoch: 1, loss = 2.04287778943084
Train:  Epoch 1, Loss=2.042658656542642, Cohen Kappa=0.39365118603309346, MAD=0.7168842151507926
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.030345620780156, Cohen Kappa=0.42442375568418433, MAD=0.7323309434705171
Eval task: 2
Eval:  Epoch 1, Loss=1.9201086101860836, Cohen Kappa=0.003926470888499511, MAD=0.732331618637658
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0506158758854043, Cohen Kappa=0.3314483150788843, MAD=0.7328115870604675
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9110900040330558, Cohen Kappa=0.00639687302993075, MAD=0.7320600312780665
south_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9523133063316345
Train: epoch: 1, loss = 1.9487378761172294
Train: epoch: 1, loss = 1.9459507409731547
Train: epoch: 1, loss = 1.9439662712812424
Train: epoch: 1, loss = 1.94557166492939
Train: epoch: 1, loss = 1.9463221347332
Train: epoch: 1, loss = 1.9439261115448816
Train: epoch: 1, loss = 1.945044782757759
Train: epoch: 1, loss = 1.9445911718739404
Train: epoch: 1, loss = 1.9440196543335915
Train: epoch: 1, loss = 1.9436744067885658
Train: epoch: 1, loss = 1.9436063350737094
Train: epoch: 1, loss = 1.9438797141038455
Train: epoch: 1, loss = 1.9433534153870173
Train: epoch: 1, loss = 1.9440700366894403
Train: epoch: 1, loss = 1.9445860344916581
Train: epoch: 1, loss = 1.9433650785684586
Train: epoch: 1, loss = 1.9425155079695913
Train: epoch: 1, loss = 1.9422438126175028
Train: epoch: 1, loss = 1.941755682528019
Train: epoch: 1, loss = 1.941275328965414
Train: epoch: 1, loss = 1.9408552458069541
Train: epoch: 1, loss = 1.940408862336822
Train: epoch: 1, loss = 1.9405875314275425
Train: epoch: 1, loss = 1.9403189698934555
Train: epoch: 1, loss = 1.9396019979623649
Train: epoch: 1, loss = 1.939971919435042
Train: epoch: 1, loss = 1.9399557925334998
Train: epoch: 1, loss = 1.9399537575244903
Train: epoch: 1, loss = 1.9398771186669668
Train: epoch: 1, loss = 1.9394910769885587
Train: epoch: 1, loss = 1.9389752882905305
Train: epoch: 1, loss = 1.938851883032105
Train: epoch: 1, loss = 1.9384942822421298
Train: epoch: 1, loss = 1.9382727088247027
Train: epoch: 1, loss = 1.9373786735534668
Train: epoch: 1, loss = 1.9367645498707489
Train: epoch: 1, loss = 1.9356596768529792
Train: epoch: 1, loss = 1.9348289810999846
Train: epoch: 1, loss = 1.934007042080164
Train: epoch: 1, loss = 1.93333630521123
Train: epoch: 1, loss = 1.9328072336032278
Train: epoch: 1, loss = 1.9322965322123018
Train:  Epoch 1, Loss=1.9319447028160095, Cohen Kappa=0.11509075708047145, MAD=0.6937519584369183
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.029678019984015, Cohen Kappa=0.40778965114438803, MAD=0.7505291545413821
Eval task: 2
Eval:  Epoch 1, Loss=1.9217610955238342, Cohen Kappa=0.15883990645647994, MAD=0.6948358949726475
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0646816759273925, Cohen Kappa=0.3108653923996493, MAD=0.7487228223335107
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.898563091097207, Cohen Kappa=0.09338753604279704, MAD=0.6942701288774088
{'0': {'precision': 0.3964757709251101, 'recall': 0.8171779141104294, 'f1-score': 0.5339105339105338, 'support': 4075}, '1': {'precision': 0.23249783923941228, 'recall': 0.18778359511343803, 'f1-score': 0.20776211623865612, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.20702634880803011, 'recall': 0.1356907894736842, 'f1-score': 0.16393442622950818, 'support': 1216}, '9': {'precision': 0.10934691431995207, 'recall': 0.3401677539608574, 'f1-score': 0.16549535252777148, 'support': 1073}, 'accuracy': 0.29620150862068967, 'macro avg': {'precision': 0.09453468732925044, 'recall': 0.14808200526584092, 'f1-score': 0.10711024289064697, 'support': 14848}, 'weighted avg': {'precision': 0.1785303310315607, 'recall': 0.29620150862068967, 'f1-score': 0.2120046244791592, 'support': 14848}}
{'0': {'precision': 0.3461289905648184, 'recall': 0.6028815848716794, 'f1-score': 0.4397733804089005, 'support': 4442}, '1': {'precision': 0.34593960715332744, 'recall': 0.45860862806062963, 'f1-score': 0.3943850267379679, 'support': 5146}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.09, 'recall': 0.05113636363636364, 'f1-score': 0.06521739130434782, 'support': 176}, '9': {'precision': 0.10582010582010581, 'recall': 0.17857142857142858, 'f1-score': 0.13289036544850497, 'support': 112}, 'accuracy': 0.3412580818965517, 'macro avg': {'precision': 0.08878887035382516, 'recall': 0.12911980051401012, 'f1-score': 0.10322661638997213, 'support': 14848}, 'weighted avg': {'precision': 0.22530994385451228, 'recall': 0.3412580818965517, 'f1-score': 0.2700256388180035, 'support': 14848}}