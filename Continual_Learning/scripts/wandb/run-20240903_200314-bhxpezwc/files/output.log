
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_west
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
west_val.csv
test_listfile.csv
west_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1781347006559373
Train: epoch: 1, loss = 2.1451252886652945
Train: epoch: 1, loss = 2.1156880301237107
Train: epoch: 1, loss = 2.0950887005031107
Train: epoch: 1, loss = 2.08482107257843
Train: epoch: 1, loss = 2.07854923615853
Train: epoch: 1, loss = 2.074352645959173
Train: epoch: 1, loss = 2.072556244134903
Train: epoch: 1, loss = 2.0684770544370017
Train: epoch: 1, loss = 2.0672326880693435
Train: epoch: 1, loss = 2.0643835984576833
Train: epoch: 1, loss = 2.0627966379622618
Train: epoch: 1, loss = 2.061452361345291
Train: epoch: 1, loss = 2.06016934633255
Train: epoch: 1, loss = 2.0594231249491375
Train: epoch: 1, loss = 2.0583829597011207
Train: epoch: 1, loss = 2.056659454247531
Train: epoch: 1, loss = 2.056131330695417
Train: epoch: 1, loss = 2.05611049956397
Train: epoch: 1, loss = 2.0557178330123422
Train: epoch: 1, loss = 2.0546915990681875
Train: epoch: 1, loss = 2.0541879762302746
Train: epoch: 1, loss = 2.0539094281196593
Train: epoch: 1, loss = 2.053276269758741
Train: epoch: 1, loss = 2.05245515294075
Train: epoch: 1, loss = 2.0520748856205207
Train: epoch: 1, loss = 2.0516572501482786
Train: epoch: 1, loss = 2.050869216216462
Train: epoch: 1, loss = 2.050271263225325
Train: epoch: 1, loss = 2.0495768149495124
Train: epoch: 1, loss = 2.049439259056122
Train: epoch: 1, loss = 2.049661382269114
Train: epoch: 1, loss = 2.0491533491466987
Train: epoch: 1, loss = 2.0486517384473015
Train: epoch: 1, loss = 2.048124917302813
Train: epoch: 1, loss = 2.047147353125943
Train: epoch: 1, loss = 2.046472032923956
Train: epoch: 1, loss = 2.0460534443510205
Train: epoch: 1, loss = 2.0462567484990144
Train: epoch: 1, loss = 2.046287798985839
Train: epoch: 1, loss = 2.046484303285436
Train: epoch: 1, loss = 2.045846633386044
Train: epoch: 1, loss = 2.045863377257835
Train:  Epoch 1, Loss=2.045728276007516, Cohen Kappa=0.3842188147821066, MAD=0.7216324799094151
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.032729013212796, Cohen Kappa=0.419171681336011, MAD=0.710870351613823
Eval task: 2
Eval:  Epoch 1, Loss=1.879286161784468, Cohen Kappa=-0.00015654912637130813, MAD=0.7466123170654295
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.062319239665722, Cohen Kappa=0.30174118263671845, MAD=0.7093503602334019
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8950135707855225, Cohen Kappa=-0.0010213415449835672, MAD=0.7469215048486392
west_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9516546607017518
Train: epoch: 1, loss = 1.9518442630767823
Train: epoch: 1, loss = 1.9501425065596898
Train: epoch: 1, loss = 1.951809288263321
Train: epoch: 1, loss = 1.953553404569626
Train: epoch: 1, loss = 1.9538048520684241
Train: epoch: 1, loss = 1.955432345696858
Train: epoch: 1, loss = 1.9551234053075313
Train: epoch: 1, loss = 1.9558638597197002
Train: epoch: 1, loss = 1.954906122624874
Train: epoch: 1, loss = 1.9549719721620733
Train: epoch: 1, loss = 1.9549173082411289
Train: epoch: 1, loss = 1.9548303867761905
Train: epoch: 1, loss = 1.954596698326724
Train: epoch: 1, loss = 1.9544584712584814
Train: epoch: 1, loss = 1.9551124159991742
Train: epoch: 1, loss = 1.9549001493874718
Train: epoch: 1, loss = 1.952964546084404
Train: epoch: 1, loss = 1.9493390516544644
Train: epoch: 1, loss = 1.9457661351561546
Train: epoch: 1, loss = 1.942338476493245
Train:  Epoch 1, Loss=1.9398321639469691, Cohen Kappa=0.0004986740112206123, MAD=0.727576520651682
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0395726479333023, Cohen Kappa=0.35462252825515816, MAD=0.7340939093905419
Eval task: 2
Eval:  Epoch 1, Loss=1.9466973255420554, Cohen Kappa=0.0014993747149114611, MAD=0.7312715422481898
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0599651172243316, Cohen Kappa=0.22642073611580893, MAD=0.7315298253845993
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8842222197302456, Cohen Kappa=-0.00040639524258745396, MAD=0.7307210253466264
{'0': {'precision': 0.41837944664031623, 'recall': 0.5195092024539877, 'f1-score': 0.4634920634920635, 'support': 4075}, '1': {'precision': 0.21155165317601865, 'recall': 0.5382198952879581, 'f1-score': 0.3037226708686232, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.08641975308641975, 'recall': 0.017269736842105265, 'f1-score': 0.028786840301576425, 'support': 1216}, '9': {'precision': 0.14627659574468085, 'recall': 0.30754892823858343, 'f1-score': 0.19825773505557226, 'support': 1073}, 'accuracy': 0.2700700431034483, 'macro avg': {'precision': 0.08626274486474356, 'recall': 0.13825477628226346, 'f1-score': 0.09942593097178354, 'support': 14848}, 'weighted avg': {'precision': 0.17329155026910772, 'recall': 0.2700700431034483, 'f1-score': 0.20249400311759902, 'support': 14848}}
{'0': {'precision': 0.3334729201563372, 'recall': 0.9640839386602098, 'f1-score': 0.49554034432690314, 'support': 2478}, '1': {'precision': 0.38846153846153847, 'recall': 0.03892100192678227, 'f1-score': 0.07075306479859894, 'support': 2595}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1084}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 501}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 215}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 121}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 103}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 153}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 102}, 'accuracy': 0.3353987068965517, 'macro avg': {'precision': 0.07219344586178758, 'recall': 0.1003004940586992, 'f1-score': 0.05662934091255021, 'support': 7424}, 'weighted avg': {'precision': 0.24709100060009376, 'recall': 0.3353987068965517, 'f1-score': 0.19013377914795665, 'support': 7424}}