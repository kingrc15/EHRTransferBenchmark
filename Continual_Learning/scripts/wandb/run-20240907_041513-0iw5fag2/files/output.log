
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1650306224822997
Train: epoch: 1, loss = 2.1279699739813807
Train: epoch: 1, loss = 2.106239259640376
Train: epoch: 1, loss = 2.0937788134813307
Train: epoch: 1, loss = 2.08712484562397
Train: epoch: 1, loss = 2.090914894739787
Train: epoch: 1, loss = 2.087760809659958
Train: epoch: 1, loss = 2.082227068170905
Train: epoch: 1, loss = 2.0779729756381777
Train: epoch: 1, loss = 2.075928209245205
Train: epoch: 1, loss = 2.0751934337074105
Train: epoch: 1, loss = 2.0726992526153722
Train: epoch: 1, loss = 2.0705236774224502
Train: epoch: 1, loss = 2.069358223761831
Train: epoch: 1, loss = 2.067786343415578
Train: epoch: 1, loss = 2.066720237582922
Train: epoch: 1, loss = 2.0657353556156157
Train: epoch: 1, loss = 2.064452384048038
Train: epoch: 1, loss = 2.0629197543232065
Train: epoch: 1, loss = 2.0615668942034246
Train: epoch: 1, loss = 2.060290195771626
Train: epoch: 1, loss = 2.0603588290918955
Train: epoch: 1, loss = 2.0605476718622704
Train: epoch: 1, loss = 2.0595604728658996
Train: epoch: 1, loss = 2.0582818537950516
Train: epoch: 1, loss = 2.057448980005888
Train: epoch: 1, loss = 2.0566443683482984
Train: epoch: 1, loss = 2.0561012804295333
Train: epoch: 1, loss = 2.0551033668065894
Train: epoch: 1, loss = 2.054607303460439
Train: epoch: 1, loss = 2.0544130080169247
Train: epoch: 1, loss = 2.053424198124558
Train: epoch: 1, loss = 2.0525860760248067
Train: epoch: 1, loss = 2.052083805974792
Train: epoch: 1, loss = 2.0518767825535367
Train: epoch: 1, loss = 2.0509179031021065
Train: epoch: 1, loss = 2.050428582445995
Train: epoch: 1, loss = 2.049638559818268
Train: epoch: 1, loss = 2.048513256143301
Train: epoch: 1, loss = 2.0482126515060664
Train: epoch: 1, loss = 2.0480634350311466
Train: epoch: 1, loss = 2.0474586496750513
Train: epoch: 1, loss = 2.046901922447737
Train:  Epoch 1, Loss=2.0465665645326885, Cohen Kappa=0.37525227665691685, MAD=0.71769531332158
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0288835455631387, Cohen Kappa=0.42883235709768, MAD=0.7284853737931792
Eval task: 2
Eval:  Epoch 1, Loss=1.9251285935270375, Cohen Kappa=0.0008921052684096598, MAD=0.7525388425832865
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0577187476486993, Cohen Kappa=0.32032506045964015, MAD=0.7274607248542249
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9182999175170372, Cohen Kappa=0.0004916380862800551, MAD=0.7531786572104229
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9480665677785873
Train: epoch: 1, loss = 1.9448701241612434
Train: epoch: 1, loss = 1.9451300795873006
Train: epoch: 1, loss = 1.9441193613409995
Train: epoch: 1, loss = 1.9446720957756043
Train: epoch: 1, loss = 1.9442601893345515
Train: epoch: 1, loss = 1.9437546471187046
Train: epoch: 1, loss = 1.9448673415184021
Train: epoch: 1, loss = 1.9433703119887247
Train: epoch: 1, loss = 1.9435423402190208
Train: epoch: 1, loss = 1.9426505543427033
Train: epoch: 1, loss = 1.9426505555709204
Train: epoch: 1, loss = 1.9438281048719699
Train: epoch: 1, loss = 1.9431072526744433
Train: epoch: 1, loss = 1.942983998854955
Train: epoch: 1, loss = 1.9419840801879764
Train: epoch: 1, loss = 1.9420322709574418
Train: epoch: 1, loss = 1.9427435186505317
Train: epoch: 1, loss = 1.9419614693679308
Train: epoch: 1, loss = 1.9418010762631892
Train: epoch: 1, loss = 1.9418758947792507
Train: epoch: 1, loss = 1.941989119269631
Train: epoch: 1, loss = 1.9412875396531561
Train: epoch: 1, loss = 1.941442619735996
Train: epoch: 1, loss = 1.9410435425281525
Train: epoch: 1, loss = 1.940681668290725
Train: epoch: 1, loss = 1.9407332273765847
Train: epoch: 1, loss = 1.9404871740298613
Train: epoch: 1, loss = 1.9403649757031736
Train: epoch: 1, loss = 1.9403100997209548
Train: epoch: 1, loss = 1.9402576353857595
Train: epoch: 1, loss = 1.9397306084632873
Train: epoch: 1, loss = 1.9402261395346034
Train: epoch: 1, loss = 1.939736647044911
Train: epoch: 1, loss = 1.9395039205551148
Train: epoch: 1, loss = 1.9384105518129138
Train: epoch: 1, loss = 1.9375079259679124
Train: epoch: 1, loss = 1.9368232783675194
Train: epoch: 1, loss = 1.9364989595688307
Train: epoch: 1, loss = 1.9361269744038583
Train: epoch: 1, loss = 1.9351378001817843
Train: epoch: 1, loss = 1.9347805332711765
Train: epoch: 1, loss = 1.9341123902243238
Train:  Epoch 1, Loss=1.9335788790021624, Cohen Kappa=0.08544190764474213, MAD=0.6953894090055931
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0332703693159697, Cohen Kappa=0.4328841407215497, MAD=0.7252421092445412
Eval task: 2
Eval:  Epoch 1, Loss=1.9434019964316795, Cohen Kappa=0.17067331499554983, MAD=0.6949280033464033
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.066912702445326, Cohen Kappa=0.3415698792447641, MAD=0.7252020063366944
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8980988407957142, Cohen Kappa=0.07573203836183884, MAD=0.6955621364394113
{'0': {'precision': 0.4514340805013256, 'recall': 0.4596319018404908, 'f1-score': 0.45549610894941633, 'support': 4075}, '1': {'precision': 0.2494996664442962, 'recall': 0.5221640488656195, 'f1-score': 0.3376594063875409, 'support': 2865}, '2': {'precision': 0.3333333333333333, 'recall': 0.0022002200220022, 'f1-score': 0.004371584699453551, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.12077789150460594, 'recall': 0.2911184210526316, 'f1-score': 0.17072582589823967, 'support': 1216}, '9': {'precision': 0.08522727272727272, 'recall': 0.13979496738117428, 'f1-score': 0.10589481115425342, 'support': 1073}, 'accuracy': 0.26111260775862066, 'macro avg': {'precision': 0.12402722445108336, 'recall': 0.14149095591619182, 'f1-score': 0.10741477370889038, 'support': 14848}, 'weighted avg': {'precision': 0.22890121242670897, 'recall': 0.26111260775862066, 'f1-score': 0.21233271288480304, 'support': 14848}}
{'0': {'precision': 0.36016628873771733, 'recall': 0.4290859972985142, 'f1-score': 0.39161701253338815, 'support': 4442}, '1': {'precision': 0.33743257820927725, 'recall': 0.6078507578701905, 'f1-score': 0.4339622641509434, 'support': 5146}, '2': {'precision': 0.06451612903225806, 'recall': 0.0007874015748031496, 'f1-score': 0.0015558148580318944, 'support': 2540}, '3': {'precision': 0.3333333333333333, 'recall': 0.0030745580322828594, 'f1-score': 0.006092916984006093, 'support': 1301}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.0761904761904762, 'recall': 0.09090909090909091, 'f1-score': 0.08290155440414508, 'support': 176}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'accuracy': 0.34051724137931033, 'macro avg': {'precision': 0.1171638805503062, 'recall': 0.11317078056848814, 'f1-score': 0.09161295629305145, 'support': 14848}, 'weighted avg': {'precision': 0.2658427977004315, 'recall': 0.3405172413793104, 'f1-score': 0.2693428010038246, 'support': 14848}}