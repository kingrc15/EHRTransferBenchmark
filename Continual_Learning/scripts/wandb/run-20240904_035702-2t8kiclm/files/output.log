
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_west
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.43822956532239915
Train: epoch: 1, loss = 0.4244178961589932
Train: epoch: 1, loss = 0.4181489726652702
Train: epoch: 1, loss = 0.4139230741746724
Train: epoch: 1, loss = 0.41195708288252353
Train: epoch: 1, loss = 0.4097061409925421
Train: epoch: 1, loss = 0.40716372158910547
Train: epoch: 1, loss = 0.40456353941001
Train: epoch: 1, loss = 0.4031386038495435
Train: epoch: 1, loss = 0.4010496456772089
Train: epoch: 1, loss = 0.3994343432716348
Train: epoch: 1, loss = 0.3979191518450777
Train: epoch: 1, loss = 0.3958822519160234
Train: epoch: 1, loss = 0.39459036148552384
Train: epoch: 1, loss = 0.3932950616280238
Train: epoch: 1, loss = 0.3923467385675758
Train: epoch: 1, loss = 0.3911804380399339
Train: epoch: 1, loss = 0.3901736037267579
Train:  Epoch 1, Loss=0.3897782495266352, AUC-ROC Macro=0.6666058043979131, AUC-ROC Micro=0.7536649879363058
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3677966569860776, AUC-ROC Macro=0.7244351670701633, AUC-ROC Micro=0.7880157162732689
Eval task: 2
Eval:  Epoch 1, Loss=0.327933669090271, AUC-ROC Macro=0.5010155333616122, AUC-ROC Micro=0.5311998381889909
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.3724751752614975
Train: epoch: 2, loss = 0.3700709906220436
Train: epoch: 2, loss = 0.3691625093917052
Train: epoch: 2, loss = 0.3705141122825444
Train: epoch: 2, loss = 0.3695054792910814
Train: epoch: 2, loss = 0.3702799923842152
Train: epoch: 2, loss = 0.3694516710511276
Train: epoch: 2, loss = 0.36961831448599697
Train: epoch: 2, loss = 0.36918408666219976
Train: epoch: 2, loss = 0.36941472121328117
Train: epoch: 2, loss = 0.36861914727498185
Train: epoch: 2, loss = 0.36878524439409377
Train: epoch: 2, loss = 0.36849897279762306
Train: epoch: 2, loss = 0.3683512521854469
Train: epoch: 2, loss = 0.3680712378869454
Train: epoch: 2, loss = 0.3672156710457057
Train: epoch: 2, loss = 0.36704083239769236
Train: epoch: 2, loss = 0.3667277000596126
Train:  Epoch 2, Loss=0.36662683919963673, AUC-ROC Macro=0.7289033300511015, AUC-ROC Micro=0.7941135613537516
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3588050305843353, AUC-ROC Macro=0.7444320668479559, AUC-ROC Micro=0.8022774088006552
Eval task: 2
Eval:  Epoch 2, Loss=0.34714246541261673, AUC-ROC Macro=0.4892358940308819, AUC-ROC Micro=0.5351335551333322
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.3657393719255924
Train: epoch: 3, loss = 0.36236938312649725
Train: epoch: 3, loss = 0.3582351630181074
Train: epoch: 3, loss = 0.3587863671220839
Train: epoch: 3, loss = 0.3584997870475054
Train: epoch: 3, loss = 0.3585083243747552
Train: epoch: 3, loss = 0.35869986765086653
Train: epoch: 3, loss = 0.3584195878915489
Train: epoch: 3, loss = 0.35881384912464354
Train: epoch: 3, loss = 0.3589279190003872
Train: epoch: 3, loss = 0.35797943632711066
Train: epoch: 3, loss = 0.3581198754099508
Train: epoch: 3, loss = 0.3584773635577697
Train: epoch: 3, loss = 0.3585821594085012
Train: epoch: 3, loss = 0.35897605661054455
Train: epoch: 3, loss = 0.3589141603000462
Train: epoch: 3, loss = 0.35858591665678163
Train: epoch: 3, loss = 0.3584733592760232
Train:  Epoch 3, Loss=0.3584795363214281, AUC-ROC Macro=0.7474751168417432, AUC-ROC Micro=0.8067035582689691
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.35468487938245136, AUC-ROC Macro=0.7533899906777012, AUC-ROC Micro=0.8082434577556115
Eval task: 2
Eval:  Epoch 3, Loss=0.35272183269262314, AUC-ROC Macro=0.477103712381328, AUC-ROC Micro=0.5229197543742856
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.34677699200809003
Train: epoch: 4, loss = 0.34998042564839127
Train: epoch: 4, loss = 0.352651615117987
Train: epoch: 4, loss = 0.3514858676120639
Train: epoch: 4, loss = 0.35139325954020023
Train: epoch: 4, loss = 0.3515830594673753
Train: epoch: 4, loss = 0.35164955051881924
Train: epoch: 4, loss = 0.3516774834692478
Train: epoch: 4, loss = 0.352214313712385
Train: epoch: 4, loss = 0.3527499445900321
Train: epoch: 4, loss = 0.3529056477546692
Train: epoch: 4, loss = 0.3528216682684918
Train: epoch: 4, loss = 0.35300269833551
Train: epoch: 4, loss = 0.35322866095496075
Train: epoch: 4, loss = 0.35311863269408544
Train: epoch: 4, loss = 0.35339022625703365
Train: epoch: 4, loss = 0.353266331943519
Train: epoch: 4, loss = 0.35359368580496975
Train:  Epoch 4, Loss=0.353451772744839, AUC-ROC Macro=0.7582567225878681, AUC-ROC Micro=0.8140209179361522
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.35242988417545956, AUC-ROC Macro=0.7572697049016073, AUC-ROC Micro=0.8118892882119271
Eval task: 2
Eval:  Epoch 4, Loss=0.37082313746213913, AUC-ROC Macro=0.48843675521818775, AUC-ROC Micro=0.5207228513987787
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.3447957883030176
Train: epoch: 5, loss = 0.34540859967470167
Train: epoch: 5, loss = 0.3470658374329408
Train: epoch: 5, loss = 0.3486630749516189
Train: epoch: 5, loss = 0.3487420860528946
Train: epoch: 5, loss = 0.34776704584558804
Train: epoch: 5, loss = 0.3481670290976763
Train: epoch: 5, loss = 0.348349238447845
Train: epoch: 5, loss = 0.3480433224224382
Train: epoch: 5, loss = 0.3484046989157796
Train: epoch: 5, loss = 0.34858567800034174
Train: epoch: 5, loss = 0.34919235269228616
Train: epoch: 5, loss = 0.3492522250631681
Train: epoch: 5, loss = 0.34943776002419846
Train: epoch: 5, loss = 0.34942934651176133
Train: epoch: 5, loss = 0.3493260579369962
Train: epoch: 5, loss = 0.349379902306725
Train: epoch: 5, loss = 0.3494622247831689
Train:  Epoch 5, Loss=0.34959417534282067, AUC-ROC Macro=0.7662009494088723, AUC-ROC Micro=0.8192946833403276
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3506544915338357, AUC-ROC Macro=0.760701087496635, AUC-ROC Micro=0.8143185669779582
Eval task: 2
Eval:  Epoch 5, Loss=0.39142847061157227, AUC-ROC Macro=0.5037353092482681, AUC-ROC Micro=0.5347860118417204
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3468612250685692
Train: epoch: 6, loss = 0.3437765831872821
Train: epoch: 6, loss = 0.3440018812318643
Train: epoch: 6, loss = 0.34474260967224835
Train: epoch: 6, loss = 0.3450343749821186
Train: epoch: 6, loss = 0.3454402447119355
Train: epoch: 6, loss = 0.34495316367064205
Train: epoch: 6, loss = 0.34517098049633205
Train: epoch: 6, loss = 0.3456353409671121
Train: epoch: 6, loss = 0.3455003365278244
Train: epoch: 6, loss = 0.34468277786943047
Train: epoch: 6, loss = 0.34464247440298396
Train: epoch: 6, loss = 0.34558652576345666
Train: epoch: 6, loss = 0.3461996418078031
Train: epoch: 6, loss = 0.3464010177652041
Train: epoch: 6, loss = 0.3462044266751036
Train: epoch: 6, loss = 0.3462330421717728
Train: epoch: 6, loss = 0.3462412229221728
Train:  Epoch 6, Loss=0.3462941506377652, AUC-ROC Macro=0.772776634169229, AUC-ROC Micro=0.8238143101400148
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3494439783195655, AUC-ROC Macro=0.7632791833700782, AUC-ROC Micro=0.8161803886830937
Eval task: 2
Eval:  Epoch 6, Loss=0.37916283309459686, AUC-ROC Macro=0.5045914261587935, AUC-ROC Micro=0.5507758168987391
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3531448816259702, AUC-ROC Macro=0.7621719512033135, AUC-ROC Micro=0.8137860957710903
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.381450854241848, AUC-ROC Macro=0.479460718646273, AUC-ROC Micro=0.5504283650748908
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.3076503947377205
Train: epoch: 1, loss = 0.30212318390607834
Train: epoch: 1, loss = 0.29063268944621085
Train:  Epoch 1, Loss=0.2843348647894048, AUC-ROC Macro=0.528512161944247, AUC-ROC Micro=0.7299325977632691
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3643120862543583, AUC-ROC Macro=0.7449154055556281, AUC-ROC Micro=0.7981083950114014
Eval task: 2
Eval:  Epoch 1, Loss=0.28887956589460373, AUC-ROC Macro=0.601783062767541, AUC-ROC Micro=0.7664324760216576
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.28858078449964525
Train: epoch: 2, loss = 0.2876632818952203
Train: epoch: 2, loss = 0.2773232166965803
Train:  Epoch 2, Loss=0.27066741082969853, AUC-ROC Macro=0.6169472320662799, AUC-ROC Micro=0.7890272047135178
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3582500082751115, AUC-ROC Macro=0.7507573946702774, AUC-ROC Micro=0.8047877521958455
Eval task: 2
Eval:  Epoch 2, Loss=0.28179139643907547, AUC-ROC Macro=0.6583255552004634, AUC-ROC Micro=0.794694478199311
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.276712770909071
Train: epoch: 3, loss = 0.27907723776996135
Train: epoch: 3, loss = 0.2705020175874233
Train:  Epoch 3, Loss=0.2646464883548981, AUC-ROC Macro=0.6818860690470783, AUC-ROC Micro=0.8107751074303542
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.3487661009033521, AUC-ROC Macro=0.7534306462667756, AUC-ROC Micro=0.8081552074023486
Eval task: 2
Eval:  Epoch 3, Loss=0.2782975658774376, AUC-ROC Macro=0.675941362556067, AUC-ROC Micro=0.8022961343201256
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.27209778495132925
Train: epoch: 4, loss = 0.2745222478732467
Train: epoch: 4, loss = 0.26558682598173616
Train:  Epoch 4, Loss=0.25997123508370934, AUC-ROC Macro=0.7020072156690741, AUC-ROC Micro=0.8198007946506043
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3504332092901071, AUC-ROC Macro=0.7509328377353717, AUC-ROC Micro=0.8050231841601381
Eval task: 2
Eval:  Epoch 4, Loss=0.27801869809627533, AUC-ROC Macro=0.6817596495021887, AUC-ROC Micro=0.8040067654839281
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.26973329424858095
Train: epoch: 5, loss = 0.2703058910369873
Train: epoch: 5, loss = 0.26155112442870937
Train:  Epoch 5, Loss=0.25582067386956514, AUC-ROC Macro=0.7252778095372909, AUC-ROC Micro=0.8276180865426281
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3468787881235282, AUC-ROC Macro=0.7498067784501338, AUC-ROC Micro=0.8043732523966849
Eval task: 2
Eval:  Epoch 5, Loss=0.2752610668540001, AUC-ROC Macro=0.6971191049848393, AUC-ROC Micro=0.8130009624782141
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.26640888415277003
Train: epoch: 6, loss = 0.2670714380219579
Train: epoch: 6, loss = 0.25798522002995017
Train:  Epoch 6, Loss=0.25184834058226185, AUC-ROC Macro=0.742702914746082, AUC-ROC Micro=0.835580415062235
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3451258751253287, AUC-ROC Macro=0.7467745581924344, AUC-ROC Micro=0.8011136654767681
Eval task: 2
Eval:  Epoch 6, Loss=0.2816261947154999, AUC-ROC Macro=0.6930169766258929, AUC-ROC Micro=0.8086920223668682
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3728068619966507, AUC-ROC Macro=0.7430560131251616, AUC-ROC Micro=0.7971905816853772
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.2232450544834137, AUC-ROC Macro=0.7124254057248516, AUC-ROC Micro=0.8121286038918246
{'0': {'precision': 0.6112600536193029, 'recall': 0.1743119266055046, 'f1-score': 0.27126710291493156, 'support': 1308}, '1': {'precision': 0.6068965517241379, 'recall': 0.43781094527363185, 'f1-score': 0.5086705202312137, 'support': 402}, '2': {'precision': 0.5365853658536586, 'recall': 0.0668693009118541, 'f1-score': 0.11891891891891891, 'support': 658}, '3': {'precision': 0.5335515548281505, 'recall': 0.16381909547738693, 'f1-score': 0.2506728181468666, 'support': 1990}, '4': {'precision': 0.6310679611650486, 'recall': 0.08064516129032258, 'f1-score': 0.143014301430143, 'support': 806}, '5': {'precision': 0.5, 'recall': 0.012853470437017995, 'f1-score': 0.02506265664160401, 'support': 778}, '6': {'precision': 0.5563218390804597, 'recall': 0.1858678955453149, 'f1-score': 0.2786413356361543, 'support': 1302}, '7': {'precision': 0.16666666666666666, 'recall': 0.0023584905660377358, 'f1-score': 0.004651162790697674, 'support': 424}, '8': {'precision': 0.5838668373879642, 'recall': 0.2773722627737226, 'f1-score': 0.37608247422680413, 'support': 1644}, '9': {'precision': 0.6746376811594202, 'recall': 0.4583948793697686, 'f1-score': 0.5458809733216066, 'support': 2031}, '10': {'precision': 0.567741935483871, 'recall': 0.30715532286212915, 'f1-score': 0.39864099660249147, 'support': 573}, '11': {'precision': 0.49375, 'recall': 0.20153061224489796, 'f1-score': 0.286231884057971, 'support': 1176}, '12': {'precision': 0.586890243902439, 'recall': 0.2175141242937853, 'f1-score': 0.3173948887056884, 'support': 1770}, '13': {'precision': 0.5772544514646755, 'recall': 0.3871340523882897, 'f1-score': 0.46345400046114826, 'support': 2596}, '14': {'precision': 0.5641547861507128, 'recall': 0.1702519975414874, 'f1-score': 0.26156751652502364, 'support': 1627}, '15': {'precision': 0.2857142857142857, 'recall': 0.004132231404958678, 'f1-score': 0.00814663951120163, 'support': 484}, '16': {'precision': 0.4365079365079365, 'recall': 0.06918238993710692, 'f1-score': 0.11943539630836048, 'support': 795}, '17': {'precision': 0.5151515151515151, 'recall': 0.03125, 'f1-score': 0.058925476603119586, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.5, 'recall': 0.030534351145038167, 'f1-score': 0.05755395683453236, 'support': 262}, '20': {'precision': 0.3333333333333333, 'recall': 0.003552397868561279, 'f1-score': 0.0070298769771529, 'support': 563}, '21': {'precision': 0.5697674418604651, 'recall': 0.17562724014336917, 'f1-score': 0.2684931506849315, 'support': 837}, '22': {'precision': 0.6828193832599119, 'recall': 0.4281767955801105, 'f1-score': 0.5263157894736842, 'support': 1086}, '23': {'precision': 0.6857142857142857, 'recall': 0.1672473867595819, 'f1-score': 0.26890756302521013, 'support': 861}, '24': {'precision': 0.6291390728476821, 'recall': 0.18811881188118812, 'f1-score': 0.2896341463414634, 'support': 505}, 'micro avg': {'precision': 0.5940101632608931, 'recall': 0.21652938162613802, 'f1-score': 0.3173704580902317, 'support': 25373}, 'macro avg': {'precision': 0.5131517273150369, 'recall': 0.16966844569204265, 'f1-score': 0.23418374185483679, 'support': 25373}, 'weighted avg': {'precision': 0.5538569076218491, 'recall': 0.21652938162613802, 'f1-score': 0.29332323657191345, 'support': 25373}, 'samples avg': {'precision': 0.353656067511048, 'recall': 0.19545326451849312, 'f1-score': 0.23000718490508423, 'support': 25373}}
{'0': {'precision': 0.5775862068965517, 'recall': 0.34183673469387754, 'f1-score': 0.42948717948717946, 'support': 196}, '1': {'precision': 0.5175438596491229, 'recall': 0.24481327800829875, 'f1-score': 0.33239436619718304, 'support': 241}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 145}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 118}, '4': {'precision': 0.5172413793103449, 'recall': 0.21634615384615385, 'f1-score': 0.3050847457627119, 'support': 208}, '5': {'precision': 0.1, 'recall': 0.01, 'f1-score': 0.01818181818181818, 'support': 100}, '6': {'precision': 0.6666666666666666, 'recall': 0.01818181818181818, 'f1-score': 0.035398230088495575, 'support': 110}, '7': {'precision': 0.78125, 'recall': 0.18796992481203006, 'f1-score': 0.303030303030303, 'support': 133}, '8': {'precision': 0.2857142857142857, 'recall': 0.02247191011235955, 'f1-score': 0.041666666666666664, 'support': 89}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87}, '13': {'precision': 0.5, 'recall': 0.0684931506849315, 'f1-score': 0.12048192771084336, 'support': 73}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 45}, '15': {'precision': 0.7446808510638298, 'recall': 0.6862745098039216, 'f1-score': 0.7142857142857144, 'support': 51}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'micro avg': {'precision': 0.5527522935779816, 'recall': 0.12086258776328987, 'f1-score': 0.19835390946502057, 'support': 1994}, 'macro avg': {'precision': 0.18762732997203205, 'recall': 0.07185549920573564, 'f1-score': 0.09200043805643662, 'support': 1994}, 'weighted avg': {'precision': 0.317285883545574, 'recall': 0.12086258776328987, 'f1-score': 0.16183112310300668, 'support': 1994}, 'samples avg': {'precision': 0.20845540364583331, 'recall': 0.13726864769345237, 'f1-score': 0.15493960249819624, 'support': 1994}}