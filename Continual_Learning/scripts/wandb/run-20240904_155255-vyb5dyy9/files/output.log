
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_phen_west
['/data/datasets/mimic3-benchmarks/data/phenotyping', '/data/datasets/eICU2MIMIC/phenotyping_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.429345118701458
Train: epoch: 1, loss = 0.4232145745307207
Train: epoch: 1, loss = 0.4186520971357822
Train: epoch: 1, loss = 0.41498010024428367
Train: epoch: 1, loss = 0.412788824737072
Train: epoch: 1, loss = 0.4116224162032207
Train: epoch: 1, loss = 0.4097811823444707
Train: epoch: 1, loss = 0.40703337560407815
Train: epoch: 1, loss = 0.40604851736790604
Train: epoch: 1, loss = 0.4051933447495103
Train: epoch: 1, loss = 0.40426973623985596
Train: epoch: 1, loss = 0.40318981792156894
Train: epoch: 1, loss = 0.40161866860320933
Train: epoch: 1, loss = 0.4002027255775673
Train: epoch: 1, loss = 0.3991997920523087
Train: epoch: 1, loss = 0.3982745710480958
Train: epoch: 1, loss = 0.3966997382483062
Train: epoch: 1, loss = 0.3954458544527491
Train:  Epoch 1, Loss=0.3950784425796607, AUC-ROC Macro=0.6480076993420686, AUC-ROC Micro=0.743433061586668
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.3730735306938489, AUC-ROC Macro=0.7131618827044899, AUC-ROC Micro=0.7792667899846326
Eval task: 2
Eval:  Epoch 1, Loss=0.33728212118148804, AUC-ROC Macro=0.49569640092592165, AUC-ROC Micro=0.5152066673780406
------------------------------------
Task: 1, Epoch: 2
Train: epoch: 2, loss = 0.37132956489920615
Train: epoch: 2, loss = 0.37273441478610037
Train: epoch: 2, loss = 0.3739669511715571
Train: epoch: 2, loss = 0.3749227138236165
Train: epoch: 2, loss = 0.37431587171554564
Train: epoch: 2, loss = 0.3750956957538923
Train: epoch: 2, loss = 0.37440839348094807
Train: epoch: 2, loss = 0.37313394537195566
Train: epoch: 2, loss = 0.37316781867709425
Train: epoch: 2, loss = 0.372061470605433
Train: epoch: 2, loss = 0.37187192278152165
Train: epoch: 2, loss = 0.37113211993748946
Train: epoch: 2, loss = 0.3704220120780743
Train: epoch: 2, loss = 0.370534391105175
Train: epoch: 2, loss = 0.37033467148741084
Train: epoch: 2, loss = 0.369956172159873
Train: epoch: 2, loss = 0.3697814660081092
Train: epoch: 2, loss = 0.3694992738465468
Train:  Epoch 2, Loss=0.3694911503180479, AUC-ROC Macro=0.7221492225581295, AUC-ROC Micro=0.7896532345932148
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3614722490310669, AUC-ROC Macro=0.7402602654791838, AUC-ROC Micro=0.7985268704600423
Eval task: 2
Eval:  Epoch 2, Loss=0.35426630079746246, AUC-ROC Macro=0.494410417284987, AUC-ROC Micro=0.5270971221742133
------------------------------------
Task: 1, Epoch: 3
Train: epoch: 3, loss = 0.367574672549963
Train: epoch: 3, loss = 0.3619627474248409
Train: epoch: 3, loss = 0.36161380290985107
Train: epoch: 3, loss = 0.3617448470182717
Train: epoch: 3, loss = 0.3615156628191471
Train: epoch: 3, loss = 0.36238211234410606
Train: epoch: 3, loss = 0.3621939451886075
Train: epoch: 3, loss = 0.3619300027471036
Train: epoch: 3, loss = 0.36188299550778336
Train: epoch: 3, loss = 0.3613875636607409
Train: epoch: 3, loss = 0.3612340354851701
Train: epoch: 3, loss = 0.3604391328804195
Train: epoch: 3, loss = 0.36049086385621476
Train: epoch: 3, loss = 0.36049937805426974
Train: epoch: 3, loss = 0.3601644179771344
Train: epoch: 3, loss = 0.3600410725455731
Train: epoch: 3, loss = 0.3599428230348755
Train: epoch: 3, loss = 0.3601243695244193
Train:  Epoch 3, Loss=0.35992266649262517, AUC-ROC Macro=0.7441396199833396, AUC-ROC Micro=0.804493409026326
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.35464272399743396, AUC-ROC Macro=0.7519351885212925, AUC-ROC Micro=0.8086188466450923
Eval task: 2
Eval:  Epoch 3, Loss=0.3698134198784828, AUC-ROC Macro=0.48902747623357756, AUC-ROC Micro=0.528070780637253
------------------------------------
Task: 1, Epoch: 4
Train: epoch: 4, loss = 0.35172748886048794
Train: epoch: 4, loss = 0.35470623411238195
Train: epoch: 4, loss = 0.35501276987294356
Train: epoch: 4, loss = 0.35594716204330323
Train: epoch: 4, loss = 0.3551905284374952
Train: epoch: 4, loss = 0.3548552765573065
Train: epoch: 4, loss = 0.35582782479269165
Train: epoch: 4, loss = 0.3550918989814818
Train: epoch: 4, loss = 0.35540030537380113
Train: epoch: 4, loss = 0.3544370599538088
Train: epoch: 4, loss = 0.3546440714597702
Train: epoch: 4, loss = 0.35465619194010894
Train: epoch: 4, loss = 0.3545856229158548
Train: epoch: 4, loss = 0.35390483149460383
Train: epoch: 4, loss = 0.35444974223275977
Train: epoch: 4, loss = 0.354421725589782
Train: epoch: 4, loss = 0.3544511555880308
Train: epoch: 4, loss = 0.3540924751220478
Train:  Epoch 4, Loss=0.353962332968019, AUC-ROC Macro=0.7573935379192699, AUC-ROC Micro=0.8131368232937426
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.3528047353029251, AUC-ROC Macro=0.7581031545888147, AUC-ROC Micro=0.8115873108418784
Eval task: 2
Eval:  Epoch 4, Loss=0.36642052978277206, AUC-ROC Macro=0.4813181992829179, AUC-ROC Micro=0.5216672798284634
------------------------------------
Task: 1, Epoch: 5
Train: epoch: 5, loss = 0.3454469645768404
Train: epoch: 5, loss = 0.3510210308432579
Train: epoch: 5, loss = 0.34841932557523253
Train: epoch: 5, loss = 0.34957908814772964
Train: epoch: 5, loss = 0.3499292772114277
Train: epoch: 5, loss = 0.34987595487385986
Train: epoch: 5, loss = 0.3494720687078578
Train: epoch: 5, loss = 0.34952830998227
Train: epoch: 5, loss = 0.3496613247940938
Train: epoch: 5, loss = 0.3494503165781498
Train: epoch: 5, loss = 0.3496362679654902
Train: epoch: 5, loss = 0.34927332773804665
Train: epoch: 5, loss = 0.34931491746352267
Train: epoch: 5, loss = 0.3493067562846201
Train: epoch: 5, loss = 0.3491612990895907
Train: epoch: 5, loss = 0.3494971030997112
Train: epoch: 5, loss = 0.34965377112521845
Train: epoch: 5, loss = 0.3500190983919634
Train:  Epoch 5, Loss=0.350005142551202, AUC-ROC Macro=0.7652049294915786, AUC-ROC Micro=0.8188005288193435
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.35119345784187317, AUC-ROC Macro=0.7610234823423848, AUC-ROC Micro=0.8153421581022917
Eval task: 2
Eval:  Epoch 5, Loss=0.3859938010573387, AUC-ROC Macro=0.49148663289520833, AUC-ROC Micro=0.5267993644352356
------------------------------------
Task: 1, Epoch: 6
Train: epoch: 6, loss = 0.3444950847327709
Train: epoch: 6, loss = 0.3444726859405637
Train: epoch: 6, loss = 0.3456886687129736
Train: epoch: 6, loss = 0.34689185667783023
Train: epoch: 6, loss = 0.34651246991753576
Train: epoch: 6, loss = 0.3458125555887818
Train: epoch: 6, loss = 0.3457339348856892
Train: epoch: 6, loss = 0.3460366219468415
Train: epoch: 6, loss = 0.34653566729691293
Train: epoch: 6, loss = 0.3463430692404509
Train: epoch: 6, loss = 0.3464769064973701
Train: epoch: 6, loss = 0.34670982827742897
Train: epoch: 6, loss = 0.3472278053370806
Train: epoch: 6, loss = 0.34706319548721826
Train: epoch: 6, loss = 0.34708564181625845
Train: epoch: 6, loss = 0.3467563095921651
Train: epoch: 6, loss = 0.3467253743638011
Train: epoch: 6, loss = 0.34684812317291897
Train:  Epoch 6, Loss=0.34686967039617717, AUC-ROC Macro=0.7716355924776411, AUC-ROC Micro=0.823073230554549
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.35047722483674687, AUC-ROC Macro=0.7653314724068574, AUC-ROC Micro=0.8169468573316505
Eval task: 2
Eval:  Epoch 6, Loss=0.3784913122653961, AUC-ROC Macro=0.501574462283396, AUC-ROC Micro=0.5183367654467668
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3536580416063468, AUC-ROC Macro=0.7641444839601729, AUC-ROC Micro=0.8153149202332651
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.3756440207362175, AUC-ROC Macro=0.49192130839188036, AUC-ROC Micro=0.5206577433733038
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.31444734551012515
Train: epoch: 1, loss = 0.3045561820268631
Train: epoch: 1, loss = 0.2997233585268259
Train:  Epoch 1, Loss=0.29841317225305247, AUC-ROC Macro=0.5463250443538297, AUC-ROC Micro=0.7281587789016849
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.34043217202027637, AUC-ROC Macro=0.7563135446603567, AUC-ROC Micro=0.8089169470894256
Eval task: 2
Eval:  Epoch 1, Loss=0.2869589701294899, AUC-ROC Macro=0.6293055254568607, AUC-ROC Micro=0.7765931031773461
------------------------------------
Task: 2, Epoch: 2
Train: epoch: 2, loss = 0.28551384165883065
Train: epoch: 2, loss = 0.2819815173372626
Train: epoch: 2, loss = 0.28156046383082867
Train:  Epoch 2, Loss=0.281736825096054, AUC-ROC Macro=0.6366905161528932, AUC-ROC Micro=0.7913365160270771
-------------
Eval task: 1
Eval:  Epoch 2, Loss=0.3433734228213628, AUC-ROC Macro=0.7549034867155971, AUC-ROC Micro=0.8082051585229242
Eval task: 2
Eval:  Epoch 2, Loss=0.29093164950609207, AUC-ROC Macro=0.6631919272625261, AUC-ROC Micro=0.7945451852465308
------------------------------------
Task: 2, Epoch: 3
Train: epoch: 3, loss = 0.27754333689808847
Train: epoch: 3, loss = 0.2776201169192791
Train: epoch: 3, loss = 0.27690886057913305
Train:  Epoch 3, Loss=0.2761371355419055, AUC-ROC Macro=0.6798900786091296, AUC-ROC Micro=0.8090048821731415
-------------
Eval task: 1
Eval:  Epoch 3, Loss=0.34438296779990196, AUC-ROC Macro=0.7536402859348316, AUC-ROC Micro=0.8087606714052875
Eval task: 2
Eval:  Epoch 3, Loss=0.2605642005801201, AUC-ROC Macro=0.6748234200028407, AUC-ROC Micro=0.801959293488965
------------------------------------
Task: 2, Epoch: 4
Train: epoch: 4, loss = 0.2723042885959148
Train: epoch: 4, loss = 0.2718020078167319
Train: epoch: 4, loss = 0.2708367952456077
Train:  Epoch 4, Loss=0.2712965491308311, AUC-ROC Macro=0.7093653280396888, AUC-ROC Micro=0.8187921125580948
-------------
Eval task: 1
Eval:  Epoch 4, Loss=0.34393030529220897, AUC-ROC Macro=0.748681957542533, AUC-ROC Micro=0.8043650507181126
Eval task: 2
Eval:  Epoch 4, Loss=0.2820034325122833, AUC-ROC Macro=0.6869214984116775, AUC-ROC Micro=0.8061968732464501
------------------------------------
Task: 2, Epoch: 5
Train: epoch: 5, loss = 0.26810391403734685
Train: epoch: 5, loss = 0.26821677293628454
Train: epoch: 5, loss = 0.2680099781602621
Train:  Epoch 5, Loss=0.2672470451214836, AUC-ROC Macro=0.7234793668795859, AUC-ROC Micro=0.8262592438598295
-------------
Eval task: 1
Eval:  Epoch 5, Loss=0.3388135954737663, AUC-ROC Macro=0.7471346469310288, AUC-ROC Micro=0.8028000960311519
Eval task: 2
Eval:  Epoch 5, Loss=0.27423863857984543, AUC-ROC Macro=0.6828274025642233, AUC-ROC Micro=0.8062559278942962
------------------------------------
Task: 2, Epoch: 6
Train: epoch: 6, loss = 0.2656210618466139
Train: epoch: 6, loss = 0.2650165979191661
Train: epoch: 6, loss = 0.2640232069790363
Train:  Epoch 6, Loss=0.26410560966948143, AUC-ROC Macro=0.7317572250327266, AUC-ROC Micro=0.8307570613341002
-------------
Eval task: 1
Eval:  Epoch 6, Loss=0.3470457506676515, AUC-ROC Macro=0.7475639382665924, AUC-ROC Micro=0.8020442696802828
Eval task: 2
Eval:  Epoch 6, Loss=0.23920533806085587, AUC-ROC Macro=0.6914574952087945, AUC-ROC Micro=0.8103713636983796
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 6, Loss=0.3699409229060014, AUC-ROC Macro=0.7464292359668473, AUC-ROC Micro=0.801081397335236
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 6, Loss=0.22392356768250465, AUC-ROC Macro=0.7076681928081855, AUC-ROC Micro=0.8100408465080065
{'0': {'precision': 0.5337142857142857, 'recall': 0.3570336391437309, 'f1-score': 0.42785158039395327, 'support': 1308}, '1': {'precision': 0.6142322097378277, 'recall': 0.4079601990049751, 'f1-score': 0.49028400597907323, 'support': 402}, '2': {'precision': 0.4222222222222222, 'recall': 0.08662613981762918, 'f1-score': 0.14375788146279947, 'support': 658}, '3': {'precision': 0.5083986562150056, 'recall': 0.22814070351758794, 'f1-score': 0.3149497051682275, 'support': 1990}, '4': {'precision': 0.41139240506329117, 'recall': 0.16129032258064516, 'f1-score': 0.23172905525846701, 'support': 806}, '5': {'precision': 0.3655913978494624, 'recall': 0.043701799485861184, 'f1-score': 0.0780711825487945, 'support': 778}, '6': {'precision': 0.5299145299145299, 'recall': 0.19047619047619047, 'f1-score': 0.280225988700565, 'support': 1302}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 424}, '8': {'precision': 0.5505747126436782, 'recall': 0.2913625304136253, 'f1-score': 0.381066030230708, 'support': 1644}, '9': {'precision': 0.6517150395778364, 'recall': 0.48645987198424423, 'f1-score': 0.5570904990132506, 'support': 2031}, '10': {'precision': 0.6066666666666667, 'recall': 0.31762652705061084, 'f1-score': 0.41695303550973656, 'support': 573}, '11': {'precision': 0.4948453608247423, 'recall': 0.20408163265306123, 'f1-score': 0.2889825406381698, 'support': 1176}, '12': {'precision': 0.5816618911174785, 'recall': 0.22937853107344633, 'f1-score': 0.32901134521880065, 'support': 1770}, '13': {'precision': 0.5657769304099142, 'recall': 0.45724191063174113, 'f1-score': 0.5057520238602471, 'support': 2596}, '14': {'precision': 0.576271186440678, 'recall': 0.22987092808850645, 'f1-score': 0.328646748681898, 'support': 1627}, '15': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 484}, '16': {'precision': 0.410958904109589, 'recall': 0.1509433962264151, 'f1-score': 0.22079116835326587, 'support': 795}, '17': {'precision': 0.43548387096774194, 'recall': 0.04963235294117647, 'f1-score': 0.0891089108910891, 'support': 544}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 351}, '19': {'precision': 0.48717948717948717, 'recall': 0.07251908396946564, 'f1-score': 0.12624584717607973, 'support': 262}, '20': {'precision': 0.3333333333333333, 'recall': 0.0017761989342806395, 'f1-score': 0.003533568904593639, 'support': 563}, '21': {'precision': 0.5522875816993464, 'recall': 0.2019115890083632, 'f1-score': 0.2957130358705162, 'support': 837}, '22': {'precision': 0.6670467502850627, 'recall': 0.5386740331491713, 'f1-score': 0.5960264900662252, 'support': 1086}, '23': {'precision': 0.6094986807387863, 'recall': 0.2682926829268293, 'f1-score': 0.37258064516129036, 'support': 861}, '24': {'precision': 0.4954954954954955, 'recall': 0.21782178217821782, 'f1-score': 0.30261348005502064, 'support': 505}, 'micro avg': {'precision': 0.5631805520384907, 'recall': 0.2629566862412801, 'f1-score': 0.35851692638366467, 'support': 25373}, 'macro avg': {'precision': 0.4561704639282585, 'recall': 0.20771288181023098, 'f1-score': 0.27123939076571085, 'support': 25373}, 'weighted avg': {'precision': 0.511384089199143, 'recall': 0.2629566862412801, 'f1-score': 0.3343941883844441, 'support': 25373}, 'samples avg': {'precision': 0.38382885425121754, 'recall': 0.23483622975523252, 'f1-score': 0.26680260200422296, 'support': 25373}}
{'0': {'precision': 0.5752212389380531, 'recall': 0.33163265306122447, 'f1-score': 0.4207119741100323, 'support': 196}, '1': {'precision': 0.4702702702702703, 'recall': 0.36099585062240663, 'f1-score': 0.40845070422535207, 'support': 241}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 145}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 118}, '4': {'precision': 0.5882352941176471, 'recall': 0.14423076923076922, 'f1-score': 0.2316602316602316, 'support': 208}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 100}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '7': {'precision': 0.78125, 'recall': 0.18796992481203006, 'f1-score': 0.303030303030303, 'support': 133}, '8': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 89}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '10': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 75}, '11': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 86}, '12': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 87}, '13': {'precision': 0.35, 'recall': 0.0958904109589041, 'f1-score': 0.15053763440860213, 'support': 73}, '14': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 45}, '15': {'precision': 0.6739130434782609, 'recall': 0.6078431372549019, 'f1-score': 0.6391752577319587, 'support': 51}, '16': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '17': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '18': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '19': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 29}, '20': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 15}, '21': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 13}, '22': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 10}, '23': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 7}, '24': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1}, 'micro avg': {'precision': 0.5408388520971302, 'recall': 0.12286860581745236, 'f1-score': 0.20024519820187986, 'support': 1994}, 'macro avg': {'precision': 0.13755559387216926, 'recall': 0.06914250983760944, 'f1-score': 0.08614264420665921, 'support': 1994}, 'weighted avg': {'precision': 0.2568993251558955, 'recall': 0.12286860581745236, 'f1-score': 0.15695672547060807, 'support': 1994}, 'samples avg': {'precision': 0.22062174479166666, 'recall': 0.14546130952380953, 'f1-score': 0.16469184027777778, 'support': 1994}}