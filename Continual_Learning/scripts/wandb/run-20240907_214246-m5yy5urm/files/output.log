
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_south
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1652910965681076
Train: epoch: 1, loss = 2.129105198085308
Train: epoch: 1, loss = 2.110560917655627
Train: epoch: 1, loss = 2.0974638964235783
Train: epoch: 1, loss = 2.0888890665769577
Train: epoch: 1, loss = 2.0830423883597056
Train: epoch: 1, loss = 2.0767114116464342
Train: epoch: 1, loss = 2.0740943425893783
Train: epoch: 1, loss = 2.0695537631379235
Train: epoch: 1, loss = 2.0679903139472007
Train: epoch: 1, loss = 2.0652221810817717
Train: epoch: 1, loss = 2.0645575123031934
Train: epoch: 1, loss = 2.0626126829477456
Train: epoch: 1, loss = 2.060896465437753
Train: epoch: 1, loss = 2.05940641160806
Train: epoch: 1, loss = 2.0578962239995597
Train: epoch: 1, loss = 2.0565387374863904
Train: epoch: 1, loss = 2.0553231251570914
Train: epoch: 1, loss = 2.0546808566545187
Train: epoch: 1, loss = 2.0536742492616176
Train: epoch: 1, loss = 2.0531396068561643
Train: epoch: 1, loss = 2.0524303742430425
Train: epoch: 1, loss = 2.0512770696826603
Train: epoch: 1, loss = 2.0506038793921473
Train: epoch: 1, loss = 2.050025306367874
Train: epoch: 1, loss = 2.0498160001406305
Train: epoch: 1, loss = 2.0498468484701933
Train: epoch: 1, loss = 2.048420293820756
Train: epoch: 1, loss = 2.0472102638154195
Train: epoch: 1, loss = 2.046969167749087
Train: epoch: 1, loss = 2.046857701443857
Train: epoch: 1, loss = 2.046461106259376
Train: epoch: 1, loss = 2.0459346264239513
Train: epoch: 1, loss = 2.045998795698671
Train: epoch: 1, loss = 2.045303587794304
Train: epoch: 1, loss = 2.044917734116316
Train: epoch: 1, loss = 2.0439474647109575
Train: epoch: 1, loss = 2.043576505199859
Train: epoch: 1, loss = 2.043360131627474
Train: epoch: 1, loss = 2.043468919441104
Train: epoch: 1, loss = 2.0433787672258004
Train: epoch: 1, loss = 2.042794372794174
Train: epoch: 1, loss = 2.042444634243499
Train:  Epoch 1, Loss=2.0425359844344, Cohen Kappa=0.3831556543047019, MAD=0.7221412530464525
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.037288452016896, Cohen Kappa=0.4231627452135618, MAD=0.7338686477185801
Eval task: 2
Eval:  Epoch 1, Loss=1.9260399711543117, Cohen Kappa=0.004623408600126999, MAD=0.7387145890761581
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0562105034959726, Cohen Kappa=0.33526902268916614, MAD=0.7303806264772644
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9184704895677238, Cohen Kappa=0.004395524510822479, MAD=0.7389983789991946
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.943397592306137
Train: epoch: 1, loss = 1.9433600226044654
Train: epoch: 1, loss = 1.9510975952943166
Train: epoch: 1, loss = 1.9500891570746899
Train: epoch: 1, loss = 1.945552457690239
Train: epoch: 1, loss = 1.9431090754270555
Train: epoch: 1, loss = 1.9441448919262205
Train: epoch: 1, loss = 1.9426813388615847
Train: epoch: 1, loss = 1.9432483546601402
Train: epoch: 1, loss = 1.944032566845417
Train: epoch: 1, loss = 1.9441428033330224
Train: epoch: 1, loss = 1.943790494898955
Train: epoch: 1, loss = 1.9429859690024303
Train: epoch: 1, loss = 1.9437256995694978
Train: epoch: 1, loss = 1.9430140653848649
Train: epoch: 1, loss = 1.9434784984961153
Train: epoch: 1, loss = 1.943189312359866
Train: epoch: 1, loss = 1.9425389578938483
Train: epoch: 1, loss = 1.9419719882074156
Train: epoch: 1, loss = 1.9421165162920953
Train: epoch: 1, loss = 1.9413041243382863
Train: epoch: 1, loss = 1.941173211444508
Train: epoch: 1, loss = 1.9407238203546275
Train: epoch: 1, loss = 1.9402863412102063
Train: epoch: 1, loss = 1.9403371722698213
Train: epoch: 1, loss = 1.9403419042779848
Train: epoch: 1, loss = 1.9404534008547112
Train: epoch: 1, loss = 1.9404485524126462
Train: epoch: 1, loss = 1.9402563529384547
Train: epoch: 1, loss = 1.9398995144963265
Train: epoch: 1, loss = 1.9397463482618331
Train: epoch: 1, loss = 1.9391884498298169
Train: epoch: 1, loss = 1.9394282712177797
Train: epoch: 1, loss = 1.9392278415665907
Train: epoch: 1, loss = 1.9388783598457064
Train: epoch: 1, loss = 1.9381206744247013
Train: epoch: 1, loss = 1.9374893375506272
Train: epoch: 1, loss = 1.936296129712933
Train: epoch: 1, loss = 1.9354565689808283
Train: epoch: 1, loss = 1.9345908665210008
Train: epoch: 1, loss = 1.9339995469116582
Train: epoch: 1, loss = 1.9329239483674368
Train: epoch: 1, loss = 1.932642417855041
Train:  Epoch 1, Loss=1.931974469607217, Cohen Kappa=0.07804033703662949, MAD=0.6935407365589639
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.127976886157332, Cohen Kappa=0.17719181703854392, MAD=0.7211520430332075
Eval task: 2
Eval:  Epoch 1, Loss=1.9578868089051082, Cohen Kappa=0.1669881104870925, MAD=0.6932042914949206
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0844996119367667, Cohen Kappa=0.15420591255418037, MAD=0.7189410929216304
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.8974955143599674, Cohen Kappa=0.06602812321648954, MAD=0.6944556430737446
{'0': {'precision': 0.4293159609120521, 'recall': 0.16171779141104295, 'f1-score': 0.23493761140819963, 'support': 4075}, '1': {'precision': 0.21009469056476157, 'recall': 0.8673647469458988, 'f1-score': 0.33825631252977606, 'support': 2865}, '2': {'precision': 0.11627906976744186, 'recall': 0.0027502750275027505, 'f1-score': 0.005373455131649651, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.6486486486486487, 'recall': 0.039473684210526314, 'f1-score': 0.07441860465116279, 'support': 1216}, '9': {'precision': 0.08260233918128655, 'recall': 0.10531220876048462, 'f1-score': 0.09258500614502253, 'support': 1073}, 'accuracy': 0.22292564655172414, 'macro avg': {'precision': 0.14869407090741907, 'recall': 0.11766187063554553, 'f1-score': 0.07455709898658107, 'support': 14848}, 'weighted avg': {'precision': 0.23169236561962153, 'recall': 0.22292564655172414, 'f1-score': 0.14318970758115465, 'support': 14848}}
{'0': {'precision': 0.3872053872053872, 'recall': 0.025889239081494823, 'f1-score': 0.0485334458746571, 'support': 4442}, '1': {'precision': 0.3502956081081081, 'recall': 0.9671589584143023, 'f1-score': 0.5143122868657642, 'support': 5146}, '2': {'precision': 0.2153846153846154, 'recall': 0.005511811023622047, 'f1-score': 0.01074856046065259, 'support': 2540}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1301}, '4': {'precision': 0.14285714285714285, 'recall': 0.0018975332068311196, 'f1-score': 0.003745318352059925, 'support': 527}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 305}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 189}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 110}, '8': {'precision': 0.12, 'recall': 0.05113636363636364, 'f1-score': 0.07171314741035857, 'support': 176}, '9': {'precision': 0.11734693877551021, 'recall': 0.20535714285714285, 'f1-score': 0.14935064935064934, 'support': 112}, 'accuracy': 0.3461072198275862, 'macro avg': {'precision': 0.13330896923307636, 'recall': 0.12569510482197568, 'f1-score': 0.0798403408314142, 'support': 14848}, 'weighted avg': {'precision': 0.28146639438282256, 'recall': 0.3461072198275862, 'f1-score': 0.19671743721710253, 'support': 14848}}