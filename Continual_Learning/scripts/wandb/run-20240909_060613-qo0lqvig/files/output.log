
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1409896606206895
Train: epoch: 1, loss = 2.109148562848568
Train: epoch: 1, loss = 2.0947683890660604
Train: epoch: 1, loss = 2.0873266273736952
Train: epoch: 1, loss = 2.0809385850429534
Train: epoch: 1, loss = 2.0767789044976235
Train: epoch: 1, loss = 2.0718096870183946
Train: epoch: 1, loss = 2.0689738038927317
Train: epoch: 1, loss = 2.066399135126008
Train: epoch: 1, loss = 2.065165586411953
Train: epoch: 1, loss = 2.063953205130317
Train: epoch: 1, loss = 2.061628618737062
Train: epoch: 1, loss = 2.061930602651376
Train: epoch: 1, loss = 2.0603726900475365
Train: epoch: 1, loss = 2.060547829111417
Train: epoch: 1, loss = 2.0582891663163903
Train: epoch: 1, loss = 2.0572177024098
Train: epoch: 1, loss = 2.055986106461949
Train: epoch: 1, loss = 2.0542220232047534
Train: epoch: 1, loss = 2.052719252645969
Train: epoch: 1, loss = 2.0515193189041954
Train: epoch: 1, loss = 2.050762374942953
Train: epoch: 1, loss = 2.0503377000922742
Train: epoch: 1, loss = 2.049705364579956
Train: epoch: 1, loss = 2.0488779252052307
Train: epoch: 1, loss = 2.047838719853988
Train: epoch: 1, loss = 2.047531684813676
Train: epoch: 1, loss = 2.04692514027868
Train: epoch: 1, loss = 2.046630194413251
Train: epoch: 1, loss = 2.0463628111084304
Train: epoch: 1, loss = 2.0461804941584987
Train: epoch: 1, loss = 2.0456886526942255
Train: epoch: 1, loss = 2.0448534726735317
Train: epoch: 1, loss = 2.04436684710138
Train: epoch: 1, loss = 2.044628100293023
Train: epoch: 1, loss = 2.0448399072554375
Train: epoch: 1, loss = 2.0445974997410903
Train: epoch: 1, loss = 2.0438563907617016
Train: epoch: 1, loss = 2.043347333073616
Train: epoch: 1, loss = 2.0432800352573395
Train: epoch: 1, loss = 2.042712924582202
Train: epoch: 1, loss = 2.042476660992418
Train: epoch: 1, loss = 2.042389873945436
Train:  Epoch 1, Loss=2.042094354888371, Cohen Kappa=0.3857239071260944, MAD=0.7173320882820812
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0282151801832793, Cohen Kappa=0.43018636008177913, MAD=0.7250222122601511
Eval task: 2
Eval:  Epoch 1, Loss=1.9775526235843528, Cohen Kappa=0.003928199539541599, MAD=0.7391027177502272
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.052184248792714, Cohen Kappa=0.3425787429933568, MAD=0.7256551631248793
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.940541197513712, Cohen Kappa=0.005084306185187515, MAD=0.736952470123682
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.957275426387787
Train: epoch: 1, loss = 1.95961302369833
Train: epoch: 1, loss = 1.9560325413942337
Train: epoch: 1, loss = 1.9509770691394805
Train: epoch: 1, loss = 1.9485793486833571
Train: epoch: 1, loss = 1.948060319920381
Train: epoch: 1, loss = 1.9502492150238582
Train: epoch: 1, loss = 1.9502807512134313
Train: epoch: 1, loss = 1.9506773402955797
Train: epoch: 1, loss = 1.950729614675045
Train: epoch: 1, loss = 1.9506464199044489
Train: epoch: 1, loss = 1.9502886429429054
Train: epoch: 1, loss = 1.9495033074342287
Train: epoch: 1, loss = 1.9497964755977903
Train: epoch: 1, loss = 1.949681023200353
Train: epoch: 1, loss = 1.9488624975830318
Train: epoch: 1, loss = 1.9481211892646901
Train: epoch: 1, loss = 1.94890527503358
Train: epoch: 1, loss = 1.9483736636764124
Train: epoch: 1, loss = 1.9472992187440394
Train: epoch: 1, loss = 1.9469184151433763
Train: epoch: 1, loss = 1.94746834540909
Train: epoch: 1, loss = 1.9477203628809556
Train: epoch: 1, loss = 1.9480573834230503
Train: epoch: 1, loss = 1.9483072875499725
Train: epoch: 1, loss = 1.9487391816881987
Train: epoch: 1, loss = 1.9485382064845826
Train: epoch: 1, loss = 1.9486157064991338
Train: epoch: 1, loss = 1.94799131235172
Train: epoch: 1, loss = 1.9477833257714907
Train: epoch: 1, loss = 1.948127777172673
Train: epoch: 1, loss = 1.9479177911579608
Train: epoch: 1, loss = 1.9478371215047259
Train: epoch: 1, loss = 1.9483112215469864
Train: epoch: 1, loss = 1.948406299676214
Train: epoch: 1, loss = 1.948109958138731
Train: epoch: 1, loss = 1.9479294541719798
Train: epoch: 1, loss = 1.9480578728098619
Train: epoch: 1, loss = 1.9480649412289643
Train: epoch: 1, loss = 1.9485605191141366
Train: epoch: 1, loss = 1.948462564480014
Train: epoch: 1, loss = 1.9485283864963623
Train: epoch: 1, loss = 1.948458409683649
Train:  Epoch 1, Loss=1.9485857283183508, Cohen Kappa=0.08628686842601707, MAD=0.6883631010613056
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0620140207224877, Cohen Kappa=0.3445878509097775, MAD=0.7064722306519517
Eval task: 2
Eval:  Epoch 1, Loss=1.9547906990708976, Cohen Kappa=0.07341251419044048, MAD=0.672160296541113
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.068934699584698, Cohen Kappa=0.24356067374658485, MAD=0.7074516350616226
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9227057058235695, Cohen Kappa=0.0889554869664827, MAD=0.6750002695856102
{'0': {'precision': 0.4026128266033254, 'recall': 0.5823312883435583, 'f1-score': 0.4760758350887752, 'support': 4075}, '1': {'precision': 0.21597494126859829, 'recall': 0.481326352530541, 'f1-score': 0.2981621621621622, 'support': 2865}, '2': {'precision': 0.04, 'recall': 0.00055005500550055, 'f1-score': 0.0010851871947911015, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.21608643457382953, 'recall': 0.4440789473684211, 'f1-score': 0.29071332436069985, 'support': 1216}, '9': {'precision': 0.08888888888888889, 'recall': 0.003727865796831314, 'f1-score': 0.007155635062611806, 'support': 1073}, 'accuracy': 0.2893992456896552, 'macro avg': {'precision': 0.09635630913346421, 'recall': 0.15120145090448522, 'f1-score': 0.10731921438690403, 'support': 14848}, 'weighted avg': {'precision': 0.18118765876634155, 'recall': 0.2893992456896552, 'f1-score': 0.21264829551092923, 'support': 14848}}
{'0': {'precision': 0.44659471529586897, 'recall': 0.2836208934058142, 'f1-score': 0.3469210754553339, 'support': 4231}, '1': {'precision': 0.3362603305785124, 'recall': 0.776386404293381, 'f1-score': 0.4692737430167598, 'support': 5031}, '2': {'precision': 0.1358695652173913, 'recall': 0.020695364238410598, 'f1-score': 0.03591954022988506, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.06779661016949153, 'recall': 0.0392156862745098, 'f1-score': 0.049689440993788817, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.3480603448275862, 'macro avg': {'precision': 0.09865212212612642, 'recall': 0.11199183482121158, 'f1-score': 0.09018037996957676, 'support': 14848}, 'weighted avg': {'precision': 0.26470060586169175, 'recall': 0.3480603448275862, 'f1-score': 0.2647309974076197, 'support': 14848}}