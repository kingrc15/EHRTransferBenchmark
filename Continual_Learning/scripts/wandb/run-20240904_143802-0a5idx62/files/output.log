
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
midwest_val.csv
test_listfile.csv
midwest_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1865826231241225
Train: epoch: 1, loss = 2.1408646923303603
Train: epoch: 1, loss = 2.118557526866595
Train: epoch: 1, loss = 2.1006265397369863
Train: epoch: 1, loss = 2.0912210392951964
Train: epoch: 1, loss = 2.082880896727244
Train: epoch: 1, loss = 2.0769647544622423
Train: epoch: 1, loss = 2.075085089281201
Train: epoch: 1, loss = 2.070614181359609
Train: epoch: 1, loss = 2.0669470467567446
Train: epoch: 1, loss = 2.0654270083254036
Train: epoch: 1, loss = 2.064041970024506
Train: epoch: 1, loss = 2.0631226912370093
Train: epoch: 1, loss = 2.06120760508946
Train: epoch: 1, loss = 2.0600289939244587
Train: epoch: 1, loss = 2.0592770405113696
Train: epoch: 1, loss = 2.0571554787018718
Train: epoch: 1, loss = 2.0567140690485637
Train: epoch: 1, loss = 2.055088703255904
Train: epoch: 1, loss = 2.054222167491913
Train: epoch: 1, loss = 2.053737429550716
Train: epoch: 1, loss = 2.0536772098053584
Train: epoch: 1, loss = 2.052831588672555
Train: epoch: 1, loss = 2.052117526680231
Train: epoch: 1, loss = 2.0505496227264404
Train: epoch: 1, loss = 2.0496693459840922
Train: epoch: 1, loss = 2.0494287831253475
Train: epoch: 1, loss = 2.0492296267620156
Train: epoch: 1, loss = 2.048319610151751
Train: epoch: 1, loss = 2.047972751220067
Train: epoch: 1, loss = 2.0476689931461887
Train: epoch: 1, loss = 2.047658777516335
Train: epoch: 1, loss = 2.0469983990987144
Train: epoch: 1, loss = 2.046729686365408
Train: epoch: 1, loss = 2.0469553479978018
Train: epoch: 1, loss = 2.0458488064673213
Train: epoch: 1, loss = 2.045557342558294
Train: epoch: 1, loss = 2.045393510837304
Train: epoch: 1, loss = 2.0453872257471084
Train: epoch: 1, loss = 2.044922552809119
Train: epoch: 1, loss = 2.0443708914663734
Train: epoch: 1, loss = 2.0439286582242877
Train: epoch: 1, loss = 2.0432425668073253
Train:  Epoch 1, Loss=2.0427031315803528, Cohen Kappa=0.3864456788669133, MAD=0.718789458908414
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.030960637947609, Cohen Kappa=0.4298881533030289, MAD=0.7360731709741469
Eval task: 2
Eval:  Epoch 1, Loss=1.978082956938908, Cohen Kappa=0.020912130895727188, MAD=0.7499616503177247
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0526505030434707, Cohen Kappa=0.3424114544729363, MAD=0.7339531575844056
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.944075931762827, Cohen Kappa=0.005687549344302045, MAD=0.7490074291674617
midwest_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 2.003946964740753
Train: epoch: 1, loss = 2.0009704518318174
Train: epoch: 1, loss = 1.99773466527462
Train: epoch: 1, loss = 1.994494623094797
Train: epoch: 1, loss = 1.997466557621956
Train: epoch: 1, loss = 1.9963161014517148
Train: epoch: 1, loss = 1.995156078338623
Train: epoch: 1, loss = 1.9954108053445816
Train: epoch: 1, loss = 1.9948312895827822
Train: epoch: 1, loss = 1.9942563566565514
Train: epoch: 1, loss = 1.9941089895638553
Train: epoch: 1, loss = 1.9943338367839654
Train: epoch: 1, loss = 1.9938538370682644
Train: epoch: 1, loss = 1.993559162063258
Train: epoch: 1, loss = 1.9934747441212337
Train: epoch: 1, loss = 1.9930512971803547
Train: epoch: 1, loss = 1.9919634293107424
Train: epoch: 1, loss = 1.9912072122097015
Train: epoch: 1, loss = 1.9909088832767385
Train: epoch: 1, loss = 1.9905581826269627
Train: epoch: 1, loss = 1.9900801969993682
Train: epoch: 1, loss = 1.989465115016157
Train: epoch: 1, loss = 1.9891710729184358
Train: epoch: 1, loss = 1.9895331260313591
Train: epoch: 1, loss = 1.9891232867717743
Train: epoch: 1, loss = 1.9889724099177581
Train: epoch: 1, loss = 1.9893280250496335
Train: epoch: 1, loss = 1.9884678088767187
Train: epoch: 1, loss = 1.9891750404547002
Train: epoch: 1, loss = 1.989136143664519
Train: epoch: 1, loss = 1.9893002476999837
Train: epoch: 1, loss = 1.9891435840912164
Train: epoch: 1, loss = 1.989068876179782
Train: epoch: 1, loss = 1.9889932342311916
Train: epoch: 1, loss = 1.989132945912225
Train: epoch: 1, loss = 1.988792055282328
Train: epoch: 1, loss = 1.9887429791205637
Train: epoch: 1, loss = 1.9886803321775637
Train: epoch: 1, loss = 1.9885972992884806
Train: epoch: 1, loss = 1.9882279857099057
Train: epoch: 1, loss = 1.9883223863781951
Train: epoch: 1, loss = 1.9878731194564274
Train: epoch: 1, loss = 1.9876488174809965
Train:  Epoch 1, Loss=1.987568865626199, Cohen Kappa=0.04302346553252934, MAD=0.6911009368744467
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.031301128453222, Cohen Kappa=0.44112517492491465, MAD=0.7205749736973028
Eval task: 2
Eval:  Epoch 1, Loss=1.9782038927078247, Cohen Kappa=0.07758504213731376, MAD=0.6897699926021826
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0480742701168717, Cohen Kappa=0.3494851790457566, MAD=0.7058820881306158
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9225587351568814, Cohen Kappa=0.0821576161366443, MAD=0.6931795897548916
{'0': {'precision': 0.40241818898672627, 'recall': 0.7514110429447852, 'f1-score': 0.5241355700102704, 'support': 4075}, '1': {'precision': 0.2751074638530676, 'recall': 0.24572425828970332, 'f1-score': 0.25958702064896755, 'support': 2865}, '2': {'precision': 0.2346368715083799, 'recall': 0.0231023102310231, 'f1-score': 0.04206309464196294, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.1131198347107438, 'recall': 0.18009868421052633, 'f1-score': 0.13895939086294415, 'support': 1216}, '9': {'precision': 0.15555555555555556, 'recall': 0.3718546132339236, 'f1-score': 0.2193512919186366, 'support': 1073}, 'accuracy': 0.2980872844827586, 'macro avg': {'precision': 0.11808379146144729, 'recall': 0.15721909089099614, 'f1-score': 0.11840963680827817, 'support': 14848}, 'weighted avg': {'precision': 0.21276075340662437, 'recall': 0.2980872844827586, 'f1-score': 0.22631859668159146, 'support': 14848}}
{'0': {'precision': 0.34760705289672544, 'recall': 0.5544788466083668, 'f1-score': 0.4273224043715847, 'support': 4231}, '1': {'precision': 0.3317194451714211, 'recall': 0.5038759689922481, 'f1-score': 0.40006312633157104, 'support': 5031}, '2': {'precision': 0.1801470588235294, 'recall': 0.020281456953642384, 'f1-score': 0.036458333333333336, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.1092896174863388, 'recall': 0.06535947712418301, 'f1-score': 0.081799591002045, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.33337823275862066, 'macro avg': {'precision': 0.09687631743780148, 'recall': 0.11439957496784403, 'f1-score': 0.09456434550385341, 'support': 14848}, 'weighted avg': {'precision': 0.24301480916836826, 'recall': 0.33337823275862066, 'f1-score': 0.2649402404128683, 'support': 14848}}