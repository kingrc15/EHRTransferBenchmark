
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest_baseline
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.152618234753609
Train: epoch: 1, loss = 2.119150032401085
Train: epoch: 1, loss = 2.108179057240486
Train: epoch: 1, loss = 2.1010770367085936
Train: epoch: 1, loss = 2.0929541041851043
Train: epoch: 1, loss = 2.0864125701785086
Train: epoch: 1, loss = 2.087687959415572
Train: epoch: 1, loss = 2.0818805830180644
Train: epoch: 1, loss = 2.0790745331843694
Train: epoch: 1, loss = 2.07316242903471
Train: epoch: 1, loss = 2.0707191504131663
Train: epoch: 1, loss = 2.069705884158611
Train: epoch: 1, loss = 2.067145792108316
Train: epoch: 1, loss = 2.0651174318364687
Train: epoch: 1, loss = 2.063769134879112
Train: epoch: 1, loss = 2.0617637595906855
Train: epoch: 1, loss = 2.05948436701999
Train: epoch: 1, loss = 2.058722029891279
Train: epoch: 1, loss = 2.0573213627777602
Train: epoch: 1, loss = 2.0557488403320314
Train: epoch: 1, loss = 2.054560565920103
Train: epoch: 1, loss = 2.0533728210221636
Train: epoch: 1, loss = 2.0518850153166315
Train: epoch: 1, loss = 2.0509040186305842
Train: epoch: 1, loss = 2.0509331577301024
Train: epoch: 1, loss = 2.0507498355782947
Train: epoch: 1, loss = 2.0509443727246035
Train: epoch: 1, loss = 2.0508277867947307
Train: epoch: 1, loss = 2.050530031138453
Train: epoch: 1, loss = 2.050279596765836
Train: epoch: 1, loss = 2.0496634829236613
Train: epoch: 1, loss = 2.0488658168539406
Train: epoch: 1, loss = 2.0484097401481685
Train: epoch: 1, loss = 2.0481726960925495
Train: epoch: 1, loss = 2.047513727699007
Train: epoch: 1, loss = 2.0473421448965867
Train: epoch: 1, loss = 2.046950975189338
Train: epoch: 1, loss = 2.0464542044307055
Train: epoch: 1, loss = 2.0458354604244233
Train: epoch: 1, loss = 2.0458874009549617
Train: epoch: 1, loss = 2.0452884118004544
Train: epoch: 1, loss = 2.044963998453958
Train: epoch: 1, loss = 2.0443615435306417
Train:  Epoch 1, Loss=2.0437621455465043, Cohen Kappa=0.38459530261339614, MAD=0.719255884961232
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0287493755077493, Cohen Kappa=0.43288731582327933, MAD=0.7364302619046474
Eval task: 2
Eval:  Epoch 1, Loss=1.978475439137426, Cohen Kappa=0.004636607093486789, MAD=0.7478225931441127
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0557258478526412, Cohen Kappa=0.3394911804999158, MAD=0.732307801043536
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.942451838789315, Cohen Kappa=0.009305636041412213, MAD=0.7458845333955428
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9732474386692047
Train: epoch: 1, loss = 1.9747326835989951
Train: epoch: 1, loss = 1.9647642117738724
Train: epoch: 1, loss = 1.961388359218836
Train: epoch: 1, loss = 1.9561826584339141
Train: epoch: 1, loss = 1.9538900010784468
Train: epoch: 1, loss = 1.954680268423898
Train: epoch: 1, loss = 1.9521925563365221
Train: epoch: 1, loss = 1.9536065692371791
Train: epoch: 1, loss = 1.953440483212471
Train: epoch: 1, loss = 1.952949538339268
Train: epoch: 1, loss = 1.9515859007338683
Train: epoch: 1, loss = 1.9505248561730752
Train: epoch: 1, loss = 1.9508702605537005
Train: epoch: 1, loss = 1.9509659178654353
Train: epoch: 1, loss = 1.949865605533123
Train: epoch: 1, loss = 1.950039810923969
Train: epoch: 1, loss = 1.9497417972816362
Train: epoch: 1, loss = 1.9490496415527243
Train: epoch: 1, loss = 1.9488118950724602
Train: epoch: 1, loss = 1.9487948943887439
Train: epoch: 1, loss = 1.948706776093353
Train: epoch: 1, loss = 1.9485577296951542
Train: epoch: 1, loss = 1.9488634059329828
Train: epoch: 1, loss = 1.94884440472126
Train: epoch: 1, loss = 1.948418556360098
Train: epoch: 1, loss = 1.948099108559114
Train: epoch: 1, loss = 1.9484124063381127
Train: epoch: 1, loss = 1.948352723429943
Train: epoch: 1, loss = 1.9476337819894154
Train: epoch: 1, loss = 1.9477510617433056
Train: epoch: 1, loss = 1.948071833383292
Train: epoch: 1, loss = 1.9479725075309926
Train: epoch: 1, loss = 1.9479191857050446
Train: epoch: 1, loss = 1.9476107853991644
Train: epoch: 1, loss = 1.947727957053317
Train: epoch: 1, loss = 1.9475175190777392
Train: epoch: 1, loss = 1.9476902596417227
Train: epoch: 1, loss = 1.9475964147463822
Train: epoch: 1, loss = 1.9474848530590534
Train: epoch: 1, loss = 1.9473069884282788
Train: epoch: 1, loss = 1.947077902172293
Train: epoch: 1, loss = 1.9469793276592742
Train:  Epoch 1, Loss=1.9470291750907898, Cohen Kappa=0.09420086204245592, MAD=0.6855589752848434
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.15497272590111, Cohen Kappa=0.08070970619541484, MAD=0.7450796493851521
Eval task: 2
Eval:  Epoch 1, Loss=1.9526597364195462, Cohen Kappa=0.16097593367865137, MAD=0.7138325152692424
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.1032044682009468, Cohen Kappa=0.08646699279465375, MAD=0.7428661827036918
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9286120451729873, Cohen Kappa=0.1337539426287644, MAD=0.7159449063150372
{'0': {'precision': 0.3919448574131639, 'recall': 0.7116564417177914, 'f1-score': 0.5054906745685899, 'support': 4075}, '1': {'precision': 0.16088458880442294, 'recall': 0.406282722513089, 'f1-score': 0.23049504950495048, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.484375, 'recall': 0.07648026315789473, 'f1-score': 0.13210227272727273, 'support': 1216}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1073}, 'accuracy': 0.27997036637931033, 'macro avg': {'precision': 0.1037204446217587, 'recall': 0.11944194273887751, 'f1-score': 0.0868087996800813, 'support': 14848}, 'weighted avg': {'precision': 0.17828055232242151, 'recall': 0.27997036637931033, 'f1-score': 0.19402472921168173, 'support': 14848}}
{'0': {'precision': 0.39734261309712116, 'recall': 0.29685653509808557, 'f1-score': 0.3398268398268398, 'support': 4231}, '1': {'precision': 0.3467318152484558, 'recall': 0.7475650964023057, 'f1-score': 0.47373724650459764, 'support': 5031}, '2': {'precision': 0.24324324324324326, 'recall': 0.0074503311258278145, 'f1-score': 0.014457831325301205, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.1031331592689295, 'recall': 0.2581699346405229, 'f1-score': 0.14738805970149255, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.34442349137931033, 'macro avg': {'precision': 0.10904508308577496, 'recall': 0.13100418972667421, 'f1-score': 0.09754099773582312, 'support': 14848}, 'weighted avg': {'precision': 0.27241371100086675, 'recall': 0.34442349137931033, 'f1-score': 0.2627431514832014, 'support': 14848}}