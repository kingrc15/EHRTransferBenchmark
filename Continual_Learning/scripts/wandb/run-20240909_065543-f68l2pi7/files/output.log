
Experiment dir: ./exp/Test_los_midwest
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1714972454309462
Train: epoch: 1, loss = 2.1300603306293486
Train: epoch: 1, loss = 2.114562643766403
Train: epoch: 1, loss = 2.1009545522928237
Train: epoch: 1, loss = 2.0929111689329147
Train: epoch: 1, loss = 2.0860953384637835
Train: epoch: 1, loss = 2.0822019462926047
Train: epoch: 1, loss = 2.0775861645489933
Train: epoch: 1, loss = 2.0759777190287907
Train: epoch: 1, loss = 2.0738099929094314
Train: epoch: 1, loss = 2.071473189213059
Train: epoch: 1, loss = 2.067944781333208
Train: epoch: 1, loss = 2.065740292255695
Train: epoch: 1, loss = 2.062370533134256
Train: epoch: 1, loss = 2.0610573800007503
Train: epoch: 1, loss = 2.06073748473078
Train: epoch: 1, loss = 2.060124628508792
Train: epoch: 1, loss = 2.05884972880284
Train: epoch: 1, loss = 2.0588274296647624
Train: epoch: 1, loss = 2.0584995349645614
Train: epoch: 1, loss = 2.0578405935707544
Train: epoch: 1, loss = 2.0567668893120508
Train: epoch: 1, loss = 2.055157588383426
Train: epoch: 1, loss = 2.053890831694007
Train: epoch: 1, loss = 2.0522869139671327
Train: epoch: 1, loss = 2.051122502249021
Train: epoch: 1, loss = 2.0503381350967618
Train: epoch: 1, loss = 2.0489428557881286
Train: epoch: 1, loss = 2.047623809740461
Train: epoch: 1, loss = 2.047857615152995
Train: epoch: 1, loss = 2.047401244178895
Train: epoch: 1, loss = 2.0464655703492465
Train: epoch: 1, loss = 2.0469486367341245
Train: epoch: 1, loss = 2.0472251067967977
Train: epoch: 1, loss = 2.0462512833731514
Train: epoch: 1, loss = 2.0462705452243486
Train: epoch: 1, loss = 2.0460493993275874
Train: epoch: 1, loss = 2.0452984994649888
Train: epoch: 1, loss = 2.044984863003095
Train: epoch: 1, loss = 2.0447832958847285
Train: epoch: 1, loss = 2.045073901632937
Train: epoch: 1, loss = 2.0450190513332687
Train: epoch: 1, loss = 2.0449596424296845
Train:  Epoch 1, Loss=2.04503252053942, Cohen Kappa=0.3796724878967255, MAD=0.7218995942100153
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.029581797534022, Cohen Kappa=0.4204302335928026, MAD=0.7447253389015481
Eval task: 2
Eval:  Epoch 1, Loss=1.9826128195072044, Cohen Kappa=0.0021525222655675025, MAD=0.7555045179536466
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0545172794111846, Cohen Kappa=0.32519201274348497, MAD=0.7438698925096424
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9464749693870544, Cohen Kappa=0.003578346918672204, MAD=0.7538226040838256
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9540612322092057
Train: epoch: 1, loss = 1.9531983834505082
Train: epoch: 1, loss = 1.9558847584327061
Train: epoch: 1, loss = 1.95687846660614
Train: epoch: 1, loss = 1.9513083971738816
Train: epoch: 1, loss = 1.9525611133376757
Train: epoch: 1, loss = 1.9513374190671102
Train: epoch: 1, loss = 1.9495161250978708
Train: epoch: 1, loss = 1.9492325826485952
Train: epoch: 1, loss = 1.950402332186699
Train: epoch: 1, loss = 1.949401276328347
Train: epoch: 1, loss = 1.9484643981854122
Train: epoch: 1, loss = 1.9496587771177292
Train: epoch: 1, loss = 1.9496655688967024
Train: epoch: 1, loss = 1.9495993521610895
Train: epoch: 1, loss = 1.9494539570435883
Train: epoch: 1, loss = 1.9487045454978942
Train: epoch: 1, loss = 1.9492317342758179
Train: epoch: 1, loss = 1.9489092501527385
Train: epoch: 1, loss = 1.9492524899840356
Train: epoch: 1, loss = 1.9491373543512254
Train: epoch: 1, loss = 1.9490223052014004
Train: epoch: 1, loss = 1.9488671865411427
Train: epoch: 1, loss = 1.9488151492675145
Train: epoch: 1, loss = 1.9485416500568389
Train: epoch: 1, loss = 1.9486550120436228
Train: epoch: 1, loss = 1.9488074207747423
Train: epoch: 1, loss = 1.9489515628559249
Train: epoch: 1, loss = 1.9488590508699417
Train: epoch: 1, loss = 1.9488507407506308
Train: epoch: 1, loss = 1.948362375305545
Train: epoch: 1, loss = 1.948333428557962
Train: epoch: 1, loss = 1.9482023032506306
Train: epoch: 1, loss = 1.948047719790655
Train: epoch: 1, loss = 1.948050304361752
Train: epoch: 1, loss = 1.9482843412624464
Train: epoch: 1, loss = 1.9482588372359404
Train: epoch: 1, loss = 1.948162600194153
Train: epoch: 1, loss = 1.948162546601051
Train: epoch: 1, loss = 1.948463073387742
Train: epoch: 1, loss = 1.9484504796528235
Train: epoch: 1, loss = 1.9485222655108996
Train: epoch: 1, loss = 1.9481914561155231
Train:  Epoch 1, Loss=1.9481962745257786, Cohen Kappa=0.10071556794884129, MAD=0.6833449737256256
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.036914792554132, Cohen Kappa=0.4214414058803484, MAD=0.7249758625582301
Eval task: 2
Eval:  Epoch 1, Loss=1.9523981090249687, Cohen Kappa=0.12546776021480044, MAD=0.6788850296745937
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0606570552135337, Cohen Kappa=0.2865454664554904, MAD=0.7218290172677616
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9234518532095284, Cohen Kappa=0.13116940594054471, MAD=0.6841213212188537
{'0': {'precision': 0.43186616858859833, 'recall': 0.6525153374233129, 'f1-score': 0.519741985926505, 'support': 4075}, '1': {'precision': 0.2451848998459168, 'recall': 0.4443280977312391, 'f1-score': 0.31599851061189027, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.20066889632107024, 'recall': 0.049342105263157895, 'f1-score': 0.07920792079207921, 'support': 1216}, '9': {'precision': 0.12747252747252746, 'recall': 0.3783783783783784, 'f1-score': 0.19069985908877407, 'support': 1073}, 'accuracy': 0.29620150862068967, 'macro avg': {'precision': 0.10051924922281127, 'recall': 0.15245639187960883, 'f1-score': 0.11056482764192484, 'support': 14848}, 'weighted avg': {'precision': 0.19148038624471533, 'recall': 0.29620150862068967, 'f1-score': 0.2238834931330143, 'support': 14848}}
{'0': {'precision': 0.43093233551605864, 'recall': 0.32663672890569606, 'f1-score': 0.37160527023393386, 'support': 4231}, '1': {'precision': 0.3354003282874339, 'recall': 0.731067382230173, 'f1-score': 0.45983621929111707, 'support': 5031}, '2': {'precision': 0.3283582089552239, 'recall': 0.009105960264900662, 'f1-score': 0.017720499395892063, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.09868421052631579, 'recall': 0.19607843137254902, 'f1-score': 0.1312910284463895, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.34630926724137934, 'macro avg': {'precision': 0.1193375083285032, 'recall': 0.1262888502773319, 'f1-score': 0.09804530173673325, 'support': 14848}, 'weighted avg': {'precision': 0.2919035940489896, 'recall': 0.34630926724137934, 'f1-score': 0.26728756053734204, 'support': 14848}}