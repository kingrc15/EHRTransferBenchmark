
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_decomp_midwest_baseline
['/data/datasets/mimic3-benchmarks/data/decompensation', '/data/datasets/eICU2MIMIC/decompensation_split']
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 0.14760276042856277
Train: epoch: 1, loss = 0.11495179049437866
Train: epoch: 1, loss = 0.10342615326788897
Train: epoch: 1, loss = 0.10086969748546835
Train: epoch: 1, loss = 0.09430945402756333
Train: epoch: 1, loss = 0.09670538982725702
Train: epoch: 1, loss = 0.09605727303440549
Train: epoch: 1, loss = 0.09455420593469172
Train: epoch: 1, loss = 0.09231262125320629
Train: epoch: 1, loss = 0.09076411360036582
Train: epoch: 1, loss = 0.09024160819551484
Train: epoch: 1, loss = 0.08892916796020775
Train: epoch: 1, loss = 0.08868232230127503
Train: epoch: 1, loss = 0.08747817785624648
Train: epoch: 1, loss = 0.08642484265647363
Train: epoch: 1, loss = 0.08636128738380648
Train: epoch: 1, loss = 0.08556045121639995
Train: epoch: 1, loss = 0.08573514706115626
Train: epoch: 1, loss = 0.08517101059027482
Train: epoch: 1, loss = 0.08468423384163179
Train: epoch: 1, loss = 0.08411492133127814
Train: epoch: 1, loss = 0.08438816658234415
Train: epoch: 1, loss = 0.08342889060835738
Train: epoch: 1, loss = 0.08314740988457439
Train: epoch: 1, loss = 0.08339826384994667
Train: epoch: 1, loss = 0.08305005885524085
Train: epoch: 1, loss = 0.08262490845766109
Train: epoch: 1, loss = 0.08190647613928637
Train: epoch: 1, loss = 0.08206856271165729
Train: epoch: 1, loss = 0.08261961903052482
Train: epoch: 1, loss = 0.08197611786336863
Train: epoch: 1, loss = 0.08169327676851026
Train: epoch: 1, loss = 0.08147755541836942
Train: epoch: 1, loss = 0.08176234046166748
Train: epoch: 1, loss = 0.08188239533698652
Train: epoch: 1, loss = 0.08210261828859479
Train: epoch: 1, loss = 0.08197006597867978
Train: epoch: 1, loss = 0.08165252662222452
Train: epoch: 1, loss = 0.08159458615785788
Train: epoch: 1, loss = 0.08191517357637348
Train: epoch: 1, loss = 0.08235032042004338
Train: epoch: 1, loss = 0.08257273042905754
Train: epoch: 1, loss = 0.08267162122080092
Train:  Epoch 1, Loss=0.08282188719264896, AUC-ROC=0.8260978105122393, AUC-PR=0.15001553606503165
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.08572113102880018, AUC-ROC=0.8572521183573348, AUC-PR=0.2234305537838072
Eval task: 2
Eval:  Epoch 1, Loss=0.13051953738362626, AUC-ROC=0.6393027195742609, AUC-PR=0.050021024291094326
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.08585273275344536, AUC-ROC=0.879099023249122, AUC-PR=0.23093163594630586
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.12014961962042184, AUC-ROC=0.6245601466508125, AUC-PR=0.043576958390757224
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 0.13811164595419542
Train: epoch: 1, loss = 0.1270902228949126
Train: epoch: 1, loss = 0.11682182025086756
Train: epoch: 1, loss = 0.11329063900455366
Train: epoch: 1, loss = 0.11215370300086215
Train: epoch: 1, loss = 0.11351923205385295
Train: epoch: 1, loss = 0.11273090146116115
Train: epoch: 1, loss = 0.11248276152793552
Train: epoch: 1, loss = 0.11258092374514996
Train: epoch: 1, loss = 0.11632223738147877
Train: epoch: 1, loss = 0.11524033699078824
Train: epoch: 1, loss = 0.11459579315890248
Train: epoch: 1, loss = 0.11308690355589184
Train: epoch: 1, loss = 0.11251447533423613
Train: epoch: 1, loss = 0.11187270212483903
Train: epoch: 1, loss = 0.11202801042498323
Train: epoch: 1, loss = 0.11153193789096001
Train: epoch: 1, loss = 0.11217898278303134
Train: epoch: 1, loss = 0.11216794746523527
Train: epoch: 1, loss = 0.11168839775689413
Train: epoch: 1, loss = 0.11210793318171497
Train: epoch: 1, loss = 0.11302272963454016
Train: epoch: 1, loss = 0.11330998500232059
Train: epoch: 1, loss = 0.11298607851349515
Train: epoch: 1, loss = 0.11275195011906326
Train: epoch: 1, loss = 0.11250625401054724
Train: epoch: 1, loss = 0.112358197363059
Train: epoch: 1, loss = 0.11218276357610843
Train: epoch: 1, loss = 0.11180737322886827
Train: epoch: 1, loss = 0.11187672353178883
Train: epoch: 1, loss = 0.11142865596774724
Train: epoch: 1, loss = 0.11161136993679975
Train: epoch: 1, loss = 0.1117885107043284
Train: epoch: 1, loss = 0.11163884337279288
Train: epoch: 1, loss = 0.11175403793535328
Train: epoch: 1, loss = 0.11170997292256087
Train: epoch: 1, loss = 0.11215007567815986
Train: epoch: 1, loss = 0.11185615739380744
Train: epoch: 1, loss = 0.11177574711386114
Train: epoch: 1, loss = 0.11198433328536339
Train: epoch: 1, loss = 0.11181837608867393
Train: epoch: 1, loss = 0.11179589318488503
Train: epoch: 1, loss = 0.11133493654603181
Train:  Epoch 1, Loss=0.11111130219234952, AUC-ROC=0.6653381609794451, AUC-PR=0.08033931976299229
-------------
Eval task: 1
Eval:  Epoch 1, Loss=0.09824985040929811, AUC-ROC=0.7781374314441596, AUC-PR=0.12889468097361406
Eval task: 2
Eval:  Epoch 1, Loss=0.11088829693095438, AUC-ROC=0.6999093559695491, AUC-PR=0.10678998292436727
Ratio of skipped batches:  0.0
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=0.08724057385376816, AUC-ROC=0.8261523049295812, AUC-PR=0.23250952291459517
Ratio of skipped batches:  0.0
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=0.10245714490783625, AUC-ROC=0.7294860285374555, AUC-PR=0.10488809061103177