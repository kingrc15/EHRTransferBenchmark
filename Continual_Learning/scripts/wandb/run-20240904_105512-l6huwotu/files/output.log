
[34m[1mwandb[39m[22m: [33mWARNING[39m No relevant files were detected in the specified directory. No code will be logged to your run.
Experiment dir: ./exp/Test_los_midwest
['/data/datasets/mimic3-benchmarks/data/length-of-stay', '/data/datasets/eICU2MIMIC/length-of-stay_split']
val_listfile.csv
midwest_val.csv
test_listfile.csv
midwest_test.csv
train_listfile.csv
------------------------------------
Task: 1, Epoch: 1
Train: epoch: 1, loss = 2.1919619917869566
Train: epoch: 1, loss = 2.149374871253967
Train: epoch: 1, loss = 2.1281877621014913
Train: epoch: 1, loss = 2.1117682273685934
Train: epoch: 1, loss = 2.1008180774450302
Train: epoch: 1, loss = 2.090554863512516
Train: epoch: 1, loss = 2.0852692682402476
Train: epoch: 1, loss = 2.082116803005338
Train: epoch: 1, loss = 2.077464583582348
Train: epoch: 1, loss = 2.074006224811077
Train: epoch: 1, loss = 2.0710057390278034
Train: epoch: 1, loss = 2.0674440927803515
Train: epoch: 1, loss = 2.0655706760516535
Train: epoch: 1, loss = 2.0632582193613054
Train: epoch: 1, loss = 2.061178899963697
Train: epoch: 1, loss = 2.0603305979073046
Train: epoch: 1, loss = 2.0595623388360527
Train: epoch: 1, loss = 2.057308760782083
Train: epoch: 1, loss = 2.0568784186714573
Train: epoch: 1, loss = 2.055319312989712
Train: epoch: 1, loss = 2.053744272305852
Train: epoch: 1, loss = 2.0521572822874243
Train: epoch: 1, loss = 2.0511178162564403
Train: epoch: 1, loss = 2.050769414578875
Train: epoch: 1, loss = 2.0503983686208724
Train: epoch: 1, loss = 2.049514389840456
Train: epoch: 1, loss = 2.0490105227408586
Train: epoch: 1, loss = 2.04899063876697
Train: epoch: 1, loss = 2.0485272787151665
Train: epoch: 1, loss = 2.0473947766224545
Train: epoch: 1, loss = 2.046456043874064
Train: epoch: 1, loss = 2.0455225497111678
Train: epoch: 1, loss = 2.0455467535148966
Train: epoch: 1, loss = 2.044673059530118
Train: epoch: 1, loss = 2.044833138993808
Train: epoch: 1, loss = 2.0447041430241533
Train: epoch: 1, loss = 2.044925881495347
Train: epoch: 1, loss = 2.044624508493825
Train: epoch: 1, loss = 2.0450245934419145
Train: epoch: 1, loss = 2.045200755402446
Train: epoch: 1, loss = 2.044674143733048
Train: epoch: 1, loss = 2.0442751366041954
Train: epoch: 1, loss = 2.044115105825801
Train:  Epoch 1, Loss=2.0437494580950055, Cohen Kappa=0.3889981049210933, MAD=0.7175404833104134
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.0374720178801438, Cohen Kappa=0.3970464353808594, MAD=0.7251414524945266
Eval task: 2
Eval:  Epoch 1, Loss=1.9805077334930157, Cohen Kappa=-9.409386976688694e-06, MAD=0.7510321414097094
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.053012157308644, Cohen Kappa=0.31228635131071925, MAD=0.7267077212940395
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9436924395890072, Cohen Kappa=0.0008232695714522897, MAD=0.7491698282159003
midwest_train.csv
------------------------------------
Task: 2, Epoch: 1
Train: epoch: 1, loss = 1.9787292993068695
Train: epoch: 1, loss = 1.983023628294468
Train: epoch: 1, loss = 1.979971426129341
Train: epoch: 1, loss = 1.9831172950565814
Train: epoch: 1, loss = 1.9803728873729707
Train: epoch: 1, loss = 1.9782836774984995
Train: epoch: 1, loss = 1.9801682483298437
Train: epoch: 1, loss = 1.9797295936197044
Train: epoch: 1, loss = 1.9796502806080711
Train: epoch: 1, loss = 1.9796178822517394
Train: epoch: 1, loss = 1.97891691533002
Train: epoch: 1, loss = 1.9792583989103636
Train: epoch: 1, loss = 1.9785372035778486
Train: epoch: 1, loss = 1.9778561963779586
Train: epoch: 1, loss = 1.9779445431232452
Train: epoch: 1, loss = 1.9768016190081834
Train: epoch: 1, loss = 1.9758147491076414
Train: epoch: 1, loss = 1.9748654535081651
Train: epoch: 1, loss = 1.9742262440919875
Train: epoch: 1, loss = 1.9742862526476384
Train: epoch: 1, loss = 1.9742072447141013
Train: epoch: 1, loss = 1.974206081032753
Train: epoch: 1, loss = 1.9743862995634909
Train: epoch: 1, loss = 1.974212180202206
Train: epoch: 1, loss = 1.9738680339097976
Train: epoch: 1, loss = 1.973455073604217
Train: epoch: 1, loss = 1.9736727888054317
Train: epoch: 1, loss = 1.9731967786593096
Train: epoch: 1, loss = 1.9733574203787179
Train: epoch: 1, loss = 1.9734016385475794
Train: epoch: 1, loss = 1.9736121397633706
Train: epoch: 1, loss = 1.9729929747618735
Train: epoch: 1, loss = 1.9731546240864377
Train: epoch: 1, loss = 1.9729425998820977
Train: epoch: 1, loss = 1.9726492156130926
Train: epoch: 1, loss = 1.971978764583667
Train: epoch: 1, loss = 1.9712239948478905
Train: epoch: 1, loss = 1.9703912221601134
Train: epoch: 1, loss = 1.970001896314132
Train: epoch: 1, loss = 1.9694190827459097
Train: epoch: 1, loss = 1.9688434284780083
Train: epoch: 1, loss = 1.9682388478659447
Train: epoch: 1, loss = 1.9678684411353844
Train:  Epoch 1, Loss=1.9677280168669564, Cohen Kappa=0.07947890232109722, MAD=0.6934243414151803
-------------
Eval task: 1
Eval:  Epoch 1, Loss=2.038961881193621, Cohen Kappa=0.42362607045362677, MAD=0.733664118234578
Eval task: 2
Eval:  Epoch 1, Loss=1.9798589780412872, Cohen Kappa=0.14169369309590996, MAD=0.7066486704468357
-------------------------
Testing task: 1
-------------------------
Test:  Epoch 1, Loss=2.0512170709412674, Cohen Kappa=0.33373293278565874, MAD=0.7324021325564258
-------------------------
Testing task: 2
-------------------------
Test:  Epoch 1, Loss=1.9257206382422611, Cohen Kappa=0.12895358221823638, MAD=0.709165759526282
{'0': {'precision': 0.41655003498950316, 'recall': 0.5842944785276074, 'f1-score': 0.48636502910836493, 'support': 4075}, '1': {'precision': 0.2450698832088838, 'recall': 0.4467713787085515, 'f1-score': 0.31651829871414444, 'support': 2865}, '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1818}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1249}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 857}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 662}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 569}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 464}, '8': {'precision': 0.18778101031473154, 'recall': 0.5838815789473685, 'f1-score': 0.2841705023013808, 'support': 1216}, '9': {'precision': 0.125, 'recall': 0.014911463187325256, 'f1-score': 0.026644462947543714, 'support': 1073}, 'accuracy': 0.2954606681034483, 'macro avg': {'precision': 0.09744009285131186, 'recall': 0.16298588993708527, 'f1-score': 0.11136982930714338, 'support': 14848}, 'weighted avg': {'precision': 0.18602056280430973, 'recall': 0.2954606681034483, 'f1-score': 0.2197537216442487, 'support': 14848}}
{'0': {'precision': 0.36391179936037704, 'recall': 0.5109903096194753, 'f1-score': 0.4250884781753834, 'support': 4231}, '1': {'precision': 0.33313077297034516, 'recall': 0.5448221029616378, 'f1-score': 0.4134550116901727, 'support': 5031}, '2': {'precision': 0.1728395061728395, 'recall': 0.005794701986754967, 'f1-score': 0.011213456147376852, 'support': 2416}, '3': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1203}, '4': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 722}, '5': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 429}, '6': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 298}, '7': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 181}, '8': {'precision': 0.11204013377926421, 'recall': 0.21895424836601307, 'f1-score': 0.14823008849557523, 'support': 306}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 31}, 'accuracy': 0.33566810344827586, 'macro avg': {'precision': 0.0981922212282826, 'recall': 0.12805613629338813, 'f1-score': 0.09979870345085082, 'support': 14848}, 'weighted avg': {'precision': 0.24700675308173467, 'recall': 0.33566810344827586, 'f1-score': 0.26610261530879675, 'support': 14848}}